[
  {
    "text": "## Architecture Overview  The VLM Pipeline architecture centers around the `VlmPipeline` class which orchestrates different VLM model implementations to process document pages as images and generate structured output.",
    "metadata": {
      "chunk_id": "dfcde1419a06-0001",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Architecture Overview"
      ],
      "heading_text": "Architecture Overview",
      "token_count": 37,
      "char_count": 217,
      "start_char": 6670,
      "end_char": 6887,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5578571428571428,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.867175",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 37,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "Architecture Overview",
      "chunk_hash": "a5837608bf596f04",
      "content_digest": "a5837608bf596f04",
      "chunk_length": 217,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "architecture",
          "the",
          "vlm",
          "overview",
          "pipeline",
          "centers",
          "around",
          "vlmpipeline",
          "class",
          "which",
          "orchestrates",
          "different",
          "model",
          "implementations",
          "process",
          "document",
          "pages",
          "images",
          "and",
          "generate"
        ],
        "term_weights": [
          {
            "term": "architecture",
            "tf": 2,
            "weight": 0.08
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.08
          },
          {
            "term": "vlm",
            "tf": 2,
            "weight": 0.08
          },
          {
            "term": "overview",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "pipeline",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "centers",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "around",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "vlmpipeline",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "which",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "orchestrates",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "implementations",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "pages",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "images",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "generate",
            "tf": 1,
            "weight": 0.04
          }
        ],
        "unique_terms": 22,
        "total_terms": 25
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Architecture Overview",
        "architecture",
        "around",
        "centers",
        "class",
        "overview",
        "pipeline",
        "the",
        "vlm",
        "vlmpipeline",
        "which"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5578571428571428,
      "overall": 0.7526190476190475
    }
  },
  {
    "text": "### VLM Pipeline System Architecture ``` ``` Sources: [docling/pipeline/vlm\\_pipeline.py50-125](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L50-L125) [docling/datamodel/pipeline\\_options\\_vlm\\_model.py11-101](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options_vlm_model.py#L11-L101)",
    "metadata": {
      "chunk_id": "dfcde1419a06-0002",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "VLM Pipeline System Architecture"
      ],
      "heading_text": "VLM Pipeline System Architecture",
      "token_count": 104,
      "char_count": 369,
      "start_char": 6889,
      "end_char": 7258,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.56,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.867757",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 104,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "VLM Pipeline System Architecture",
      "chunk_hash": "eceba10703ede6d1",
      "content_digest": "eceba10703ede6d1",
      "chunk_length": 369,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "docling",
          "pipeline",
          "vlm",
          "https",
          "github",
          "com",
          "project",
          "blob",
          "f7244a43",
          "datamodel",
          "options",
          "model",
          "system",
          "architecture",
          "sources",
          "py50",
          "125",
          "l50",
          "l125",
          "py11"
        ],
        "term_weights": [
          {
            "term": "docling",
            "tf": 8,
            "weight": 0.163265
          },
          {
            "term": "pipeline",
            "tf": 7,
            "weight": 0.142857
          },
          {
            "term": "vlm",
            "tf": 5,
            "weight": 0.102041
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "project",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "f7244a43",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "datamodel",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "options",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "architecture",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "py50",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "125",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "l50",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "l125",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "py11",
            "tf": 1,
            "weight": 0.020408
          }
        ],
        "unique_terms": 23,
        "total_terms": 49
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "VLM Pipeline System Architecture",
        "blob",
        "com",
        "datamodel",
        "docling",
        "f7244a43",
        "github",
        "https",
        "pipeline",
        "project",
        "vlm"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.56,
      "overall": 0.6866666666666666
    }
  },
  {
    "text": "### VLM Model Class Hierarchy ``` ``` Sources: [docling/models/base\\_model.py40-120](https://github.com/docling-project/docling/blob/f7244a43/docling/models/base_model.py#L40-L120) [docling/models/vlm\\_models\\_inline/hf\\_transformers\\_model.py32](https://github.com/docling-project/docling/blob/f7244a43/docling/models/vlm_models_inline/hf_transformers_model.py#L32-L32) [docling/models/vlm\\_models\\_inline/mlx\\_model.py30](https://github.com/docling-project/docling/blob/f7244a43/docling/models/vlm_models_inline/mlx_model.py#L30-L30) [docling/models/api\\_vlm\\_model.py13](https://github.com/docling-project/docling/blob/f7244a43/docling/models/api_vlm_model.py#L13-L13)",
    "metadata": {
      "chunk_id": "dfcde1419a06-0003",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "VLM Model Class Hierarchy"
      ],
      "heading_text": "VLM Model Class Hierarchy",
      "token_count": 195,
      "char_count": 671,
      "start_char": 7262,
      "end_char": 7933,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.565,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.868460",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 195,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "VLM Model Class Hierarchy",
      "chunk_hash": "08e77dc3ae3b2ed4",
      "content_digest": "08e77dc3ae3b2ed4",
      "chunk_length": 671,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "docling",
          "models",
          "model",
          "vlm",
          "https",
          "github",
          "com",
          "project",
          "blob",
          "f7244a43",
          "inline",
          "base",
          "transformers",
          "l32",
          "mlx",
          "l30",
          "api",
          "l13",
          "class",
          "hierarchy"
        ],
        "term_weights": [
          {
            "term": "docling",
            "tf": 16,
            "weight": 0.166667
          },
          {
            "term": "models",
            "tf": 12,
            "weight": 0.125
          },
          {
            "term": "model",
            "tf": 9,
            "weight": 0.09375
          },
          {
            "term": "vlm",
            "tf": 7,
            "weight": 0.072917
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.041667
          },
          {
            "term": "github",
            "tf": 4,
            "weight": 0.041667
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.041667
          },
          {
            "term": "project",
            "tf": 4,
            "weight": 0.041667
          },
          {
            "term": "blob",
            "tf": 4,
            "weight": 0.041667
          },
          {
            "term": "f7244a43",
            "tf": 4,
            "weight": 0.041667
          },
          {
            "term": "inline",
            "tf": 4,
            "weight": 0.041667
          },
          {
            "term": "base",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "l32",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "mlx",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "l30",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "api",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "l13",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.010417
          },
          {
            "term": "hierarchy",
            "tf": 1,
            "weight": 0.010417
          }
        ],
        "unique_terms": 28,
        "total_terms": 96
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "VLM Model Class Hierarchy",
        "blob",
        "com",
        "docling",
        "f7244a43",
        "github",
        "https",
        "model",
        "models",
        "project",
        "vlm"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.565,
      "overall": 0.6883333333333334
    }
  },
  {
    "text": "## VLM Model Implementations\n\nThe VLM Pipeline supports multiple backend implementations for different use cases and hardware configurations.",
    "metadata": {
      "chunk_id": "dfcde1419a06-0004",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "VLM Model Implementations"
      ],
      "heading_text": "VLM Model Implementations",
      "token_count": 23,
      "char_count": 141,
      "start_char": 7937,
      "end_char": 8078,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.868758",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 23,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "VLM Model Implementations",
      "chunk_hash": "599d0289f2c66e35",
      "content_digest": "599d0289f2c66e35",
      "chunk_length": 141,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "vlm",
          "implementations",
          "model",
          "the",
          "pipeline",
          "supports",
          "multiple",
          "backend",
          "for",
          "different",
          "use",
          "cases",
          "and",
          "hardware",
          "configurations"
        ],
        "term_weights": [
          {
            "term": "vlm",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "implementations",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "pipeline",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "backend",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "cases",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "hardware",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "configurations",
            "tf": 1,
            "weight": 0.058824
          }
        ],
        "unique_terms": 15,
        "total_terms": 17
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "VLM Model Implementations",
        "backend",
        "different",
        "for",
        "implementations",
        "model",
        "multiple",
        "pipeline",
        "supports",
        "the",
        "vlm"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "overall": 0.7522222222222222
    }
  },
  {
    "text": "### HuggingFace Transformers Model  The `HuggingFaceTransformersVlmModel` provides local inference using the HuggingFace Transformers library with support for various model architectures. **Key Features:**  - Supports multiple `TransformersModelType`: `AUTOMODEL`, `AUTOMODEL_VISION2SEQ`, `AUTOMODEL_CAUSALLM`, `AUTOMODEL_IMAGETEXTTOTEXT` - Batch processing with proper padding and attention handling - Flash Attention 2 support for CUDA devices - Quantization support via `BitsAndBytesConfig` - Multiple prompt styles: `CHAT`, `RAW`, `NONE`  **Configuration Options:**  - `repo_id`: HuggingFace model repository identifier - `quantized`: Enable 8-bit quantization - `torch_dtype`: Specify torch data type - `stop_strings`: Custom stopping criteria - `max_new_tokens`: Maximum generation length  Sources: [docling/models/vlm\\_models\\_inline/hf\\_transformers\\_model.py32-315](https://github.com/docling-project/docling/blob/f7244a43/docling/models/vlm_models_inline/hf_transformers_model.py#L32-L315) [docling/datamodel/pipeline\\_options\\_vlm\\_model.py52-84](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options_vlm_model.py#L52-L84)",
    "metadata": {
      "chunk_id": "dfcde1419a06-0005",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "HuggingFace Transformers Model"
      ],
      "heading_text": "HuggingFace Transformers Model",
      "token_count": 294,
      "char_count": 1171,
      "start_char": 8080,
      "end_char": 9251,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5174725274725275,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.869280",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 294,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "HuggingFace Transformers Model",
      "chunk_hash": "ba95e5eec245ec6b",
      "content_digest": "ba95e5eec245ec6b",
      "chunk_length": 1171,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "docling",
          "model",
          "transformers",
          "automodel",
          "models",
          "vlm",
          "huggingface",
          "support",
          "options",
          "the",
          "with",
          "for",
          "multiple",
          "attention",
          "quantization",
          "torch",
          "inline",
          "https",
          "github",
          "com"
        ],
        "term_weights": [
          {
            "term": "docling",
            "tf": 8,
            "weight": 0.06015
          },
          {
            "term": "model",
            "tf": 7,
            "weight": 0.052632
          },
          {
            "term": "transformers",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "automodel",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "vlm",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "huggingface",
            "tf": 3,
            "weight": 0.022556
          },
          {
            "term": "support",
            "tf": 3,
            "weight": 0.022556
          },
          {
            "term": "options",
            "tf": 3,
            "weight": 0.022556
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "multiple",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "attention",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "quantization",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "torch",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "inline",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.015038
          }
        ],
        "unique_terms": 86,
        "total_terms": 133
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "HuggingFace Transformers Model",
        "automodel",
        "docling",
        "huggingface",
        "model",
        "models",
        "options",
        "support",
        "the",
        "transformers",
        "vlm"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5174725274725275,
      "overall": 0.7391575091575091
    }
  },
  {
    "text": "### MLX Model Implementation  The `HuggingFaceMlxModel` provides optimized inference for Apple Silicon using the MLX framework. **Key Features:**  - Thread-safe with global locking mechanism (`_MLX_GLOBAL_LOCK`) - Stream generation with token-level processing - Optimized for Apple Silicon hardware - Support for stop string termination - Token-level logprob tracking  **Thread Safety:** ``` ``` Sources: [docling/models/vlm\\_models\\_inline/mlx\\_model.py25-261](https://github.com/docling-project/docling/blob/f7244a43/docling/models/vlm_models_inline/mlx_model.py#L25-L261)",
    "metadata": {
      "chunk_id": "dfcde1419a06-0006",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "MLX Model Implementation"
      ],
      "heading_text": "MLX Model Implementation",
      "token_count": 132,
      "char_count": 574,
      "start_char": 9254,
      "end_char": 9828,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5107547169811321,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.870904",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 132,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "MLX Model Implementation",
      "chunk_hash": "3300c21d9f4fffc0",
      "content_digest": "3300c21d9f4fffc0",
      "chunk_length": 574,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "mlx",
          "docling",
          "models",
          "model",
          "for",
          "the",
          "optimized",
          "apple",
          "silicon",
          "thread",
          "with",
          "global",
          "token",
          "level",
          "vlm",
          "inline",
          "implementation",
          "huggingfacemlxmodel",
          "provides",
          "inference"
        ],
        "term_weights": [
          {
            "term": "mlx",
            "tf": 5,
            "weight": 0.066667
          },
          {
            "term": "docling",
            "tf": 4,
            "weight": 0.053333
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.053333
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.04
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.04
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "optimized",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "apple",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "silicon",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "thread",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "global",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "token",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "level",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "vlm",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "inline",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "huggingfacemlxmodel",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.013333
          }
        ],
        "unique_terms": 50,
        "total_terms": 75
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "MLX Model Implementation",
        "apple",
        "docling",
        "for",
        "mlx",
        "model",
        "models",
        "optimized",
        "silicon",
        "the",
        "thread"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5107547169811321,
      "overall": 0.7035849056603772
    }
  },
  {
    "text": "### API-Based VLM Model  The `ApiVlmModel` enables integration with remote VLM services through standardized chat completion APIs. **Key Features:**  - Concurrent processing with `ThreadPoolExecutor` - Configurable timeout and concurrency limits - Custom headers and parameters support - Compatible with OpenAI-style chat completion APIs  **Configuration Example:**  - `url`: API endpoint (default: `http://localhost:11434/v1/chat/completions`) - `params`: API-specific parameters (model, temperature, etc.) - `headers`: Authentication and custom headers - `concurrency`: Maximum concurrent requests  Sources: [docling/models/api\\_vlm\\_model.py13-73](https://github.com/docling-project/docling/blob/f7244a43/docling/models/api_vlm_model.py#L13-L73) [docling/datamodel/pipeline\\_options\\_vlm\\_model.py90-101](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options_vlm_model.py#L90-L101)",
    "metadata": {
      "chunk_id": "dfcde1419a06-0007",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "API-Based VLM Model"
      ],
      "heading_text": "API-Based VLM Model",
      "token_count": 219,
      "char_count": 922,
      "start_char": 9833,
      "end_char": 10755,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.715,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.871482",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 219,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "API-Based VLM Model",
      "chunk_hash": "68cdf9be2d470b33",
      "content_digest": "68cdf9be2d470b33",
      "chunk_length": 922,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "docling",
          "vlm",
          "model",
          "api",
          "with",
          "chat",
          "and",
          "headers",
          "completion",
          "apis",
          "concurrent",
          "concurrency",
          "custom",
          "parameters",
          "models",
          "https",
          "github",
          "com",
          "project",
          "blob"
        ],
        "term_weights": [
          {
            "term": "docling",
            "tf": 8,
            "weight": 0.070796
          },
          {
            "term": "vlm",
            "tf": 6,
            "weight": 0.053097
          },
          {
            "term": "model",
            "tf": 6,
            "weight": 0.053097
          },
          {
            "term": "api",
            "tf": 5,
            "weight": 0.044248
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.026549
          },
          {
            "term": "chat",
            "tf": 3,
            "weight": 0.026549
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.026549
          },
          {
            "term": "headers",
            "tf": 3,
            "weight": 0.026549
          },
          {
            "term": "completion",
            "tf": 2,
            "weight": 0.017699
          },
          {
            "term": "apis",
            "tf": 2,
            "weight": 0.017699
          },
          {
            "term": "concurrent",
            "tf": 2,
            "weight": 0.017699
          },
          {
            "term": "concurrency",
            "tf": 2,
            "weight": 0.017699
          },
          {
            "term": "custom",
            "tf": 2,
            "weight": 0.017699
          },
          {
            "term": "parameters",
            "tf": 2,
            "weight": 0.017699
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.017699
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.017699
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.017699
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.017699
          },
          {
            "term": "project",
            "tf": 2,
            "weight": 0.017699
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.017699
          }
        ],
        "unique_terms": 68,
        "total_terms": 113
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "API-Based VLM Model",
        "and",
        "api",
        "apis",
        "chat",
        "completion",
        "docling",
        "headers",
        "model",
        "vlm",
        "with"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.715,
      "overall": 0.7716666666666666
    }
  },
  {
    "text": "## Response Formats and Processing\n\nThe VLM Pipeline supports multiple response formats, each processed differently to generate the final `DoclingDocument`.",
    "metadata": {
      "chunk_id": "dfcde1419a06-0008",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Response Formats and Processing"
      ],
      "heading_text": "Response Formats and Processing",
      "token_count": 27,
      "char_count": 156,
      "start_char": 10758,
      "end_char": 10914,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.56,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.871799",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 27,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "Response Formats and Processing",
      "chunk_hash": "f7d5167c2e8ceb21",
      "content_digest": "f7d5167c2e8ceb21",
      "chunk_length": 156,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "response",
          "formats",
          "the",
          "and",
          "processing",
          "vlm",
          "pipeline",
          "supports",
          "multiple",
          "each",
          "processed",
          "differently",
          "generate",
          "final",
          "doclingdocument"
        ],
        "term_weights": [
          {
            "term": "response",
            "tf": 2,
            "weight": 0.111111
          },
          {
            "term": "formats",
            "tf": 2,
            "weight": 0.111111
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.111111
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "vlm",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "pipeline",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "each",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "processed",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "differently",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "generate",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "final",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "doclingdocument",
            "tf": 1,
            "weight": 0.055556
          }
        ],
        "unique_terms": 15,
        "total_terms": 18
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Response Formats and Processing",
        "and",
        "each",
        "formats",
        "multiple",
        "pipeline",
        "processing",
        "response",
        "supports",
        "the",
        "vlm"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.56,
      "overall": 0.7533333333333333
    }
  },
  {
    "text": "### Response Format Processing Flow ``` ``` Sources: [docling/pipeline/vlm\\_pipeline.py148-392](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L148-L392)",
    "metadata": {
      "chunk_id": "dfcde1419a06-0009",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Response Format Processing Flow"
      ],
      "heading_text": "Response Format Processing Flow",
      "token_count": 52,
      "char_count": 196,
      "start_char": 10916,
      "end_char": 11112,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.872407",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 52,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "Response Format Processing Flow",
      "chunk_hash": "e69630e9b9033617",
      "content_digest": "e69630e9b9033617",
      "chunk_length": 196,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "docling",
          "pipeline",
          "vlm",
          "response",
          "format",
          "processing",
          "flow",
          "sources",
          "py148",
          "392",
          "https",
          "github",
          "com",
          "project",
          "blob",
          "f7244a43",
          "l148",
          "l392"
        ],
        "term_weights": [
          {
            "term": "docling",
            "tf": 4,
            "weight": 0.16
          },
          {
            "term": "pipeline",
            "tf": 4,
            "weight": 0.16
          },
          {
            "term": "vlm",
            "tf": 2,
            "weight": 0.08
          },
          {
            "term": "response",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "format",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "flow",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "py148",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "392",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "github",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "com",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "project",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "blob",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "f7244a43",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "l148",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "l392",
            "tf": 1,
            "weight": 0.04
          }
        ],
        "unique_terms": 18,
        "total_terms": 25
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "392",
        "Response Format Processing Flow",
        "docling",
        "flow",
        "format",
        "pipeline",
        "processing",
        "py148",
        "response",
        "sources",
        "vlm"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "overall": 0.6855555555555556
    }
  },
  {
    "text": "### DocTags Format Processing  DocTags format provides the most structured output with precise bounding box information and element classification. **Key Features:**  - Direct conversion to `DoclingDocument` via `DocTagsDocument.from_doctags_and_image_pairs()` - Preserves spatial relationships and element types - Optional backend text extraction with `force_backend_text` - Support for picture image generation  **Backend Text Extraction:** When `force_backend_text=True` and `response_format=ResponseFormat.DOCTAGS`, the pipeline extracts actual text from the PDF backend using predicted bounding boxes instead of relying on VLM-generated text. Sources: [docling/pipeline/vlm\\_pipeline.py200-238](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L200-L238)",
    "metadata": {
      "chunk_id": "dfcde1419a06-0010",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "DocTags Format Processing"
      ],
      "heading_text": "DocTags Format Processing",
      "token_count": 167,
      "char_count": 800,
      "start_char": 11116,
      "end_char": 11916,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5307894736842105,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.873216",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 167,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "DocTags Format Processing",
      "chunk_hash": "a08b6975c467bbd1",
      "content_digest": "a08b6975c467bbd1",
      "chunk_length": 800,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "text",
          "backend",
          "pipeline",
          "doctags",
          "and",
          "docling",
          "format",
          "the",
          "vlm",
          "with",
          "bounding",
          "element",
          "from",
          "image",
          "extraction",
          "force",
          "processing",
          "provides",
          "most",
          "structured"
        ],
        "term_weights": [
          {
            "term": "text",
            "tf": 6,
            "weight": 0.059406
          },
          {
            "term": "backend",
            "tf": 5,
            "weight": 0.049505
          },
          {
            "term": "pipeline",
            "tf": 5,
            "weight": 0.049505
          },
          {
            "term": "doctags",
            "tf": 4,
            "weight": 0.039604
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.039604
          },
          {
            "term": "docling",
            "tf": 4,
            "weight": 0.039604
          },
          {
            "term": "format",
            "tf": 3,
            "weight": 0.029703
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.029703
          },
          {
            "term": "vlm",
            "tf": 3,
            "weight": 0.029703
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.019802
          },
          {
            "term": "bounding",
            "tf": 2,
            "weight": 0.019802
          },
          {
            "term": "element",
            "tf": 2,
            "weight": 0.019802
          },
          {
            "term": "from",
            "tf": 2,
            "weight": 0.019802
          },
          {
            "term": "image",
            "tf": 2,
            "weight": 0.019802
          },
          {
            "term": "extraction",
            "tf": 2,
            "weight": 0.019802
          },
          {
            "term": "force",
            "tf": 2,
            "weight": 0.019802
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.009901
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.009901
          },
          {
            "term": "most",
            "tf": 1,
            "weight": 0.009901
          },
          {
            "term": "structured",
            "tf": 1,
            "weight": 0.009901
          }
        ],
        "unique_terms": 66,
        "total_terms": 101
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "DocTags Format Processing",
        "and",
        "backend",
        "docling",
        "doctags",
        "format",
        "pipeline",
        "text",
        "the",
        "vlm",
        "with"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5307894736842105,
      "overall": 0.7102631578947367
    }
  },
  {
    "text": "### Markdown and HTML Processing\n\nBoth Markdown and HTML formats follow similar processing patterns, using respective document backends for conversion.\n\n**Processing Steps:**\n\n1. Extract content from code blocks (triple backticks)\n2. Create temporary `BytesIO` stream with extracted content\n3. Use `MarkdownDocumentBackend` or `HTMLDocumentBackend` for conversion\n4. Generate page structure with image dimensions\n5. Add provenance information with placeholder bounding boxes\n\nSources: [docling/pipeline/vlm\\_pipeline.py240-392](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L240-L392)",
    "metadata": {
      "chunk_id": "dfcde1419a06-0011",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Markdown and HTML Processing"
      ],
      "heading_text": "Markdown and HTML Processing",
      "token_count": 137,
      "char_count": 628,
      "start_char": 11920,
      "end_char": 12548,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7512903225806452,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.875303",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 137,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "Markdown and HTML Processing",
      "chunk_hash": "1146d3f9f016b056",
      "content_digest": "1146d3f9f016b056",
      "chunk_length": 628,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "docling",
          "pipeline",
          "processing",
          "with",
          "markdown",
          "and",
          "html",
          "for",
          "conversion",
          "content",
          "vlm",
          "both",
          "formats",
          "follow",
          "similar",
          "patterns",
          "using",
          "respective",
          "document",
          "backends"
        ],
        "term_weights": [
          {
            "term": "docling",
            "tf": 4,
            "weight": 0.054054
          },
          {
            "term": "pipeline",
            "tf": 4,
            "weight": 0.054054
          },
          {
            "term": "processing",
            "tf": 3,
            "weight": 0.040541
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.040541
          },
          {
            "term": "markdown",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "html",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "conversion",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "content",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "vlm",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "both",
            "tf": 1,
            "weight": 0.013514
          },
          {
            "term": "formats",
            "tf": 1,
            "weight": 0.013514
          },
          {
            "term": "follow",
            "tf": 1,
            "weight": 0.013514
          },
          {
            "term": "similar",
            "tf": 1,
            "weight": 0.013514
          },
          {
            "term": "patterns",
            "tf": 1,
            "weight": 0.013514
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.013514
          },
          {
            "term": "respective",
            "tf": 1,
            "weight": 0.013514
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.013514
          },
          {
            "term": "backends",
            "tf": 1,
            "weight": 0.013514
          }
        ],
        "unique_terms": 57,
        "total_terms": 74
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Markdown and HTML Processing",
        "and",
        "content",
        "conversion",
        "docling",
        "for",
        "html",
        "markdown",
        "pipeline",
        "processing",
        "with"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7512903225806452,
      "overall": 0.7504301075268817
    }
  },
  {
    "text": "## Pipeline Configuration\n\nThe VLM Pipeline uses `VlmPipelineOptions` for configuration, which includes VLM-specific options and general pipeline settings.",
    "metadata": {
      "chunk_id": "dfcde1419a06-0012",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Pipeline Configuration"
      ],
      "heading_text": "Pipeline Configuration",
      "token_count": 29,
      "char_count": 155,
      "start_char": 12550,
      "end_char": 12705,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.875899",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 29,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "Pipeline Configuration",
      "chunk_hash": "980a84002c4f46b2",
      "content_digest": "980a84002c4f46b2",
      "chunk_length": 155,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "pipeline",
          "configuration",
          "vlm",
          "the",
          "uses",
          "vlmpipelineoptions",
          "for",
          "which",
          "includes",
          "specific",
          "options",
          "and",
          "general",
          "settings"
        ],
        "term_weights": [
          {
            "term": "pipeline",
            "tf": 3,
            "weight": 0.166667
          },
          {
            "term": "configuration",
            "tf": 2,
            "weight": 0.111111
          },
          {
            "term": "vlm",
            "tf": 2,
            "weight": 0.111111
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "uses",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "vlmpipelineoptions",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "which",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "includes",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "specific",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "options",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "general",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "settings",
            "tf": 1,
            "weight": 0.055556
          }
        ],
        "unique_terms": 14,
        "total_terms": 18
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Pipeline Configuration",
        "configuration",
        "for",
        "includes",
        "pipeline",
        "specific",
        "the",
        "uses",
        "vlm",
        "vlmpipelineoptions",
        "which"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "overall": 0.7522222222222222
    }
  },
  {
    "text": "### Configuration Class Hierarchy ``` ``` Sources: [docling/datamodel/pipeline\\_options.py](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options.py) [docling/datamodel/pipeline\\_options\\_vlm\\_model.py11-101](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options_vlm_model.py#L11-L101)",
    "metadata": {
      "chunk_id": "dfcde1419a06-0013",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Configuration Class Hierarchy"
      ],
      "heading_text": "Configuration Class Hierarchy",
      "token_count": 95,
      "char_count": 361,
      "start_char": 12707,
      "end_char": 13068,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.877016",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 95,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "Configuration Class Hierarchy",
      "chunk_hash": "a3031017628f92f5",
      "content_digest": "a3031017628f92f5",
      "chunk_length": 361,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "docling",
          "datamodel",
          "pipeline",
          "options",
          "https",
          "github",
          "com",
          "project",
          "blob",
          "f7244a43",
          "vlm",
          "model",
          "configuration",
          "class",
          "hierarchy",
          "sources",
          "py11",
          "101",
          "l11",
          "l101"
        ],
        "term_weights": [
          {
            "term": "docling",
            "tf": 8,
            "weight": 0.181818
          },
          {
            "term": "datamodel",
            "tf": 4,
            "weight": 0.090909
          },
          {
            "term": "pipeline",
            "tf": 4,
            "weight": 0.090909
          },
          {
            "term": "options",
            "tf": 4,
            "weight": 0.090909
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "project",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "f7244a43",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "vlm",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "configuration",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "hierarchy",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "py11",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "101",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "l11",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "l101",
            "tf": 1,
            "weight": 0.022727
          }
        ],
        "unique_terms": 20,
        "total_terms": 44
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Configuration Class Hierarchy",
        "blob",
        "com",
        "datamodel",
        "docling",
        "f7244a43",
        "github",
        "https",
        "options",
        "pipeline",
        "project"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "overall": 0.6855555555555556
    }
  },
  {
    "text": "### Page Initialization Process  The `initialize_page()` method prepares pages for VLM processing:  1. **Backend Loading**: Load page backend via `conv_res.input._backend.load_page(page.page_no)` 2. **Size Calculation**: Set `page.size` from backend dimensions 3. **Conditional Text Extraction**: If `force_backend_text=True`, extract `parsed_page` for prompt construction  **Backend Text Extraction Logic:** ``` ``` Sources: [docling/pipeline/vlm\\_pipeline.py126-135](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L126-L135)",
    "metadata": {
      "chunk_id": "dfcde1419a06-0017",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Page Initialization Process"
      ],
      "heading_text": "Page Initialization Process",
      "token_count": 134,
      "char_count": 569,
      "start_char": 14495,
      "end_char": 15064,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5517021276595745,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.880136",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 134,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "Page Initialization Process",
      "chunk_hash": "df9fd5c10a1ee688",
      "content_digest": "df9fd5c10a1ee688",
      "chunk_length": 569,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "page",
          "backend",
          "docling",
          "pipeline",
          "vlm",
          "text",
          "for",
          "load",
          "size",
          "extraction",
          "initialization",
          "process",
          "the",
          "initialize",
          "method",
          "prepares",
          "pages",
          "processing",
          "loading",
          "via"
        ],
        "term_weights": [
          {
            "term": "page",
            "tf": 8,
            "weight": 0.111111
          },
          {
            "term": "backend",
            "tf": 6,
            "weight": 0.083333
          },
          {
            "term": "docling",
            "tf": 4,
            "weight": 0.055556
          },
          {
            "term": "pipeline",
            "tf": 4,
            "weight": 0.055556
          },
          {
            "term": "vlm",
            "tf": 3,
            "weight": 0.041667
          },
          {
            "term": "text",
            "tf": 3,
            "weight": 0.041667
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "load",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "size",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "extraction",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "initialization",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "initialize",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "method",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "prepares",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "pages",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "loading",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "via",
            "tf": 1,
            "weight": 0.013889
          }
        ],
        "unique_terms": 46,
        "total_terms": 72
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Page Initialization Process",
        "backend",
        "docling",
        "extraction",
        "for",
        "load",
        "page",
        "pipeline",
        "size",
        "text",
        "vlm"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5517021276595745,
      "overall": 0.6839007092198582
    }
  },
  {
    "text": "### Backend Compatibility  The VLM Pipeline supports specific backend types through the `is_backend_supported()` method: ``` ``` Currently, only `PdfDocumentBackend` instances are supported, limiting VLM processing to PDF documents. Sources: [docling/pipeline/vlm\\_pipeline.py398-400](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L398-L400)  Dismiss  Refresh this wiki  This wiki was recently refreshed. Please wait 4 days to refresh again.",
    "metadata": {
      "chunk_id": "dfcde1419a06-0020",
      "source_file": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Backend Compatibility"
      ],
      "heading_text": "Backend Compatibility",
      "token_count": 111,
      "char_count": 485,
      "start_char": 15571,
      "end_char": 16056,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5378260869565217,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:06.882123",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 111,
      "document_id": "dfcde1419a06",
      "document_name": "_docling-project_docling_5.3-vlm-pipeline",
      "source_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "source_filename": "_docling-project_docling_5.3-vlm-pipeline.md",
      "source_directory": "Docs\\Docling",
      "relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "hierarchy_path": "Backend Compatibility",
      "chunk_hash": "e085726e5ffa6576",
      "content_digest": "e085726e5ffa6576",
      "chunk_length": 485,
      "payload_version": "1.3",
      "collection_hints": [
        "docling"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "pipeline",
          "vlm",
          "docling",
          "backend",
          "the",
          "supported",
          "refresh",
          "this",
          "wiki",
          "compatibility",
          "supports",
          "specific",
          "types",
          "through",
          "method",
          "currently",
          "only",
          "pdfdocumentbackend",
          "instances",
          "are"
        ],
        "term_weights": [
          {
            "term": "pipeline",
            "tf": 5,
            "weight": 0.083333
          },
          {
            "term": "vlm",
            "tf": 4,
            "weight": 0.066667
          },
          {
            "term": "docling",
            "tf": 4,
            "weight": 0.066667
          },
          {
            "term": "backend",
            "tf": 3,
            "weight": 0.05
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "supported",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "refresh",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "this",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "wiki",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "compatibility",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "specific",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "types",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "method",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "currently",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "only",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "pdfdocumentbackend",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "instances",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.016667
          }
        ],
        "unique_terms": 43,
        "total_terms": 60
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Backend Compatibility",
        "backend",
        "compatibility",
        "docling",
        "pipeline",
        "refresh",
        "supported",
        "the",
        "this",
        "vlm",
        "wiki"
      ],
      "collection_name": "Docling"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5378260869565217,
      "overall": 0.7126086956521739
    }
  }
]
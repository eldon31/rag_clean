[
  {
    "text": "# Image Data Applications  Relevant source files  - [ecommerce\\_reverse\\_image\\_search/ecommerce-reverse-image-search.ipynb](https://github.com/qdrant/examples/blob/b3c4b28f/ecommerce_reverse_image_search/ecommerce-reverse-image-search.ipynb) - [ecommerce\\_reverse\\_image\\_search/queries/cable.jpg](https://github.com/qdrant/examples/blob/b3c4b28f/ecommerce_reverse_image_search/queries/cable.jpg) - [ecommerce\\_reverse\\_image\\_search/queries/cleaning.jpg](https://github.com/qdrant/examples/blob/b3c4b28f/ecommerce_reverse_image_search/queries/cleaning.jpg) - [ecommerce\\_reverse\\_image\\_search/queries/skating.jpg](https://github.com/qdrant/examples/blob/b3c4b28f/ecommerce_reverse_image_search/queries/skating.jpg) - [ecommerce\\_reverse\\_image\\_search/queries/spoon.jpg](https://github.com/qdrant/examples/blob/b3c4b28f/ecommerce_reverse_image_search/queries/spoon.jpg) - [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb) - [qdrant\\_101\\_image\\_data/README.md](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md)  This document covers image-based applications using Qdrant vector database for visual similarity search and retrieval. The content focuses on two primary implementations: e-commerce reverse image search and medical image analysis systems. These applications demonstrate how to extract visual embeddings from images and perform semantic search operations. For text-based search applications, see [Text Data Applications](qdrant/examples/3-text-data-applications.md). For audio processing systems, see [Audio Data Applications](qdrant/examples/5-audio-data-applications.md).",
    "metadata": {
      "chunk_id": "408f0653b41c-0000",
      "source_file": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "filename": "_qdrant_examples_4-image-data-applications.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Image Data Applications"
      ],
      "heading_text": "Image Data Applications",
      "token_count": 446,
      "char_count": 1717,
      "start_char": 2074,
      "end_char": 3791,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7578963855421685,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:39.184250",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 446,
      "document_id": "408f0653b41c",
      "document_name": "_qdrant_examples_4-image-data-applications",
      "source_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "source_filename": "_qdrant_examples_4-image-data-applications.md",
      "source_directory": "Docs\\Qdrant\\qdrant_examples",
      "relative_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "hierarchy_path": "Image Data Applications",
      "chunk_hash": "8a2a89c1d91d111b",
      "content_digest": "8a2a89c1d91d111b",
      "chunk_length": 1717,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "image",
          "search",
          "qdrant",
          "reverse",
          "ecommerce",
          "data",
          "examples",
          "applications",
          "queries",
          "jpg",
          "https",
          "github",
          "com",
          "blob",
          "b3c4b28f",
          "101",
          "ipynb",
          "for",
          "and",
          "text"
        ],
        "term_weights": [
          {
            "term": "image",
            "tf": 20,
            "weight": 0.088889
          },
          {
            "term": "search",
            "tf": 16,
            "weight": 0.071111
          },
          {
            "term": "qdrant",
            "tf": 16,
            "weight": 0.071111
          },
          {
            "term": "reverse",
            "tf": 13,
            "weight": 0.057778
          },
          {
            "term": "ecommerce",
            "tf": 12,
            "weight": 0.053333
          },
          {
            "term": "data",
            "tf": 9,
            "weight": 0.04
          },
          {
            "term": "examples",
            "tf": 9,
            "weight": 0.04
          },
          {
            "term": "applications",
            "tf": 8,
            "weight": 0.035556
          },
          {
            "term": "queries",
            "tf": 8,
            "weight": 0.035556
          },
          {
            "term": "jpg",
            "tf": 8,
            "weight": 0.035556
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.031111
          },
          {
            "term": "github",
            "tf": 7,
            "weight": 0.031111
          },
          {
            "term": "com",
            "tf": 7,
            "weight": 0.031111
          },
          {
            "term": "blob",
            "tf": 7,
            "weight": 0.031111
          },
          {
            "term": "b3c4b28f",
            "tf": 7,
            "weight": 0.031111
          },
          {
            "term": "101",
            "tf": 6,
            "weight": 0.026667
          },
          {
            "term": "ipynb",
            "tf": 4,
            "weight": 0.017778
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.013333
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.013333
          },
          {
            "term": "text",
            "tf": 3,
            "weight": 0.013333
          }
        ],
        "unique_terms": 61,
        "total_terms": 225
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Image Data Applications",
        "applications",
        "data",
        "ecommerce",
        "examples",
        "image",
        "jpg",
        "qdrant",
        "queries",
        "reverse",
        "search"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7578963855421685,
      "overall": 0.7526321285140561
    }
  },
  {
    "text": "## Core Architecture and Components  Image data applications in Qdrant follow a common pattern of embedding extraction, storage, and similarity search. The architecture involves image preprocessing, feature extraction using pre-trained models, vector storage, and search operations. ``` ``` **Core Technical Components**  | Component             | Implementation            | Purpose                                    | | --------------------- | ------------------------- | ------------------------------------------ | | `ViTImageProcessor`   | Hugging Face Transformers | Image preprocessing and tokenization       | | `ViTModel`            | Vision Transformer models | Feature extraction from images             | | `QdrantClient`        | Qdrant Python client      | Vector database operations                 | | `models.VectorParams` | Qdrant configuration      | Collection setup with embedding dimensions | | `models.Filter`       | Qdrant filtering          | Metadata-based search refinement           |  Sources: [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb137-142](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb#L137-L142) [ecommerce\\_reverse\\_image\\_search/ecommerce-reverse-image-search.ipynb1-100](https://github.com/qdrant/examples/blob/b3c4b28f/ecommerce_reverse_image_search/ecommerce-reverse-image-search.ipynb#L1-L100)",
    "metadata": {
      "chunk_id": "408f0653b41c-0001",
      "source_file": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "filename": "_qdrant_examples_4-image-data-applications.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Core Architecture and Components"
      ],
      "heading_text": "Core Architecture and Components",
      "token_count": 304,
      "char_count": 1393,
      "start_char": 3794,
      "end_char": 5187,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6790260869565218,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:39.188343",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 304,
      "document_id": "408f0653b41c",
      "document_name": "_qdrant_examples_4-image-data-applications",
      "source_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "source_filename": "_qdrant_examples_4-image-data-applications.md",
      "source_directory": "Docs\\Qdrant\\qdrant_examples",
      "relative_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "hierarchy_path": "Core Architecture and Components",
      "chunk_hash": "6cf533745a2ea3d8",
      "content_digest": "6cf533745a2ea3d8",
      "chunk_length": 1393,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "image",
          "search",
          "and",
          "models",
          "101",
          "ecommerce",
          "reverse",
          "data",
          "extraction",
          "core",
          "architecture",
          "components",
          "embedding",
          "storage",
          "preprocessing",
          "feature",
          "vector",
          "operations",
          "https"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.076336
          },
          {
            "term": "image",
            "tf": 9,
            "weight": 0.068702
          },
          {
            "term": "search",
            "tf": 7,
            "weight": 0.053435
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.030534
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.030534
          },
          {
            "term": "101",
            "tf": 4,
            "weight": 0.030534
          },
          {
            "term": "ecommerce",
            "tf": 4,
            "weight": 0.030534
          },
          {
            "term": "reverse",
            "tf": 4,
            "weight": 0.030534
          },
          {
            "term": "data",
            "tf": 3,
            "weight": 0.022901
          },
          {
            "term": "extraction",
            "tf": 3,
            "weight": 0.022901
          },
          {
            "term": "core",
            "tf": 2,
            "weight": 0.015267
          },
          {
            "term": "architecture",
            "tf": 2,
            "weight": 0.015267
          },
          {
            "term": "components",
            "tf": 2,
            "weight": 0.015267
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.015267
          },
          {
            "term": "storage",
            "tf": 2,
            "weight": 0.015267
          },
          {
            "term": "preprocessing",
            "tf": 2,
            "weight": 0.015267
          },
          {
            "term": "feature",
            "tf": 2,
            "weight": 0.015267
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.015267
          },
          {
            "term": "operations",
            "tf": 2,
            "weight": 0.015267
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.015267
          }
        ],
        "unique_terms": 73,
        "total_terms": 131
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "101",
        "Core Architecture and Components",
        "and",
        "data",
        "ecommerce",
        "extraction",
        "image",
        "models",
        "qdrant",
        "reverse",
        "search"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6790260869565218,
      "overall": 0.7930086956521739
    }
  },
  {
    "text": "## E-commerce Reverse Image Search\n\nThe e-commerce implementation enables visual product search using the Amazon Product Dataset 2020. Users can submit product images to find visually similar items in the catalog.",
    "metadata": {
      "chunk_id": "408f0653b41c-0002",
      "source_file": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "filename": "_qdrant_examples_4-image-data-applications.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "E-commerce Reverse Image Search"
      ],
      "heading_text": "E-commerce Reverse Image Search",
      "token_count": 38,
      "char_count": 213,
      "start_char": 5191,
      "end_char": 5404,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5319354838709677,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:39.188875",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 38,
      "document_id": "408f0653b41c",
      "document_name": "_qdrant_examples_4-image-data-applications",
      "source_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "source_filename": "_qdrant_examples_4-image-data-applications.md",
      "source_directory": "Docs\\Qdrant\\qdrant_examples",
      "relative_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "hierarchy_path": "E-commerce Reverse Image Search",
      "chunk_hash": "6de957a821e5359b",
      "content_digest": "6de957a821e5359b",
      "chunk_length": 213,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "product",
          "commerce",
          "search",
          "reverse",
          "image",
          "implementation",
          "enables",
          "visual",
          "using",
          "amazon",
          "dataset",
          "2020",
          "users",
          "can",
          "submit",
          "images",
          "find",
          "visually",
          "similar"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 3,
            "weight": 0.107143
          },
          {
            "term": "product",
            "tf": 3,
            "weight": 0.107143
          },
          {
            "term": "commerce",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "reverse",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "image",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "enables",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "visual",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "amazon",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "dataset",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "2020",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "users",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "submit",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "images",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "find",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "visually",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "similar",
            "tf": 1,
            "weight": 0.035714
          }
        ],
        "unique_terms": 22,
        "total_terms": 28
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "E-commerce Reverse Image Search",
        "commerce",
        "enables",
        "image",
        "implementation",
        "product",
        "reverse",
        "search",
        "the",
        "using",
        "visual"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5319354838709677,
      "overall": 0.7106451612903225
    }
  },
  {
    "text": "### Dataset and Setup  The system processes product data with image URLs and metadata including product names, categories, and pricing information. The implementation uses a configurable dataset fraction for testing and development. ``` ``` **Key Implementation Details**  The dataset fraction is controlled by the `DATASET_FRACTION` variable, typically set to `0.1` for development to process only 10% of the full dataset. The system downloads images from provided URLs and extracts embeddings using vision models. Sources: [ecommerce\\_reverse\\_image\\_search/ecommerce-reverse-image-search.ipynb275-277](https://github.com/qdrant/examples/blob/b3c4b28f/ecommerce_reverse_image_search/ecommerce-reverse-image-search.ipynb#L275-L277) [ecommerce\\_reverse\\_image\\_search/ecommerce-reverse-image-search.ipynb51-58](https://github.com/qdrant/examples/blob/b3c4b28f/ecommerce_reverse_image_search/ecommerce-reverse-image-search.ipynb#L51-L58)",
    "metadata": {
      "chunk_id": "408f0653b41c-0003",
      "source_file": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "filename": "_qdrant_examples_4-image-data-applications.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Dataset and Setup"
      ],
      "heading_text": "Dataset and Setup",
      "token_count": 220,
      "char_count": 936,
      "start_char": 5406,
      "end_char": 6342,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.715,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:39.190767",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 220,
      "document_id": "408f0653b41c",
      "document_name": "_qdrant_examples_4-image-data-applications",
      "source_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "source_filename": "_qdrant_examples_4-image-data-applications.md",
      "source_directory": "Docs\\Qdrant\\qdrant_examples",
      "relative_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "hierarchy_path": "Dataset and Setup",
      "chunk_hash": "3274ed3046059c82",
      "content_digest": "3274ed3046059c82",
      "chunk_length": 936,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "image",
          "ecommerce",
          "reverse",
          "search",
          "the",
          "dataset",
          "and",
          "fraction",
          "system",
          "product",
          "urls",
          "implementation",
          "for",
          "development",
          "https",
          "github",
          "com",
          "qdrant",
          "examples",
          "blob"
        ],
        "term_weights": [
          {
            "term": "image",
            "tf": 9,
            "weight": 0.07563
          },
          {
            "term": "ecommerce",
            "tf": 8,
            "weight": 0.067227
          },
          {
            "term": "reverse",
            "tf": 8,
            "weight": 0.067227
          },
          {
            "term": "search",
            "tf": 8,
            "weight": 0.067227
          },
          {
            "term": "the",
            "tf": 6,
            "weight": 0.05042
          },
          {
            "term": "dataset",
            "tf": 5,
            "weight": 0.042017
          },
          {
            "term": "and",
            "tf": 5,
            "weight": 0.042017
          },
          {
            "term": "fraction",
            "tf": 3,
            "weight": 0.02521
          },
          {
            "term": "system",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "product",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "urls",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "implementation",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "development",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.016807
          }
        ],
        "unique_terms": 61,
        "total_terms": 119
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Dataset and Setup",
        "and",
        "dataset",
        "ecommerce",
        "fraction",
        "image",
        "product",
        "reverse",
        "search",
        "system",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.715,
      "overall": 0.7716666666666666
    }
  },
  {
    "text": "### Visual Search Implementation  The search system processes query images through the same embedding pipeline and performs cosine similarity matching against stored product vectors. ``` ``` Sources: [ecommerce\\_reverse\\_image\\_search/ecommerce-reverse-image-search.ipynb1-50](https://github.com/qdrant/examples/blob/b3c4b28f/ecommerce_reverse_image_search/ecommerce-reverse-image-search.ipynb#L1-L50)",
    "metadata": {
      "chunk_id": "408f0653b41c-0004",
      "source_file": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "filename": "_qdrant_examples_4-image-data-applications.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Visual Search Implementation"
      ],
      "heading_text": "Visual Search Implementation",
      "token_count": 91,
      "char_count": 401,
      "start_char": 6347,
      "end_char": 6748,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7578571428571429,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:39.191732",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 91,
      "document_id": "408f0653b41c",
      "document_name": "_qdrant_examples_4-image-data-applications",
      "source_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "source_filename": "_qdrant_examples_4-image-data-applications.md",
      "source_directory": "Docs\\Qdrant\\qdrant_examples",
      "relative_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "hierarchy_path": "Visual Search Implementation",
      "chunk_hash": "6f8f12dc0fbdb515",
      "content_digest": "6f8f12dc0fbdb515",
      "chunk_length": 401,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "ecommerce",
          "reverse",
          "image",
          "the",
          "visual",
          "implementation",
          "system",
          "processes",
          "query",
          "images",
          "through",
          "same",
          "embedding",
          "pipeline",
          "and",
          "performs",
          "cosine",
          "similarity",
          "matching"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 6,
            "weight": 0.12
          },
          {
            "term": "ecommerce",
            "tf": 4,
            "weight": 0.08
          },
          {
            "term": "reverse",
            "tf": 4,
            "weight": 0.08
          },
          {
            "term": "image",
            "tf": 4,
            "weight": 0.08
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "visual",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "processes",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "query",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "images",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "same",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "pipeline",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "performs",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "cosine",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "similarity",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "matching",
            "tf": 1,
            "weight": 0.02
          }
        ],
        "unique_terms": 35,
        "total_terms": 50
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Visual Search Implementation",
        "ecommerce",
        "image",
        "implementation",
        "processes",
        "query",
        "reverse",
        "search",
        "system",
        "the",
        "visual"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7578571428571429,
      "overall": 0.7859523809523808
    }
  },
  {
    "text": "## Medical Image Search with Vision Transformers\n\nThe medical application focuses on skin cancer image analysis using the `marmal88/skin_cancer` dataset from Hugging Face. This system assists medical professionals in comparing diagnostic images.",
    "metadata": {
      "chunk_id": "408f0653b41c-0005",
      "source_file": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "filename": "_qdrant_examples_4-image-data-applications.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Medical Image Search with Vision Transformers"
      ],
      "heading_text": "Medical Image Search with Vision Transformers",
      "token_count": 45,
      "char_count": 245,
      "start_char": 6752,
      "end_char": 6997,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:39.192013",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 45,
      "document_id": "408f0653b41c",
      "document_name": "_qdrant_examples_4-image-data-applications",
      "source_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "source_filename": "_qdrant_examples_4-image-data-applications.md",
      "source_directory": "Docs\\Qdrant\\qdrant_examples",
      "relative_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "hierarchy_path": "Medical Image Search with Vision Transformers",
      "chunk_hash": "ae5e7ddbf395f9a9",
      "content_digest": "ae5e7ddbf395f9a9",
      "chunk_length": 245,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "medical",
          "image",
          "the",
          "skin",
          "cancer",
          "search",
          "with",
          "vision",
          "transformers",
          "application",
          "focuses",
          "analysis",
          "using",
          "marmal88",
          "dataset",
          "from",
          "hugging",
          "face",
          "this",
          "system"
        ],
        "term_weights": [
          {
            "term": "medical",
            "tf": 3,
            "weight": 0.096774
          },
          {
            "term": "image",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "skin",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "cancer",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "vision",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "application",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "focuses",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "analysis",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "marmal88",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "dataset",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "hugging",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "face",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.032258
          }
        ],
        "unique_terms": 25,
        "total_terms": 31
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Medical Image Search with Vision Transformers",
        "application",
        "cancer",
        "image",
        "medical",
        "search",
        "skin",
        "the",
        "transformers",
        "vision",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "overall": 0.7508333333333331
    }
  },
  {
    "text": "### Dataset Structure and Medical Metadata  The skin cancer dataset contains 9,577 images with comprehensive medical metadata including diagnosis types, patient demographics, and lesion locations. **Dataset Schema**  | Field          | Type      | Description                                               | | -------------- | --------- | --------------------------------------------------------- | | `image`        | PIL Image | 600x450 RGB medical images                                | | `image_id`     | String    | Unique image identifier                                   | | `lesion_id`    | String    | Lesion type identifier                                    | | `dx`           | String    | Diagnosis (melanoma, basal\\_cell\\_carcinoma, etc.)        | | `dx_type`      | String    | Diagnosis method (histo, follow\\_up, consensus, confocal) | | `age`          | Float     | Patient age (5-86 years)                                  | | `sex`          | String    | Patient gender (female, male, unknown)                    | | `localization` | String    | Body location of lesion                                   |  Sources: [qdrant\\_101\\_image\\_data/README.md23-34](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L23-L34) [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb257-258](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb#L257-L258)",
    "metadata": {
      "chunk_id": "408f0653b41c-0006",
      "source_file": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "filename": "_qdrant_examples_4-image-data-applications.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Dataset Structure and Medical Metadata"
      ],
      "heading_text": "Dataset Structure and Medical Metadata",
      "token_count": 332,
      "char_count": 1433,
      "start_char": 6999,
      "end_char": 8432,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6591238095238096,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:39.192803",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 332,
      "document_id": "408f0653b41c",
      "document_name": "_qdrant_examples_4-image-data-applications",
      "source_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "source_filename": "_qdrant_examples_4-image-data-applications.md",
      "source_directory": "Docs\\Qdrant\\qdrant_examples",
      "relative_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "hierarchy_path": "Dataset Structure and Medical Metadata",
      "chunk_hash": "00b57b55aace4f80",
      "content_digest": "00b57b55aace4f80",
      "chunk_length": 1433,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "image",
          "qdrant",
          "string",
          "101",
          "lesion",
          "data",
          "dataset",
          "medical",
          "diagnosis",
          "patient",
          "type",
          "and",
          "metadata",
          "images",
          "identifier",
          "age",
          "readme",
          "https",
          "github",
          "com"
        ],
        "term_weights": [
          {
            "term": "image",
            "tf": 8,
            "weight": 0.065041
          },
          {
            "term": "qdrant",
            "tf": 8,
            "weight": 0.065041
          },
          {
            "term": "string",
            "tf": 6,
            "weight": 0.04878
          },
          {
            "term": "101",
            "tf": 6,
            "weight": 0.04878
          },
          {
            "term": "lesion",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "data",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "dataset",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "medical",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "diagnosis",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "patient",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "type",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "metadata",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "images",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "identifier",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "age",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "readme",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.01626
          }
        ],
        "unique_terms": 71,
        "total_terms": 123
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "101",
        "Dataset Structure and Medical Metadata",
        "data",
        "dataset",
        "diagnosis",
        "image",
        "lesion",
        "medical",
        "patient",
        "qdrant",
        "string"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6591238095238096,
      "overall": 0.7863746031746031
    }
  },
  {
    "text": "### Vision Transformer Integration  The system uses Facebook's DINO model (`facebook/dino-vits16`) for feature extraction. The implementation processes images through `ViTImageProcessor` and generates 384-dimensional embeddings. ``` ``` **Key Technical Implementation**  The embedding process uses mean pooling across patches to compress the 197-patch ViT output into a single 384-dimensional vector per image. ``` ``` Sources: [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb204-207](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb#L204-L207) [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb296-302](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb#L296-L302) [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb187-192](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb#L187-L192)",
    "metadata": {
      "chunk_id": "408f0653b41c-0007",
      "source_file": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "filename": "_qdrant_examples_4-image-data-applications.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Vision Transformer Integration"
      ],
      "heading_text": "Vision Transformer Integration",
      "token_count": 284,
      "char_count": 922,
      "start_char": 8435,
      "end_char": 9357,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7471428571428571,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:39.195101",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 284,
      "document_id": "408f0653b41c",
      "document_name": "_qdrant_examples_4-image-data-applications",
      "source_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "source_filename": "_qdrant_examples_4-image-data-applications.md",
      "source_directory": "Docs\\Qdrant\\qdrant_examples",
      "relative_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "hierarchy_path": "Vision Transformer Integration",
      "chunk_hash": "979047fd4fa63538",
      "content_digest": "979047fd4fa63538",
      "chunk_length": 922,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "101",
          "image",
          "data",
          "the",
          "https",
          "github",
          "com",
          "examples",
          "blob",
          "b3c4b28f",
          "ipynb",
          "uses",
          "facebook",
          "dino",
          "implementation",
          "384",
          "dimensional",
          "vision",
          "transformer"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 15,
            "weight": 0.121951
          },
          {
            "term": "101",
            "tf": 12,
            "weight": 0.097561
          },
          {
            "term": "image",
            "tf": 7,
            "weight": 0.056911
          },
          {
            "term": "data",
            "tf": 6,
            "weight": 0.04878
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "examples",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "b3c4b28f",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "ipynb",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "uses",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "facebook",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "dino",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "implementation",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "384",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "dimensional",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "vision",
            "tf": 1,
            "weight": 0.00813
          },
          {
            "term": "transformer",
            "tf": 1,
            "weight": 0.00813
          }
        ],
        "unique_terms": 64,
        "total_terms": 123
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "101",
        "Vision Transformer Integration",
        "blob",
        "com",
        "data",
        "examples",
        "github",
        "https",
        "image",
        "qdrant",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7471428571428571,
      "overall": 0.7823809523809523
    }
  },
  {
    "text": "### Medical Search and Filtering  The medical search system supports demographic filtering to find cases similar to specific patient profiles. This enables targeted diagnostic assistance based on patient characteristics. ``` ``` **Filter Implementation Example**  The system implements complex demographic filtering using Qdrant's filter syntax: ``` ``` Sources: [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb484-492](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb#L484-L492) [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb496-503](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb#L496-L503)",
    "metadata": {
      "chunk_id": "408f0653b41c-0008",
      "source_file": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "filename": "_qdrant_examples_4-image-data-applications.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Medical Search and Filtering"
      ],
      "heading_text": "Medical Search and Filtering",
      "token_count": 192,
      "char_count": 692,
      "start_char": 9363,
      "end_char": 10055,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7165306122448979,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:39.197353",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 192,
      "document_id": "408f0653b41c",
      "document_name": "_qdrant_examples_4-image-data-applications",
      "source_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "source_filename": "_qdrant_examples_4-image-data-applications.md",
      "source_directory": "Docs\\Qdrant\\qdrant_examples",
      "relative_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "hierarchy_path": "Medical Search and Filtering",
      "chunk_hash": "eeccbe4371f04aae",
      "content_digest": "eeccbe4371f04aae",
      "chunk_length": 692,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "101",
          "image",
          "data",
          "filtering",
          "medical",
          "search",
          "the",
          "system",
          "demographic",
          "patient",
          "filter",
          "https",
          "github",
          "com",
          "examples",
          "blob",
          "b3c4b28f",
          "ipynb",
          "and"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 11,
            "weight": 0.126437
          },
          {
            "term": "101",
            "tf": 8,
            "weight": 0.091954
          },
          {
            "term": "image",
            "tf": 4,
            "weight": 0.045977
          },
          {
            "term": "data",
            "tf": 4,
            "weight": 0.045977
          },
          {
            "term": "filtering",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "medical",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "system",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "demographic",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "patient",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "filter",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "b3c4b28f",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "ipynb",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.011494
          }
        ],
        "unique_terms": 48,
        "total_terms": 87
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "101",
        "Medical Search and Filtering",
        "data",
        "demographic",
        "filtering",
        "image",
        "medical",
        "qdrant",
        "search",
        "system",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7165306122448979,
      "overall": 0.7721768707482992
    }
  },
  {
    "text": "## Data Processing and Storage Pipeline\n\nBoth applications follow similar patterns for data ingestion, embedding generation, and vector storage in Qdrant collections.",
    "metadata": {
      "chunk_id": "408f0653b41c-0009",
      "source_file": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "filename": "_qdrant_examples_4-image-data-applications.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Data Processing and Storage Pipeline"
      ],
      "heading_text": "Data Processing and Storage Pipeline",
      "token_count": 28,
      "char_count": 166,
      "start_char": 10061,
      "end_char": 10227,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5490909090909091,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:39.197716",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 28,
      "document_id": "408f0653b41c",
      "document_name": "_qdrant_examples_4-image-data-applications",
      "source_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "source_filename": "_qdrant_examples_4-image-data-applications.md",
      "source_directory": "Docs\\Qdrant\\qdrant_examples",
      "relative_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "hierarchy_path": "Data Processing and Storage Pipeline",
      "chunk_hash": "67f7e2f1aa863b31",
      "content_digest": "67f7e2f1aa863b31",
      "chunk_length": 166,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "data",
          "and",
          "storage",
          "processing",
          "pipeline",
          "both",
          "applications",
          "follow",
          "similar",
          "patterns",
          "for",
          "ingestion",
          "embedding",
          "generation",
          "vector",
          "qdrant",
          "collections"
        ],
        "term_weights": [
          {
            "term": "data",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "storage",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "pipeline",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "both",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "applications",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "follow",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "similar",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "patterns",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "ingestion",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "generation",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.05
          }
        ],
        "unique_terms": 17,
        "total_terms": 20
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Data Processing and Storage Pipeline",
        "and",
        "applications",
        "both",
        "data",
        "follow",
        "patterns",
        "pipeline",
        "processing",
        "similar",
        "storage"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5490909090909091,
      "overall": 0.7496969696969696
    }
  },
  {
    "text": "### Batch Processing and Collection Management  The systems implement batch processing for efficient embedding generation and storage. The medical application processes images in batches of 16, while the e-commerce system uses configurable batch sizes of 1000 for vector uploads. ``` ``` **Collection Configuration**  Both systems use cosine distance for similarity measurement, with embedding dimensions matching the model output (384 for ViT models). Sources: [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb306-307](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb#L306-L307) [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb380-398](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb#L380-L398) [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb187-192](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb#L187-L192)",
    "metadata": {
      "chunk_id": "408f0653b41c-0010",
      "source_file": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "filename": "_qdrant_examples_4-image-data-applications.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Batch Processing and Collection Management"
      ],
      "heading_text": "Batch Processing and Collection Management",
      "token_count": 280,
      "char_count": 956,
      "start_char": 10229,
      "end_char": 11185,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7263636363636363,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:39.199729",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 280,
      "document_id": "408f0653b41c",
      "document_name": "_qdrant_examples_4-image-data-applications",
      "source_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "source_filename": "_qdrant_examples_4-image-data-applications.md",
      "source_directory": "Docs\\Qdrant\\qdrant_examples",
      "relative_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "hierarchy_path": "Batch Processing and Collection Management",
      "chunk_hash": "627925ba1a89cdb2",
      "content_digest": "627925ba1a89cdb2",
      "chunk_length": 956,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "101",
          "image",
          "data",
          "the",
          "for",
          "batch",
          "https",
          "github",
          "com",
          "examples",
          "blob",
          "b3c4b28f",
          "ipynb",
          "processing",
          "and",
          "collection",
          "systems",
          "embedding",
          "management"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 15,
            "weight": 0.117188
          },
          {
            "term": "101",
            "tf": 12,
            "weight": 0.09375
          },
          {
            "term": "image",
            "tf": 6,
            "weight": 0.046875
          },
          {
            "term": "data",
            "tf": 6,
            "weight": 0.046875
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.03125
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.03125
          },
          {
            "term": "batch",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "examples",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "b3c4b28f",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "ipynb",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "processing",
            "tf": 2,
            "weight": 0.015625
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.015625
          },
          {
            "term": "collection",
            "tf": 2,
            "weight": 0.015625
          },
          {
            "term": "systems",
            "tf": 2,
            "weight": 0.015625
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.015625
          },
          {
            "term": "management",
            "tf": 1,
            "weight": 0.007812
          }
        ],
        "unique_terms": 66,
        "total_terms": 128
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "101",
        "Batch Processing and Collection Management",
        "batch",
        "com",
        "data",
        "for",
        "github",
        "https",
        "image",
        "qdrant",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7263636363636363,
      "overall": 0.7754545454545454
    }
  },
  {
    "text": "### Metadata and Payload Management  The applications store comprehensive metadata alongside vectors to enable filtering and result enrichment. The medical system handles missing values by filling NaN ages with 0, while preserving other patient information. **Payload Structure** ``` ``` The payload conversion process transforms HuggingFace dataset columns into Qdrant-compatible dictionary records, ensuring proper handling of missing values and data type compatibility. Sources: [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb332-337](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb#L332-L337) [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb363-365](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb#L363-L365)  Dismiss  Refresh this wiki  Enter email to refresh",
    "metadata": {
      "chunk_id": "408f0653b41c-0011",
      "source_file": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "filename": "_qdrant_examples_4-image-data-applications.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Metadata and Payload Management"
      ],
      "heading_text": "Metadata and Payload Management",
      "token_count": 223,
      "char_count": 863,
      "start_char": 11190,
      "end_char": 12053,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7441666666666666,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:39.201879",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 223,
      "document_id": "408f0653b41c",
      "document_name": "_qdrant_examples_4-image-data-applications",
      "source_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "source_filename": "_qdrant_examples_4-image-data-applications.md",
      "source_directory": "Docs\\Qdrant\\qdrant_examples",
      "relative_path": "Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4-image-data-applications.md",
      "hierarchy_path": "Metadata and Payload Management",
      "chunk_hash": "8fe6499bf49f1341",
      "content_digest": "8fe6499bf49f1341",
      "chunk_length": 863,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "101",
          "data",
          "image",
          "and",
          "payload",
          "the",
          "metadata",
          "missing",
          "values",
          "https",
          "github",
          "com",
          "examples",
          "blob",
          "b3c4b28f",
          "ipynb",
          "refresh",
          "management",
          "applications"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 11,
            "weight": 0.099099
          },
          {
            "term": "101",
            "tf": 8,
            "weight": 0.072072
          },
          {
            "term": "data",
            "tf": 5,
            "weight": 0.045045
          },
          {
            "term": "image",
            "tf": 4,
            "weight": 0.036036
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.027027
          },
          {
            "term": "payload",
            "tf": 3,
            "weight": 0.027027
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.027027
          },
          {
            "term": "metadata",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "missing",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "values",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "b3c4b28f",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "ipynb",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "refresh",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "management",
            "tf": 1,
            "weight": 0.009009
          },
          {
            "term": "applications",
            "tf": 1,
            "weight": 0.009009
          }
        ],
        "unique_terms": 70,
        "total_terms": 111
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "101",
        "Metadata and Payload Management",
        "and",
        "data",
        "image",
        "metadata",
        "missing",
        "payload",
        "qdrant",
        "the",
        "values"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7441666666666666,
      "overall": 0.7813888888888888
    }
  }
]
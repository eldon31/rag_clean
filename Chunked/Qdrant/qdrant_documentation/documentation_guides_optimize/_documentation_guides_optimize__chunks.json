[
  {
    "text": "### User Manual  [Concepts](https://qdrant.tech/documentation/concepts/)  - [Collections](https://qdrant.tech/documentation/concepts/collections/) - [Points](https://qdrant.tech/documentation/concepts/points/) - [Vectors](https://qdrant.tech/documentation/concepts/vectors/) - [Payload](https://qdrant.tech/documentation/concepts/payload/) - [Search](https://qdrant.tech/documentation/concepts/search/) - [Explore](https://qdrant.tech/documentation/concepts/explore/) - [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/) - [Filtering](https://qdrant.tech/documentation/concepts/filtering/) - [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/) - [Storage](https://qdrant.tech/documentation/concepts/storage/) - [Indexing](https://qdrant.tech/documentation/concepts/indexing/) - [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)  [Guides](https://qdrant.tech/documentation/guides/installation/)  - [Installation](https://qdrant.tech/documentation/guides/installation/) - [Administration](https://qdrant.tech/documentation/guides/administration/) - [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/) - [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/) - [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/) - [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/) - [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/) - [Quantization](https://qdrant.tech/documentation/guides/quantization/) - [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/) - [Configuration](https://qdrant.tech/documentation/guides/configuration/) - [Security](https://qdrant.tech/documentation/guides/security/) - [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/) - [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0001",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "User Manual"
      ],
      "heading_text": "User Manual",
      "token_count": 485,
      "char_count": 1968,
      "start_char": 1046,
      "end_char": 3014,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.733,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.439618",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 485,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "User Manual",
      "chunk_hash": "aa99483e94fddd20",
      "content_digest": "aa99483e94fddd20",
      "chunk_length": 1968,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "guides",
          "concepts",
          "installation",
          "collections",
          "points",
          "vectors",
          "payload",
          "search",
          "explore",
          "hybrid",
          "queries",
          "filtering",
          "optimizer",
          "storage",
          "indexing",
          "snapshots"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "qdrant",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "tech",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "documentation",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "guides",
            "tf": 15,
            "weight": 0.072816
          },
          {
            "term": "concepts",
            "tf": 14,
            "weight": 0.067961
          },
          {
            "term": "installation",
            "tf": 3,
            "weight": 0.014563
          },
          {
            "term": "collections",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "points",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "vectors",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "payload",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "explore",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "hybrid",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "queries",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "filtering",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "optimizer",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "storage",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "indexing",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "snapshots",
            "tf": 2,
            "weight": 0.009709
          }
        ],
        "unique_terms": 45,
        "total_terms": 206
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "User Manual",
        "collections",
        "concepts",
        "documentation",
        "guides",
        "https",
        "installation",
        "points",
        "qdrant",
        "tech",
        "vectors"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.733,
      "overall": 0.7776666666666666
    }
  },
  {
    "text": "### Tutorials  [Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)  - [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/) - [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/) - [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/) - [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)  [Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)  - [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/) - [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/) - [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/) - [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/) - [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)  [Using the Database](https://qdrant.tech/documentation/database-tutorials/)  - [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/) - [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/) - [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/) - [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/) - [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/) - [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/) - [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0003",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Tutorials"
      ],
      "heading_text": "Tutorials",
      "token_count": 459,
      "char_count": 1988,
      "start_char": 3696,
      "end_char": 5684,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7480092783505154,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.446563",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 459,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Tutorials",
      "chunk_hash": "f480f0283a04b78a",
      "content_digest": "f480f0283a04b78a",
      "chunk_length": 1988,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "tutorials",
          "https",
          "tech",
          "documentation",
          "search",
          "database",
          "advanced",
          "beginner",
          "with",
          "hybrid",
          "retrieval",
          "build",
          "scale",
          "neural",
          "fastembed",
          "quality",
          "multivector",
          "representations",
          "using"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 22,
            "weight": 0.098655
          },
          {
            "term": "tutorials",
            "tf": 20,
            "weight": 0.089686
          },
          {
            "term": "https",
            "tf": 19,
            "weight": 0.085202
          },
          {
            "term": "tech",
            "tf": 19,
            "weight": 0.085202
          },
          {
            "term": "documentation",
            "tf": 19,
            "weight": 0.085202
          },
          {
            "term": "search",
            "tf": 14,
            "weight": 0.06278
          },
          {
            "term": "database",
            "tf": 9,
            "weight": 0.040359
          },
          {
            "term": "advanced",
            "tf": 7,
            "weight": 0.03139
          },
          {
            "term": "beginner",
            "tf": 5,
            "weight": 0.022422
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.022422
          },
          {
            "term": "hybrid",
            "tf": 4,
            "weight": 0.017937
          },
          {
            "term": "retrieval",
            "tf": 4,
            "weight": 0.017937
          },
          {
            "term": "build",
            "tf": 3,
            "weight": 0.013453
          },
          {
            "term": "scale",
            "tf": 3,
            "weight": 0.013453
          },
          {
            "term": "neural",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "quality",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "multivector",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "representations",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "using",
            "tf": 2,
            "weight": 0.008969
          }
        ],
        "unique_terms": 64,
        "total_terms": 223
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Tutorials",
        "advanced",
        "beginner",
        "database",
        "documentation",
        "https",
        "qdrant",
        "search",
        "tech",
        "tutorials",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7480092783505154,
      "overall": 0.7826697594501718
    }
  },
  {
    "text": "### Support  [FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)  - [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/) - [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)  [Release Notes](https://github.com/qdrant/qdrant/releases)",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0004",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Support"
      ],
      "heading_text": "Support",
      "token_count": 83,
      "char_count": 311,
      "start_char": 5686,
      "end_char": 5997,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5627272727272727,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.447770",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 83,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Support",
      "chunk_hash": "f059a5deb61e367d",
      "content_digest": "f059a5deb61e367d",
      "chunk_length": 311,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "faq",
          "https",
          "tech",
          "documentation",
          "fundamentals",
          "database",
          "optimization",
          "support",
          "release",
          "notes",
          "github",
          "com",
          "releases"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 8,
            "weight": 0.228571
          },
          {
            "term": "faq",
            "tf": 4,
            "weight": 0.114286
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.114286
          },
          {
            "term": "tech",
            "tf": 3,
            "weight": 0.085714
          },
          {
            "term": "documentation",
            "tf": 3,
            "weight": 0.085714
          },
          {
            "term": "fundamentals",
            "tf": 3,
            "weight": 0.085714
          },
          {
            "term": "database",
            "tf": 2,
            "weight": 0.057143
          },
          {
            "term": "optimization",
            "tf": 2,
            "weight": 0.057143
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "release",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "notes",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "github",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "com",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "releases",
            "tf": 1,
            "weight": 0.028571
          }
        ],
        "unique_terms": 14,
        "total_terms": 35
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Support",
        "database",
        "documentation",
        "faq",
        "fundamentals",
        "https",
        "optimization",
        "qdrant",
        "release",
        "support",
        "tech"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5627272727272727,
      "overall": 0.7209090909090908
    }
  },
  {
    "text": "### User Manual  [Concepts](https://qdrant.tech/documentation/concepts/)  - [Collections](https://qdrant.tech/documentation/concepts/collections/) - [Points](https://qdrant.tech/documentation/concepts/points/) - [Vectors](https://qdrant.tech/documentation/concepts/vectors/) - [Payload](https://qdrant.tech/documentation/concepts/payload/) - [Search](https://qdrant.tech/documentation/concepts/search/) - [Explore](https://qdrant.tech/documentation/concepts/explore/) - [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/) - [Filtering](https://qdrant.tech/documentation/concepts/filtering/) - [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/) - [Storage](https://qdrant.tech/documentation/concepts/storage/) - [Indexing](https://qdrant.tech/documentation/concepts/indexing/) - [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)  [Guides](https://qdrant.tech/documentation/guides/installation/)  - [Installation](https://qdrant.tech/documentation/guides/installation/) - [Administration](https://qdrant.tech/documentation/guides/administration/) - [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/) - [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/) - [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/) - [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/) - [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/) - [Quantization](https://qdrant.tech/documentation/guides/quantization/) - [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/) - [Configuration](https://qdrant.tech/documentation/guides/configuration/) - [Security](https://qdrant.tech/documentation/guides/security/) - [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/) - [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0006",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "User Manual"
      ],
      "heading_text": "User Manual",
      "token_count": 485,
      "char_count": 1968,
      "start_char": 6374,
      "end_char": 8342,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.733,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.455425",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 485,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "User Manual",
      "chunk_hash": "aa99483e94fddd20",
      "content_digest": "aa99483e94fddd20",
      "chunk_length": 1968,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "guides",
          "concepts",
          "installation",
          "collections",
          "points",
          "vectors",
          "payload",
          "search",
          "explore",
          "hybrid",
          "queries",
          "filtering",
          "optimizer",
          "storage",
          "indexing",
          "snapshots"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "qdrant",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "tech",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "documentation",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "guides",
            "tf": 15,
            "weight": 0.072816
          },
          {
            "term": "concepts",
            "tf": 14,
            "weight": 0.067961
          },
          {
            "term": "installation",
            "tf": 3,
            "weight": 0.014563
          },
          {
            "term": "collections",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "points",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "vectors",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "payload",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "explore",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "hybrid",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "queries",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "filtering",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "optimizer",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "storage",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "indexing",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "snapshots",
            "tf": 2,
            "weight": 0.009709
          }
        ],
        "unique_terms": 45,
        "total_terms": 206
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "User Manual",
        "collections",
        "concepts",
        "documentation",
        "guides",
        "https",
        "installation",
        "points",
        "qdrant",
        "tech",
        "vectors"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.733,
      "overall": 0.7776666666666666
    }
  },
  {
    "text": "### Tutorials  [Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)  - [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/) - [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/) - [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/) - [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)  [Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)  - [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/) - [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/) - [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/) - [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/) - [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)  [Using the Database](https://qdrant.tech/documentation/database-tutorials/)  - [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/) - [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/) - [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/) - [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/) - [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/) - [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/) - [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0008",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Tutorials"
      ],
      "heading_text": "Tutorials",
      "token_count": 459,
      "char_count": 1988,
      "start_char": 9024,
      "end_char": 11012,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7480092783505154,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.461808",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 459,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Tutorials",
      "chunk_hash": "f480f0283a04b78a",
      "content_digest": "f480f0283a04b78a",
      "chunk_length": 1988,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "tutorials",
          "https",
          "tech",
          "documentation",
          "search",
          "database",
          "advanced",
          "beginner",
          "with",
          "hybrid",
          "retrieval",
          "build",
          "scale",
          "neural",
          "fastembed",
          "quality",
          "multivector",
          "representations",
          "using"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 22,
            "weight": 0.098655
          },
          {
            "term": "tutorials",
            "tf": 20,
            "weight": 0.089686
          },
          {
            "term": "https",
            "tf": 19,
            "weight": 0.085202
          },
          {
            "term": "tech",
            "tf": 19,
            "weight": 0.085202
          },
          {
            "term": "documentation",
            "tf": 19,
            "weight": 0.085202
          },
          {
            "term": "search",
            "tf": 14,
            "weight": 0.06278
          },
          {
            "term": "database",
            "tf": 9,
            "weight": 0.040359
          },
          {
            "term": "advanced",
            "tf": 7,
            "weight": 0.03139
          },
          {
            "term": "beginner",
            "tf": 5,
            "weight": 0.022422
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.022422
          },
          {
            "term": "hybrid",
            "tf": 4,
            "weight": 0.017937
          },
          {
            "term": "retrieval",
            "tf": 4,
            "weight": 0.017937
          },
          {
            "term": "build",
            "tf": 3,
            "weight": 0.013453
          },
          {
            "term": "scale",
            "tf": 3,
            "weight": 0.013453
          },
          {
            "term": "neural",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "quality",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "multivector",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "representations",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "using",
            "tf": 2,
            "weight": 0.008969
          }
        ],
        "unique_terms": 64,
        "total_terms": 223
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Tutorials",
        "advanced",
        "beginner",
        "database",
        "documentation",
        "https",
        "qdrant",
        "search",
        "tech",
        "tutorials",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7480092783505154,
      "overall": 0.7826697594501718
    }
  },
  {
    "text": "### Support  [FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)  - [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/) - [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)  [Release Notes](https://github.com/qdrant/qdrant/releases)  - [Documentation](https://qdrant.tech/documentation/) - - [Guides](https://qdrant.tech/documentation/guides/) - - Optimize Performance",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0009",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Support"
      ],
      "heading_text": "Support",
      "token_count": 118,
      "char_count": 447,
      "start_char": 11014,
      "end_char": 11461,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7000000000000001,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.463408",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 118,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Support",
      "chunk_hash": "72dfe4fa465cb533",
      "content_digest": "72dfe4fa465cb533",
      "chunk_length": 447,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "https",
          "documentation",
          "tech",
          "faq",
          "fundamentals",
          "database",
          "optimization",
          "guides",
          "support",
          "release",
          "notes",
          "github",
          "com",
          "releases",
          "optimize",
          "performance"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.208333
          },
          {
            "term": "https",
            "tf": 6,
            "weight": 0.125
          },
          {
            "term": "documentation",
            "tf": 6,
            "weight": 0.125
          },
          {
            "term": "tech",
            "tf": 5,
            "weight": 0.104167
          },
          {
            "term": "faq",
            "tf": 4,
            "weight": 0.083333
          },
          {
            "term": "fundamentals",
            "tf": 3,
            "weight": 0.0625
          },
          {
            "term": "database",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "optimization",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "guides",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "release",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "notes",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "github",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "com",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "releases",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "optimize",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.020833
          }
        ],
        "unique_terms": 17,
        "total_terms": 48
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Support",
        "database",
        "documentation",
        "faq",
        "fundamentals",
        "guides",
        "https",
        "optimization",
        "qdrant",
        "support",
        "tech"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7000000000000001,
      "overall": 0.7666666666666666
    }
  },
  {
    "text": "# Optimizing Qdrant Performance: Three Scenarios  Different use cases require different balances between memory usage, search speed, and precision. Qdrant is designed to be flexible and customizable so you can tune it to your specific needs. This guide will walk you three main optimization strategies:  - High Speed Search & Low Memory Usage - High Precision & Low Memory Usage - High Precision & High Speed Search",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0010",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Optimizing Qdrant Performance: Three Scenarios"
      ],
      "heading_text": "Optimizing Qdrant Performance: Three Scenarios",
      "token_count": 81,
      "char_count": 415,
      "start_char": 11463,
      "end_char": 11878,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6959701492537312,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.463830",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 81,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Optimizing Qdrant Performance: Three Scenarios",
      "chunk_hash": "a1a26161d01eec54",
      "content_digest": "a1a26161d01eec54",
      "chunk_length": 415,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "high",
          "memory",
          "usage",
          "search",
          "speed",
          "precision",
          "qdrant",
          "three",
          "different",
          "and",
          "you",
          "low",
          "optimizing",
          "performance",
          "scenarios",
          "use",
          "cases",
          "require",
          "balances",
          "between"
        ],
        "term_weights": [
          {
            "term": "high",
            "tf": 4,
            "weight": 0.074074
          },
          {
            "term": "memory",
            "tf": 3,
            "weight": 0.055556
          },
          {
            "term": "usage",
            "tf": 3,
            "weight": 0.055556
          },
          {
            "term": "search",
            "tf": 3,
            "weight": 0.055556
          },
          {
            "term": "speed",
            "tf": 3,
            "weight": 0.055556
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.055556
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "three",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "different",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "low",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "optimizing",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "scenarios",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "cases",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "require",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "balances",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "between",
            "tf": 1,
            "weight": 0.018519
          }
        ],
        "unique_terms": 35,
        "total_terms": 54
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Optimizing Qdrant Performance: Three Scenarios",
        "and",
        "different",
        "high",
        "memory",
        "precision",
        "qdrant",
        "search",
        "speed",
        "three",
        "usage"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6959701492537312,
      "overall": 0.7986567164179103
    }
  },
  {
    "text": "## 1. High-Speed Search with Low Memory Usage  To achieve high search speed with minimal memory usage, you can store vectors on disk while minimizing the number of disk reads. Vector quantization is a technique that compresses vectors, allowing more of them to be stored in memory, thus reducing the need to read from disk. To configure in-memory quantization, with on-disk original vectors, you need to create a collection with the following parameters:  - `on_disk`: Stores original vectors on disk. - `quantization_config`: Compresses quantized vectors to `int8` using the `scalar` method. - `always_ram`: Keeps quantized vectors in RAM. ```http PUT /collections/{collection_name} {     \"vectors\": {         \"size\": 768,         \"distance\": \"Cosine\",         \"on_disk\": true     },     \"quantization_config\": {         \"scalar\": {             \"type\": \"int8\",             \"always_ram\": true         }     } } ``` ```python from qdrant_client import QdrantClient, models  client = QdrantClient(url=\"http://localhost:6333\")  client.create_collection(     collection_name=\"{collection_name}\",     vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE, on_disk=True),     quantization_config=models.ScalarQuantization(         scalar=models.ScalarQuantizationConfig(             type=models.ScalarType.INT8,             always_ram=True,         ),     ), ) ``` ```typescript import { QdrantClient } from \"@qdrant/js-client-rest\";  const client = new QdrantClient({ host: \"localhost\", port: 6333 });  client.createCollection(\"{collection_name}\", {   vectors: {     size: 768,     distance: \"Cosine\",     on_disk: true,   },   quantization_config: {     scalar: {       type: \"int8\",       always_ram: true,     },   }, }); ``` ```rust use qdrant_client::qdrant::{     CreateCollectionBuilder, Distance, QuantizationType, ScalarQuantizationBuilder,     VectorParamsBuilder, }; use qdrant_client::Qdrant;  let client = Qdrant::from_url(\"http://localhost:6334\").build()?;  client     .create_collection(         CreateCollectionBuilder::new(\"{collection_name}\")             .vectors_config(VectorParamsBuilder::new(768, Distance::Cosine))             .quantization_config(                 ScalarQuantizationBuilder::default()                     .r#type(QuantizationType::Int8.into())                     .always_ram(true),             ),     )     .await?; ``` ```java import io.qdrant.client.QdrantClient; import io.qdrant.client.QdrantGrpcClient; import io.qdrant.client.grpc.Collections.CreateCollection; import io.qdrant.client.grpc.Collections.Distance; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff; import io.qdrant.client.grpc.Collections.QuantizationConfig; import io.qdrant.client.grpc.Collections.QuantizationType; import io.qdrant.client.grpc.Collections.ScalarQuantization; import io.qdrant.client.grpc.Collections.VectorParams; import io.qdrant.client.grpc.Collections.VectorsConfig;  QdrantClient client =     new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());  client     .createCollectionAsync(         CreateCollection.newBuilder()             .setCollectionName(\"{collection_name}\")             .setVectorsConfig(                 VectorsConfig.newBuilder()                     .setParams(                         VectorParams.newBuilder()                             .setSize(768)                             .setDistance(Distance.Cosine)                             .setOnDisk(true)                             .build())                     .build())             .setQuantizationConfig(                 QuantizationConfig.newBuilder()                     .setScalar(                         ScalarQuantization.newBuilder()                             .setType(QuantizationType.Int8)                             .setAlwaysRam(true)                             .build())                     .build())             .build())     .get(); ``` ```csharp using Qdrant.Client; using Qdrant.Client.Grpc;  var client = new QdrantClient(\"localhost\", 6334);  await client.CreateCollectionAsync( \tcollectionName: \"{collection_name}\", \tvectorsConfig: new VectorParams { Size = 768, Distance = Distance.Cosine, OnDisk = true }, \tquantizationConfig: new QuantizationConfig \t{ \t\tScalar = new ScalarQuantization { Type = QuantizationType.Int8, AlwaysRam = true } \t} ); ``` ```go import ( \t\"context\"  \t\"github.com/qdrant/go-client/qdrant\" )  client, err := qdrant.NewClient(&qdrant.Config{ \tHost: \"localhost\", \tPort: 6334, })  client.CreateCollection(context.Background(), &qdrant.CreateCollection{ \tCollectionName: \"{collection_name}\", \tVectorsConfig: qdrant.NewVectorsConfig(&qdrant.VectorParams{ \t\tSize:     768, \t\tDistance: qdrant.Distance_Cosine, \t\tOnDisk:   qdrant.PtrOf(true), \t}), \tQuantizationConfig: qdrant.NewQuantizationScalar(&qdrant.ScalarQuantization{ \t\tType:      qdrant.QuantizationType_Int8, \t\tAlwaysRam: qdrant.PtrOf(true), \t}), }) ```",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0011",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "1. High-Speed Search with Low Memory Usage"
      ],
      "heading_text": "1. High-Speed Search with Low Memory Usage",
      "token_count": 1139,
      "char_count": 4918,
      "start_char": 11881,
      "end_char": 16799,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6911428571428571,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.471371",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 1139,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "1. High-Speed Search with Low Memory Usage",
      "chunk_hash": "52da9ad70cc0d70b",
      "content_digest": "52da9ad70cc0d70b",
      "chunk_length": 4918,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "true",
          "import",
          "distance",
          "collection",
          "vectors",
          "disk",
          "collections",
          "grpc",
          "config",
          "int8",
          "name",
          "qdrantclient",
          "new",
          "quantization",
          "768",
          "cosine",
          "build",
          "ram"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 32,
            "weight": 0.074766
          },
          {
            "term": "client",
            "tf": 29,
            "weight": 0.067757
          },
          {
            "term": "true",
            "tf": 13,
            "weight": 0.030374
          },
          {
            "term": "import",
            "tf": 13,
            "weight": 0.030374
          },
          {
            "term": "distance",
            "tf": 12,
            "weight": 0.028037
          },
          {
            "term": "collection",
            "tf": 11,
            "weight": 0.025701
          },
          {
            "term": "vectors",
            "tf": 10,
            "weight": 0.023364
          },
          {
            "term": "disk",
            "tf": 9,
            "weight": 0.021028
          },
          {
            "term": "collections",
            "tf": 9,
            "weight": 0.021028
          },
          {
            "term": "grpc",
            "tf": 9,
            "weight": 0.021028
          },
          {
            "term": "config",
            "tf": 8,
            "weight": 0.018692
          },
          {
            "term": "int8",
            "tf": 8,
            "weight": 0.018692
          },
          {
            "term": "name",
            "tf": 8,
            "weight": 0.018692
          },
          {
            "term": "qdrantclient",
            "tf": 8,
            "weight": 0.018692
          },
          {
            "term": "new",
            "tf": 8,
            "weight": 0.018692
          },
          {
            "term": "quantization",
            "tf": 7,
            "weight": 0.016355
          },
          {
            "term": "768",
            "tf": 7,
            "weight": 0.016355
          },
          {
            "term": "cosine",
            "tf": 7,
            "weight": 0.016355
          },
          {
            "term": "build",
            "tf": 7,
            "weight": 0.016355
          },
          {
            "term": "ram",
            "tf": 6,
            "weight": 0.014019
          }
        ],
        "unique_terms": 125,
        "total_terms": 428
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "1. High-Speed Search with Low Memory Usage",
        "client",
        "collection",
        "collections",
        "disk",
        "distance",
        "grpc",
        "import",
        "qdrant",
        "true",
        "vectors"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6911428571428571,
      "overall": 0.7303809523809525
    }
  },
  {
    "text": "### Disable Rescoring for Faster Search (optional)  This is completely optional. Disabling rescoring with search `params` can further reduce the number of disk reads. Note that this might slightly decrease precision. ```http POST /collections/{collection_name}/points/query {     \"query\": [0.2, 0.1, 0.9, 0.7],     \"params\": {         \"quantization\": {             \"rescore\": false         }     },     \"limit\": 10 } ``` ```python from qdrant_client import QdrantClient, models  client = QdrantClient(url=\"http://localhost:6333\")  client.query_points(     collection_name=\"{collection_name}\",     query=[0.2, 0.1, 0.9, 0.7],     search_params=models.SearchParams(         quantization=models.QuantizationSearchParams(rescore=False)     ), ) ``` ```typescript import { QdrantClient } from \"@qdrant/js-client-rest\";  const client = new QdrantClient({ host: \"localhost\", port: 6333 });  client.query(\"{collection_name}\", {     query: [0.2, 0.1, 0.9, 0.7],     params: {         quantization: {             rescore: false,         },     }, }); ``` ```rust use qdrant_client::qdrant::{     QuantizationSearchParamsBuilder, QueryPointsBuilder, SearchParamsBuilder, }; use qdrant_client::Qdrant;  let client = Qdrant::from_url(\"http://localhost:6334\").build()?;  client     .query(         QueryPointsBuilder::new(\"{collection_name}\")             .query(vec![0.2, 0.1, 0.9, 0.7])             .limit(3)             .params(                 SearchParamsBuilder::default()                     .quantization(QuantizationSearchParamsBuilder::default().rescore(false)),             ),     )     .await?; ``` ```java import io.qdrant.client.QdrantClient; import io.qdrant.client.QdrantGrpcClient; import io.qdrant.client.grpc.Points.QuantizationSearchParams; import io.qdrant.client.grpc.Points.QueryPoints; import io.qdrant.client.grpc.Points.SearchParams;  import static io.qdrant.client.QueryFactory.nearest;  QdrantClient client =     new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());  client.queryAsync(         QueryPoints.newBuilder()                 .setCollectionName(\"{collection_name}\")                 .setQuery(nearest(0.2f, 0.1f, 0.9f, 0.7f))                 .setParams(                         SearchParams.newBuilder()                                 .setQuantization(                                         QuantizationSearchParams.newBuilder().setRescore(false).build())                                 .build())                 .setLimit(3)                 .build())         .get(); ``` ```csharp using Qdrant.Client; using Qdrant.Client.Grpc;  var client = new QdrantClient(\"localhost\", 6334);  await client.QueryAsync( \tcollectionName: \"{collection_name}\", \tquery: new float[] { 0.2f, 0.1f, 0.9f, 0.7f }, \tsearchParams: new SearchParams \t{ \t\tQuantization = new QuantizationSearchParams { Rescore = false } \t}, \tlimit: 3 ); ``` ```go import ( \t\"context\"  \t\"github.com/qdrant/go-client/qdrant\" )  client, err := qdrant.NewClient(&qdrant.Config{ \tHost: \"localhost\", \tPort: 6334, })  client.Query(context.Background(), &qdrant.QueryPoints{ \tCollectionName: \"{collection_name}\", \tQuery:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7), \tParams: &qdrant.SearchParams{ \t\tQuantization: &qdrant.QuantizationSearchParams{ \t\t\tRescore: qdrant.PtrOf(true), \t\t}, \t}, }) ```",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0012",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Disable Rescoring for Faster Search (optional)"
      ],
      "heading_text": "Disable Rescoring for Faster Search (optional)",
      "token_count": 892,
      "char_count": 3296,
      "start_char": 16809,
      "end_char": 20105,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6943319838056681,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.478889",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 892,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Disable Rescoring for Faster Search (optional)",
      "chunk_hash": "63f707aa62519af8",
      "content_digest": "63f707aa62519af8",
      "chunk_length": 3296,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "client",
          "qdrant",
          "query",
          "import",
          "collection",
          "name",
          "qdrantclient",
          "false",
          "new",
          "params",
          "quantization",
          "rescore",
          "localhost",
          "searchparams",
          "points",
          "quantizationsearchparams",
          "build",
          "6334",
          "grpc",
          "newbuilder"
        ],
        "term_weights": [
          {
            "term": "client",
            "tf": 25,
            "weight": 0.092593
          },
          {
            "term": "qdrant",
            "tf": 24,
            "weight": 0.088889
          },
          {
            "term": "query",
            "tf": 11,
            "weight": 0.040741
          },
          {
            "term": "import",
            "tf": 9,
            "weight": 0.033333
          },
          {
            "term": "collection",
            "tf": 8,
            "weight": 0.02963
          },
          {
            "term": "name",
            "tf": 8,
            "weight": 0.02963
          },
          {
            "term": "qdrantclient",
            "tf": 8,
            "weight": 0.02963
          },
          {
            "term": "false",
            "tf": 7,
            "weight": 0.025926
          },
          {
            "term": "new",
            "tf": 7,
            "weight": 0.025926
          },
          {
            "term": "params",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "quantization",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "rescore",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "localhost",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "searchparams",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "points",
            "tf": 5,
            "weight": 0.018519
          },
          {
            "term": "quantizationsearchparams",
            "tf": 5,
            "weight": 0.018519
          },
          {
            "term": "build",
            "tf": 5,
            "weight": 0.018519
          },
          {
            "term": "6334",
            "tf": 4,
            "weight": 0.014815
          },
          {
            "term": "grpc",
            "tf": 4,
            "weight": 0.014815
          },
          {
            "term": "newbuilder",
            "tf": 4,
            "weight": 0.014815
          }
        ],
        "unique_terms": 95,
        "total_terms": 270
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Disable Rescoring for Faster Search (optional)",
        "client",
        "collection",
        "false",
        "import",
        "name",
        "new",
        "params",
        "qdrant",
        "qdrantclient",
        "query"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6943319838056681,
      "overall": 0.7314439946018894
    }
  },
  {
    "text": "## 2. High Precision with Low Memory Usage  If you require high precision but have limited RAM, you can store both vectors and the HNSW index on disk. This setup reduces memory usage while maintaining search precision. To store the vectors `on_disk`, you need to configure both the vectors and the HNSW index: ```http PUT /collections/{collection_name} {     \"vectors\": {       \"size\": 768,       \"distance\": \"Cosine\",       \"on_disk\": true     },     \"hnsw_config\": {         \"on_disk\": true     } } ``` ```python from qdrant_client import QdrantClient, models  client = QdrantClient(url=\"http://localhost:6333\")  client.create_collection(     collection_name=\"{collection_name}\",     vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE, on_disk=True),     hnsw_config=models.HnswConfigDiff(on_disk=True), ) ``` ```typescript import { QdrantClient } from \"@qdrant/js-client-rest\";  const client = new QdrantClient({ host: \"localhost\", port: 6333 });  client.createCollection(\"{collection_name}\", {   vectors: {     size: 768,     distance: \"Cosine\",     on_disk: true,   },   hnsw_config: {     on_disk: true,   }, }); ``` ```rust use qdrant_client::qdrant::{     CreateCollectionBuilder, Distance, HnswConfigDiffBuilder,     VectorParamsBuilder, }; use qdrant_client::Qdrant;  let client = Qdrant::from_url(\"http://localhost:6334\").build()?;  client     .create_collection(         CreateCollectionBuilder::new(\"{collection_name}\")             .vectors_config(VectorParamsBuilder::new(768, Distance::Cosine).on_disk(true))             .hnsw_config(HnswConfigDiffBuilder::default().on_disk(true)),     )     .await?; ``` ```java import io.qdrant.client.QdrantClient; import io.qdrant.client.QdrantGrpcClient; import io.qdrant.client.grpc.Collections.CreateCollection; import io.qdrant.client.grpc.Collections.Distance; import io.qdrant.client.grpc.Collections.HnswConfigDiff; import io.qdrant.client.grpc.Collections.VectorParams; import io.qdrant.client.grpc.Collections.VectorsConfig;  QdrantClient client =     new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());  client     .createCollectionAsync(         CreateCollection.newBuilder()             .setCollectionName(\"{collection_name}\")             .setVectorsConfig(                 VectorsConfig.newBuilder()                     .setParams(                         VectorParams.newBuilder()                             .setSize(768)                             .setDistance(Distance.Cosine)                             .setOnDisk(true)                             .build())                     .build())             .setHnswConfig(HnswConfigDiff.newBuilder().setOnDisk(true).build())             .build())     .get(); ``` ```csharp using Qdrant.Client; using Qdrant.Client.Grpc;  var client = new QdrantClient(\"localhost\", 6334);  await client.CreateCollectionAsync( \tcollectionName: \"{collection_name}\", \tvectorsConfig: new VectorParams { Size = 768, Distance = Distance.Cosine, OnDisk = true }, \thnswConfig: new HnswConfigDiff { OnDisk = true } ); ``` ```go import ( \t\"context\"  \t\"github.com/qdrant/go-client/qdrant\" )  client, err := qdrant.NewClient(&qdrant.Config{ \tHost: \"localhost\", \tPort: 6334, })  client.CreateCollection(context.Background(), &qdrant.CreateCollection{ \tCollectionName: \"{collection_name}\", \tVectorsConfig: qdrant.NewVectorsConfig(&qdrant.VectorParams{ \t\tSize:     768, \t\tDistance: qdrant.Distance_Cosine, \t\tOnDisk:   qdrant.PtrOf(true), \t}), \tHnswConfig: &qdrant.HnswConfigDiff{ \t\tOnDisk: qdrant.PtrOf(true), \t}, }) ```",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0013",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "2. High Precision with Low Memory Usage"
      ],
      "heading_text": "2. High Precision with Low Memory Usage",
      "token_count": 891,
      "char_count": 3558,
      "start_char": 20114,
      "end_char": 23672,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6885057471264369,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.486367",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 891,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "2. High Precision with Low Memory Usage",
      "chunk_hash": "6db670bbddb4f295",
      "content_digest": "6db670bbddb4f295",
      "chunk_length": 3558,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "true",
          "distance",
          "disk",
          "collection",
          "import",
          "name",
          "qdrantclient",
          "vectors",
          "768",
          "cosine",
          "config",
          "new",
          "hnsw",
          "collections",
          "localhost",
          "build",
          "grpc",
          "size"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 27,
            "weight": 0.079882
          },
          {
            "term": "client",
            "tf": 26,
            "weight": 0.076923
          },
          {
            "term": "true",
            "tf": 14,
            "weight": 0.04142
          },
          {
            "term": "distance",
            "tf": 12,
            "weight": 0.035503
          },
          {
            "term": "disk",
            "tf": 10,
            "weight": 0.029586
          },
          {
            "term": "collection",
            "tf": 10,
            "weight": 0.029586
          },
          {
            "term": "import",
            "tf": 10,
            "weight": 0.029586
          },
          {
            "term": "name",
            "tf": 8,
            "weight": 0.023669
          },
          {
            "term": "qdrantclient",
            "tf": 8,
            "weight": 0.023669
          },
          {
            "term": "vectors",
            "tf": 7,
            "weight": 0.02071
          },
          {
            "term": "768",
            "tf": 7,
            "weight": 0.02071
          },
          {
            "term": "cosine",
            "tf": 7,
            "weight": 0.02071
          },
          {
            "term": "config",
            "tf": 7,
            "weight": 0.02071
          },
          {
            "term": "new",
            "tf": 7,
            "weight": 0.02071
          },
          {
            "term": "hnsw",
            "tf": 6,
            "weight": 0.017751
          },
          {
            "term": "collections",
            "tf": 6,
            "weight": 0.017751
          },
          {
            "term": "localhost",
            "tf": 6,
            "weight": 0.017751
          },
          {
            "term": "build",
            "tf": 6,
            "weight": 0.017751
          },
          {
            "term": "grpc",
            "tf": 6,
            "weight": 0.017751
          },
          {
            "term": "size",
            "tf": 5,
            "weight": 0.014793
          }
        ],
        "unique_terms": 99,
        "total_terms": 338
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "2. High Precision with Low Memory Usage",
        "client",
        "collection",
        "disk",
        "distance",
        "import",
        "name",
        "qdrant",
        "qdrantclient",
        "true",
        "vectors"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6885057471264369,
      "overall": 0.7295019157088123
    }
  },
  {
    "text": "## 3. High Precision with High-Speed Search  For scenarios requiring both high speed and high precision, keep as much data in RAM as possible. Apply quantization with re-scoring for tunable accuracy. Here is how you can configure scalar quantization for a collection: ```http PUT /collections/{collection_name} {     \"vectors\": {       \"size\": 768,       \"distance\": \"Cosine\"     },     \"quantization_config\": {         \"scalar\": {             \"type\": \"int8\",             \"always_ram\": true         }     } } ``` ```python from qdrant_client import QdrantClient, models  client = QdrantClient(url=\"http://localhost:6333\")  client.create_collection(     collection_name=\"{collection_name}\",     vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE),     quantization_config=models.ScalarQuantization(         scalar=models.ScalarQuantizationConfig(             type=models.ScalarType.INT8,             always_ram=True,         ),     ), ) ``` ```typescript import { QdrantClient } from \"@qdrant/js-client-rest\";  const client = new QdrantClient({ host: \"localhost\", port: 6333 });  client.createCollection(\"{collection_name}\", {   vectors: {     size: 768,     distance: \"Cosine\",   },   quantization_config: {     scalar: {       type: \"int8\",       always_ram: true,     },   }, }); ``` ```rust use qdrant_client::qdrant::{     CreateCollectionBuilder, Distance, QuantizationType, ScalarQuantizationBuilder,     VectorParamsBuilder, }; use qdrant_client::Qdrant;  let client = Qdrant::from_url(\"http://localhost:6334\").build()?;  client     .create_collection(         CreateCollectionBuilder::new(\"{collection_name}\")             .vectors_config(VectorParamsBuilder::new(768, Distance::Cosine))             .quantization_config(                 ScalarQuantizationBuilder::default()                     .r#type(QuantizationType::Int8.into())                     .always_ram(true),             ),     )     .await?; ``` ```java import io.qdrant.client.QdrantClient; import io.qdrant.client.QdrantGrpcClient; import io.qdrant.client.grpc.Collections.CreateCollection; import io.qdrant.client.grpc.Collections.Distance; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff; import io.qdrant.client.grpc.Collections.QuantizationConfig; import io.qdrant.client.grpc.Collections.QuantizationType; import io.qdrant.client.grpc.Collections.ScalarQuantization; import io.qdrant.client.grpc.Collections.VectorParams; import io.qdrant.client.grpc.Collections.VectorsConfig;  QdrantClient client =     new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());  client     .createCollectionAsync(         CreateCollection.newBuilder()             .setCollectionName(\"{collection_name}\")             .setVectorsConfig(                 VectorsConfig.newBuilder()                     .setParams(                         VectorParams.newBuilder()                             .setSize(768)                             .setDistance(Distance.Cosine)                             .build())                     .build())             .setQuantizationConfig(                 QuantizationConfig.newBuilder()                     .setScalar(                         ScalarQuantization.newBuilder()                             .setType(QuantizationType.Int8)                             .setAlwaysRam(true)                             .build())                     .build())             .build())     .get(); ``` ```csharp using Qdrant.Client; using Qdrant.Client.Grpc;  var client = new QdrantClient(\"localhost\", 6334);  await client.CreateCollectionAsync( \tcollectionName: \"{collection_name}\", \tvectorsConfig: new VectorParams { Size = 768, Distance = Distance.Cosine}, \tquantizationConfig: new QuantizationConfig \t{ \t\tScalar = new ScalarQuantization { Type = QuantizationType.Int8, AlwaysRam = true } \t} ); ``` ```go import ( \t\"context\"  \t\"github.com/qdrant/go-client/qdrant\" )  client, err := qdrant.NewClient(&qdrant.Config{ \tHost: \"localhost\", \tPort: 6334, })  client.CreateCollection(context.Background(), &qdrant.CreateCollection{ \tCollectionName: \"{collection_name}\", \tVectorsConfig: qdrant.NewVectorsConfig(&qdrant.VectorParams{ \t\tSize:     768, \t\tDistance: qdrant.Distance_Cosine, \t}), \tQuantizationConfig: qdrant.NewQuantizationScalar(&qdrant.ScalarQuantization{ \t\tType:      qdrant.QuantizationType_Int8, \t\tAlwaysRam: qdrant.PtrOf(true), \t}), }) ```",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0015",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "3. High Precision with High-Speed Search"
      ],
      "heading_text": "3. High Precision with High-Speed Search",
      "token_count": 1015,
      "char_count": 4390,
      "start_char": 24115,
      "end_char": 28505,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6978723404255318,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.497138",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 1015,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "3. High Precision with High-Speed Search",
      "chunk_hash": "effd7796a4f52827",
      "content_digest": "effd7796a4f52827",
      "chunk_length": 4390,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "import",
          "distance",
          "collection",
          "collections",
          "grpc",
          "name",
          "qdrantclient",
          "new",
          "768",
          "cosine",
          "config",
          "int8",
          "true",
          "build",
          "quantization",
          "type",
          "models",
          "localhost"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 31,
            "weight": 0.083784
          },
          {
            "term": "client",
            "tf": 29,
            "weight": 0.078378
          },
          {
            "term": "import",
            "tf": 13,
            "weight": 0.035135
          },
          {
            "term": "distance",
            "tf": 12,
            "weight": 0.032432
          },
          {
            "term": "collection",
            "tf": 11,
            "weight": 0.02973
          },
          {
            "term": "collections",
            "tf": 9,
            "weight": 0.024324
          },
          {
            "term": "grpc",
            "tf": 9,
            "weight": 0.024324
          },
          {
            "term": "name",
            "tf": 8,
            "weight": 0.021622
          },
          {
            "term": "qdrantclient",
            "tf": 8,
            "weight": 0.021622
          },
          {
            "term": "new",
            "tf": 8,
            "weight": 0.021622
          },
          {
            "term": "768",
            "tf": 7,
            "weight": 0.018919
          },
          {
            "term": "cosine",
            "tf": 7,
            "weight": 0.018919
          },
          {
            "term": "config",
            "tf": 7,
            "weight": 0.018919
          },
          {
            "term": "int8",
            "tf": 7,
            "weight": 0.018919
          },
          {
            "term": "true",
            "tf": 7,
            "weight": 0.018919
          },
          {
            "term": "build",
            "tf": 7,
            "weight": 0.018919
          },
          {
            "term": "quantization",
            "tf": 6,
            "weight": 0.016216
          },
          {
            "term": "type",
            "tf": 6,
            "weight": 0.016216
          },
          {
            "term": "models",
            "tf": 6,
            "weight": 0.016216
          },
          {
            "term": "localhost",
            "tf": 6,
            "weight": 0.016216
          }
        ],
        "unique_terms": 108,
        "total_terms": 370
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "3. High Precision with High-Speed Search",
        "client",
        "collection",
        "collections",
        "distance",
        "grpc",
        "import",
        "name",
        "new",
        "qdrant",
        "qdrantclient"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6978723404255318,
      "overall": 0.7326241134751772
    }
  },
  {
    "text": "### Fine-Tuning Search Parameters  You can adjust search parameters like `hnsw_ef` and `exact` to balance between speed and precision:  **Key Parameters:**  - `hnsw_ef`: Number of neighbors to visit during search (higher value = better accuracy, slower speed). - `exact`: Set to `true` for exact search, which is slower but more accurate. You can use it to compare results of the search with different `hnsw_ef` values versus the ground truth. ```http POST /collections/{collection_name}/points/query {     \"query\": [0.2, 0.1, 0.9, 0.7],     \"params\": {         \"hnsw_ef\": 128,         \"exact\": false     },     \"limit\": 3 } ``` ```python from qdrant_client import QdrantClient, models  client = QdrantClient(url=\"http://localhost:6333\")  client.query_points(     collection_name=\"{collection_name}\",     query=[0.2, 0.1, 0.9, 0.7],     search_params=models.SearchParams(hnsw_ef=128, exact=False),     limit=3, ) ``` ```typescript import { QdrantClient } from \"@qdrant/js-client-rest\";  const client = new QdrantClient({ host: \"localhost\", port: 6333 });  client.query(\"{collection_name}\", {     query: [0.2, 0.1, 0.9, 0.7],     params: {         hnsw_ef: 128,         exact: false,     },     limit: 3, }); ``` ```rust use qdrant_client::qdrant::{QueryPointsBuilder, SearchParamsBuilder}; use qdrant_client::Qdrant;  let client = Qdrant::from_url(\"http://localhost:6334\").build()?;  client     .query(         QueryPointsBuilder::new(\"{collection_name}\")             .query(vec![0.2, 0.1, 0.9, 0.7])             .limit(3)             .params(SearchParamsBuilder::default().hnsw_ef(128).exact(false)),     )     .await?; ``` ```java import io.qdrant.client.QdrantClient; import io.qdrant.client.QdrantGrpcClient; import io.qdrant.client.grpc.Points.QueryPoints; import io.qdrant.client.grpc.Points.SearchParams;  import static io.qdrant.client.QueryFactory.nearest;  QdrantClient client =     new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());  client.queryAsync(         QueryPoints.newBuilder()                 .setCollectionName(\"{collection_name}\")                 .setQuery(nearest(0.2f, 0.1f, 0.9f, 0.7f))                 .setParams(SearchParams.newBuilder().setHnswEf(128).setExact(false).build())                 .setLimit(3)                 .build())         .get(); ``` ```csharp using Qdrant.Client; using Qdrant.Client.Grpc;  var client = new QdrantClient(\"localhost\", 6334);  await client.QueryAsync( \tcollectionName: \"{collection_name}\", \tquery: new float[] { 0.2f, 0.1f, 0.9f, 0.7f }, \tsearchParams: new SearchParams { HnswEf = 128, Exact = false }, \tlimit: 3 ); ``` ```go import ( \t\"context\"  \t\"github.com/qdrant/go-client/qdrant\" )  client, err := qdrant.NewClient(&qdrant.Config{ \tHost: \"localhost\", \tPort: 6334, })  client.Query(context.Background(), &qdrant.QueryPoints{ \tCollectionName: \"{collection_name}\", \tQuery:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7), \tParams: &qdrant.SearchParams{ \t\tHnswEf: qdrant.PtrOf(uint64(128)), \t\tExact:  qdrant.PtrOf(false), \t}, }) ```",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0016",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Fine-Tuning Search Parameters"
      ],
      "heading_text": "Fine-Tuning Search Parameters",
      "token_count": 905,
      "char_count": 3022,
      "start_char": 28515,
      "end_char": 31537,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6951672862453531,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.505039",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 905,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Fine-Tuning Search Parameters",
      "chunk_hash": "11d758fc81d71e28",
      "content_digest": "11d758fc81d71e28",
      "chunk_length": 3022,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "client",
          "qdrant",
          "query",
          "exact",
          "collection",
          "name",
          "false",
          "import",
          "qdrantclient",
          "hnsw",
          "128",
          "search",
          "localhost",
          "searchparams",
          "new",
          "params",
          "limit",
          "points",
          "6334",
          "build"
        ],
        "term_weights": [
          {
            "term": "client",
            "tf": 24,
            "weight": 0.081633
          },
          {
            "term": "qdrant",
            "tf": 23,
            "weight": 0.078231
          },
          {
            "term": "query",
            "tf": 11,
            "weight": 0.037415
          },
          {
            "term": "exact",
            "tf": 9,
            "weight": 0.030612
          },
          {
            "term": "collection",
            "tf": 8,
            "weight": 0.027211
          },
          {
            "term": "name",
            "tf": 8,
            "weight": 0.027211
          },
          {
            "term": "false",
            "tf": 8,
            "weight": 0.027211
          },
          {
            "term": "import",
            "tf": 8,
            "weight": 0.027211
          },
          {
            "term": "qdrantclient",
            "tf": 8,
            "weight": 0.027211
          },
          {
            "term": "hnsw",
            "tf": 7,
            "weight": 0.02381
          },
          {
            "term": "128",
            "tf": 7,
            "weight": 0.02381
          },
          {
            "term": "search",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "localhost",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "searchparams",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "new",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "params",
            "tf": 5,
            "weight": 0.017007
          },
          {
            "term": "limit",
            "tf": 5,
            "weight": 0.017007
          },
          {
            "term": "points",
            "tf": 4,
            "weight": 0.013605
          },
          {
            "term": "6334",
            "tf": 4,
            "weight": 0.013605
          },
          {
            "term": "build",
            "tf": 4,
            "weight": 0.013605
          }
        ],
        "unique_terms": 111,
        "total_terms": 294
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Fine-Tuning Search Parameters",
        "client",
        "collection",
        "exact",
        "false",
        "hnsw",
        "import",
        "name",
        "qdrant",
        "qdrantclient",
        "query"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6951672862453531,
      "overall": 0.7317224287484511
    }
  },
  {
    "text": "## Balancing Latency and Throughput  When optimizing search performance, latency and throughput are two main metrics to consider:  - **Latency:** Time taken for a single request. - **Throughput:** Number of requests handled per second. The following optimization approaches are not mutually exclusive, but in some cases it might be preferable to optimize for one or another.",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0017",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Balancing Latency and Throughput"
      ],
      "heading_text": "Balancing Latency and Throughput",
      "token_count": 73,
      "char_count": 374,
      "start_char": 31546,
      "end_char": 31920,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.506066",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 73,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Balancing Latency and Throughput",
      "chunk_hash": "652059d509172a05",
      "content_digest": "652059d509172a05",
      "chunk_length": 374,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "latency",
          "throughput",
          "and",
          "are",
          "for",
          "balancing",
          "when",
          "optimizing",
          "search",
          "performance",
          "two",
          "main",
          "metrics",
          "consider",
          "time",
          "taken",
          "single",
          "request",
          "number",
          "requests"
        ],
        "term_weights": [
          {
            "term": "latency",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "throughput",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "balancing",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "when",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "optimizing",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "two",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "main",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "metrics",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "consider",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "time",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "taken",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "single",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "request",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "number",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "requests",
            "tf": 1,
            "weight": 0.022222
          }
        ],
        "unique_terms": 38,
        "total_terms": 45
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Balancing Latency and Throughput",
        "and",
        "are",
        "balancing",
        "for",
        "latency",
        "optimizing",
        "performance",
        "search",
        "throughput",
        "when"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "overall": 0.7508333333333331
    }
  },
  {
    "text": "### Minimizing Latency  To minimize latency, you can set up Qdrant to use as many cores as possible for a single request. You can do this by setting the number of segments in the collection to be equal to the number of cores in the system. In this case, each segment will be processed in parallel, and the final result will be obtained faster. ```http PUT /collections/{collection_name} {     \"vectors\": {       \"size\": 768,       \"distance\": \"Cosine\"     },     \"optimizers_config\": {         \"default_segment_number\": 16     } } ``` ```python from qdrant_client import QdrantClient, models  client = QdrantClient(url=\"http://localhost:6333\")  client.create_collection(     collection_name=\"{collection_name}\",     vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE),     optimizers_config=models.OptimizersConfigDiff(default_segment_number=16), ) ``` ```typescript import { QdrantClient } from \"@qdrant/js-client-rest\";  const client = new QdrantClient({ host: \"localhost\", port: 6333 });  client.createCollection(\"{collection_name}\", {   vectors: {     size: 768,     distance: \"Cosine\",   },   optimizers_config: {     default_segment_number: 16,   }, }); ``` ```rust use qdrant_client::qdrant::{     CreateCollectionBuilder, Distance, OptimizersConfigDiffBuilder, VectorParamsBuilder, }; use qdrant_client::Qdrant;  let client = Qdrant::from_url(\"http://localhost:6334\").build()?;  client     .create_collection(         CreateCollectionBuilder::new(\"{collection_name}\")             .vectors_config(VectorParamsBuilder::new(768, Distance::Cosine))             .optimizers_config(                 OptimizersConfigDiffBuilder::default().default_segment_number(16),             ),     )     .await?; ``` ```java import io.qdrant.client.QdrantClient; import io.qdrant.client.QdrantGrpcClient; import io.qdrant.client.grpc.Collections.CreateCollection; import io.qdrant.client.grpc.Collections.Distance; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff; import io.qdrant.client.grpc.Collections.VectorParams; import io.qdrant.client.grpc.Collections.VectorsConfig;  QdrantClient client =     new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());  client     .createCollectionAsync(         CreateCollection.newBuilder()             .setCollectionName(\"{collection_name}\")             .setVectorsConfig(                 VectorsConfig.newBuilder()                     .setParams(                         VectorParams.newBuilder()                             .setSize(768)                             .setDistance(Distance.Cosine)                             .build())                     .build())             .setOptimizersConfig(                 OptimizersConfigDiff.newBuilder().setDefaultSegmentNumber(16).build())             .build())     .get(); ``` ```csharp using Qdrant.Client; using Qdrant.Client.Grpc;  var client = new QdrantClient(\"localhost\", 6334);  await client.CreateCollectionAsync( \tcollectionName: \"{collection_name}\", \tvectorsConfig: new VectorParams { Size = 768, Distance = Distance.Cosine }, \toptimizersConfig: new OptimizersConfigDiff { DefaultSegmentNumber = 16 } ); ``` ```go import ( \t\"context\"  \t\"github.com/qdrant/go-client/qdrant\" )  client, err := qdrant.NewClient(&qdrant.Config{ \tHost: \"localhost\", \tPort: 6334, })  client.CreateCollection(context.Background(), &qdrant.CreateCollection{ \tCollectionName: \"{collection_name}\", \tVectorsConfig: qdrant.NewVectorsConfig(&qdrant.VectorParams{ \t\tSize:     768, \t\tDistance: qdrant.Distance_Cosine, \t}), \tOptimizersConfig: &qdrant.OptimizersConfigDiff{ \t\tDefaultSegmentNumber: qdrant.PtrOf(uint64(16)), \t}, }) ```",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0018",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Minimizing Latency"
      ],
      "heading_text": "Minimizing Latency",
      "token_count": 876,
      "char_count": 3654,
      "start_char": 31923,
      "end_char": 35577,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6954545454545454,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.512280",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 876,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Minimizing Latency",
      "chunk_hash": "c6271e99b73a6b40",
      "content_digest": "c6271e99b73a6b40",
      "chunk_length": 3654,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "distance",
          "collection",
          "import",
          "name",
          "qdrantclient",
          "768",
          "cosine",
          "config",
          "new",
          "number",
          "collections",
          "localhost",
          "build",
          "grpc",
          "the",
          "segment",
          "size",
          "default"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 27,
            "weight": 0.084112
          },
          {
            "term": "client",
            "tf": 26,
            "weight": 0.080997
          },
          {
            "term": "distance",
            "tf": 12,
            "weight": 0.037383
          },
          {
            "term": "collection",
            "tf": 11,
            "weight": 0.034268
          },
          {
            "term": "import",
            "tf": 10,
            "weight": 0.031153
          },
          {
            "term": "name",
            "tf": 8,
            "weight": 0.024922
          },
          {
            "term": "qdrantclient",
            "tf": 8,
            "weight": 0.024922
          },
          {
            "term": "768",
            "tf": 7,
            "weight": 0.021807
          },
          {
            "term": "cosine",
            "tf": 7,
            "weight": 0.021807
          },
          {
            "term": "config",
            "tf": 7,
            "weight": 0.021807
          },
          {
            "term": "new",
            "tf": 7,
            "weight": 0.021807
          },
          {
            "term": "number",
            "tf": 6,
            "weight": 0.018692
          },
          {
            "term": "collections",
            "tf": 6,
            "weight": 0.018692
          },
          {
            "term": "localhost",
            "tf": 6,
            "weight": 0.018692
          },
          {
            "term": "build",
            "tf": 6,
            "weight": 0.018692
          },
          {
            "term": "grpc",
            "tf": 6,
            "weight": 0.018692
          },
          {
            "term": "the",
            "tf": 5,
            "weight": 0.015576
          },
          {
            "term": "segment",
            "tf": 5,
            "weight": 0.015576
          },
          {
            "term": "size",
            "tf": 5,
            "weight": 0.015576
          },
          {
            "term": "default",
            "tf": 5,
            "weight": 0.015576
          }
        ],
        "unique_terms": 102,
        "total_terms": 321
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "768",
        "Minimizing Latency",
        "client",
        "collection",
        "config",
        "cosine",
        "distance",
        "import",
        "name",
        "qdrant",
        "qdrantclient"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6954545454545454,
      "overall": 0.7318181818181818
    }
  },
  {
    "text": "### Maximizing Throughput  To maximize throughput, configure Qdrant to use as many cores as possible to process multiple requests in parallel. To do that, use fewer segments (usually 2) of larger size (default 200Mb per segment) to handle more requests in parallel. Large segments benefit from the size of the index and overall smaller number of vector comparisons required to find the nearest neighbors. However, they will require more time to build the HNSW index. ```http PUT /collections/{collection_name} {     \"vectors\": {       \"size\": 768,       \"distance\": \"Cosine\"     },     \"optimizers_config\": {         \"default_segment_number\": 2,         \"max_segment_size\": 5000000     } } ``` ```python from qdrant_client import QdrantClient, models  client = QdrantClient(url=\"http://localhost:6333\")  client.create_collection(     collection_name=\"{collection_name}\",     vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE),     optimizers_config=models.OptimizersConfigDiff(default_segment_number=2, max_segment_size=5000000), ) ``` ```typescript import { QdrantClient } from \"@qdrant/js-client-rest\";  const client = new QdrantClient({ host: \"localhost\", port: 6333 });  client.createCollection(\"{collection_name}\", {   vectors: {     size: 768,     distance: \"Cosine\",   },   optimizers_config: {     default_segment_number: 2,     max_segment_size: 5000000,   }, }); ``` ```rust use qdrant_client::qdrant::{     CreateCollectionBuilder, Distance, OptimizersConfigDiffBuilder, VectorParamsBuilder, }; use qdrant_client::Qdrant;  let client = Qdrant::from_url(\"http://localhost:6334\").build()?;  client     .create_collection(         CreateCollectionBuilder::new(\"{collection_name}\")             .vectors_config(VectorParamsBuilder::new(768, Distance::Cosine))             .optimizers_config(                 OptimizersConfigDiffBuilder::default().default_segment_number(2).max_segment_size(5000000),             ),     )     .await?; ``` ```java import io.qdrant.client.QdrantClient; import io.qdrant.client.QdrantGrpcClient; import io.qdrant.client.grpc.Collections.CreateCollection; import io.qdrant.client.grpc.Collections.Distance; import io.qdrant.client.grpc.Collections.OptimizersConfigDiff; import io.qdrant.client.grpc.Collections.VectorParams; import io.qdrant.client.grpc.Collections.VectorsConfig;  QdrantClient client =     new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());  client     .createCollectionAsync(         CreateCollection.newBuilder()             .setCollectionName(\"{collection_name}\")             .setVectorsConfig(                 VectorsConfig.newBuilder()                     .setParams(                         VectorParams.newBuilder()                             .setSize(768)                             .setDistance(Distance.Cosine)                             .build())                     .build())             .setOptimizersConfig(                 OptimizersConfigDiff.newBuilder()                     .setDefaultSegmentNumber(2)                     .setMaxSegmentSize(5000000)                     .build()             )             .build())     .get(); ``` ```csharp using Qdrant.Client; using Qdrant.Client.Grpc;  var client = new QdrantClient(\"localhost\", 6334);  await client.CreateCollectionAsync( \tcollectionName: \"{collection_name}\", \tvectorsConfig: new VectorParams { Size = 768, Distance = Distance.Cosine }, \toptimizersConfig: new OptimizersConfigDiff { DefaultSegmentNumber = 2, MaxSegmentSize = 5000000 } ); ``` ```go import ( \t\"context\"  \t\"github.com/qdrant/go-client/qdrant\" )  client, err := qdrant.NewClient(&qdrant.Config{ \tHost: \"localhost\", \tPort: 6334, })  client.CreateCollection(context.Background(), &qdrant.CreateCollection{ \tCollectionName: \"{collection_name}\", \tVectorsConfig: qdrant.NewVectorsConfig(&qdrant.VectorParams{ \t\tSize:     768, \t\tDistance: qdrant.Distance_Cosine, \t}), \tOptimizersConfig: &qdrant.OptimizersConfigDiff{ \t\tDefaultSegmentNumber: qdrant.PtrOf(uint64(2)), \t\tMaxSegmentSize:       qdrant.PtrOf(uint64(5000000)), \t}, }) ```",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0019",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Maximizing Throughput"
      ],
      "heading_text": "Maximizing Throughput",
      "token_count": 977,
      "char_count": 4074,
      "start_char": 35587,
      "end_char": 39661,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6993079584775086,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.519742",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 977,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Maximizing Throughput",
      "chunk_hash": "5dedff3f33261743",
      "content_digest": "5dedff3f33261743",
      "chunk_length": 4074,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "distance",
          "size",
          "collection",
          "import",
          "segment",
          "name",
          "qdrantclient",
          "build",
          "768",
          "cosine",
          "config",
          "5000000",
          "new",
          "default",
          "collections",
          "localhost",
          "grpc",
          "number"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 28,
            "weight": 0.077778
          },
          {
            "term": "client",
            "tf": 26,
            "weight": 0.072222
          },
          {
            "term": "distance",
            "tf": 12,
            "weight": 0.033333
          },
          {
            "term": "size",
            "tf": 11,
            "weight": 0.030556
          },
          {
            "term": "collection",
            "tf": 10,
            "weight": 0.027778
          },
          {
            "term": "import",
            "tf": 10,
            "weight": 0.027778
          },
          {
            "term": "segment",
            "tf": 9,
            "weight": 0.025
          },
          {
            "term": "name",
            "tf": 8,
            "weight": 0.022222
          },
          {
            "term": "qdrantclient",
            "tf": 8,
            "weight": 0.022222
          },
          {
            "term": "build",
            "tf": 7,
            "weight": 0.019444
          },
          {
            "term": "768",
            "tf": 7,
            "weight": 0.019444
          },
          {
            "term": "cosine",
            "tf": 7,
            "weight": 0.019444
          },
          {
            "term": "config",
            "tf": 7,
            "weight": 0.019444
          },
          {
            "term": "5000000",
            "tf": 7,
            "weight": 0.019444
          },
          {
            "term": "new",
            "tf": 7,
            "weight": 0.019444
          },
          {
            "term": "default",
            "tf": 6,
            "weight": 0.016667
          },
          {
            "term": "collections",
            "tf": 6,
            "weight": 0.016667
          },
          {
            "term": "localhost",
            "tf": 6,
            "weight": 0.016667
          },
          {
            "term": "grpc",
            "tf": 6,
            "weight": 0.016667
          },
          {
            "term": "number",
            "tf": 5,
            "weight": 0.013889
          }
        ],
        "unique_terms": 117,
        "total_terms": 360
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Maximizing Throughput",
        "build",
        "client",
        "collection",
        "distance",
        "import",
        "name",
        "qdrant",
        "qdrantclient",
        "segment",
        "size"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6993079584775086,
      "overall": 0.7331026528258362
    }
  },
  {
    "text": "## Summary  By adjusting configurations like vector storage, quantization, and search parameters, you can optimize Qdrant for different use cases:  - **Low Memory + High Speed:** Use vector quantization. - **High Precision + Low Memory:** Store vectors and HNSW index on disk. - **High Precision + High Speed:** Keep data in RAM, use quantization with re-scoring. - **Latency vs. Throughput:** Adjust segment numbers based on the priority. Choose the strategy that best fits your use case to get the most out of Qdrant’s performance capabilities.",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0020",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Summary"
      ],
      "heading_text": "Summary",
      "token_count": 120,
      "char_count": 546,
      "start_char": 39672,
      "end_char": 40218,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.53,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.520961",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 120,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Summary",
      "chunk_hash": "6648decb998c3179",
      "content_digest": "6648decb998c3179",
      "chunk_length": 546,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "use",
          "high",
          "quantization",
          "the",
          "vector",
          "and",
          "qdrant",
          "low",
          "memory",
          "speed",
          "precision",
          "summary",
          "adjusting",
          "configurations",
          "like",
          "storage",
          "search",
          "parameters",
          "you",
          "can"
        ],
        "term_weights": [
          {
            "term": "use",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "high",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "quantization",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "low",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "memory",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "speed",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "precision",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "summary",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "adjusting",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "configurations",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "like",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "storage",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "parameters",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.014286
          }
        ],
        "unique_terms": 53,
        "total_terms": 70
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Summary",
        "and",
        "high",
        "low",
        "memory",
        "qdrant",
        "quantization",
        "speed",
        "the",
        "use",
        "vector"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.53,
      "overall": 0.71
    }
  },
  {
    "text": "##### Was this page useful? Yes No  Thank you for your feedback! 🙏  We are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/optimize.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue. On this page:  - [Optimizing Qdrant Performance: Three Scenarios](#optimizing-qdrant-performance-three-scenarios.md)    - [1. High-Speed Search with Low Memory Usage](#1-high-speed-search-with-low-memory-usage.md)     - [Disable Rescoring for Faster Search (optional)](#disable-rescoring-for-faster-search-optional.md)    - [2. High Precision with Low Memory Usage](#2-high-precision-with-low-memory-usage.md)     - [Improving Precision](#improving-precision.md)    - [3. High Precision with High-Speed Search](#3-high-precision-with-high-speed-search.md)     - [Fine-Tuning Search Parameters](#fine-tuning-search-parameters.md)    - [Balancing Latency and Throughput](#balancing-latency-and-throughput.md)      - [Minimizing Latency](#minimizing-latency.md)     - [Maximizing Throughput](#maximizing-throughput.md)    - [Summary](#summary.md)  * [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/optimize.md) * [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)",
    "metadata": {
      "chunk_id": "caf49a91d5b9-0021",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Was this page useful?"
      ],
      "heading_text": "Was this page useful?",
      "token_count": 367,
      "char_count": 1375,
      "start_char": 40221,
      "end_char": 41596,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7282818181818181,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:32.523532",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 367,
      "document_id": "caf49a91d5b9",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Was this page useful?",
      "chunk_hash": "2ae95b5f9f776619",
      "content_digest": "2ae95b5f9f776619",
      "chunk_length": 1375,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "high",
          "search",
          "page",
          "github",
          "landing",
          "with",
          "precision",
          "https",
          "com",
          "speed",
          "low",
          "memory",
          "usage",
          "latency",
          "throughput",
          "this",
          "for",
          "you",
          "edit"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 8,
            "weight": 0.048485
          },
          {
            "term": "high",
            "tf": 8,
            "weight": 0.048485
          },
          {
            "term": "search",
            "tf": 8,
            "weight": 0.048485
          },
          {
            "term": "page",
            "tf": 7,
            "weight": 0.042424
          },
          {
            "term": "github",
            "tf": 7,
            "weight": 0.042424
          },
          {
            "term": "landing",
            "tf": 6,
            "weight": 0.036364
          },
          {
            "term": "with",
            "tf": 6,
            "weight": 0.036364
          },
          {
            "term": "precision",
            "tf": 6,
            "weight": 0.036364
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "speed",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "low",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "memory",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "usage",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "latency",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "throughput",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "this",
            "tf": 3,
            "weight": 0.018182
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.018182
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.012121
          },
          {
            "term": "edit",
            "tf": 2,
            "weight": 0.012121
          }
        ],
        "unique_terms": 59,
        "total_terms": 165
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Was this page useful?",
        "com",
        "github",
        "high",
        "https",
        "landing",
        "page",
        "precision",
        "qdrant",
        "search",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7282818181818181,
      "overall": 0.7427606060606061
    }
  }
]
[
  {
    "text": "### Essentials  [Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)  [Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)  [Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)  [Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)  [Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)  [5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)  [Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)",
    "metadata": {
      "chunk_id": "a04e36e09b40-0000",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Essentials"
      ],
      "heading_text": "Essentials",
      "token_count": 189,
      "char_count": 673,
      "start_char": 681,
      "end_char": 1354,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5053846153846153,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.736568",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 189,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Essentials",
      "chunk_hash": "a64044a3995d82e4",
      "content_digest": "a64044a3995d82e4",
      "chunk_length": 673,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "https",
          "tech",
          "documentation",
          "agentic",
          "with",
          "data",
          "ingestion",
          "beginners",
          "langgraph",
          "discord",
          "multimodal",
          "and",
          "deepseek",
          "n8n",
          "essentials",
          "for",
          "simple",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "documentation",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "agentic",
            "tf": 6,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "beginners",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "langgraph",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "discord",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "multimodal",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "deepseek",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "n8n",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "essentials",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 31,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Essentials",
        "agentic",
        "beginners",
        "data",
        "documentation",
        "https",
        "ingestion",
        "qdrant",
        "rag",
        "tech",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5053846153846153,
      "overall": 0.7017948717948718
    }
  },
  {
    "text": "### Integrations  [Data Management](https://qdrant.tech/documentation/data-management/)  - [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/) - [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/) - [Apache Spark](https://qdrant.tech/documentation/data-management/spark/) - [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/) - [cognee](https://qdrant.tech/documentation/data-management/cognee/) - [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/) - [DLT](https://qdrant.tech/documentation/data-management/dlt/) - [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/) - [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/) - [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)  [Embeddings](https://qdrant.tech/documentation/embeddings/)  - [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/) - [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/) - [Cohere](https://qdrant.tech/documentation/embeddings/cohere/) - [Gemini](https://qdrant.tech/documentation/embeddings/gemini/) - [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/) - [Mistral](https://qdrant.tech/documentation/embeddings/mistral/) - [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/) - [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/) - [Nomic](https://qdrant.tech/documentation/embeddings/nomic/) - [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/) - [Ollama](https://qdrant.tech/documentation/embeddings/ollama/) - [OpenAI](https://qdrant.tech/documentation/embeddings/openai/) - [Prem AI](https://qdrant.tech/documentation/embeddings/premai/) - [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/) - [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/) - [Upstage](https://qdrant.tech/documentation/embeddings/upstage/) - [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)  [Frameworks](https://qdrant.tech/documentation/frameworks/)  - [Autogen](https://qdrant.tech/documentation/frameworks/autogen/) - [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/) - [CamelAI](https://qdrant.tech/documentation/frameworks/camel/) - [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/) - [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/) - [Dagster](https://qdrant.tech/documentation/frameworks/dagster/) - [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/) - [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/) - [Feast](https://qdrant.tech/documentation/frameworks/feast/) - [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/) - [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/) - [Haystack](https://qdrant.tech/documentation/frameworks/haystack/) - [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/) - [Langchain](https://qdrant.tech/documentation/frameworks/langchain/) - [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/) - [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/) - [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/) - [Mastra](https://qdrant.tech/documentation/frameworks/mastra/) - [Mem0](https://qdrant.tech/documentation/frameworks/mem0/) - [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/) - [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/) - [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/) - [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/) - [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/) - [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/) - [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/) - [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/) - [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/) - [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/) - [txtai](https://qdrant.tech/documentation/frameworks/txtai/) - [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/) - [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/) - [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)  [Observability](https://qdrant.tech/documentation/observability/)  - [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/) - [OpenLIT](https://qdrant.tech/documentation/observability/openlit/) - [Datadog](https://qdrant.tech/documentation/observability/datadog/)  [Platforms](https://qdrant.tech/documentation/platforms/)  - [Apify](https://qdrant.tech/documentation/platforms/apify/) - [BuildShip](https://qdrant.tech/documentation/platforms/buildship/) - [Keboola](https://qdrant.tech/documentation/platforms/keboola/) - [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/) - [Make.com](https://qdrant.tech/documentation/platforms/make/) - [N8N](https://qdrant.tech/documentation/platforms/n8n/) - [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/) - [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/) - [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/) - [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/) - [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/) - [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)",
    "metadata": {
      "chunk_id": "a04e36e09b40-0001",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integrations"
      ],
      "heading_text": "Integrations",
      "token_count": 1498,
      "char_count": 5661,
      "start_char": 1356,
      "end_char": 7017,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.779456",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 1498,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Integrations",
      "chunk_hash": "8a3f2e84e2a75ae9",
      "content_digest": "8a3f2e84e2a75ae9",
      "chunk_length": 5661,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "frameworks",
          "embeddings",
          "platforms",
          "data",
          "management",
          "observability",
          "airbyte",
          "apache",
          "airflow",
          "spark",
          "cocoindex",
          "cognee",
          "confluent",
          "dlt",
          "fluvio",
          "redpanda"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "qdrant",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "tech",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "documentation",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "frameworks",
            "tf": 35,
            "weight": 0.058528
          },
          {
            "term": "embeddings",
            "tf": 21,
            "weight": 0.035117
          },
          {
            "term": "platforms",
            "tf": 14,
            "weight": 0.023411
          },
          {
            "term": "data",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "management",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "observability",
            "tf": 5,
            "weight": 0.008361
          },
          {
            "term": "airbyte",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "apache",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "airflow",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "spark",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cocoindex",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cognee",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "confluent",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "dlt",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "fluvio",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "redpanda",
            "tf": 2,
            "weight": 0.003344
          }
        ],
        "unique_terms": 113,
        "total_terms": 598
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integrations",
        "data",
        "documentation",
        "embeddings",
        "frameworks",
        "https",
        "management",
        "observability",
        "platforms",
        "qdrant",
        "tech"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "overall": 0.7576923076923077
    }
  },
  {
    "text": "### Examples  [Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)  - [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) - [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)  [Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)  - [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/) - [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/) - [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)  [Build Prototypes](https://qdrant.tech/documentation/examples/)  - [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/) - [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/) - [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/) - [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/) - [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/) - [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/) - [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/) - [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/) - [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/) - [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/) - [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/) - [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)  [Practice Datasets](https://qdrant.tech/documentation/datasets/)",
    "metadata": {
      "chunk_id": "a04e36e09b40-0002",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Examples"
      ],
      "heading_text": "Examples",
      "token_count": 576,
      "char_count": 2347,
      "start_char": 7019,
      "end_char": 9366,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.9076923076923078,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.796974",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 576,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Examples",
      "chunk_hash": "59078d11dd9c9931",
      "content_digest": "59078d11dd9c9931",
      "chunk_length": 2347,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "https",
          "tech",
          "documentation",
          "examples",
          "search",
          "with",
          "rag",
          "data",
          "chatbot",
          "send",
          "system",
          "semantic",
          "and",
          "cohere",
          "precision",
          "reranking",
          "dspy",
          "for",
          "automate"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 30,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "tech",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "documentation",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "examples",
            "tf": 14,
            "weight": 0.05
          },
          {
            "term": "search",
            "tf": 10,
            "weight": 0.035714
          },
          {
            "term": "with",
            "tf": 9,
            "weight": 0.032143
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.032143
          },
          {
            "term": "data",
            "tf": 7,
            "weight": 0.025
          },
          {
            "term": "chatbot",
            "tf": 6,
            "weight": 0.021429
          },
          {
            "term": "send",
            "tf": 5,
            "weight": 0.017857
          },
          {
            "term": "system",
            "tf": 5,
            "weight": 0.017857
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "cohere",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "dspy",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "automate",
            "tf": 2,
            "weight": 0.007143
          }
        ],
        "unique_terms": 96,
        "total_terms": 280
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Examples",
        "chatbot",
        "data",
        "documentation",
        "examples",
        "https",
        "qdrant",
        "rag",
        "search",
        "tech",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.9076923076923078,
      "overall": 0.8358974358974359
    }
  },
  {
    "text": "### Essentials  [Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)  [Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)  [Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)  [Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)  [Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)  [5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)  [Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)",
    "metadata": {
      "chunk_id": "a04e36e09b40-0003",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Essentials"
      ],
      "heading_text": "Essentials",
      "token_count": 189,
      "char_count": 673,
      "start_char": 9368,
      "end_char": 10041,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5053846153846153,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.803677",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 189,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Essentials",
      "chunk_hash": "a64044a3995d82e4",
      "content_digest": "a64044a3995d82e4",
      "chunk_length": 673,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "https",
          "tech",
          "documentation",
          "agentic",
          "with",
          "data",
          "ingestion",
          "beginners",
          "langgraph",
          "discord",
          "multimodal",
          "and",
          "deepseek",
          "n8n",
          "essentials",
          "for",
          "simple",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "documentation",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "agentic",
            "tf": 6,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "beginners",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "langgraph",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "discord",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "multimodal",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "deepseek",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "n8n",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "essentials",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 31,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Essentials",
        "agentic",
        "beginners",
        "data",
        "documentation",
        "https",
        "ingestion",
        "qdrant",
        "rag",
        "tech",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5053846153846153,
      "overall": 0.7017948717948718
    }
  },
  {
    "text": "### Integrations  [Data Management](https://qdrant.tech/documentation/data-management/)  - [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/) - [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/) - [Apache Spark](https://qdrant.tech/documentation/data-management/spark/) - [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/) - [cognee](https://qdrant.tech/documentation/data-management/cognee/) - [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/) - [DLT](https://qdrant.tech/documentation/data-management/dlt/) - [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/) - [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/) - [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)  [Embeddings](https://qdrant.tech/documentation/embeddings/)  - [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/) - [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/) - [Cohere](https://qdrant.tech/documentation/embeddings/cohere/) - [Gemini](https://qdrant.tech/documentation/embeddings/gemini/) - [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/) - [Mistral](https://qdrant.tech/documentation/embeddings/mistral/) - [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/) - [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/) - [Nomic](https://qdrant.tech/documentation/embeddings/nomic/) - [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/) - [Ollama](https://qdrant.tech/documentation/embeddings/ollama/) - [OpenAI](https://qdrant.tech/documentation/embeddings/openai/) - [Prem AI](https://qdrant.tech/documentation/embeddings/premai/) - [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/) - [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/) - [Upstage](https://qdrant.tech/documentation/embeddings/upstage/) - [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)  [Frameworks](https://qdrant.tech/documentation/frameworks/)  - [Autogen](https://qdrant.tech/documentation/frameworks/autogen/) - [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/) - [CamelAI](https://qdrant.tech/documentation/frameworks/camel/) - [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/) - [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/) - [Dagster](https://qdrant.tech/documentation/frameworks/dagster/) - [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/) - [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/) - [Feast](https://qdrant.tech/documentation/frameworks/feast/) - [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/) - [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/) - [Haystack](https://qdrant.tech/documentation/frameworks/haystack/) - [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/) - [Langchain](https://qdrant.tech/documentation/frameworks/langchain/) - [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/) - [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/) - [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/) - [Mastra](https://qdrant.tech/documentation/frameworks/mastra/) - [Mem0](https://qdrant.tech/documentation/frameworks/mem0/) - [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/) - [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/) - [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/) - [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/) - [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/) - [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/) - [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/) - [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/) - [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/) - [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/) - [txtai](https://qdrant.tech/documentation/frameworks/txtai/) - [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/) - [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/) - [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)  [Observability](https://qdrant.tech/documentation/observability/)  - [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/) - [OpenLIT](https://qdrant.tech/documentation/observability/openlit/) - [Datadog](https://qdrant.tech/documentation/observability/datadog/)  [Platforms](https://qdrant.tech/documentation/platforms/)  - [Apify](https://qdrant.tech/documentation/platforms/apify/) - [BuildShip](https://qdrant.tech/documentation/platforms/buildship/) - [Keboola](https://qdrant.tech/documentation/platforms/keboola/) - [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/) - [Make.com](https://qdrant.tech/documentation/platforms/make/) - [N8N](https://qdrant.tech/documentation/platforms/n8n/) - [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/) - [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/) - [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/) - [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/) - [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/) - [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)",
    "metadata": {
      "chunk_id": "a04e36e09b40-0004",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integrations"
      ],
      "heading_text": "Integrations",
      "token_count": 1498,
      "char_count": 5661,
      "start_char": 10043,
      "end_char": 15704,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.843823",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 1498,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Integrations",
      "chunk_hash": "8a3f2e84e2a75ae9",
      "content_digest": "8a3f2e84e2a75ae9",
      "chunk_length": 5661,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "frameworks",
          "embeddings",
          "platforms",
          "data",
          "management",
          "observability",
          "airbyte",
          "apache",
          "airflow",
          "spark",
          "cocoindex",
          "cognee",
          "confluent",
          "dlt",
          "fluvio",
          "redpanda"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "qdrant",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "tech",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "documentation",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "frameworks",
            "tf": 35,
            "weight": 0.058528
          },
          {
            "term": "embeddings",
            "tf": 21,
            "weight": 0.035117
          },
          {
            "term": "platforms",
            "tf": 14,
            "weight": 0.023411
          },
          {
            "term": "data",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "management",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "observability",
            "tf": 5,
            "weight": 0.008361
          },
          {
            "term": "airbyte",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "apache",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "airflow",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "spark",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cocoindex",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cognee",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "confluent",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "dlt",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "fluvio",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "redpanda",
            "tf": 2,
            "weight": 0.003344
          }
        ],
        "unique_terms": 113,
        "total_terms": 598
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integrations",
        "data",
        "documentation",
        "embeddings",
        "frameworks",
        "https",
        "management",
        "observability",
        "platforms",
        "qdrant",
        "tech"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "overall": 0.7576923076923077
    }
  },
  {
    "text": "### Examples  [Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)  - [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) - [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)  [Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)  - [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/) - [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/) - [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)  [Build Prototypes](https://qdrant.tech/documentation/examples/)  - [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/) - [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/) - [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/) - [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/) - [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/) - [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/) - [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/) - [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/) - [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/) - [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/) - [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/) - [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)  [Practice Datasets](https://qdrant.tech/documentation/datasets/)  - [Documentation](https://qdrant.tech/documentation/) - - [Examples](https://qdrant.tech/documentation/examples/) - - GraphRAG with Qdrant and Neo4j",
    "metadata": {
      "chunk_id": "a04e36e09b40-0005",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Examples"
      ],
      "heading_text": "Examples",
      "token_count": 616,
      "char_count": 2497,
      "start_char": 15706,
      "end_char": 18203,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.8976744186046512,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.851471",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 616,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Examples",
      "chunk_hash": "7fe7c46771088e67",
      "content_digest": "7fe7c46771088e67",
      "chunk_length": 2497,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "documentation",
          "https",
          "tech",
          "examples",
          "search",
          "with",
          "rag",
          "data",
          "chatbot",
          "send",
          "and",
          "system",
          "semantic",
          "cohere",
          "precision",
          "reranking",
          "graphrag",
          "neo4j",
          "dspy"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 33,
            "weight": 0.111486
          },
          {
            "term": "documentation",
            "tf": 24,
            "weight": 0.081081
          },
          {
            "term": "https",
            "tf": 23,
            "weight": 0.077703
          },
          {
            "term": "tech",
            "tf": 23,
            "weight": 0.077703
          },
          {
            "term": "examples",
            "tf": 16,
            "weight": 0.054054
          },
          {
            "term": "search",
            "tf": 10,
            "weight": 0.033784
          },
          {
            "term": "with",
            "tf": 10,
            "weight": 0.033784
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.030405
          },
          {
            "term": "data",
            "tf": 7,
            "weight": 0.023649
          },
          {
            "term": "chatbot",
            "tf": 6,
            "weight": 0.02027
          },
          {
            "term": "send",
            "tf": 5,
            "weight": 0.016892
          },
          {
            "term": "and",
            "tf": 5,
            "weight": 0.016892
          },
          {
            "term": "system",
            "tf": 5,
            "weight": 0.016892
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.013514
          },
          {
            "term": "cohere",
            "tf": 4,
            "weight": 0.013514
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010135
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.010135
          },
          {
            "term": "graphrag",
            "tf": 3,
            "weight": 0.010135
          },
          {
            "term": "neo4j",
            "tf": 3,
            "weight": 0.010135
          },
          {
            "term": "dspy",
            "tf": 3,
            "weight": 0.010135
          }
        ],
        "unique_terms": 96,
        "total_terms": 296
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Examples",
        "chatbot",
        "data",
        "documentation",
        "examples",
        "https",
        "qdrant",
        "rag",
        "search",
        "tech",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.8976744186046512,
      "overall": 0.8325581395348838
    }
  },
  {
    "text": "# Build a GraphRAG Agent with Neo4j and Qdrant  | Time: 30 min | Level: Intermediate | Output: [GitHub](https://github.com/qdrant/examples/blob/master/graphrag_neo4j/graphrag.py) | | ------------ | ------------------- | ------------------------------------------------------------------------------------------- |  To make Artificial Intelligence (AI) systems more intelligent and reliable, we face a paradox: Large Language Models (LLMs) possess remarkable reasoning capabilities, yet they struggle to connect information in ways humans find intuitive. While groundbreaking, Retrieval-Augmented Generation (RAG) approaches often fall short when tasked with complex information synthesis. When asked to connect disparate pieces of information or understand holistic concepts across large documents, these systems frequently miss crucial connections that would be obvious to human experts. To solve these problems, Microsoft introduced **GraphRAG,** which uses Knowledge Graphs (KGs) instead of vectors as a context for LLMs. GraphRAG depends mainly on LLMs for creating KGs and querying them. However, this reliance on LLMs can lead to many problems. We will address these challenges by combining vector databases with graph-based databases. This tutorial will demonstrate how to build a GraphRAG system with vector search using Neo4j and Qdrant. | Additional Materials                                                                                                                                                         | | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | This advanced tutorial is based on our original integration doc: [**Neo4j - Qdrant Integration**](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)              | | The output for this tutorial is in our GitHub Examples repo: [**Neo4j - Qdrant Agent in Python**](https://github.com/qdrant/examples/blob/master/graphrag_neo4j/graphrag.py) |",
    "metadata": {
      "chunk_id": "a04e36e09b40-0006",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Build a GraphRAG Agent with Neo4j and Qdrant"
      ],
      "heading_text": "Build a GraphRAG Agent with Neo4j and Qdrant",
      "token_count": 360,
      "char_count": 2054,
      "start_char": 18205,
      "end_char": 20259,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7173023255813954,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.852946",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 360,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Build a GraphRAG Agent with Neo4j and Qdrant",
      "chunk_hash": "e85bf6f2e78a0539",
      "content_digest": "e85bf6f2e78a0539",
      "chunk_length": 2054,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "graphrag",
          "neo4j",
          "qdrant",
          "with",
          "and",
          "github",
          "llms",
          "this",
          "https",
          "examples",
          "information",
          "these",
          "for",
          "tutorial",
          "build",
          "agent",
          "output",
          "com",
          "blob",
          "master"
        ],
        "term_weights": [
          {
            "term": "graphrag",
            "tf": 9,
            "weight": 0.046875
          },
          {
            "term": "neo4j",
            "tf": 7,
            "weight": 0.036458
          },
          {
            "term": "qdrant",
            "tf": 7,
            "weight": 0.036458
          },
          {
            "term": "with",
            "tf": 4,
            "weight": 0.020833
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.020833
          },
          {
            "term": "github",
            "tf": 4,
            "weight": 0.020833
          },
          {
            "term": "llms",
            "tf": 4,
            "weight": 0.020833
          },
          {
            "term": "this",
            "tf": 4,
            "weight": 0.020833
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.015625
          },
          {
            "term": "examples",
            "tf": 3,
            "weight": 0.015625
          },
          {
            "term": "information",
            "tf": 3,
            "weight": 0.015625
          },
          {
            "term": "these",
            "tf": 3,
            "weight": 0.015625
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.015625
          },
          {
            "term": "tutorial",
            "tf": 3,
            "weight": 0.015625
          },
          {
            "term": "build",
            "tf": 2,
            "weight": 0.010417
          },
          {
            "term": "agent",
            "tf": 2,
            "weight": 0.010417
          },
          {
            "term": "output",
            "tf": 2,
            "weight": 0.010417
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.010417
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.010417
          },
          {
            "term": "master",
            "tf": 2,
            "weight": 0.010417
          }
        ],
        "unique_terms": 127,
        "total_terms": 192
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Build a GraphRAG Agent with Neo4j and Qdrant",
        "and",
        "examples",
        "github",
        "graphrag",
        "https",
        "llms",
        "neo4j",
        "qdrant",
        "this",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7173023255813954,
      "overall": 0.805767441860465
    }
  },
  {
    "text": "# RAG & Its Challenges\n\n[RAG](https://qdrant.tech/rag/) combines retrieval-based and generative AI to enhance LLMs with relevant, up-to-date information from a knowledge base, like a vector database. However, RAG faces several challenges:\n\n1. **Understanding Context:** Models may misinterpret queries, particularly when the context is complex or ambiguous, leading to incorrect or irrelevant answers.\n2. **Balancing Similarity vs. Relevance:** RAG systems can struggle to ensure that retrieved information is similar and contextually relevant.\n3. **Answer Completeness:** Traditional RAGs might not be able to capture all relevant details for complex queries that require LLMs to find relationships in the context that are not explicitly present.",
    "metadata": {
      "chunk_id": "a04e36e09b40-0008",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "RAG & Its Challenges"
      ],
      "heading_text": "RAG & Its Challenges",
      "token_count": 153,
      "char_count": 747,
      "start_char": 20284,
      "end_char": 21031,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5370588235294117,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.853840",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 153,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "RAG & Its Challenges",
      "chunk_hash": "216241e16aceaa7f",
      "content_digest": "216241e16aceaa7f",
      "chunk_length": 747,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "rag",
          "relevant",
          "context",
          "that",
          "challenges",
          "and",
          "llms",
          "information",
          "queries",
          "the",
          "complex",
          "not",
          "its",
          "https",
          "qdrant",
          "tech",
          "combines",
          "retrieval",
          "based",
          "generative"
        ],
        "term_weights": [
          {
            "term": "rag",
            "tf": 5,
            "weight": 0.057471
          },
          {
            "term": "relevant",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "context",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "that",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "challenges",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "llms",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "information",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "queries",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "complex",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "not",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "its",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "tech",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "combines",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "retrieval",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "generative",
            "tf": 1,
            "weight": 0.011494
          }
        ],
        "unique_terms": 69,
        "total_terms": 87
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "RAG & Its Challenges",
        "and",
        "challenges",
        "context",
        "information",
        "llms",
        "queries",
        "rag",
        "relevant",
        "that",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5370588235294117,
      "overall": 0.7123529411764705
    }
  },
  {
    "text": "# Introduction to GraphRAG  Unlike RAG, which typically relies on document retrieval, GraphRAG builds knowledge graphs (KGs) to capture entities and their relationships. For datasets or use cases that demand human-level intelligence from an AI system, GraphRAG offers a promising solution:  - It can follow chains of relationships to answer complex queries, making it suitable for better reasoning beyond simple document retrieval. - The graph structure allows a deeper understanding of the context, leading to more accurate and relevant responses. The workflow of GraphRAG is as follows:  1. The LLM analyzes the dataset to identify entities (people, places, organizations) and their relationships, creating a comprehensive knowledge graph where entities are nodes and their connections form edges. 2. A bottom-up clustering algorithm organizes the KG into hierarchical semantic groups. This creates meaningful segments of related information, enabling understanding at different levels of abstraction. 3. GraphRAG uses both the KG and semantic clusters to select a relevant context for the LLM when answering queries. [Fig](https://arxiv.org/pdf/2404.16130) 1: A Complete Picture of GraphRAG Ingestion and Retrieval",
    "metadata": {
      "chunk_id": "a04e36e09b40-0009",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Introduction to GraphRAG"
      ],
      "heading_text": "Introduction to GraphRAG",
      "token_count": 242,
      "char_count": 1217,
      "start_char": 21033,
      "end_char": 22250,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5062790697674419,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.854349",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 242,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Introduction to GraphRAG",
      "chunk_hash": "93f2f0f7e1d69eee",
      "content_digest": "93f2f0f7e1d69eee",
      "chunk_length": 1217,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "graphrag",
          "and",
          "retrieval",
          "entities",
          "their",
          "relationships",
          "for",
          "document",
          "knowledge",
          "queries",
          "graph",
          "understanding",
          "context",
          "relevant",
          "llm",
          "semantic",
          "introduction",
          "unlike",
          "rag"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 8,
            "weight": 0.055944
          },
          {
            "term": "graphrag",
            "tf": 6,
            "weight": 0.041958
          },
          {
            "term": "and",
            "tf": 6,
            "weight": 0.041958
          },
          {
            "term": "retrieval",
            "tf": 3,
            "weight": 0.020979
          },
          {
            "term": "entities",
            "tf": 3,
            "weight": 0.020979
          },
          {
            "term": "their",
            "tf": 3,
            "weight": 0.020979
          },
          {
            "term": "relationships",
            "tf": 3,
            "weight": 0.020979
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.020979
          },
          {
            "term": "document",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "knowledge",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "queries",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "graph",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "understanding",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "context",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "relevant",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "llm",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "semantic",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "introduction",
            "tf": 1,
            "weight": 0.006993
          },
          {
            "term": "unlike",
            "tf": 1,
            "weight": 0.006993
          },
          {
            "term": "rag",
            "tf": 1,
            "weight": 0.006993
          }
        ],
        "unique_terms": 107,
        "total_terms": 143
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Introduction to GraphRAG",
        "and",
        "document",
        "entities",
        "for",
        "graphrag",
        "knowledge",
        "relationships",
        "retrieval",
        "the",
        "their"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5062790697674419,
      "overall": 0.7020930232558139
    }
  },
  {
    "text": "### Challenges of GraphRAG  Despite its advantages, the LLM-centric GraphRAG approach faces several challenges:  - **KG Construction with LLMs:** Since the LLM is responsible for constructing the knowledge graph, there are risks such as inconsistencies, propagation of biases or errors, and lack of control over the ontology used. However, we used a LLM to extract the ontology in our implementation. - **Querying KG with LLMs:** Once the graph is constructed, an LLM translates the human query into Cypher (Neo4j’s declarative query language). However, crafting complex queries in Cypher may result in inaccurate outcomes. - **Scalability & Cost Consideration:** To be practical, applications must be both scalable and cost-effective. Relying on LLMs increases costs and decreases scalability, as they are used every time data is added, queried, or generated. To address these challenges, a more controlled and structured knowledge representation system may be required for GraphRAG to function optimally at scale.",
    "metadata": {
      "chunk_id": "a04e36e09b40-0010",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Challenges of GraphRAG"
      ],
      "heading_text": "Challenges of GraphRAG",
      "token_count": 210,
      "char_count": 1015,
      "start_char": 22254,
      "end_char": 23269,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.51,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.857681",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 210,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Challenges of GraphRAG",
      "chunk_hash": "f3048f1795bab4b4",
      "content_digest": "f3048f1795bab4b4",
      "chunk_length": 1015,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "llm",
          "and",
          "challenges",
          "graphrag",
          "llms",
          "used",
          "with",
          "for",
          "knowledge",
          "graph",
          "are",
          "ontology",
          "however",
          "query",
          "cypher",
          "may",
          "scalability",
          "cost",
          "despite"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 7,
            "weight": 0.058824
          },
          {
            "term": "llm",
            "tf": 4,
            "weight": 0.033613
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.033613
          },
          {
            "term": "challenges",
            "tf": 3,
            "weight": 0.02521
          },
          {
            "term": "graphrag",
            "tf": 3,
            "weight": 0.02521
          },
          {
            "term": "llms",
            "tf": 3,
            "weight": 0.02521
          },
          {
            "term": "used",
            "tf": 3,
            "weight": 0.02521
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "knowledge",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "graph",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "ontology",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "however",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "cypher",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "may",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "scalability",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "cost",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "despite",
            "tf": 1,
            "weight": 0.008403
          }
        ],
        "unique_terms": 87,
        "total_terms": 119
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Challenges of GraphRAG",
        "and",
        "challenges",
        "for",
        "graphrag",
        "knowledge",
        "llm",
        "llms",
        "the",
        "used",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.51,
      "overall": 0.7366666666666667
    }
  },
  {
    "text": "# Architecture Overview\n\nThe architecture has two main components: **Ingestion** and **Retrieval & Generation**. Ingestion processes raw data into structured knowledge and vector representations, while Retrieval and Generation enable efficient querying and response generation.\n\nThis process is divided into two steps: **Ingestion**, where data is prepared and stored, and **Retrieval and Generation**, where the prepared data is queried and utilized. Let’s start with Ingestion.",
    "metadata": {
      "chunk_id": "a04e36e09b40-0011",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Architecture Overview"
      ],
      "heading_text": "Architecture Overview",
      "token_count": 95,
      "char_count": 479,
      "start_char": 23272,
      "end_char": 23751,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7056250000000001,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.858497",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 95,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Architecture Overview",
      "chunk_hash": "83a7bbf5fc6ce657",
      "content_digest": "83a7bbf5fc6ce657",
      "chunk_length": 479,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "and",
          "ingestion",
          "generation",
          "retrieval",
          "data",
          "architecture",
          "the",
          "two",
          "into",
          "where",
          "prepared",
          "overview",
          "has",
          "main",
          "components",
          "processes",
          "raw",
          "structured",
          "knowledge",
          "vector"
        ],
        "term_weights": [
          {
            "term": "and",
            "tf": 8,
            "weight": 0.135593
          },
          {
            "term": "ingestion",
            "tf": 4,
            "weight": 0.067797
          },
          {
            "term": "generation",
            "tf": 4,
            "weight": 0.067797
          },
          {
            "term": "retrieval",
            "tf": 3,
            "weight": 0.050847
          },
          {
            "term": "data",
            "tf": 3,
            "weight": 0.050847
          },
          {
            "term": "architecture",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "two",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "into",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "where",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "prepared",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "overview",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "has",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "main",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "components",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "processes",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "raw",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "structured",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "knowledge",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.016949
          }
        ],
        "unique_terms": 36,
        "total_terms": 59
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Architecture Overview",
        "and",
        "architecture",
        "data",
        "generation",
        "ingestion",
        "into",
        "retrieval",
        "the",
        "two",
        "where"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7056250000000001,
      "overall": 0.7685416666666667
    }
  },
  {
    "text": "## Ingestion\n\nThe GraphRAG ingestion pipeline combines a **Graph Database** and a **Vector Database** to improve RAG workflows.\n\nFig 2: Overview of Ingestion Pipeline\n\nLet’s break it down:\n\n1. **Raw Data:** Serves as the foundation, comprising unstructured or structured content.\n2. **Ontology Creation:** An **LLM** processes the raw data into an **ontology**, structuring entities, relationships, and hierarchies. Better approaches exist to extracting more structured information from raw data, like using NER to identify the names of people, organizations, and places. Unlike LLMs, this method creates.\n3. **Graph Database:** The ontology is stored in a **Graph database** to capture complex relationships.\n4. **Vector Embeddings:** An **Embedding model** converts the raw data into high-dimensional vectors capturing semantic similarities.\n5. **Vector Database:** These embeddings are stored in a **Vector database** for similarity-based retrieval.\n6. **Database Interlinking:** The **Graph database** (e.g., Neo4j) and **Vector database** (e.g., Qdrant) share unique IDs, enabling cross-referencing between ontology-based and vector-based results.",
    "metadata": {
      "chunk_id": "a04e36e09b40-0012",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Ingestion"
      ],
      "heading_text": "Ingestion",
      "token_count": 252,
      "char_count": 1152,
      "start_char": 23753,
      "end_char": 24905,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5056862745098039,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.859703",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 252,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Ingestion",
      "chunk_hash": "70c46cf55f78897b",
      "content_digest": "70c46cf55f78897b",
      "chunk_length": 1152,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "database",
          "the",
          "vector",
          "and",
          "graph",
          "raw",
          "data",
          "ontology",
          "ingestion",
          "based",
          "pipeline",
          "structured",
          "into",
          "relationships",
          "stored",
          "embeddings",
          "graphrag",
          "combines",
          "improve",
          "rag"
        ],
        "term_weights": [
          {
            "term": "database",
            "tf": 9,
            "weight": 0.069767
          },
          {
            "term": "the",
            "tf": 7,
            "weight": 0.054264
          },
          {
            "term": "vector",
            "tf": 6,
            "weight": 0.046512
          },
          {
            "term": "and",
            "tf": 5,
            "weight": 0.03876
          },
          {
            "term": "graph",
            "tf": 4,
            "weight": 0.031008
          },
          {
            "term": "raw",
            "tf": 4,
            "weight": 0.031008
          },
          {
            "term": "data",
            "tf": 4,
            "weight": 0.031008
          },
          {
            "term": "ontology",
            "tf": 4,
            "weight": 0.031008
          },
          {
            "term": "ingestion",
            "tf": 3,
            "weight": 0.023256
          },
          {
            "term": "based",
            "tf": 3,
            "weight": 0.023256
          },
          {
            "term": "pipeline",
            "tf": 2,
            "weight": 0.015504
          },
          {
            "term": "structured",
            "tf": 2,
            "weight": 0.015504
          },
          {
            "term": "into",
            "tf": 2,
            "weight": 0.015504
          },
          {
            "term": "relationships",
            "tf": 2,
            "weight": 0.015504
          },
          {
            "term": "stored",
            "tf": 2,
            "weight": 0.015504
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.015504
          },
          {
            "term": "graphrag",
            "tf": 1,
            "weight": 0.007752
          },
          {
            "term": "combines",
            "tf": 1,
            "weight": 0.007752
          },
          {
            "term": "improve",
            "tf": 1,
            "weight": 0.007752
          },
          {
            "term": "rag",
            "tf": 1,
            "weight": 0.007752
          }
        ],
        "unique_terms": 84,
        "total_terms": 129
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Ingestion",
        "and",
        "based",
        "data",
        "database",
        "graph",
        "ingestion",
        "ontology",
        "raw",
        "the",
        "vector"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5056862745098039,
      "overall": 0.7018954248366013
    }
  },
  {
    "text": "## Retrieval & Generation\n\nThe **Retrieval and Generation** process is designed to handle user queries by leveraging both semantic search and graph-based context extraction.\n\nFig 3: Overview of Retrieval and Generation Pipeline\n\nThe architecture can be broken down into the following steps:\n\n1. **Query Vectorization:** An embedding model converts The user query into a high-dimensional vector.\n2. **Semantic Search:** The vector performs a similarity-based search in the **Vector database**, retrieving relevant documents or entries.\n3. **ID Extraction:** Extracted IDs from the semantic search results are used to query the **Graph database**.\n4. **Graph Context Retrieval:** The **Graph database** provides contextual information, including relationships and entities linked to the extracted IDs.\n5. **Response Generation:** The context retrieved from the graph is passed to an LLM to generate a final response.\n6. **Results:** The generated response is returned to the user.\n\nThis architecture combines the strengths of both databases:\n\n1. **Semantic Search with Vector Database:** The user query is first processed semantically to identify the most relevant data points without needing explicit keyword matches.\n2. **Contextual Expansion with Graph Database:** IDs or entities retrieved from the vector database query the graph database for detailed relationships, enriching the retrieved data with structured context.\n3. **Enhanced Generation:** The architecture combines semantic relevance (from the vector database) and graph-based context to enable the LLM to generate more informed, accurate, and contextually rich responses.",
    "metadata": {
      "chunk_id": "a04e36e09b40-0013",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Retrieval & Generation"
      ],
      "heading_text": "Retrieval & Generation",
      "token_count": 303,
      "char_count": 1635,
      "start_char": 24907,
      "end_char": 26542,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6711631578947368,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.861109",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 303,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Retrieval & Generation",
      "chunk_hash": "e91ab0e812311b04",
      "content_digest": "e91ab0e812311b04",
      "chunk_length": 1635,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "graph",
          "database",
          "and",
          "vector",
          "generation",
          "semantic",
          "search",
          "context",
          "query",
          "retrieval",
          "user",
          "from",
          "based",
          "architecture",
          "ids",
          "response",
          "retrieved",
          "with",
          "both"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 23,
            "weight": 0.118557
          },
          {
            "term": "graph",
            "tf": 8,
            "weight": 0.041237
          },
          {
            "term": "database",
            "tf": 8,
            "weight": 0.041237
          },
          {
            "term": "and",
            "tf": 6,
            "weight": 0.030928
          },
          {
            "term": "vector",
            "tf": 6,
            "weight": 0.030928
          },
          {
            "term": "generation",
            "tf": 5,
            "weight": 0.025773
          },
          {
            "term": "semantic",
            "tf": 5,
            "weight": 0.025773
          },
          {
            "term": "search",
            "tf": 5,
            "weight": 0.025773
          },
          {
            "term": "context",
            "tf": 5,
            "weight": 0.025773
          },
          {
            "term": "query",
            "tf": 5,
            "weight": 0.025773
          },
          {
            "term": "retrieval",
            "tf": 4,
            "weight": 0.020619
          },
          {
            "term": "user",
            "tf": 4,
            "weight": 0.020619
          },
          {
            "term": "from",
            "tf": 4,
            "weight": 0.020619
          },
          {
            "term": "based",
            "tf": 3,
            "weight": 0.015464
          },
          {
            "term": "architecture",
            "tf": 3,
            "weight": 0.015464
          },
          {
            "term": "ids",
            "tf": 3,
            "weight": 0.015464
          },
          {
            "term": "response",
            "tf": 3,
            "weight": 0.015464
          },
          {
            "term": "retrieved",
            "tf": 3,
            "weight": 0.015464
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.015464
          },
          {
            "term": "both",
            "tf": 2,
            "weight": 0.010309
          }
        ],
        "unique_terms": 94,
        "total_terms": 194
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Retrieval & Generation",
        "and",
        "context",
        "database",
        "generation",
        "graph",
        "query",
        "search",
        "semantic",
        "the",
        "vector"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6711631578947368,
      "overall": 0.7903877192982455
    }
  },
  {
    "text": "# Implementation\n\nWe’ll walk through a complete pipeline that ingests data into Neo4j and Qdrant, retrieves relevant data, and generates responses using an LLM based on the retrieved graph context.\n\nThe main components of this pipeline include data ingestion (to Neo4j and Qdrant), retrieval, and generation steps.",
    "metadata": {
      "chunk_id": "a04e36e09b40-0014",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Implementation"
      ],
      "heading_text": "Implementation",
      "token_count": 66,
      "char_count": 314,
      "start_char": 26544,
      "end_char": 26858,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7453191489361702,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.861448",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 66,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Implementation",
      "chunk_hash": "51ab69d4edd0ff0f",
      "content_digest": "51ab69d4edd0ff0f",
      "chunk_length": 314,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "and",
          "data",
          "pipeline",
          "neo4j",
          "qdrant",
          "the",
          "implementation",
          "walk",
          "through",
          "complete",
          "that",
          "ingests",
          "into",
          "retrieves",
          "relevant",
          "generates",
          "responses",
          "using",
          "llm",
          "based"
        ],
        "term_weights": [
          {
            "term": "and",
            "tf": 4,
            "weight": 0.1
          },
          {
            "term": "data",
            "tf": 3,
            "weight": 0.075
          },
          {
            "term": "pipeline",
            "tf": 2,
            "weight": 0.05
          },
          {
            "term": "neo4j",
            "tf": 2,
            "weight": 0.05
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.05
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.05
          },
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "walk",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "complete",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "ingests",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "into",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "retrieves",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "relevant",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "generates",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "responses",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "llm",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.025
          }
        ],
        "unique_terms": 31,
        "total_terms": 40
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Implementation",
        "and",
        "complete",
        "data",
        "implementation",
        "neo4j",
        "pipeline",
        "qdrant",
        "the",
        "through",
        "walk"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7453191489361702,
      "overall": 0.8151063829787234
    }
  },
  {
    "text": "## Prerequisites\n\nThese are the tutorial prerequisites, which are divided into setup, imports, and initialization of the two DBs.",
    "metadata": {
      "chunk_id": "a04e36e09b40-0015",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Prerequisites"
      ],
      "heading_text": "Prerequisites",
      "token_count": 26,
      "char_count": 129,
      "start_char": 26860,
      "end_char": 26989,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5584210526315789,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.861643",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 26,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Prerequisites",
      "chunk_hash": "e27301bc53030869",
      "content_digest": "e27301bc53030869",
      "chunk_length": 129,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "prerequisites",
          "are",
          "the",
          "these",
          "tutorial",
          "which",
          "divided",
          "into",
          "setup",
          "imports",
          "and",
          "initialization",
          "two",
          "dbs"
        ],
        "term_weights": [
          {
            "term": "prerequisites",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "these",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "tutorial",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "which",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "divided",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "into",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "setup",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "imports",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "initialization",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "two",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "dbs",
            "tf": 1,
            "weight": 0.058824
          }
        ],
        "unique_terms": 14,
        "total_terms": 17
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Prerequisites",
        "are",
        "divided",
        "imports",
        "into",
        "prerequisites",
        "setup",
        "the",
        "these",
        "tutorial",
        "which"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5584210526315789,
      "overall": 0.7528070175438596
    }
  },
  {
    "text": "## Ingestion\n\nWe will follow the workflow of the ingestion pipeline presented in the architecture section. Let’s examine it implementation-wise.",
    "metadata": {
      "chunk_id": "a04e36e09b40-0026",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 26,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Ingestion"
      ],
      "heading_text": "Ingestion",
      "token_count": 27,
      "char_count": 144,
      "start_char": 30035,
      "end_char": 30179,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.545,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.870609",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 27,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Ingestion",
      "chunk_hash": "ba9d265a37fdff1f",
      "content_digest": "ba9d265a37fdff1f",
      "chunk_length": 144,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "ingestion",
          "will",
          "follow",
          "workflow",
          "pipeline",
          "presented",
          "architecture",
          "section",
          "let",
          "examine",
          "implementation",
          "wise"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 3,
            "weight": 0.1875
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.125
          },
          {
            "term": "will",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "follow",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "workflow",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "pipeline",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "presented",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "architecture",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "section",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "let",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "examine",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "wise",
            "tf": 1,
            "weight": 0.0625
          }
        ],
        "unique_terms": 13,
        "total_terms": 16
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Ingestion",
        "architecture",
        "follow",
        "ingestion",
        "let",
        "pipeline",
        "presented",
        "section",
        "the",
        "will",
        "workflow"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.545,
      "overall": 0.715
    }
  },
  {
    "text": "# Try to fetch the collection status try:     collection_info = client.get_collection(collection_name)     print(f\"Skipping creating collection; '{collection_name}' already exists.\") except Exception as e:     # If collection does not exist, an error will be thrown, so we create the collection     if 'Not found: Collection' in str(e):         print(f\"Collection '{collection_name}' not found. Creating it now...\")          client.create_collection(             collection_name=collection_name,             vectors_config=models.VectorParams(size=vector_dimension, distance=models.Distance.COSINE)         )          print(f\"Collection '{collection_name}' created successfully.\")     else:         print(f\"Error while checking collection: {e}\") ``` ---  - **Qdrant Client:** The QdrantClient is used to connect to the Qdrant instance. - **Creating Collection:** The create\\_collection function checks if a collection exists. If not, it creates one with a specified vector dimension and distance metric (cosine similarity in this case).",
    "metadata": {
      "chunk_id": "a04e36e09b40-0033",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 33,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Try to fetch the collection status"
      ],
      "heading_text": "Try to fetch the collection status",
      "token_count": 210,
      "char_count": 1036,
      "start_char": 35278,
      "end_char": 36314,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5294495412844037,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.883032",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 210,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Try to fetch the collection status",
      "chunk_hash": "808f8e8a83760ef6",
      "content_digest": "808f8e8a83760ef6",
      "chunk_length": 1036,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "collection",
          "name",
          "the",
          "print",
          "not",
          "client",
          "creating",
          "create",
          "distance",
          "try",
          "exists",
          "error",
          "found",
          "models",
          "vector",
          "dimension",
          "cosine",
          "qdrant",
          "fetch",
          "status"
        ],
        "term_weights": [
          {
            "term": "collection",
            "tf": 20,
            "weight": 0.186916
          },
          {
            "term": "name",
            "tf": 6,
            "weight": 0.056075
          },
          {
            "term": "the",
            "tf": 5,
            "weight": 0.046729
          },
          {
            "term": "print",
            "tf": 4,
            "weight": 0.037383
          },
          {
            "term": "not",
            "tf": 4,
            "weight": 0.037383
          },
          {
            "term": "client",
            "tf": 3,
            "weight": 0.028037
          },
          {
            "term": "creating",
            "tf": 3,
            "weight": 0.028037
          },
          {
            "term": "create",
            "tf": 3,
            "weight": 0.028037
          },
          {
            "term": "distance",
            "tf": 3,
            "weight": 0.028037
          },
          {
            "term": "try",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "exists",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "error",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "found",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "dimension",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "cosine",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "fetch",
            "tf": 1,
            "weight": 0.009346
          },
          {
            "term": "status",
            "tf": 1,
            "weight": 0.009346
          }
        ],
        "unique_terms": 56,
        "total_terms": 107
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Try to fetch the collection status",
        "client",
        "collection",
        "create",
        "creating",
        "distance",
        "name",
        "not",
        "print",
        "the",
        "try"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5294495412844037,
      "overall": 0.7098165137614679
    }
  },
  {
    "text": "## Retrieval & Generation\n\nIn this section, we will create the retrieval and generation engine for the system.",
    "metadata": {
      "chunk_id": "a04e36e09b40-0036",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 36,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Retrieval & Generation"
      ],
      "heading_text": "Retrieval & Generation",
      "token_count": 22,
      "char_count": 110,
      "start_char": 37595,
      "end_char": 37705,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.54,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.888164",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 22,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Retrieval & Generation",
      "chunk_hash": "69703dbcf279bc32",
      "content_digest": "69703dbcf279bc32",
      "chunk_length": 110,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "retrieval",
          "generation",
          "the",
          "this",
          "section",
          "will",
          "create",
          "and",
          "engine",
          "for",
          "system"
        ],
        "term_weights": [
          {
            "term": "retrieval",
            "tf": 2,
            "weight": 0.142857
          },
          {
            "term": "generation",
            "tf": 2,
            "weight": 0.142857
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.142857
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "section",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "will",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "create",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "engine",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.071429
          }
        ],
        "unique_terms": 11,
        "total_terms": 14
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Retrieval & Generation",
        "and",
        "create",
        "engine",
        "for",
        "generation",
        "retrieval",
        "section",
        "the",
        "this",
        "will"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.54,
      "overall": 0.7466666666666667
    }
  },
  {
    "text": "### End-to-End Pipeline  Finally, let’s integrate everything into an end-to-end pipeline where we ingest some sample data, run the retrieval process, and query the language model. ```python if __name__ == \"__main__\":     print(\"Script started\")     print(\"Loading environment variables...\")     load_dotenv('.env.local')     print(\"Environment variables loaded\")          print(\"Initializing clients...\")     neo4j_driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password))     qdrant_client = QdrantClient(         url=qdrant_url,         api_key=qdrant_key     )     print(\"Clients initialized\")          print(\"Creating collection...\")     collection_name = \"graphRAGstoreds\"     vector_dimension = 1536     create_collection(qdrant_client, collection_name, vector_dimension)     print(\"Collection created/verified\")          print(\"Extracting graph components...\")          raw_data = \"\"\"Alice is a data scientist at TechCorp's Seattle office. Bob and Carol collaborate on the Alpha project. Carol transferred to the New York office last year. Dave mentors both Alice and Bob. TechCorp's headquarters is in Seattle. Carol leads the East Coast team. Dave started his career in Seattle. The Alpha project is managed from New York. Alice previously worked with Carol at DataCo. Bob joined the team after Dave's recommendation. Eve runs the West Coast operations from Seattle. Frank works with Carol on client relations. The New York office expanded under Carol's leadership. Dave's team spans multiple locations. Alice visits Seattle monthly for team meetings. Bob's expertise is crucial for the Alpha project. Carol implemented new processes in New York. Eve and Dave collaborated on previous projects. Frank reports to the New York office. TechCorp's main AI research is in Seattle. The Alpha project revolutionized East Coast operations. Dave oversees projects in both offices. Bob's contributions are mainly remote. Carol's team grew significantly after moving to New York. Seattle remains the technology hub for TechCorp.\"\"\"      nodes, relationships = extract_graph_components(raw_data)     print(\"Nodes:\", nodes)     print(\"Relationships:\", relationships)          print(\"Ingesting to Neo4j...\")     node_id_mapping = ingest_to_neo4j(nodes, relationships)     print(\"Neo4j ingestion complete\")          print(\"Ingesting to Qdrant...\")     ingest_to_qdrant(collection_name, raw_data, node_id_mapping)     print(\"Qdrant ingestion complete\")      query = \"How is Bob connected to New York?\"     print(\"Starting retriever search...\")     retriever_result = retriever_search(neo4j_driver, qdrant_client, collection_name, query)     print(\"Retriever results:\", retriever_result)          print(\"Extracting entity IDs...\")     entity_ids = [item.content.split(\"'id': '\")[1].split(\"'\")[0] for item in retriever_result.items]     print(\"Entity IDs:\", entity_ids)          print(\"Fetching related graph...\")     subgraph = fetch_related_graph(neo4j_driver, entity_ids)     print(\"Subgraph:\", subgraph)          print(\"Formatting graph context...\")     graph_context = format_graph_context(subgraph)     print(\"Graph context:\", graph_context)          print(\"Running GraphRAG...\")     answer = graphRAG_run(graph_context, query)     print(\"Final Answer:\", answer) ``` ---  Here’s what’s happening:  - First, the user query is defined (“How is Bob connected to New York?”). - The QdrantNeo4jRetriever searches for related entities in the Qdrant vector database based on the user query’s embedding. It retrieves the top 5 results (top\\_k=5). - The entity\\_ids are extracted from the retriever result. - The fetch\\_related\\_graph function retrieves related entities and their relationships from the Neo4j database. - The format\\_graph\\_context function prepares the graph data in a format the LLM can understand. - Finally, the graphRAG\\_run function is called to generate and query the language model, producing an answer based on the retrieved graph context. With this, we have successfully created GraphRAG, a system capable of capturing complex relationships and delivering improved performance compared to the baseline RAG approach.",
    "metadata": {
      "chunk_id": "a04e36e09b40-0041",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 41,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "End-to-End Pipeline"
      ],
      "heading_text": "End-to-End Pipeline",
      "token_count": 899,
      "char_count": 4152,
      "start_char": 43110,
      "end_char": 47262,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6862955032119915,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.907131",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 899,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "End-to-End Pipeline",
      "chunk_hash": "d7ec9ecf8c7b137e",
      "content_digest": "d7ec9ecf8c7b137e",
      "chunk_length": 4152,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "print",
          "graph",
          "neo4j",
          "qdrant",
          "new",
          "carol",
          "york",
          "context",
          "and",
          "query",
          "collection",
          "seattle",
          "bob",
          "retriever",
          "data",
          "dave",
          "relationships",
          "entity",
          "ids"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 29,
            "weight": 0.058824
          },
          {
            "term": "print",
            "tf": 24,
            "weight": 0.048682
          },
          {
            "term": "graph",
            "tf": 14,
            "weight": 0.028398
          },
          {
            "term": "neo4j",
            "tf": 10,
            "weight": 0.020284
          },
          {
            "term": "qdrant",
            "tf": 9,
            "weight": 0.018256
          },
          {
            "term": "new",
            "tf": 9,
            "weight": 0.018256
          },
          {
            "term": "carol",
            "tf": 8,
            "weight": 0.016227
          },
          {
            "term": "york",
            "tf": 8,
            "weight": 0.016227
          },
          {
            "term": "context",
            "tf": 8,
            "weight": 0.016227
          },
          {
            "term": "and",
            "tf": 7,
            "weight": 0.014199
          },
          {
            "term": "query",
            "tf": 7,
            "weight": 0.014199
          },
          {
            "term": "collection",
            "tf": 7,
            "weight": 0.014199
          },
          {
            "term": "seattle",
            "tf": 7,
            "weight": 0.014199
          },
          {
            "term": "bob",
            "tf": 7,
            "weight": 0.014199
          },
          {
            "term": "retriever",
            "tf": 7,
            "weight": 0.014199
          },
          {
            "term": "data",
            "tf": 6,
            "weight": 0.01217
          },
          {
            "term": "dave",
            "tf": 6,
            "weight": 0.01217
          },
          {
            "term": "relationships",
            "tf": 6,
            "weight": 0.01217
          },
          {
            "term": "entity",
            "tf": 6,
            "weight": 0.01217
          },
          {
            "term": "ids",
            "tf": 6,
            "weight": 0.01217
          }
        ],
        "unique_terms": 207,
        "total_terms": 493
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "End-to-End Pipeline",
        "and",
        "carol",
        "context",
        "graph",
        "neo4j",
        "new",
        "print",
        "qdrant",
        "the",
        "york"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6862955032119915,
      "overall": 0.7620985010706637
    }
  },
  {
    "text": "# Advantages of Qdrant + Neo4j GraphRAG\n\nCombining Qdrant with Neo4j in a GraphRAG architecture offers several compelling advantages, particularly regarding recall and precision combo, contextual understanding, adaptability to complex queries, and better cost and scalability.\n\n1. **Improved Recall and Precision:** By leveraging Qdrant, a highly efficient vector search engine, alongside Neo4j’s robust graph database, the system benefits from both semantic search and relationship-based retrieval. Qdrant identifies relevant vectors and captures the similarity between queries and stored data. At the same time, Neo4j adds a layer of connectivity through its graph structure, ensuring that relevant and contextually linked information is retrieved. This combination improves recall (retrieving a broader set of relevant results) and precision (delivering more accurate and contextually relevant results), addressing a common challenge in traditional retrieval-based AI systems.\n2. **Enhanced Contextual Understanding:** Neo4j enhances contextual understanding by representing information as a graph, where entities and their relationships are naturally modeled. When integrated with Qdrant, the system can retrieve similar items based on vector embeddings and those that fit within the desired relational context, leading to more nuanced and meaningful responses.\n3. **Adaptability to Complex Queries:** Combining Qdrant and Neo4j makes the system highly adaptable to complex queries. While Qdrant handles the vector search for relevant data, Neo4j’s graph capabilities enable sophisticated querying through relationships. This allows for multi-hop reasoning and handling complex, structured queries that would be challenging for traditional search engines.\n4. **Better Cost & Scalability:** GraphRAG, on its own, demands significant resources, as it relies on LLMs to construct and query knowledge graphs. It also employs clustering algorithms to create semantic clusters for local searches. These can hinder scalability and increase costs. Qdrant addresses the issue of local search through vector search, while Neo4j’s knowledge graph is queried for more precise answers, enhancing both efficiency and accuracy. Furthermore, instead of using an LLM, Named Entity Recognition (NER)-based techniques can reduce the cost further, but it depends mainly on the dataset.",
    "metadata": {
      "chunk_id": "a04e36e09b40-0042",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 42,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Advantages of Qdrant + Neo4j GraphRAG"
      ],
      "heading_text": "Advantages of Qdrant + Neo4j GraphRAG",
      "token_count": 442,
      "char_count": 2369,
      "start_char": 47363,
      "end_char": 49732,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5279703703703703,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.910365",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 442,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Advantages of Qdrant + Neo4j GraphRAG",
      "chunk_hash": "f50bd0338cb310c1",
      "content_digest": "f50bd0338cb310c1",
      "chunk_length": 2369,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "and",
          "the",
          "qdrant",
          "neo4j",
          "search",
          "queries",
          "graph",
          "relevant",
          "for",
          "complex",
          "vector",
          "based",
          "graphrag",
          "recall",
          "precision",
          "contextual",
          "understanding",
          "cost",
          "scalability",
          "system"
        ],
        "term_weights": [
          {
            "term": "and",
            "tf": 18,
            "weight": 0.063158
          },
          {
            "term": "the",
            "tf": 10,
            "weight": 0.035088
          },
          {
            "term": "qdrant",
            "tf": 8,
            "weight": 0.02807
          },
          {
            "term": "neo4j",
            "tf": 8,
            "weight": 0.02807
          },
          {
            "term": "search",
            "tf": 6,
            "weight": 0.021053
          },
          {
            "term": "queries",
            "tf": 5,
            "weight": 0.017544
          },
          {
            "term": "graph",
            "tf": 5,
            "weight": 0.017544
          },
          {
            "term": "relevant",
            "tf": 5,
            "weight": 0.017544
          },
          {
            "term": "for",
            "tf": 5,
            "weight": 0.017544
          },
          {
            "term": "complex",
            "tf": 4,
            "weight": 0.014035
          },
          {
            "term": "vector",
            "tf": 4,
            "weight": 0.014035
          },
          {
            "term": "based",
            "tf": 4,
            "weight": 0.014035
          },
          {
            "term": "graphrag",
            "tf": 3,
            "weight": 0.010526
          },
          {
            "term": "recall",
            "tf": 3,
            "weight": 0.010526
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010526
          },
          {
            "term": "contextual",
            "tf": 3,
            "weight": 0.010526
          },
          {
            "term": "understanding",
            "tf": 3,
            "weight": 0.010526
          },
          {
            "term": "cost",
            "tf": 3,
            "weight": 0.010526
          },
          {
            "term": "scalability",
            "tf": 3,
            "weight": 0.010526
          },
          {
            "term": "system",
            "tf": 3,
            "weight": 0.010526
          }
        ],
        "unique_terms": 171,
        "total_terms": 285
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Advantages of Qdrant + Neo4j GraphRAG",
        "and",
        "complex",
        "for",
        "graph",
        "neo4j",
        "qdrant",
        "queries",
        "relevant",
        "search",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5279703703703703,
      "overall": 0.7426567901234566
    }
  },
  {
    "text": "# Conclusion\n\nGraphRAG with Neo4j and Qdrant marks an important step forward in retrieval-augmented generation. This hybrid approach delivers significant advantages by combining vector search and graph databases. Qdrant’s semantic search capabilities enhance recall accuracy, while Neo4j’s relationship modeling provides deeper context understanding.\n\nThe implementation template we’ve explored offers a foundation for your projects. You can adapt and customize it based on your specific needs, whether for document analysis, knowledge management, or other information retrieval tasks.\n\nAs AI systems evolve, this combination of technologies shows how we can build smarter, more efficient solutions. We encourage you to experiment with this approach and discover how it can enhance your applications.",
    "metadata": {
      "chunk_id": "a04e36e09b40-0043",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 43,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Conclusion"
      ],
      "heading_text": "Conclusion",
      "token_count": 139,
      "char_count": 800,
      "start_char": 49734,
      "end_char": 50534,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5404587155963303,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.911033",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 139,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Conclusion",
      "chunk_hash": "f97c4a518c1b3767",
      "content_digest": "f97c4a518c1b3767",
      "chunk_length": 800,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "and",
          "this",
          "your",
          "can",
          "with",
          "neo4j",
          "qdrant",
          "retrieval",
          "approach",
          "search",
          "enhance",
          "for",
          "you",
          "how",
          "conclusion",
          "graphrag",
          "marks",
          "important",
          "step",
          "forward"
        ],
        "term_weights": [
          {
            "term": "and",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "this",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "your",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "can",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "neo4j",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "retrieval",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "approach",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "enhance",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "how",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "conclusion",
            "tf": 1,
            "weight": 0.010638
          },
          {
            "term": "graphrag",
            "tf": 1,
            "weight": 0.010638
          },
          {
            "term": "marks",
            "tf": 1,
            "weight": 0.010638
          },
          {
            "term": "important",
            "tf": 1,
            "weight": 0.010638
          },
          {
            "term": "step",
            "tf": 1,
            "weight": 0.010638
          },
          {
            "term": "forward",
            "tf": 1,
            "weight": 0.010638
          }
        ],
        "unique_terms": 75,
        "total_terms": 94
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Conclusion",
        "and",
        "approach",
        "can",
        "neo4j",
        "qdrant",
        "retrieval",
        "search",
        "this",
        "with",
        "your"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5404587155963303,
      "overall": 0.7134862385321101
    }
  },
  {
    "text": "##### Was this page useful? Yes No  Thank you for your feedback! 🙏  We are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/graphrag-qdrant-neo4j.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue. On this page:  - [Build a GraphRAG Agent with Neo4j and Qdrant](#build-a-graphrag-agent-with-neo4j-and-qdrant.md)   - [Watch the Video](#watch-the-video.md)  - [RAG & Its Challenges](#rag--its-challenges.md)  - [Introduction to GraphRAG](#introduction-to-graphrag.md)   - - [Challenges of GraphRAG](#challenges-of-graphrag.md)  - [Architecture Overview](#architecture-overview.md)    - [Ingestion](#ingestion.md)   - [Retrieval & Generation](#retrieval--generation.md)  - [Implementation](#implementation.md)    - [Prerequisites](#prerequisites.md)      - [Setup](#setup.md)     - [Qdrant Setup](#qdrant-setup.md)     - [Neo4j Setup](#neo4j-setup.md)     - [Imports](#imports.md)     - [Setting Up Environment Variables](#setting-up-environment-variables.md)     - [Initializing Neo4j and Qdrant Clients](#initializing-neo4j-and-qdrant-clients.md)    - [Ingestion](#ingestion-1.md)      - [Defining Output Parser](#defining-output-parser.md)     - [Defining OpenAI Client and LLM Parser Function](#defining-openai-client-and-llm-parser-function.md)     - [Extracting Graph Components](#extracting-graph-components.md)     - [Ingesting Data to Neo4j](#ingesting-data-to-neo4j.md)     - [Creating Qdrant Collection](#creating-qdrant-collection.md)     - [Generating Embeddings](#generating-embeddings.md)     - [Ingesting into Qdrant](#ingesting-into-qdrant.md)    - [Retrieval & Generation](#retrieval--generation-1.md)      - [Building a Retriever](#building-a-retriever.md)     - [Querying Neo4j for Related Graph Data](#querying-neo4j-for-related-graph-data.md)     - [Setting up the Graph Context](#setting-up-the-graph-context.md)     - [Integrating with the LLM](#integrating-with-the-llm.md)     - [End-to-End Pipeline](#end-to-end-pipeline.md)  - [Advantages of Qdrant + Neo4j GraphRAG](#advantages-of-qdrant--neo4j-graphrag.md)  - [Conclusion](#conclusion.md)  * [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/graphrag-qdrant-neo4j.md) * [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)",
    "metadata": {
      "chunk_id": "a04e36e09b40-0044",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "file_extension": ".md",
      "chunk_index": 44,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Was this page useful?"
      ],
      "heading_text": "Was this page useful?",
      "token_count": 717,
      "char_count": 2429,
      "start_char": 50536,
      "end_char": 52965,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.8909090909090909,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:22.917505",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 717,
      "document_id": "a04e36e09b40",
      "document_name": "_documentation_examples_graphrag-qdrant-neo4j_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_filename": "_documentation_examples_graphrag-qdrant-neo4j_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_graphrag-qdrant-neo4j\\_documentation_examples_graphrag-qdrant-neo4j_.md",
      "hierarchy_path": "Was this page useful?",
      "chunk_hash": "71c71c649b41eaf6",
      "content_digest": "71c71c649b41eaf6",
      "chunk_length": 2429,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "neo4j",
          "graphrag",
          "page",
          "github",
          "landing",
          "and",
          "the",
          "setup",
          "graph",
          "https",
          "com",
          "with",
          "challenges",
          "ingestion",
          "retrieval",
          "generation",
          "setting",
          "defining",
          "parser"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 20,
            "weight": 0.077821
          },
          {
            "term": "neo4j",
            "tf": 14,
            "weight": 0.054475
          },
          {
            "term": "graphrag",
            "tf": 10,
            "weight": 0.038911
          },
          {
            "term": "page",
            "tf": 7,
            "weight": 0.027237
          },
          {
            "term": "github",
            "tf": 7,
            "weight": 0.027237
          },
          {
            "term": "landing",
            "tf": 6,
            "weight": 0.023346
          },
          {
            "term": "and",
            "tf": 6,
            "weight": 0.023346
          },
          {
            "term": "the",
            "tf": 6,
            "weight": 0.023346
          },
          {
            "term": "setup",
            "tf": 6,
            "weight": 0.023346
          },
          {
            "term": "graph",
            "tf": 6,
            "weight": 0.023346
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.015564
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.015564
          },
          {
            "term": "with",
            "tf": 4,
            "weight": 0.015564
          },
          {
            "term": "challenges",
            "tf": 4,
            "weight": 0.015564
          },
          {
            "term": "ingestion",
            "tf": 4,
            "weight": 0.015564
          },
          {
            "term": "retrieval",
            "tf": 4,
            "weight": 0.015564
          },
          {
            "term": "generation",
            "tf": 4,
            "weight": 0.015564
          },
          {
            "term": "setting",
            "tf": 4,
            "weight": 0.015564
          },
          {
            "term": "defining",
            "tf": 4,
            "weight": 0.015564
          },
          {
            "term": "parser",
            "tf": 4,
            "weight": 0.015564
          }
        ],
        "unique_terms": 85,
        "total_terms": 257
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Was this page useful?",
        "and",
        "github",
        "graph",
        "graphrag",
        "landing",
        "neo4j",
        "page",
        "qdrant",
        "setup",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.8909090909090909,
      "overall": 0.7969696969696969
    }
  }
]
[
  {
    "text": "### Essentials  [Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)  [Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)  [Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)  [Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)  [Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)  [5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)  [Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)",
    "metadata": {
      "chunk_id": "f952f2857b12-0000",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Essentials"
      ],
      "heading_text": "Essentials",
      "token_count": 189,
      "char_count": 673,
      "start_char": 679,
      "end_char": 1352,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5053846153846153,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.200547",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 189,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Essentials",
      "chunk_hash": "a64044a3995d82e4",
      "content_digest": "a64044a3995d82e4",
      "chunk_length": 673,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "https",
          "tech",
          "documentation",
          "agentic",
          "with",
          "data",
          "ingestion",
          "beginners",
          "langgraph",
          "discord",
          "multimodal",
          "and",
          "deepseek",
          "n8n",
          "essentials",
          "for",
          "simple",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "documentation",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "agentic",
            "tf": 6,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "beginners",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "langgraph",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "discord",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "multimodal",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "deepseek",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "n8n",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "essentials",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 31,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Essentials",
        "agentic",
        "beginners",
        "data",
        "documentation",
        "https",
        "ingestion",
        "qdrant",
        "rag",
        "tech",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5053846153846153,
      "overall": 0.7017948717948718
    }
  },
  {
    "text": "### Integrations  [Data Management](https://qdrant.tech/documentation/data-management/)  - [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/) - [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/) - [Apache Spark](https://qdrant.tech/documentation/data-management/spark/) - [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/) - [cognee](https://qdrant.tech/documentation/data-management/cognee/) - [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/) - [DLT](https://qdrant.tech/documentation/data-management/dlt/) - [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/) - [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/) - [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)  [Embeddings](https://qdrant.tech/documentation/embeddings/)  - [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/) - [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/) - [Cohere](https://qdrant.tech/documentation/embeddings/cohere/) - [Gemini](https://qdrant.tech/documentation/embeddings/gemini/) - [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/) - [Mistral](https://qdrant.tech/documentation/embeddings/mistral/) - [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/) - [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/) - [Nomic](https://qdrant.tech/documentation/embeddings/nomic/) - [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/) - [Ollama](https://qdrant.tech/documentation/embeddings/ollama/) - [OpenAI](https://qdrant.tech/documentation/embeddings/openai/) - [Prem AI](https://qdrant.tech/documentation/embeddings/premai/) - [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/) - [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/) - [Upstage](https://qdrant.tech/documentation/embeddings/upstage/) - [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)  [Frameworks](https://qdrant.tech/documentation/frameworks/)  - [Autogen](https://qdrant.tech/documentation/frameworks/autogen/) - [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/) - [CamelAI](https://qdrant.tech/documentation/frameworks/camel/) - [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/) - [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/) - [Dagster](https://qdrant.tech/documentation/frameworks/dagster/) - [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/) - [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/) - [Feast](https://qdrant.tech/documentation/frameworks/feast/) - [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/) - [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/) - [Haystack](https://qdrant.tech/documentation/frameworks/haystack/) - [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/) - [Langchain](https://qdrant.tech/documentation/frameworks/langchain/) - [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/) - [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/) - [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/) - [Mastra](https://qdrant.tech/documentation/frameworks/mastra/) - [Mem0](https://qdrant.tech/documentation/frameworks/mem0/) - [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/) - [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/) - [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/) - [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/) - [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/) - [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/) - [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/) - [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/) - [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/) - [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/) - [txtai](https://qdrant.tech/documentation/frameworks/txtai/) - [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/) - [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/) - [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)  [Observability](https://qdrant.tech/documentation/observability/)  - [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/) - [OpenLIT](https://qdrant.tech/documentation/observability/openlit/) - [Datadog](https://qdrant.tech/documentation/observability/datadog/)  [Platforms](https://qdrant.tech/documentation/platforms/)  - [Apify](https://qdrant.tech/documentation/platforms/apify/) - [BuildShip](https://qdrant.tech/documentation/platforms/buildship/) - [Keboola](https://qdrant.tech/documentation/platforms/keboola/) - [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/) - [Make.com](https://qdrant.tech/documentation/platforms/make/) - [N8N](https://qdrant.tech/documentation/platforms/n8n/) - [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/) - [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/) - [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/) - [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/) - [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/) - [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)",
    "metadata": {
      "chunk_id": "f952f2857b12-0001",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integrations"
      ],
      "heading_text": "Integrations",
      "token_count": 1498,
      "char_count": 5661,
      "start_char": 1354,
      "end_char": 7015,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.232256",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 1498,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Integrations",
      "chunk_hash": "8a3f2e84e2a75ae9",
      "content_digest": "8a3f2e84e2a75ae9",
      "chunk_length": 5661,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "frameworks",
          "embeddings",
          "platforms",
          "data",
          "management",
          "observability",
          "airbyte",
          "apache",
          "airflow",
          "spark",
          "cocoindex",
          "cognee",
          "confluent",
          "dlt",
          "fluvio",
          "redpanda"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "qdrant",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "tech",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "documentation",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "frameworks",
            "tf": 35,
            "weight": 0.058528
          },
          {
            "term": "embeddings",
            "tf": 21,
            "weight": 0.035117
          },
          {
            "term": "platforms",
            "tf": 14,
            "weight": 0.023411
          },
          {
            "term": "data",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "management",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "observability",
            "tf": 5,
            "weight": 0.008361
          },
          {
            "term": "airbyte",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "apache",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "airflow",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "spark",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cocoindex",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cognee",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "confluent",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "dlt",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "fluvio",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "redpanda",
            "tf": 2,
            "weight": 0.003344
          }
        ],
        "unique_terms": 113,
        "total_terms": 598
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integrations",
        "data",
        "documentation",
        "embeddings",
        "frameworks",
        "https",
        "management",
        "observability",
        "platforms",
        "qdrant",
        "tech"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "overall": 0.7576923076923077
    }
  },
  {
    "text": "### Examples  [Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)  - [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) - [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)  [Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)  - [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/) - [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/) - [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)  [Build Prototypes](https://qdrant.tech/documentation/examples/)  - [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/) - [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/) - [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/) - [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/) - [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/) - [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/) - [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/) - [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/) - [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/) - [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/) - [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/) - [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)  [Practice Datasets](https://qdrant.tech/documentation/datasets/)",
    "metadata": {
      "chunk_id": "f952f2857b12-0002",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Examples"
      ],
      "heading_text": "Examples",
      "token_count": 576,
      "char_count": 2347,
      "start_char": 7017,
      "end_char": 9364,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.9076923076923078,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.242943",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 576,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Examples",
      "chunk_hash": "59078d11dd9c9931",
      "content_digest": "59078d11dd9c9931",
      "chunk_length": 2347,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "https",
          "tech",
          "documentation",
          "examples",
          "search",
          "with",
          "rag",
          "data",
          "chatbot",
          "send",
          "system",
          "semantic",
          "and",
          "cohere",
          "precision",
          "reranking",
          "dspy",
          "for",
          "automate"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 30,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "tech",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "documentation",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "examples",
            "tf": 14,
            "weight": 0.05
          },
          {
            "term": "search",
            "tf": 10,
            "weight": 0.035714
          },
          {
            "term": "with",
            "tf": 9,
            "weight": 0.032143
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.032143
          },
          {
            "term": "data",
            "tf": 7,
            "weight": 0.025
          },
          {
            "term": "chatbot",
            "tf": 6,
            "weight": 0.021429
          },
          {
            "term": "send",
            "tf": 5,
            "weight": 0.017857
          },
          {
            "term": "system",
            "tf": 5,
            "weight": 0.017857
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "cohere",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "dspy",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "automate",
            "tf": 2,
            "weight": 0.007143
          }
        ],
        "unique_terms": 96,
        "total_terms": 280
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Examples",
        "chatbot",
        "data",
        "documentation",
        "examples",
        "https",
        "qdrant",
        "rag",
        "search",
        "tech",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.9076923076923078,
      "overall": 0.8358974358974359
    }
  },
  {
    "text": "### Essentials  [Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)  [Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)  [Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)  [Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)  [Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)  [5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)  [Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)",
    "metadata": {
      "chunk_id": "f952f2857b12-0003",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Essentials"
      ],
      "heading_text": "Essentials",
      "token_count": 189,
      "char_count": 673,
      "start_char": 9366,
      "end_char": 10039,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5053846153846153,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.245866",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 189,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Essentials",
      "chunk_hash": "a64044a3995d82e4",
      "content_digest": "a64044a3995d82e4",
      "chunk_length": 673,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "https",
          "tech",
          "documentation",
          "agentic",
          "with",
          "data",
          "ingestion",
          "beginners",
          "langgraph",
          "discord",
          "multimodal",
          "and",
          "deepseek",
          "n8n",
          "essentials",
          "for",
          "simple",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "documentation",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "agentic",
            "tf": 6,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "beginners",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "langgraph",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "discord",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "multimodal",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "deepseek",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "n8n",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "essentials",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 31,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Essentials",
        "agentic",
        "beginners",
        "data",
        "documentation",
        "https",
        "ingestion",
        "qdrant",
        "rag",
        "tech",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5053846153846153,
      "overall": 0.7017948717948718
    }
  },
  {
    "text": "### Integrations  [Data Management](https://qdrant.tech/documentation/data-management/)  - [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/) - [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/) - [Apache Spark](https://qdrant.tech/documentation/data-management/spark/) - [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/) - [cognee](https://qdrant.tech/documentation/data-management/cognee/) - [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/) - [DLT](https://qdrant.tech/documentation/data-management/dlt/) - [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/) - [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/) - [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)  [Embeddings](https://qdrant.tech/documentation/embeddings/)  - [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/) - [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/) - [Cohere](https://qdrant.tech/documentation/embeddings/cohere/) - [Gemini](https://qdrant.tech/documentation/embeddings/gemini/) - [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/) - [Mistral](https://qdrant.tech/documentation/embeddings/mistral/) - [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/) - [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/) - [Nomic](https://qdrant.tech/documentation/embeddings/nomic/) - [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/) - [Ollama](https://qdrant.tech/documentation/embeddings/ollama/) - [OpenAI](https://qdrant.tech/documentation/embeddings/openai/) - [Prem AI](https://qdrant.tech/documentation/embeddings/premai/) - [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/) - [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/) - [Upstage](https://qdrant.tech/documentation/embeddings/upstage/) - [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)  [Frameworks](https://qdrant.tech/documentation/frameworks/)  - [Autogen](https://qdrant.tech/documentation/frameworks/autogen/) - [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/) - [CamelAI](https://qdrant.tech/documentation/frameworks/camel/) - [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/) - [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/) - [Dagster](https://qdrant.tech/documentation/frameworks/dagster/) - [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/) - [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/) - [Feast](https://qdrant.tech/documentation/frameworks/feast/) - [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/) - [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/) - [Haystack](https://qdrant.tech/documentation/frameworks/haystack/) - [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/) - [Langchain](https://qdrant.tech/documentation/frameworks/langchain/) - [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/) - [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/) - [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/) - [Mastra](https://qdrant.tech/documentation/frameworks/mastra/) - [Mem0](https://qdrant.tech/documentation/frameworks/mem0/) - [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/) - [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/) - [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/) - [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/) - [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/) - [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/) - [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/) - [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/) - [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/) - [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/) - [txtai](https://qdrant.tech/documentation/frameworks/txtai/) - [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/) - [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/) - [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)  [Observability](https://qdrant.tech/documentation/observability/)  - [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/) - [OpenLIT](https://qdrant.tech/documentation/observability/openlit/) - [Datadog](https://qdrant.tech/documentation/observability/datadog/)  [Platforms](https://qdrant.tech/documentation/platforms/)  - [Apify](https://qdrant.tech/documentation/platforms/apify/) - [BuildShip](https://qdrant.tech/documentation/platforms/buildship/) - [Keboola](https://qdrant.tech/documentation/platforms/keboola/) - [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/) - [Make.com](https://qdrant.tech/documentation/platforms/make/) - [N8N](https://qdrant.tech/documentation/platforms/n8n/) - [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/) - [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/) - [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/) - [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/) - [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/) - [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)",
    "metadata": {
      "chunk_id": "f952f2857b12-0004",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integrations"
      ],
      "heading_text": "Integrations",
      "token_count": 1498,
      "char_count": 5661,
      "start_char": 10041,
      "end_char": 15702,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.270905",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 1498,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Integrations",
      "chunk_hash": "8a3f2e84e2a75ae9",
      "content_digest": "8a3f2e84e2a75ae9",
      "chunk_length": 5661,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "frameworks",
          "embeddings",
          "platforms",
          "data",
          "management",
          "observability",
          "airbyte",
          "apache",
          "airflow",
          "spark",
          "cocoindex",
          "cognee",
          "confluent",
          "dlt",
          "fluvio",
          "redpanda"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "qdrant",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "tech",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "documentation",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "frameworks",
            "tf": 35,
            "weight": 0.058528
          },
          {
            "term": "embeddings",
            "tf": 21,
            "weight": 0.035117
          },
          {
            "term": "platforms",
            "tf": 14,
            "weight": 0.023411
          },
          {
            "term": "data",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "management",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "observability",
            "tf": 5,
            "weight": 0.008361
          },
          {
            "term": "airbyte",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "apache",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "airflow",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "spark",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cocoindex",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cognee",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "confluent",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "dlt",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "fluvio",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "redpanda",
            "tf": 2,
            "weight": 0.003344
          }
        ],
        "unique_terms": 113,
        "total_terms": 598
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integrations",
        "data",
        "documentation",
        "embeddings",
        "frameworks",
        "https",
        "management",
        "observability",
        "platforms",
        "qdrant",
        "tech"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "overall": 0.7576923076923077
    }
  },
  {
    "text": "### Examples  [Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)  - [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) - [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)  [Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)  - [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/) - [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/) - [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)  [Build Prototypes](https://qdrant.tech/documentation/examples/)  - [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/) - [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/) - [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/) - [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/) - [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/) - [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/) - [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/) - [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/) - [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/) - [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/) - [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/) - [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)  [Practice Datasets](https://qdrant.tech/documentation/datasets/)  - [Documentation](https://qdrant.tech/documentation/) - - [Examples](https://qdrant.tech/documentation/examples/) - - Multitenancy with LlamaIndex",
    "metadata": {
      "chunk_id": "f952f2857b12-0005",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Examples"
      ],
      "heading_text": "Examples",
      "token_count": 612,
      "char_count": 2495,
      "start_char": 15704,
      "end_char": 18199,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.9007874015748032,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.278978",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 612,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Examples",
      "chunk_hash": "c765e91f1374c1ab",
      "content_digest": "c765e91f1374c1ab",
      "chunk_length": 2495,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "documentation",
          "https",
          "tech",
          "examples",
          "search",
          "with",
          "rag",
          "data",
          "chatbot",
          "send",
          "system",
          "semantic",
          "and",
          "cohere",
          "precision",
          "reranking",
          "dspy",
          "multitenancy",
          "llamaindex"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 32,
            "weight": 0.108844
          },
          {
            "term": "documentation",
            "tf": 24,
            "weight": 0.081633
          },
          {
            "term": "https",
            "tf": 23,
            "weight": 0.078231
          },
          {
            "term": "tech",
            "tf": 23,
            "weight": 0.078231
          },
          {
            "term": "examples",
            "tf": 16,
            "weight": 0.054422
          },
          {
            "term": "search",
            "tf": 10,
            "weight": 0.034014
          },
          {
            "term": "with",
            "tf": 10,
            "weight": 0.034014
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.030612
          },
          {
            "term": "data",
            "tf": 7,
            "weight": 0.02381
          },
          {
            "term": "chatbot",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "send",
            "tf": 5,
            "weight": 0.017007
          },
          {
            "term": "system",
            "tf": 5,
            "weight": 0.017007
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.013605
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.013605
          },
          {
            "term": "cohere",
            "tf": 4,
            "weight": 0.013605
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010204
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.010204
          },
          {
            "term": "dspy",
            "tf": 3,
            "weight": 0.010204
          },
          {
            "term": "multitenancy",
            "tf": 3,
            "weight": 0.010204
          },
          {
            "term": "llamaindex",
            "tf": 3,
            "weight": 0.010204
          }
        ],
        "unique_terms": 96,
        "total_terms": 294
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Examples",
        "chatbot",
        "data",
        "documentation",
        "examples",
        "https",
        "qdrant",
        "rag",
        "search",
        "tech",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.9007874015748032,
      "overall": 0.8335958005249343
    }
  },
  {
    "text": "# Multitenancy with LlamaIndex\n\nIf you are building a service that serves vectors for many independent users, and you want to isolate their data, the best practice is to use a single collection with payload-based partitioning. This approach is called **multitenancy**. Our guide on the [Separate Partitions](https://qdrant.tech/documentation/guides/multiple-partitions/) describes how to set it up in general, but if you use [LlamaIndex](https://qdrant.tech/documentation/integrations/llama-index/) as a backend, you may prefer reading a more specific instruction. So here it is!",
    "metadata": {
      "chunk_id": "f952f2857b12-0006",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Multitenancy with LlamaIndex"
      ],
      "heading_text": "Multitenancy with LlamaIndex",
      "token_count": 132,
      "char_count": 579,
      "start_char": 18201,
      "end_char": 18780,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.534,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.279957",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 132,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Multitenancy with LlamaIndex",
      "chunk_hash": "ea46bdff69848020",
      "content_digest": "ea46bdff69848020",
      "chunk_length": 579,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "you",
          "multitenancy",
          "with",
          "llamaindex",
          "the",
          "use",
          "partitions",
          "https",
          "qdrant",
          "tech",
          "documentation",
          "are",
          "building",
          "service",
          "that",
          "serves",
          "vectors",
          "for",
          "many",
          "independent"
        ],
        "term_weights": [
          {
            "term": "you",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "multitenancy",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "llamaindex",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "use",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "partitions",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "tech",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "documentation",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "building",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "service",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "serves",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "vectors",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "many",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "independent",
            "tf": 1,
            "weight": 0.014286
          }
        ],
        "unique_terms": 57,
        "total_terms": 70
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Multitenancy with LlamaIndex",
        "https",
        "llamaindex",
        "multitenancy",
        "partitions",
        "qdrant",
        "tech",
        "the",
        "use",
        "with",
        "you"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.534,
      "overall": 0.7113333333333333
    }
  },
  {
    "text": "## Prerequisites  This tutorial assumes that you have already installed Qdrant and LlamaIndex. If you haven’t, please run the following commands: ```bash pip install llama-index llama-index-vector-stores-qdrant ``` We are going to use a local Docker-based instance of Qdrant. If you want to use a remote instance, please adjust the code accordingly. Here is how we can start a local instance: ```bash docker run -d --name qdrant -p 6333:6333 -p 6334:6334 qdrant/qdrant:latest ```",
    "metadata": {
      "chunk_id": "f952f2857b12-0007",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Prerequisites"
      ],
      "heading_text": "Prerequisites",
      "token_count": 122,
      "char_count": 479,
      "start_char": 18782,
      "end_char": 19261,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5233333333333333,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.281823",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 122,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Prerequisites",
      "chunk_hash": "7d69b9d4ca149877",
      "content_digest": "7d69b9d4ca149877",
      "chunk_length": 479,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "you",
          "instance",
          "please",
          "run",
          "the",
          "bash",
          "llama",
          "index",
          "use",
          "local",
          "docker",
          "6333",
          "6334",
          "prerequisites",
          "this",
          "tutorial",
          "assumes",
          "that",
          "have"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.092308
          },
          {
            "term": "you",
            "tf": 3,
            "weight": 0.046154
          },
          {
            "term": "instance",
            "tf": 3,
            "weight": 0.046154
          },
          {
            "term": "please",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "run",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "bash",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "llama",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "index",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "use",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "local",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "docker",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "6333",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "6334",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "prerequisites",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "tutorial",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "assumes",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "have",
            "tf": 1,
            "weight": 0.015385
          }
        ],
        "unique_terms": 45,
        "total_terms": 65
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Prerequisites",
        "bash",
        "index",
        "instance",
        "llama",
        "please",
        "qdrant",
        "run",
        "the",
        "use",
        "you"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5233333333333333,
      "overall": 0.7077777777777777
    }
  },
  {
    "text": "## Setting up LlamaIndex pipeline\n\nWe are going to implement an end-to-end example of multitenant application using LlamaIndex. We’ll be indexing the documentation of different Python libraries, and we definitely don’t want any users to see the results coming from a library they are not interested in. In real case scenarios, this is even more dangerous, as the documents may contain sensitive information.",
    "metadata": {
      "chunk_id": "f952f2857b12-0008",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Setting up LlamaIndex pipeline"
      ],
      "heading_text": "Setting up LlamaIndex pipeline",
      "token_count": 80,
      "char_count": 407,
      "start_char": 19266,
      "end_char": 19673,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5614285714285714,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.282244",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 80,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Setting up LlamaIndex pipeline",
      "chunk_hash": "88e0f79f78327d8f",
      "content_digest": "88e0f79f78327d8f",
      "chunk_length": 407,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "llamaindex",
          "are",
          "end",
          "setting",
          "pipeline",
          "going",
          "implement",
          "example",
          "multitenant",
          "application",
          "using",
          "indexing",
          "documentation",
          "different",
          "python",
          "libraries",
          "and",
          "definitely",
          "don"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 3,
            "weight": 0.0625
          },
          {
            "term": "llamaindex",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "setting",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "pipeline",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "going",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "implement",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "example",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "multitenant",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "application",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "indexing",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "documentation",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "libraries",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "definitely",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "don",
            "tf": 1,
            "weight": 0.020833
          }
        ],
        "unique_terms": 43,
        "total_terms": 48
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Setting up LlamaIndex pipeline",
        "are",
        "end",
        "example",
        "going",
        "implement",
        "llamaindex",
        "multitenant",
        "pipeline",
        "setting",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5614285714285714,
      "overall": 0.7538095238095237
    }
  },
  {
    "text": "### Creating vector store  [QdrantVectorStore](https://docs.llamaindex.ai/en/stable/examples/vector_stores/QdrantIndexDemo.html) is a wrapper around Qdrant that provides all the necessary methods to work with your vector database in LlamaIndex. Let’s create a vector store for our collection. It requires setting a collection name and passing an instance of `QdrantClient`. ```python from qdrant_client import QdrantClient from llama_index.vector_stores.qdrant import QdrantVectorStore   client = QdrantClient(\"http://localhost:6333\")  vector_store = QdrantVectorStore(     collection_name=\"my_collection\",     client=client, ) ```",
    "metadata": {
      "chunk_id": "f952f2857b12-0009",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Creating vector store"
      ],
      "heading_text": "Creating vector store",
      "token_count": 151,
      "char_count": 631,
      "start_char": 19675,
      "end_char": 20306,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.751904761904762,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.283605",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 151,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Creating vector store",
      "chunk_hash": "7890f0ce863aaa13",
      "content_digest": "7890f0ce863aaa13",
      "chunk_length": 631,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "vector",
          "collection",
          "client",
          "store",
          "qdrantvectorstore",
          "qdrant",
          "qdrantclient",
          "llamaindex",
          "stores",
          "name",
          "from",
          "import",
          "creating",
          "https",
          "docs",
          "stable",
          "examples",
          "qdrantindexdemo",
          "html",
          "wrapper"
        ],
        "term_weights": [
          {
            "term": "vector",
            "tf": 6,
            "weight": 0.085714
          },
          {
            "term": "collection",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "client",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "store",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "qdrantvectorstore",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "qdrantclient",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "llamaindex",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "stores",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "name",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "from",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "import",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "creating",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "docs",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "stable",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "examples",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "qdrantindexdemo",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "html",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "wrapper",
            "tf": 1,
            "weight": 0.014286
          }
        ],
        "unique_terms": 46,
        "total_terms": 70
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Creating vector store",
        "client",
        "collection",
        "llamaindex",
        "name",
        "qdrant",
        "qdrantclient",
        "qdrantvectorstore",
        "store",
        "stores",
        "vector"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.751904761904762,
      "overall": 0.7839682539682539
    }
  },
  {
    "text": "## Indexing documents  No matter how our documents are generated, LlamaIndex will automatically split them into nodes, if required, encode using selected embedding model, and then store in the vector store. Let’s define some documents manually and insert them into Qdrant collection. Our documents are going to have a single metadata attribute - a library name they belong to. ```python from llama_index.core.schema import Document  documents = [     Document(         text=\"LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models.\",         metadata={             \"library\": \"llama-index\",         },     ),     Document(         text=\"Qdrant is a vector database & vector similarity search engine.\",         metadata={             \"library\": \"qdrant\",         },     ), ] ``` Now we can index them using our `VectorStoreIndex`: ```python for document in documents:     index.insert(document) ```",
    "metadata": {
      "chunk_id": "f952f2857b12-0012",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Indexing documents"
      ],
      "heading_text": "Indexing documents",
      "token_count": 190,
      "char_count": 949,
      "start_char": 22254,
      "end_char": 23203,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5162295081967213,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.291157",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 190,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Indexing documents",
      "chunk_hash": "0ef754c95bcb573e",
      "content_digest": "0ef754c95bcb573e",
      "chunk_length": 949,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "documents",
          "document",
          "index",
          "our",
          "them",
          "vector",
          "qdrant",
          "metadata",
          "library",
          "are",
          "llamaindex",
          "into",
          "using",
          "and",
          "store",
          "insert",
          "python",
          "llama",
          "text",
          "data"
        ],
        "term_weights": [
          {
            "term": "documents",
            "tf": 6,
            "weight": 0.057692
          },
          {
            "term": "document",
            "tf": 5,
            "weight": 0.048077
          },
          {
            "term": "index",
            "tf": 4,
            "weight": 0.038462
          },
          {
            "term": "our",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "them",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "vector",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "metadata",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "library",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "llamaindex",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "into",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "using",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "store",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "insert",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "python",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "llama",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.019231
          }
        ],
        "unique_terms": 68,
        "total_terms": 104
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Indexing documents",
        "are",
        "document",
        "documents",
        "index",
        "library",
        "metadata",
        "our",
        "qdrant",
        "them",
        "vector"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5162295081967213,
      "overall": 0.7054098360655737
    }
  },
  {
    "text": "### Performance considerations  Our documents have been split into nodes, encoded using the embedding model, and stored in the vector store. However, we don’t want to allow our users to search for all the documents in the collection, but only for the documents that belong to a library they are interested in. For that reason, we need to set up the Qdrant [payload index](https://qdrant.tech/documentation/concepts/indexing/#payload-index), so the search is more efficient. ```python from qdrant_client import models  client.create_payload_index(     collection_name=\"my_collection\",     field_name=\"metadata.library\",     field_type=models.PayloadSchemaType.KEYWORD, ) ``` The payload index is not the only thing we want to change. Since none of the search queries will be executed on the whole collection, we can also change its configuration, so the HNSW graph is not built globally. This is also done due to [performance reasons](https://qdrant.tech/documentation/guides/multiple-partitions/#calibrate-performance). **You should not be changing these parameters, if you know there will be some global search operations done on the collection.** ```python client.update_collection(     collection_name=\"my_collection\",     hnsw_config=models.HnswConfigDiff(payload_m=16, m=0), ) ``` Once both operations are completed, we can start searching for our documents. These steps are done just once, when you index your first documents!",
    "metadata": {
      "chunk_id": "f952f2857b12-0013",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance considerations"
      ],
      "heading_text": "Performance considerations",
      "token_count": 301,
      "char_count": 1432,
      "start_char": 23208,
      "end_char": 24640,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6903000000000001,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.295079",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 301,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Performance considerations",
      "chunk_hash": "92ac1a53a126fba2",
      "content_digest": "92ac1a53a126fba2",
      "chunk_length": 1432,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "collection",
          "documents",
          "payload",
          "index",
          "search",
          "for",
          "qdrant",
          "performance",
          "our",
          "are",
          "client",
          "models",
          "name",
          "not",
          "done",
          "you",
          "want",
          "only",
          "that"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 13,
            "weight": 0.071038
          },
          {
            "term": "collection",
            "tf": 8,
            "weight": 0.043716
          },
          {
            "term": "documents",
            "tf": 5,
            "weight": 0.027322
          },
          {
            "term": "payload",
            "tf": 5,
            "weight": 0.027322
          },
          {
            "term": "index",
            "tf": 5,
            "weight": 0.027322
          },
          {
            "term": "search",
            "tf": 4,
            "weight": 0.021858
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.021858
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.021858
          },
          {
            "term": "performance",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "our",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "are",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "client",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "name",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "not",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "done",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "you",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "want",
            "tf": 2,
            "weight": 0.010929
          },
          {
            "term": "only",
            "tf": 2,
            "weight": 0.010929
          },
          {
            "term": "that",
            "tf": 2,
            "weight": 0.010929
          }
        ],
        "unique_terms": 108,
        "total_terms": 183
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance considerations",
        "collection",
        "documents",
        "for",
        "index",
        "our",
        "payload",
        "performance",
        "qdrant",
        "search",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6903000000000001,
      "overall": 0.7634333333333334
    }
  },
  {
    "text": "## Querying documents with constraints  Let’s assume we are searching for some information about large language models, but are only allowed to use Qdrant documentation. LlamaIndex has a concept of retrievers, responsible for finding the most relevant nodes for a given query. Our `VectorStoreIndex` can be used as a retriever, with some additional constraints - in our case value of the `library` metadata attribute. ```python from llama_index.core.vector_stores.types import MetadataFilters, ExactMatchFilter  qdrant_retriever = index.as_retriever(     filters=MetadataFilters(         filters=[             ExactMatchFilter(                 key=\"library\",                 value=\"qdrant\",             )         ]     ) )  nodes_with_scores = qdrant_retriever.retrieve(\"large language models\") for node in nodes_with_scores:     print(node.text, node.score)",
    "metadata": {
      "chunk_id": "f952f2857b12-0014",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Querying documents with constraints"
      ],
      "heading_text": "Querying documents with constraints",
      "token_count": 181,
      "char_count": 858,
      "start_char": 24647,
      "end_char": 25505,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5351612903225806,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.297257",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 181,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Querying documents with constraints",
      "chunk_hash": "9113e2dd87a89f2a",
      "content_digest": "9113e2dd87a89f2a",
      "chunk_length": 858,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "with",
          "for",
          "qdrant",
          "retriever",
          "nodes",
          "node",
          "constraints",
          "are",
          "some",
          "large",
          "language",
          "models",
          "the",
          "our",
          "value",
          "library",
          "index",
          "metadatafilters",
          "exactmatchfilter",
          "filters"
        ],
        "term_weights": [
          {
            "term": "with",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "retriever",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "nodes",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "node",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "constraints",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "some",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "large",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "language",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "our",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "value",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "library",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "index",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "metadatafilters",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "exactmatchfilter",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "filters",
            "tf": 2,
            "weight": 0.021277
          }
        ],
        "unique_terms": 63,
        "total_terms": 94
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Querying documents with constraints",
        "are",
        "constraints",
        "for",
        "large",
        "node",
        "nodes",
        "qdrant",
        "retriever",
        "some",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5351612903225806,
      "overall": 0.7117204301075267
    }
  },
  {
    "text": "# Output: Qdrant is a vector database & vector similarity search engine. 0.60551536 ``` The description of Qdrant was the best match, even though it didn’t mention large language models at all. However, it was the only document that belonged to the `qdrant` library, so there was no other choice. Let’s try to search for something that is not present in the collection. Let’s define another retrieve, this time for the `llama-index` library: ```python llama_index_retriever = index.as_retriever(     filters=MetadataFilters(         filters=[             ExactMatchFilter(                 key=\"library\",                 value=\"llama-index\",             )         ]     ) )  nodes_with_scores = llama_index_retriever.retrieve(\"large language models\") for node in nodes_with_scores:     print(node.text, node.score)",
    "metadata": {
      "chunk_id": "f952f2857b12-0015",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Output: Qdrant is a vector database & vector similarity search engine. 0.60551536"
      ],
      "heading_text": "Output: Qdrant is a vector database & vector similarity search engine. 0.60551536",
      "token_count": 181,
      "char_count": 813,
      "start_char": 25507,
      "end_char": 26320,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5219587628865979,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.299392",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 181,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Output: Qdrant is a vector database & vector similarity search engine. 0.60551536",
      "chunk_hash": "91fd31d2e5f22698",
      "content_digest": "91fd31d2e5f22698",
      "chunk_length": 813,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "index",
          "llama",
          "qdrant",
          "was",
          "library",
          "for",
          "retriever",
          "node",
          "vector",
          "search",
          "large",
          "language",
          "models",
          "that",
          "let",
          "retrieve",
          "filters",
          "nodes",
          "with"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 6,
            "weight": 0.06383
          },
          {
            "term": "index",
            "tf": 5,
            "weight": 0.053191
          },
          {
            "term": "llama",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "was",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "library",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "retriever",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "node",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "large",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "language",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "that",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "let",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "retrieve",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "filters",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "nodes",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.021277
          }
        ],
        "unique_terms": 58,
        "total_terms": 94
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Output: Qdrant is a vector database & vector similarity search engine. 0.60551536",
        "for",
        "index",
        "library",
        "llama",
        "node",
        "qdrant",
        "retriever",
        "the",
        "vector",
        "was"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5219587628865979,
      "overall": 0.7073195876288659
    }
  },
  {
    "text": "# Output: LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models. 0.63576734 ``` The results returned by both retrievers are different, due to the different constraints, so we implemented a real multitenant search application!",
    "metadata": {
      "chunk_id": "f952f2857b12-0016",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Output: LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models. 0.63576734"
      ],
      "heading_text": "Output: LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models. 0.63576734",
      "token_count": 57,
      "char_count": 279,
      "start_char": 26324,
      "end_char": 26603,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5607317073170732,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.300107",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 57,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Output: LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models. 0.63576734",
      "chunk_hash": "0c57ca97ac6e7fd9",
      "content_digest": "0c57ca97ac6e7fd9",
      "chunk_length": 279,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "data",
          "the",
          "different",
          "output",
          "llamaindex",
          "simple",
          "flexible",
          "framework",
          "for",
          "connecting",
          "custom",
          "sources",
          "large",
          "language",
          "models",
          "63576734",
          "results",
          "returned",
          "both",
          "retrievers"
        ],
        "term_weights": [
          {
            "term": "data",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "different",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "output",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "llamaindex",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "flexible",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "framework",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "connecting",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "custom",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "large",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "language",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "63576734",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "results",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "returned",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "both",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "retrievers",
            "tf": 1,
            "weight": 0.032258
          }
        ],
        "unique_terms": 28,
        "total_terms": 31
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Output: LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models. 0.63576734",
        "connecting",
        "data",
        "different",
        "flexible",
        "for",
        "framework",
        "llamaindex",
        "output",
        "simple",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5607317073170732,
      "overall": 0.7535772357723577
    }
  },
  {
    "text": "##### Was this page useful? Yes No  Thank you for your feedback! 🙏  We are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/llama-index-multitenancy.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue. On this page:  - [Multitenancy with LlamaIndex](#multitenancy-with-llamaindex.md)    - [Prerequisites](#prerequisites.md)    - [Setting up LlamaIndex pipeline](#setting-up-llamaindex-pipeline.md)      - [Creating vector store](#creating-vector-store.md)     - [Defining chunking strategy and embedding model](#defining-chunking-strategy-and-embedding-model.md)     - [Combining everything together](#combining-everything-together.md)    - [Indexing documents](#indexing-documents.md)     - [Performance considerations](#performance-considerations.md)    - [Querying documents with constraints](#querying-documents-with-constraints.md)  * [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/llama-index-multitenancy.md) * [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)",
    "metadata": {
      "chunk_id": "f952f2857b12-0017",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Was this page useful?"
      ],
      "heading_text": "Was this page useful?",
      "token_count": 310,
      "char_count": 1202,
      "start_char": 26606,
      "end_char": 27808,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.733,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:23.302432",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 310,
      "document_id": "f952f2857b12",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Was this page useful?",
      "chunk_hash": "00cc5a62b3018950",
      "content_digest": "00cc5a62b3018950",
      "chunk_length": 1202,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "page",
          "github",
          "qdrant",
          "landing",
          "https",
          "com",
          "multitenancy",
          "with",
          "llamaindex",
          "documents",
          "this",
          "you",
          "edit",
          "tree",
          "master",
          "content",
          "documentation",
          "examples",
          "llama",
          "index"
        ],
        "term_weights": [
          {
            "term": "page",
            "tf": 7,
            "weight": 0.052632
          },
          {
            "term": "github",
            "tf": 7,
            "weight": 0.052632
          },
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.045113
          },
          {
            "term": "landing",
            "tf": 6,
            "weight": 0.045113
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "multitenancy",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "with",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "llamaindex",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "documents",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "this",
            "tf": 3,
            "weight": 0.022556
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "edit",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "tree",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "master",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "content",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "documentation",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "llama",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "index",
            "tf": 2,
            "weight": 0.015038
          }
        ],
        "unique_terms": 57,
        "total_terms": 133
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Was this page useful?",
        "com",
        "documents",
        "github",
        "https",
        "landing",
        "llamaindex",
        "multitenancy",
        "page",
        "qdrant",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.733,
      "overall": 0.7776666666666666
    }
  }
]
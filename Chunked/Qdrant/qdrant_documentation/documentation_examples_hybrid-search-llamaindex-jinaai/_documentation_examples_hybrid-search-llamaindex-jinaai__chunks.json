[
  {
    "text": "### Essentials  [Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)  [Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)  [Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)  [Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)  [Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)  [5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)  [Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)",
    "metadata": {
      "chunk_id": "beebe77eb764-0000",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Essentials"
      ],
      "heading_text": "Essentials",
      "token_count": 189,
      "char_count": 673,
      "start_char": 700,
      "end_char": 1373,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5053846153846153,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.839222",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 189,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Essentials",
      "chunk_hash": "a64044a3995d82e4",
      "content_digest": "a64044a3995d82e4",
      "chunk_length": 673,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "https",
          "tech",
          "documentation",
          "agentic",
          "with",
          "data",
          "ingestion",
          "beginners",
          "langgraph",
          "discord",
          "multimodal",
          "and",
          "deepseek",
          "n8n",
          "essentials",
          "for",
          "simple",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "documentation",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "agentic",
            "tf": 6,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "beginners",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "langgraph",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "discord",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "multimodal",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "deepseek",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "n8n",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "essentials",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 31,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Essentials",
        "agentic",
        "beginners",
        "data",
        "documentation",
        "https",
        "ingestion",
        "qdrant",
        "rag",
        "tech",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5053846153846153,
      "overall": 0.7017948717948718
    }
  },
  {
    "text": "### Integrations  [Data Management](https://qdrant.tech/documentation/data-management/)  - [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/) - [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/) - [Apache Spark](https://qdrant.tech/documentation/data-management/spark/) - [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/) - [cognee](https://qdrant.tech/documentation/data-management/cognee/) - [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/) - [DLT](https://qdrant.tech/documentation/data-management/dlt/) - [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/) - [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/) - [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)  [Embeddings](https://qdrant.tech/documentation/embeddings/)  - [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/) - [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/) - [Cohere](https://qdrant.tech/documentation/embeddings/cohere/) - [Gemini](https://qdrant.tech/documentation/embeddings/gemini/) - [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/) - [Mistral](https://qdrant.tech/documentation/embeddings/mistral/) - [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/) - [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/) - [Nomic](https://qdrant.tech/documentation/embeddings/nomic/) - [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/) - [Ollama](https://qdrant.tech/documentation/embeddings/ollama/) - [OpenAI](https://qdrant.tech/documentation/embeddings/openai/) - [Prem AI](https://qdrant.tech/documentation/embeddings/premai/) - [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/) - [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/) - [Upstage](https://qdrant.tech/documentation/embeddings/upstage/) - [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)  [Frameworks](https://qdrant.tech/documentation/frameworks/)  - [Autogen](https://qdrant.tech/documentation/frameworks/autogen/) - [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/) - [CamelAI](https://qdrant.tech/documentation/frameworks/camel/) - [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/) - [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/) - [Dagster](https://qdrant.tech/documentation/frameworks/dagster/) - [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/) - [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/) - [Feast](https://qdrant.tech/documentation/frameworks/feast/) - [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/) - [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/) - [Haystack](https://qdrant.tech/documentation/frameworks/haystack/) - [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/) - [Langchain](https://qdrant.tech/documentation/frameworks/langchain/) - [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/) - [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/) - [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/) - [Mastra](https://qdrant.tech/documentation/frameworks/mastra/) - [Mem0](https://qdrant.tech/documentation/frameworks/mem0/) - [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/) - [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/) - [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/) - [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/) - [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/) - [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/) - [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/) - [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/) - [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/) - [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/) - [txtai](https://qdrant.tech/documentation/frameworks/txtai/) - [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/) - [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/) - [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)  [Observability](https://qdrant.tech/documentation/observability/)  - [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/) - [OpenLIT](https://qdrant.tech/documentation/observability/openlit/) - [Datadog](https://qdrant.tech/documentation/observability/datadog/)  [Platforms](https://qdrant.tech/documentation/platforms/)  - [Apify](https://qdrant.tech/documentation/platforms/apify/) - [BuildShip](https://qdrant.tech/documentation/platforms/buildship/) - [Keboola](https://qdrant.tech/documentation/platforms/keboola/) - [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/) - [Make.com](https://qdrant.tech/documentation/platforms/make/) - [N8N](https://qdrant.tech/documentation/platforms/n8n/) - [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/) - [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/) - [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/) - [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/) - [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/) - [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)",
    "metadata": {
      "chunk_id": "beebe77eb764-0001",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integrations"
      ],
      "heading_text": "Integrations",
      "token_count": 1498,
      "char_count": 5661,
      "start_char": 1375,
      "end_char": 7036,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.863128",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 1498,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Integrations",
      "chunk_hash": "8a3f2e84e2a75ae9",
      "content_digest": "8a3f2e84e2a75ae9",
      "chunk_length": 5661,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "frameworks",
          "embeddings",
          "platforms",
          "data",
          "management",
          "observability",
          "airbyte",
          "apache",
          "airflow",
          "spark",
          "cocoindex",
          "cognee",
          "confluent",
          "dlt",
          "fluvio",
          "redpanda"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "qdrant",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "tech",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "documentation",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "frameworks",
            "tf": 35,
            "weight": 0.058528
          },
          {
            "term": "embeddings",
            "tf": 21,
            "weight": 0.035117
          },
          {
            "term": "platforms",
            "tf": 14,
            "weight": 0.023411
          },
          {
            "term": "data",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "management",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "observability",
            "tf": 5,
            "weight": 0.008361
          },
          {
            "term": "airbyte",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "apache",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "airflow",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "spark",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cocoindex",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cognee",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "confluent",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "dlt",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "fluvio",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "redpanda",
            "tf": 2,
            "weight": 0.003344
          }
        ],
        "unique_terms": 113,
        "total_terms": 598
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integrations",
        "data",
        "documentation",
        "embeddings",
        "frameworks",
        "https",
        "management",
        "observability",
        "platforms",
        "qdrant",
        "tech"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "overall": 0.7576923076923077
    }
  },
  {
    "text": "### Examples  [Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)  - [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) - [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)  [Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)  - [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/) - [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/) - [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)  [Build Prototypes](https://qdrant.tech/documentation/examples/)  - [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/) - [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/) - [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/) - [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/) - [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/) - [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/) - [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/) - [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/) - [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/) - [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/) - [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/) - [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)  [Practice Datasets](https://qdrant.tech/documentation/datasets/)",
    "metadata": {
      "chunk_id": "beebe77eb764-0002",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Examples"
      ],
      "heading_text": "Examples",
      "token_count": 576,
      "char_count": 2347,
      "start_char": 7038,
      "end_char": 9385,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.9076923076923078,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.870058",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 576,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Examples",
      "chunk_hash": "59078d11dd9c9931",
      "content_digest": "59078d11dd9c9931",
      "chunk_length": 2347,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "https",
          "tech",
          "documentation",
          "examples",
          "search",
          "with",
          "rag",
          "data",
          "chatbot",
          "send",
          "system",
          "semantic",
          "and",
          "cohere",
          "precision",
          "reranking",
          "dspy",
          "for",
          "automate"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 30,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "tech",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "documentation",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "examples",
            "tf": 14,
            "weight": 0.05
          },
          {
            "term": "search",
            "tf": 10,
            "weight": 0.035714
          },
          {
            "term": "with",
            "tf": 9,
            "weight": 0.032143
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.032143
          },
          {
            "term": "data",
            "tf": 7,
            "weight": 0.025
          },
          {
            "term": "chatbot",
            "tf": 6,
            "weight": 0.021429
          },
          {
            "term": "send",
            "tf": 5,
            "weight": 0.017857
          },
          {
            "term": "system",
            "tf": 5,
            "weight": 0.017857
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "cohere",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "dspy",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "automate",
            "tf": 2,
            "weight": 0.007143
          }
        ],
        "unique_terms": 96,
        "total_terms": 280
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Examples",
        "chatbot",
        "data",
        "documentation",
        "examples",
        "https",
        "qdrant",
        "rag",
        "search",
        "tech",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.9076923076923078,
      "overall": 0.8358974358974359
    }
  },
  {
    "text": "### Essentials  [Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)  [Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)  [Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)  [Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)  [Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)  [5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)  [Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)",
    "metadata": {
      "chunk_id": "beebe77eb764-0003",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Essentials"
      ],
      "heading_text": "Essentials",
      "token_count": 189,
      "char_count": 673,
      "start_char": 9387,
      "end_char": 10060,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5053846153846153,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.872094",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 189,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Essentials",
      "chunk_hash": "a64044a3995d82e4",
      "content_digest": "a64044a3995d82e4",
      "chunk_length": 673,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "https",
          "tech",
          "documentation",
          "agentic",
          "with",
          "data",
          "ingestion",
          "beginners",
          "langgraph",
          "discord",
          "multimodal",
          "and",
          "deepseek",
          "n8n",
          "essentials",
          "for",
          "simple",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "documentation",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "agentic",
            "tf": 6,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "beginners",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "langgraph",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "discord",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "multimodal",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "deepseek",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "n8n",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "essentials",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 31,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Essentials",
        "agentic",
        "beginners",
        "data",
        "documentation",
        "https",
        "ingestion",
        "qdrant",
        "rag",
        "tech",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5053846153846153,
      "overall": 0.7017948717948718
    }
  },
  {
    "text": "### Integrations  [Data Management](https://qdrant.tech/documentation/data-management/)  - [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/) - [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/) - [Apache Spark](https://qdrant.tech/documentation/data-management/spark/) - [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/) - [cognee](https://qdrant.tech/documentation/data-management/cognee/) - [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/) - [DLT](https://qdrant.tech/documentation/data-management/dlt/) - [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/) - [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/) - [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)  [Embeddings](https://qdrant.tech/documentation/embeddings/)  - [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/) - [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/) - [Cohere](https://qdrant.tech/documentation/embeddings/cohere/) - [Gemini](https://qdrant.tech/documentation/embeddings/gemini/) - [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/) - [Mistral](https://qdrant.tech/documentation/embeddings/mistral/) - [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/) - [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/) - [Nomic](https://qdrant.tech/documentation/embeddings/nomic/) - [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/) - [Ollama](https://qdrant.tech/documentation/embeddings/ollama/) - [OpenAI](https://qdrant.tech/documentation/embeddings/openai/) - [Prem AI](https://qdrant.tech/documentation/embeddings/premai/) - [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/) - [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/) - [Upstage](https://qdrant.tech/documentation/embeddings/upstage/) - [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)  [Frameworks](https://qdrant.tech/documentation/frameworks/)  - [Autogen](https://qdrant.tech/documentation/frameworks/autogen/) - [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/) - [CamelAI](https://qdrant.tech/documentation/frameworks/camel/) - [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/) - [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/) - [Dagster](https://qdrant.tech/documentation/frameworks/dagster/) - [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/) - [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/) - [Feast](https://qdrant.tech/documentation/frameworks/feast/) - [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/) - [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/) - [Haystack](https://qdrant.tech/documentation/frameworks/haystack/) - [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/) - [Langchain](https://qdrant.tech/documentation/frameworks/langchain/) - [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/) - [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/) - [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/) - [Mastra](https://qdrant.tech/documentation/frameworks/mastra/) - [Mem0](https://qdrant.tech/documentation/frameworks/mem0/) - [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/) - [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/) - [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/) - [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/) - [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/) - [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/) - [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/) - [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/) - [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/) - [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/) - [txtai](https://qdrant.tech/documentation/frameworks/txtai/) - [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/) - [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/) - [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)  [Observability](https://qdrant.tech/documentation/observability/)  - [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/) - [OpenLIT](https://qdrant.tech/documentation/observability/openlit/) - [Datadog](https://qdrant.tech/documentation/observability/datadog/)  [Platforms](https://qdrant.tech/documentation/platforms/)  - [Apify](https://qdrant.tech/documentation/platforms/apify/) - [BuildShip](https://qdrant.tech/documentation/platforms/buildship/) - [Keboola](https://qdrant.tech/documentation/platforms/keboola/) - [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/) - [Make.com](https://qdrant.tech/documentation/platforms/make/) - [N8N](https://qdrant.tech/documentation/platforms/n8n/) - [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/) - [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/) - [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/) - [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/) - [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/) - [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)",
    "metadata": {
      "chunk_id": "beebe77eb764-0004",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integrations"
      ],
      "heading_text": "Integrations",
      "token_count": 1498,
      "char_count": 5661,
      "start_char": 10062,
      "end_char": 15723,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.895951",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 1498,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Integrations",
      "chunk_hash": "8a3f2e84e2a75ae9",
      "content_digest": "8a3f2e84e2a75ae9",
      "chunk_length": 5661,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "frameworks",
          "embeddings",
          "platforms",
          "data",
          "management",
          "observability",
          "airbyte",
          "apache",
          "airflow",
          "spark",
          "cocoindex",
          "cognee",
          "confluent",
          "dlt",
          "fluvio",
          "redpanda"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "qdrant",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "tech",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "documentation",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "frameworks",
            "tf": 35,
            "weight": 0.058528
          },
          {
            "term": "embeddings",
            "tf": 21,
            "weight": 0.035117
          },
          {
            "term": "platforms",
            "tf": 14,
            "weight": 0.023411
          },
          {
            "term": "data",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "management",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "observability",
            "tf": 5,
            "weight": 0.008361
          },
          {
            "term": "airbyte",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "apache",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "airflow",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "spark",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cocoindex",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cognee",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "confluent",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "dlt",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "fluvio",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "redpanda",
            "tf": 2,
            "weight": 0.003344
          }
        ],
        "unique_terms": 113,
        "total_terms": 598
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integrations",
        "data",
        "documentation",
        "embeddings",
        "frameworks",
        "https",
        "management",
        "observability",
        "platforms",
        "qdrant",
        "tech"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "overall": 0.7576923076923077
    }
  },
  {
    "text": "### Examples  [Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)  - [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) - [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)  [Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)  - [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/) - [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/) - [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)  [Build Prototypes](https://qdrant.tech/documentation/examples/)  - [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/) - [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/) - [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/) - [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/) - [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/) - [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/) - [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/) - [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/) - [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/) - [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/) - [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/) - [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)  [Practice Datasets](https://qdrant.tech/documentation/datasets/)  - [Documentation](https://qdrant.tech/documentation/) - - [Examples](https://qdrant.tech/documentation/examples/) - - Chat With Product PDF Manuals Using Hybrid Search",
    "metadata": {
      "chunk_id": "beebe77eb764-0005",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Examples"
      ],
      "heading_text": "Examples",
      "token_count": 613,
      "char_count": 2516,
      "start_char": 15725,
      "end_char": 18241,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.8931818181818183,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.903614",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 613,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Examples",
      "chunk_hash": "e981bc5e36432b67",
      "content_digest": "e981bc5e36432b67",
      "chunk_length": 2516,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "documentation",
          "https",
          "tech",
          "examples",
          "search",
          "with",
          "rag",
          "data",
          "chatbot",
          "send",
          "system",
          "semantic",
          "and",
          "cohere",
          "precision",
          "reranking",
          "dspy",
          "for",
          "hybrid"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 32,
            "weight": 0.107023
          },
          {
            "term": "documentation",
            "tf": 24,
            "weight": 0.080268
          },
          {
            "term": "https",
            "tf": 23,
            "weight": 0.076923
          },
          {
            "term": "tech",
            "tf": 23,
            "weight": 0.076923
          },
          {
            "term": "examples",
            "tf": 16,
            "weight": 0.053512
          },
          {
            "term": "search",
            "tf": 11,
            "weight": 0.036789
          },
          {
            "term": "with",
            "tf": 10,
            "weight": 0.033445
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.0301
          },
          {
            "term": "data",
            "tf": 7,
            "weight": 0.023411
          },
          {
            "term": "chatbot",
            "tf": 6,
            "weight": 0.020067
          },
          {
            "term": "send",
            "tf": 5,
            "weight": 0.016722
          },
          {
            "term": "system",
            "tf": 5,
            "weight": 0.016722
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.013378
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.013378
          },
          {
            "term": "cohere",
            "tf": 4,
            "weight": 0.013378
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010033
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.010033
          },
          {
            "term": "dspy",
            "tf": 3,
            "weight": 0.010033
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.010033
          },
          {
            "term": "hybrid",
            "tf": 3,
            "weight": 0.010033
          }
        ],
        "unique_terms": 96,
        "total_terms": 299
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Examples",
        "chatbot",
        "data",
        "documentation",
        "examples",
        "https",
        "qdrant",
        "rag",
        "search",
        "tech",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.8931818181818183,
      "overall": 0.831060606060606
    }
  },
  {
    "text": "# Chat With Product PDF Manuals Using Hybrid Search  | Time: 120 min | Level: Advanced | Output: [GitHub](https://github.com/infoslack/qdrant-example/blob/main/HC-demo/HC-DO-LlamaIndex-Jina-v2.ipynb) | [](https://githubtocolab.com/infoslack/qdrant-example/blob/main/HC-demo/HC-DO-LlamaIndex-Jina-v2.ipynb) | | ------------- | --------------- | -------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |  With the proliferation of digital manuals and the increasing demand for quick and accurate customer support, having a chatbot capable of efficiently parsing through complex PDF documents and delivering precise information can be a game-changer for any business. In this tutorial, well walk you through the process of building a RAG-based chatbot, designed specifically to assist users with understanding the operation of various household appliances. Well cover the essential steps required to build your system, including data ingestion, natural language understanding, and response generation for customer support use cases.",
    "metadata": {
      "chunk_id": "beebe77eb764-0006",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Chat With Product PDF Manuals Using Hybrid Search"
      ],
      "heading_text": "Chat With Product PDF Manuals Using Hybrid Search",
      "token_count": 215,
      "char_count": 1192,
      "start_char": 18243,
      "end_char": 19435,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7125,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.904715",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 215,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Chat With Product PDF Manuals Using Hybrid Search",
      "chunk_hash": "9e770f4b66136269",
      "content_digest": "9e770f4b66136269",
      "chunk_length": 1192,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "and",
          "with",
          "for",
          "pdf",
          "manuals",
          "github",
          "https",
          "com",
          "infoslack",
          "qdrant",
          "example",
          "blob",
          "main",
          "demo",
          "llamaindex",
          "jina",
          "ipynb",
          "customer",
          "support"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 5,
            "weight": 0.042735
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.034188
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "pdf",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "manuals",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "infoslack",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "example",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "main",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "demo",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "llamaindex",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "jina",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "ipynb",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "customer",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "support",
            "tf": 2,
            "weight": 0.017094
          }
        ],
        "unique_terms": 87,
        "total_terms": 117
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Chat With Product PDF Manuals Using Hybrid Search",
        "and",
        "com",
        "for",
        "github",
        "https",
        "infoslack",
        "manuals",
        "pdf",
        "the",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7125,
      "overall": 0.8041666666666666
    }
  },
  {
    "text": "## Components  - **Embeddings:** Jina Embeddings, served via the [Jina Embeddings API](https://jina.ai/embeddings/#apiform) - **Database:** [Qdrant Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/), deployed in a managed Kubernetes cluster on [DigitalOcean (DOKS)](https://www.digitalocean.com/products/kubernetes) - **LLM:** [Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1) language model on HuggingFace - **Framework:** [LlamaIndex](https://www.llamaindex.ai/) for extended RAG functionality and [Hybrid Search support](https://docs.llamaindex.ai/en/stable/examples/vector_stores/qdrant_hybrid/). - **Parser:** [LlamaParse](https://github.com/run-llama/llama_parse) as a way to parse complex documents with embedded objects such as tables and figures.",
    "metadata": {
      "chunk_id": "beebe77eb764-0007",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Components"
      ],
      "heading_text": "Components",
      "token_count": 226,
      "char_count": 807,
      "start_char": 19438,
      "end_char": 20245,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7512903225806452,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.906977",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 226,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Components",
      "chunk_hash": "21050ee815af6ecd",
      "content_digest": "21050ee815af6ecd",
      "chunk_length": 807,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "embeddings",
          "hybrid",
          "jina",
          "qdrant",
          "llamaindex",
          "cloud",
          "kubernetes",
          "digitalocean",
          "www",
          "com",
          "mixtral",
          "8x7b",
          "instruct",
          "huggingface",
          "and",
          "llama",
          "parse",
          "components",
          "served"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 7,
            "weight": 0.076923
          },
          {
            "term": "embeddings",
            "tf": 4,
            "weight": 0.043956
          },
          {
            "term": "hybrid",
            "tf": 4,
            "weight": 0.043956
          },
          {
            "term": "jina",
            "tf": 3,
            "weight": 0.032967
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.032967
          },
          {
            "term": "llamaindex",
            "tf": 3,
            "weight": 0.032967
          },
          {
            "term": "cloud",
            "tf": 2,
            "weight": 0.021978
          },
          {
            "term": "kubernetes",
            "tf": 2,
            "weight": 0.021978
          },
          {
            "term": "digitalocean",
            "tf": 2,
            "weight": 0.021978
          },
          {
            "term": "www",
            "tf": 2,
            "weight": 0.021978
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.021978
          },
          {
            "term": "mixtral",
            "tf": 2,
            "weight": 0.021978
          },
          {
            "term": "8x7b",
            "tf": 2,
            "weight": 0.021978
          },
          {
            "term": "instruct",
            "tf": 2,
            "weight": 0.021978
          },
          {
            "term": "huggingface",
            "tf": 2,
            "weight": 0.021978
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.021978
          },
          {
            "term": "llama",
            "tf": 2,
            "weight": 0.021978
          },
          {
            "term": "parse",
            "tf": 2,
            "weight": 0.021978
          },
          {
            "term": "components",
            "tf": 1,
            "weight": 0.010989
          },
          {
            "term": "served",
            "tf": 1,
            "weight": 0.010989
          }
        ],
        "unique_terms": 61,
        "total_terms": 91
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Components",
        "cloud",
        "digitalocean",
        "embeddings",
        "https",
        "hybrid",
        "jina",
        "kubernetes",
        "llamaindex",
        "qdrant",
        "www"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7512903225806452,
      "overall": 0.783763440860215
    }
  },
  {
    "text": "### Procedure\n\nRetrieval Augmented Generation (RAG) combines search with language generation. An external information retrieval system is used to identify documents likely to provide information relevant to the users query. These documents, along with the users request, are then passed on to a text-generating language model, producing a natural response.\n\nThis method enables a language model to respond to questions and access information from a much larger set of documents than it could see otherwise. The language model only looks at a few relevant sections of the documents when generating responses, which also helps to reduce inexplicable errors.",
    "metadata": {
      "chunk_id": "beebe77eb764-0008",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Procedure"
      ],
      "heading_text": "Procedure",
      "token_count": 119,
      "char_count": 657,
      "start_char": 20247,
      "end_char": 20904,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5104081632653061,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.907543",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 119,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Procedure",
      "chunk_hash": "35e2f6802a94e353",
      "content_digest": "35e2f6802a94e353",
      "chunk_length": 657,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "language",
          "documents",
          "the",
          "information",
          "model",
          "retrieval",
          "generation",
          "with",
          "relevant",
          "user",
          "generating",
          "procedure",
          "augmented",
          "rag",
          "combines",
          "search",
          "external",
          "system",
          "used",
          "identify"
        ],
        "term_weights": [
          {
            "term": "language",
            "tf": 4,
            "weight": 0.050633
          },
          {
            "term": "documents",
            "tf": 4,
            "weight": 0.050633
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.050633
          },
          {
            "term": "information",
            "tf": 3,
            "weight": 0.037975
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.037975
          },
          {
            "term": "retrieval",
            "tf": 2,
            "weight": 0.025316
          },
          {
            "term": "generation",
            "tf": 2,
            "weight": 0.025316
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.025316
          },
          {
            "term": "relevant",
            "tf": 2,
            "weight": 0.025316
          },
          {
            "term": "user",
            "tf": 2,
            "weight": 0.025316
          },
          {
            "term": "generating",
            "tf": 2,
            "weight": 0.025316
          },
          {
            "term": "procedure",
            "tf": 1,
            "weight": 0.012658
          },
          {
            "term": "augmented",
            "tf": 1,
            "weight": 0.012658
          },
          {
            "term": "rag",
            "tf": 1,
            "weight": 0.012658
          },
          {
            "term": "combines",
            "tf": 1,
            "weight": 0.012658
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.012658
          },
          {
            "term": "external",
            "tf": 1,
            "weight": 0.012658
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.012658
          },
          {
            "term": "used",
            "tf": 1,
            "weight": 0.012658
          },
          {
            "term": "identify",
            "tf": 1,
            "weight": 0.012658
          }
        ],
        "unique_terms": 60,
        "total_terms": 79
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Procedure",
        "documents",
        "generation",
        "information",
        "language",
        "model",
        "relevant",
        "retrieval",
        "the",
        "user",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5104081632653061,
      "overall": 0.7368027210884353
    }
  },
  {
    "text": "## Implementation",
    "metadata": {
      "chunk_id": "beebe77eb764-0013",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Implementation"
      ],
      "heading_text": "Implementation",
      "token_count": 2,
      "char_count": 17,
      "start_char": 22715,
      "end_char": 22732,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.910027",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 2,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Implementation",
      "chunk_hash": "3ddd9203f21c2556",
      "content_digest": "3ddd9203f21c2556",
      "chunk_length": 17,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "implementation"
        ],
        "term_weights": [
          {
            "term": "implementation",
            "tf": 1,
            "weight": 1.0
          }
        ],
        "unique_terms": 1,
        "total_terms": 1
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Implementation",
        "implementation"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Connect Jina Embeddings and Mixtral LLM  LlamaIndex provides built-in support for the [Jina Embeddings API](https://jina.ai/embeddings/#apiform). To use it, you need to initialize the `JinaEmbedding` object with your API Key and model name. For the LLM, you need wrap it in a subclass of `llama_index.llms.CustomLLM` to make it compatible with LlamaIndex. ```python",
    "metadata": {
      "chunk_id": "beebe77eb764-0014",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Connect Jina Embeddings and Mixtral LLM"
      ],
      "heading_text": "Connect Jina Embeddings and Mixtral LLM",
      "token_count": 98,
      "char_count": 369,
      "start_char": 22734,
      "end_char": 23103,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5265384615384615,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.911042",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 98,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Connect Jina Embeddings and Mixtral LLM",
      "chunk_hash": "406aa1434cbc1ee0",
      "content_digest": "406aa1434cbc1ee0",
      "chunk_length": 369,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "jina",
          "embeddings",
          "the",
          "and",
          "llm",
          "llamaindex",
          "for",
          "api",
          "you",
          "need",
          "with",
          "connect",
          "mixtral",
          "provides",
          "built",
          "support",
          "https",
          "apiform",
          "use",
          "initialize"
        ],
        "term_weights": [
          {
            "term": "jina",
            "tf": 3,
            "weight": 0.061224
          },
          {
            "term": "embeddings",
            "tf": 3,
            "weight": 0.061224
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.061224
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "llm",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "llamaindex",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "api",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "need",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "connect",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "mixtral",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "built",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "apiform",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "initialize",
            "tf": 1,
            "weight": 0.020408
          }
        ],
        "unique_terms": 35,
        "total_terms": 49
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Connect Jina Embeddings and Mixtral LLM",
        "and",
        "api",
        "embeddings",
        "for",
        "jina",
        "llamaindex",
        "llm",
        "need",
        "the",
        "you"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5265384615384615,
      "overall": 0.7088461538461538
    }
  },
  {
    "text": "# connect embeddings from llama_index.embeddings.jinaai import JinaEmbedding  jina_embedding_model = JinaEmbedding(     model=\"jina-embeddings-v2-base-en\",     api_key=os.getenv(\"JINAAI_API_KEY\"), )",
    "metadata": {
      "chunk_id": "beebe77eb764-0015",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "connect embeddings"
      ],
      "heading_text": "connect embeddings",
      "token_count": 54,
      "char_count": 198,
      "start_char": 23106,
      "end_char": 23304,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.911421",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 54,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "connect embeddings",
      "chunk_hash": "0c3c37dc0d45f726",
      "content_digest": "0c3c37dc0d45f726",
      "chunk_length": 198,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "embeddings",
          "jinaai",
          "jinaembedding",
          "jina",
          "model",
          "api",
          "key",
          "connect",
          "from",
          "llama",
          "index",
          "import",
          "embedding",
          "base",
          "getenv"
        ],
        "term_weights": [
          {
            "term": "embeddings",
            "tf": 3,
            "weight": 0.130435
          },
          {
            "term": "jinaai",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "jinaembedding",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "jina",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "api",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "key",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "connect",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "llama",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "index",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "import",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "base",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "getenv",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 15,
        "total_terms": 23
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "api",
        "connect",
        "connect embeddings",
        "embeddings",
        "from",
        "jina",
        "jinaai",
        "jinaembedding",
        "key",
        "llama",
        "model"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.73
    }
  },
  {
    "text": "# connect LLM from llama_index.llms.huggingface import HuggingFaceInferenceAPI  mixtral_llm = HuggingFaceInferenceAPI(     model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\",     token=os.getenv(\"HF_INFERENCE_API_KEY\"), ) ```",
    "metadata": {
      "chunk_id": "beebe77eb764-0016",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "connect LLM"
      ],
      "heading_text": "connect LLM",
      "token_count": 70,
      "char_count": 226,
      "start_char": 23306,
      "end_char": 23532,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.57125,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.911779",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 70,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "connect LLM",
      "chunk_hash": "22ad34087c18d719",
      "content_digest": "22ad34087c18d719",
      "chunk_length": 226,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "llm",
          "huggingfaceinferenceapi",
          "mixtral",
          "connect",
          "from",
          "llama",
          "index",
          "llms",
          "huggingface",
          "import",
          "model",
          "name",
          "mistralai",
          "8x7b",
          "instruct",
          "token",
          "getenv",
          "inference",
          "api",
          "key"
        ],
        "term_weights": [
          {
            "term": "llm",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "huggingfaceinferenceapi",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "mixtral",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "connect",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "llama",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "index",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "llms",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "huggingface",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "import",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "name",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "mistralai",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "8x7b",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "instruct",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "token",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "getenv",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "api",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 20,
        "total_terms": 23
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "connect",
        "connect LLM",
        "from",
        "huggingface",
        "huggingfaceinferenceapi",
        "import",
        "index",
        "llama",
        "llm",
        "llms",
        "mixtral"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.57125,
      "overall": 0.6904166666666667
    }
  },
  {
    "text": "### Prepare data for RAG  This example will use household appliance manuals, which are generally available as PDF documents. LlamaPar In the `data` folder, we have three documents, and we will use it to extract the textual content from the PDF and use it as a knowledge base in a simple RAG. The free LlamaIndex Cloud plan is sufficient for our example: ```python import nest_asyncio nest_asyncio.apply() from llama_parse import LlamaParse  llamaparse_api_key = os.getenv(\"LLAMA_CLOUD_API_KEY\")  llama_parse_documents = LlamaParse(api_key=llamaparse_api_key, result_type=\"markdown\").load_data([     \"data/DJ68-00682F_0.0.pdf\",      \"data/F500E_WF80F5E_03445F_EN.pdf\",      \"data/O_ME4000R_ME19R7041FS_AA_EN.pdf\" ]) ```",
    "metadata": {
      "chunk_id": "beebe77eb764-0017",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Prepare data for RAG"
      ],
      "heading_text": "Prepare data for RAG",
      "token_count": 193,
      "char_count": 718,
      "start_char": 23534,
      "end_char": 24252,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5278048780487805,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.914077",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 193,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Prepare data for RAG",
      "chunk_hash": "e12ae8e04da0c9e8",
      "content_digest": "e12ae8e04da0c9e8",
      "chunk_length": 718,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "data",
          "pdf",
          "the",
          "llamaparse",
          "api",
          "key",
          "use",
          "documents",
          "llama",
          "for",
          "rag",
          "example",
          "will",
          "and",
          "from",
          "cloud",
          "import",
          "nest",
          "asyncio",
          "parse"
        ],
        "term_weights": [
          {
            "term": "data",
            "tf": 6,
            "weight": 0.0625
          },
          {
            "term": "pdf",
            "tf": 5,
            "weight": 0.052083
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.041667
          },
          {
            "term": "llamaparse",
            "tf": 4,
            "weight": 0.041667
          },
          {
            "term": "api",
            "tf": 4,
            "weight": 0.041667
          },
          {
            "term": "key",
            "tf": 4,
            "weight": 0.041667
          },
          {
            "term": "use",
            "tf": 3,
            "weight": 0.03125
          },
          {
            "term": "documents",
            "tf": 3,
            "weight": 0.03125
          },
          {
            "term": "llama",
            "tf": 3,
            "weight": 0.03125
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "rag",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "example",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "will",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "from",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "cloud",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "import",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "nest",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "asyncio",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "parse",
            "tf": 2,
            "weight": 0.020833
          }
        ],
        "unique_terms": 58,
        "total_terms": 96
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Prepare data for RAG",
        "api",
        "data",
        "documents",
        "for",
        "key",
        "llama",
        "llamaparse",
        "pdf",
        "the",
        "use"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5278048780487805,
      "overall": 0.7092682926829269
    }
  },
  {
    "text": "# By default llamaindex uses OpenAI models",
    "metadata": {
      "chunk_id": "beebe77eb764-0019",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "By default llamaindex uses OpenAI models"
      ],
      "heading_text": "By default llamaindex uses OpenAI models",
      "token_count": 10,
      "char_count": 42,
      "start_char": 24630,
      "end_char": 24672,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.916116",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 10,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "By default llamaindex uses OpenAI models",
      "chunk_hash": "5191d3cfa1aab55e",
      "content_digest": "5191d3cfa1aab55e",
      "chunk_length": 42,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "default",
          "llamaindex",
          "uses",
          "openai",
          "models"
        ],
        "term_weights": [
          {
            "term": "default",
            "tf": 1,
            "weight": 0.2
          },
          {
            "term": "llamaindex",
            "tf": 1,
            "weight": 0.2
          },
          {
            "term": "uses",
            "tf": 1,
            "weight": 0.2
          },
          {
            "term": "openai",
            "tf": 1,
            "weight": 0.2
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.2
          }
        ],
        "unique_terms": 5,
        "total_terms": 5
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "By default llamaindex uses OpenAI models",
        "default",
        "llamaindex",
        "models",
        "openai",
        "uses"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "# setting embed_model to Jina and llm model to Mixtral from llama_index.core import Settings Settings.embed_model = jina_embedding_model Settings.llm = mixtral_llm  from llama_index.core import VectorStoreIndex, StorageContext from llama_index.vector_stores.qdrant import QdrantVectorStore import qdrant_client  client = qdrant_client.QdrantClient(     url=os.getenv(\"QDRANT_HOST\"),     api_key=os.getenv(\"QDRANT_API_KEY\") )  vector_store = QdrantVectorStore(     client=client, collection_name=\"demo\", enable_hybrid=True, batch_size=20 ) Settings.chunk_size = 512  storage_context = StorageContext.from_defaults(vector_store=vector_store) index = VectorStoreIndex.from_documents(     documents=llama_parse_documents,      storage_context=storage_context ) ```",
    "metadata": {
      "chunk_id": "beebe77eb764-0020",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "setting embed_model to Jina and llm model to Mixtral"
      ],
      "heading_text": "setting embed_model to Jina and llm model to Mixtral",
      "token_count": 179,
      "char_count": 760,
      "start_char": 24673,
      "end_char": 25433,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5124137931034483,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.916885",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 179,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "setting embed_model to Jina and llm model to Mixtral",
      "chunk_hash": "c84ed1618902d28d",
      "content_digest": "c84ed1618902d28d",
      "chunk_length": 760,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "from",
          "qdrant",
          "client",
          "model",
          "llama",
          "index",
          "import",
          "settings",
          "vector",
          "llm",
          "store",
          "storage",
          "context",
          "documents",
          "embed",
          "jina",
          "mixtral",
          "core",
          "vectorstoreindex",
          "storagecontext"
        ],
        "term_weights": [
          {
            "term": "from",
            "tf": 5,
            "weight": 0.053191
          },
          {
            "term": "qdrant",
            "tf": 5,
            "weight": 0.053191
          },
          {
            "term": "client",
            "tf": 5,
            "weight": 0.053191
          },
          {
            "term": "model",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "llama",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "index",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "import",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "settings",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "vector",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "llm",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "store",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "storage",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "context",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "documents",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "embed",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "jina",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "mixtral",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "core",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "vectorstoreindex",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "storagecontext",
            "tf": 2,
            "weight": 0.021277
          }
        ],
        "unique_terms": 43,
        "total_terms": 94
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "client",
        "from",
        "import",
        "index",
        "llama",
        "llm",
        "model",
        "qdrant",
        "setting embed_model to Jina and llm model to Mixtral",
        "settings",
        "vector"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5124137931034483,
      "overall": 0.6708045977011494
    }
  },
  {
    "text": "##### Was this page useful? Yes No  Thank you for your feedback!   We are sorry to hear that.  You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/hybrid-search-llamaindex-jinaai.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue. On this page:  - [Chat With Product PDF Manuals Using Hybrid Search](#chat-with-product-pdf-manuals-using-hybrid-search.md)    - [Components](#components.md)     - [Procedure](#procedure.md)    - [](#heading.md)    - [Prerequisites](#prerequisites.md)      - [Deploying Qdrant Hybrid Cloud on DigitalOcean](#deploying-qdrant-hybrid-cloud-on-digitalocean.md)     - [Development environment](#development-environment.md)    - [Implementation](#implementation.md)      - [Connect Jina Embeddings and Mixtral LLM](#connect-jina-embeddings-and-mixtral-llm.md)     - [Prepare data for RAG](#prepare-data-for-rag.md)     - [Store data into Qdrant](#store-data-into-qdrant.md)     - [Prepare a prompt](#prepare-a-prompt.md)    - [Run a test query](#run-a-test-query.md)  * [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/hybrid-search-llamaindex-jinaai.md) * [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)",
    "metadata": {
      "chunk_id": "beebe77eb764-0026",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "file_extension": ".md",
      "chunk_index": 26,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Was this page useful?"
      ],
      "heading_text": "Was this page useful?",
      "token_count": 370,
      "char_count": 1343,
      "start_char": 27708,
      "end_char": 29051,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7314081632653062,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:24.923742",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 370,
      "document_id": "beebe77eb764",
      "document_name": "_documentation_examples_hybrid-search-llamaindex-jinaai_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_filename": "_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_examples_hybrid-search-llamaindex-jinaai\\_documentation_examples_hybrid-search-llamaindex-jinaai_.md",
      "hierarchy_path": "Was this page useful?",
      "chunk_hash": "643f734fb5a13469",
      "content_digest": "643f734fb5a13469",
      "chunk_length": 1343,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "page",
          "github",
          "landing",
          "hybrid",
          "https",
          "com",
          "search",
          "prepare",
          "data",
          "this",
          "for",
          "you",
          "edit",
          "tree",
          "master",
          "content",
          "documentation",
          "examples",
          "llamaindex"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.063291
          },
          {
            "term": "page",
            "tf": 7,
            "weight": 0.044304
          },
          {
            "term": "github",
            "tf": 7,
            "weight": 0.044304
          },
          {
            "term": "landing",
            "tf": 6,
            "weight": 0.037975
          },
          {
            "term": "hybrid",
            "tf": 6,
            "weight": 0.037975
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "search",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "prepare",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "data",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "this",
            "tf": 3,
            "weight": 0.018987
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.018987
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.012658
          },
          {
            "term": "edit",
            "tf": 2,
            "weight": 0.012658
          },
          {
            "term": "tree",
            "tf": 2,
            "weight": 0.012658
          },
          {
            "term": "master",
            "tf": 2,
            "weight": 0.012658
          },
          {
            "term": "content",
            "tf": 2,
            "weight": 0.012658
          },
          {
            "term": "documentation",
            "tf": 2,
            "weight": 0.012658
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.012658
          },
          {
            "term": "llamaindex",
            "tf": 2,
            "weight": 0.012658
          }
        ],
        "unique_terms": 66,
        "total_terms": 158
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Was this page useful?",
        "com",
        "data",
        "github",
        "https",
        "hybrid",
        "landing",
        "page",
        "prepare",
        "qdrant",
        "search"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7314081632653062,
      "overall": 0.7771360544217686
    }
  }
]
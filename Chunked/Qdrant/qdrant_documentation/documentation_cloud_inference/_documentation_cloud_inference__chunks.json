[
  {
    "text": "### Managed Services  [Getting Started](https://qdrant.tech/documentation/cloud-getting-started/)  [Account Setup](https://qdrant.tech/documentation/cloud-account-setup/)  [Cloud RBAC](https://qdrant.tech/documentation/cloud-rbac/)  - [Role Management](https://qdrant.tech/documentation/cloud-rbac/role-management/) - [User Management](https://qdrant.tech/documentation/cloud-rbac/user-management/) - [Permission Reference](https://qdrant.tech/documentation/cloud-rbac/permission-reference/)  [Managed Cloud](https://qdrant.tech/documentation/cloud/)  - [Create a Cluster](https://qdrant.tech/documentation/cloud/create-cluster/) - [Authentication](https://qdrant.tech/documentation/cloud/authentication/) - [Cluster Access](https://qdrant.tech/documentation/cloud/cluster-access/) - [Scale Clusters](https://qdrant.tech/documentation/cloud/cluster-scaling/) - [Configure Clusters](https://qdrant.tech/documentation/cloud/configure-cluster/) - [Monitor Clusters](https://qdrant.tech/documentation/cloud/cluster-monitoring/) - [Update Clusters](https://qdrant.tech/documentation/cloud/cluster-upgrades/) - [Backup Clusters](https://qdrant.tech/documentation/cloud/backups/) - [Inference](https://qdrant.tech/documentation/cloud/inference/)  [Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/)  - [Setup Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/hybrid-cloud-setup/) - [Create a Cluster](https://qdrant.tech/documentation/hybrid-cloud/hybrid-cloud-cluster-creation/) - [Configure, Scale & Update Clusters](https://qdrant.tech/documentation/hybrid-cloud/configure-scale-upgrade/) - [Configure the Qdrant Operator](https://qdrant.tech/documentation/hybrid-cloud/operator-configuration/) - [Networking, Logging & Monitoring](https://qdrant.tech/documentation/hybrid-cloud/networking-logging-monitoring/) - [Deployment Platforms](https://qdrant.tech/documentation/hybrid-cloud/platform-deployment-options/)  [Private Cloud](https://qdrant.tech/documentation/private-cloud/)  - [Setup Private Cloud](https://qdrant.tech/documentation/private-cloud/private-cloud-setup/) - [Configuration](https://qdrant.tech/documentation/private-cloud/configuration/) - [Managing a Cluster](https://qdrant.tech/documentation/private-cloud/qdrant-cluster-management/) - [Backups](https://qdrant.tech/documentation/private-cloud/backups/) - [Logging & Monitoring](https://qdrant.tech/documentation/private-cloud/logging-monitoring/) - [API Reference](https://qdrant.tech/documentation/private-cloud/api-reference/) - [Changelog](https://qdrant.tech/documentation/private-cloud/changelog/)  [Billing & Payments](https://qdrant.tech/documentation/cloud-pricing-payments/)  [Premium Tier](https://qdrant.tech/documentation/cloud-premium/)",
    "metadata": {
      "chunk_id": "c5533cbbb261-0001",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Managed Services"
      ],
      "heading_text": "Managed Services",
      "token_count": 614,
      "char_count": 2741,
      "start_char": 754,
      "end_char": 3495,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7067961165048544,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.836133",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 614,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Managed Services",
      "chunk_hash": "81e21f320195534d",
      "content_digest": "81e21f320195534d",
      "chunk_length": 2741,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cloud",
          "qdrant",
          "https",
          "tech",
          "documentation",
          "cluster",
          "hybrid",
          "private",
          "setup",
          "clusters",
          "rbac",
          "management",
          "configure",
          "monitoring",
          "reference",
          "logging",
          "create",
          "scale",
          "backups",
          "configuration"
        ],
        "term_weights": [
          {
            "term": "cloud",
            "tf": 42,
            "weight": 0.134185
          },
          {
            "term": "qdrant",
            "tf": 35,
            "weight": 0.111821
          },
          {
            "term": "https",
            "tf": 33,
            "weight": 0.105431
          },
          {
            "term": "tech",
            "tf": 33,
            "weight": 0.105431
          },
          {
            "term": "documentation",
            "tf": 33,
            "weight": 0.105431
          },
          {
            "term": "cluster",
            "tf": 12,
            "weight": 0.038339
          },
          {
            "term": "hybrid",
            "tf": 11,
            "weight": 0.035144
          },
          {
            "term": "private",
            "tf": 11,
            "weight": 0.035144
          },
          {
            "term": "setup",
            "tf": 6,
            "weight": 0.019169
          },
          {
            "term": "clusters",
            "tf": 6,
            "weight": 0.019169
          },
          {
            "term": "rbac",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "management",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "configure",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "monitoring",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "reference",
            "tf": 4,
            "weight": 0.01278
          },
          {
            "term": "logging",
            "tf": 4,
            "weight": 0.01278
          },
          {
            "term": "create",
            "tf": 3,
            "weight": 0.009585
          },
          {
            "term": "scale",
            "tf": 3,
            "weight": 0.009585
          },
          {
            "term": "backups",
            "tf": 3,
            "weight": 0.009585
          },
          {
            "term": "configuration",
            "tf": 3,
            "weight": 0.009585
          }
        ],
        "unique_terms": 53,
        "total_terms": 313
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Managed Services",
        "cloud",
        "cluster",
        "clusters",
        "documentation",
        "https",
        "hybrid",
        "private",
        "qdrant",
        "setup",
        "tech"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7067961165048544,
      "overall": 0.7689320388349513
    }
  },
  {
    "text": "### Support  [Support](https://qdrant.tech/documentation/support/)  [Security](https://qdrant.tech/documentation/cloud-security/)  [Tutorials & Examples](https://qdrant.tech/documentation/tutorials-and-examples/)  - [Using Cloud Inference to Build Hybrid Search](https://qdrant.tech/documentation/tutorials-and-examples/cloud-inference-hybrid-search/) - [Monitoring Hybrid/Private Cloud with Prometheus and Grafana](https://qdrant.tech/documentation/tutorials-and-examples/hybrid-cloud-prometheus/)",
    "metadata": {
      "chunk_id": "c5533cbbb261-0003",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Support"
      ],
      "heading_text": "Support",
      "token_count": 110,
      "char_count": 498,
      "start_char": 3798,
      "end_char": 4296,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5639130434782609,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.840793",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 110,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Support",
      "chunk_hash": "bd66045741770c14",
      "content_digest": "bd66045741770c14",
      "chunk_length": 498,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "cloud",
          "tutorials",
          "examples",
          "and",
          "hybrid",
          "support",
          "security",
          "inference",
          "search",
          "prometheus",
          "using",
          "build",
          "monitoring",
          "private",
          "with",
          "grafana"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 5,
            "weight": 0.086207
          },
          {
            "term": "qdrant",
            "tf": 5,
            "weight": 0.086207
          },
          {
            "term": "tech",
            "tf": 5,
            "weight": 0.086207
          },
          {
            "term": "documentation",
            "tf": 5,
            "weight": 0.086207
          },
          {
            "term": "cloud",
            "tf": 5,
            "weight": 0.086207
          },
          {
            "term": "tutorials",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "examples",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "hybrid",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "support",
            "tf": 3,
            "weight": 0.051724
          },
          {
            "term": "security",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "prometheus",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "build",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "monitoring",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "private",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "grafana",
            "tf": 1,
            "weight": 0.017241
          }
        ],
        "unique_terms": 20,
        "total_terms": 58
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Support",
        "and",
        "cloud",
        "documentation",
        "examples",
        "https",
        "hybrid",
        "qdrant",
        "support",
        "tech",
        "tutorials"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5639130434782609,
      "overall": 0.6879710144927537
    }
  },
  {
    "text": "### Managed Services  [Getting Started](https://qdrant.tech/documentation/cloud-getting-started/)  [Account Setup](https://qdrant.tech/documentation/cloud-account-setup/)  [Cloud RBAC](https://qdrant.tech/documentation/cloud-rbac/)  - [Role Management](https://qdrant.tech/documentation/cloud-rbac/role-management/) - [User Management](https://qdrant.tech/documentation/cloud-rbac/user-management/) - [Permission Reference](https://qdrant.tech/documentation/cloud-rbac/permission-reference/)  [Managed Cloud](https://qdrant.tech/documentation/cloud/)  - [Create a Cluster](https://qdrant.tech/documentation/cloud/create-cluster/) - [Authentication](https://qdrant.tech/documentation/cloud/authentication/) - [Cluster Access](https://qdrant.tech/documentation/cloud/cluster-access/) - [Scale Clusters](https://qdrant.tech/documentation/cloud/cluster-scaling/) - [Configure Clusters](https://qdrant.tech/documentation/cloud/configure-cluster/) - [Monitor Clusters](https://qdrant.tech/documentation/cloud/cluster-monitoring/) - [Update Clusters](https://qdrant.tech/documentation/cloud/cluster-upgrades/) - [Backup Clusters](https://qdrant.tech/documentation/cloud/backups/) - [Inference](https://qdrant.tech/documentation/cloud/inference/)  [Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/)  - [Setup Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/hybrid-cloud-setup/) - [Create a Cluster](https://qdrant.tech/documentation/hybrid-cloud/hybrid-cloud-cluster-creation/) - [Configure, Scale & Update Clusters](https://qdrant.tech/documentation/hybrid-cloud/configure-scale-upgrade/) - [Configure the Qdrant Operator](https://qdrant.tech/documentation/hybrid-cloud/operator-configuration/) - [Networking, Logging & Monitoring](https://qdrant.tech/documentation/hybrid-cloud/networking-logging-monitoring/) - [Deployment Platforms](https://qdrant.tech/documentation/hybrid-cloud/platform-deployment-options/)  [Private Cloud](https://qdrant.tech/documentation/private-cloud/)  - [Setup Private Cloud](https://qdrant.tech/documentation/private-cloud/private-cloud-setup/) - [Configuration](https://qdrant.tech/documentation/private-cloud/configuration/) - [Managing a Cluster](https://qdrant.tech/documentation/private-cloud/qdrant-cluster-management/) - [Backups](https://qdrant.tech/documentation/private-cloud/backups/) - [Logging & Monitoring](https://qdrant.tech/documentation/private-cloud/logging-monitoring/) - [API Reference](https://qdrant.tech/documentation/private-cloud/api-reference/) - [Changelog](https://qdrant.tech/documentation/private-cloud/changelog/)  [Billing & Payments](https://qdrant.tech/documentation/cloud-pricing-payments/)  [Premium Tier](https://qdrant.tech/documentation/cloud-premium/)",
    "metadata": {
      "chunk_id": "c5533cbbb261-0005",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Managed Services"
      ],
      "heading_text": "Managed Services",
      "token_count": 614,
      "char_count": 2741,
      "start_char": 4392,
      "end_char": 7133,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7067961165048544,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.855009",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 614,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Managed Services",
      "chunk_hash": "81e21f320195534d",
      "content_digest": "81e21f320195534d",
      "chunk_length": 2741,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cloud",
          "qdrant",
          "https",
          "tech",
          "documentation",
          "cluster",
          "hybrid",
          "private",
          "setup",
          "clusters",
          "rbac",
          "management",
          "configure",
          "monitoring",
          "reference",
          "logging",
          "create",
          "scale",
          "backups",
          "configuration"
        ],
        "term_weights": [
          {
            "term": "cloud",
            "tf": 42,
            "weight": 0.134185
          },
          {
            "term": "qdrant",
            "tf": 35,
            "weight": 0.111821
          },
          {
            "term": "https",
            "tf": 33,
            "weight": 0.105431
          },
          {
            "term": "tech",
            "tf": 33,
            "weight": 0.105431
          },
          {
            "term": "documentation",
            "tf": 33,
            "weight": 0.105431
          },
          {
            "term": "cluster",
            "tf": 12,
            "weight": 0.038339
          },
          {
            "term": "hybrid",
            "tf": 11,
            "weight": 0.035144
          },
          {
            "term": "private",
            "tf": 11,
            "weight": 0.035144
          },
          {
            "term": "setup",
            "tf": 6,
            "weight": 0.019169
          },
          {
            "term": "clusters",
            "tf": 6,
            "weight": 0.019169
          },
          {
            "term": "rbac",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "management",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "configure",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "monitoring",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "reference",
            "tf": 4,
            "weight": 0.01278
          },
          {
            "term": "logging",
            "tf": 4,
            "weight": 0.01278
          },
          {
            "term": "create",
            "tf": 3,
            "weight": 0.009585
          },
          {
            "term": "scale",
            "tf": 3,
            "weight": 0.009585
          },
          {
            "term": "backups",
            "tf": 3,
            "weight": 0.009585
          },
          {
            "term": "configuration",
            "tf": 3,
            "weight": 0.009585
          }
        ],
        "unique_terms": 53,
        "total_terms": 313
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Managed Services",
        "cloud",
        "cluster",
        "clusters",
        "documentation",
        "https",
        "hybrid",
        "private",
        "qdrant",
        "setup",
        "tech"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7067961165048544,
      "overall": 0.7689320388349513
    }
  },
  {
    "text": "### Support  [Support](https://qdrant.tech/documentation/support/)  [Security](https://qdrant.tech/documentation/cloud-security/)  [Tutorials & Examples](https://qdrant.tech/documentation/tutorials-and-examples/)  - [Using Cloud Inference to Build Hybrid Search](https://qdrant.tech/documentation/tutorials-and-examples/cloud-inference-hybrid-search/) - [Monitoring Hybrid/Private Cloud with Prometheus and Grafana](https://qdrant.tech/documentation/tutorials-and-examples/hybrid-cloud-prometheus/)  * [Documentation](https://qdrant.tech/documentation/) * * [Cloud](https://qdrant.tech/documentation/cloud/) * * Inference",
    "metadata": {
      "chunk_id": "c5533cbbb261-0007",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Support"
      ],
      "heading_text": "Support",
      "token_count": 141,
      "char_count": 621,
      "start_char": 7436,
      "end_char": 8057,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.522258064516129,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.862488",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 141,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Support",
      "chunk_hash": "9eb4849eb649b14d",
      "content_digest": "9eb4849eb649b14d",
      "chunk_length": 621,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "documentation",
          "https",
          "qdrant",
          "tech",
          "cloud",
          "tutorials",
          "examples",
          "and",
          "hybrid",
          "support",
          "inference",
          "security",
          "search",
          "prometheus",
          "using",
          "build",
          "monitoring",
          "private",
          "with",
          "grafana"
        ],
        "term_weights": [
          {
            "term": "documentation",
            "tf": 8,
            "weight": 0.114286
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.1
          },
          {
            "term": "qdrant",
            "tf": 7,
            "weight": 0.1
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.1
          },
          {
            "term": "cloud",
            "tf": 7,
            "weight": 0.1
          },
          {
            "term": "tutorials",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "examples",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "hybrid",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "support",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "security",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "prometheus",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "build",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "monitoring",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "private",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "grafana",
            "tf": 1,
            "weight": 0.014286
          }
        ],
        "unique_terms": 20,
        "total_terms": 70
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Support",
        "and",
        "cloud",
        "documentation",
        "examples",
        "https",
        "hybrid",
        "qdrant",
        "support",
        "tech",
        "tutorials"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.522258064516129,
      "overall": 0.7074193548387097
    }
  },
  {
    "text": "# Inference in Qdrant Managed Cloud\n\nInference is the process of creating vector embeddings from text, images, or other data types using a machine learning model.\n\nQdrant Managed Cloud allows you to use inference directly in the cloud, without the need to set up and maintain your own inference infrastructure.\n\nInference is currently only available in US regions for paid clusters. Support for inference in other regions is coming soon.",
    "metadata": {
      "chunk_id": "c5533cbbb261-0008",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Inference in Qdrant Managed Cloud"
      ],
      "heading_text": "Inference in Qdrant Managed Cloud",
      "token_count": 85,
      "char_count": 437,
      "start_char": 8059,
      "end_char": 8496,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5085714285714286,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.863405",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 85,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Inference in Qdrant Managed Cloud",
      "chunk_hash": "283f9ddf701bd86f",
      "content_digest": "283f9ddf701bd86f",
      "chunk_length": 437,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "inference",
          "cloud",
          "the",
          "qdrant",
          "managed",
          "other",
          "regions",
          "for",
          "process",
          "creating",
          "vector",
          "embeddings",
          "from",
          "text",
          "images",
          "data",
          "types",
          "using",
          "machine",
          "learning"
        ],
        "term_weights": [
          {
            "term": "inference",
            "tf": 6,
            "weight": 0.109091
          },
          {
            "term": "cloud",
            "tf": 3,
            "weight": 0.054545
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.054545
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "managed",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "other",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "regions",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "creating",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "text",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "images",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "data",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "types",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "machine",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "learning",
            "tf": 1,
            "weight": 0.018182
          }
        ],
        "unique_terms": 41,
        "total_terms": 55
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Inference in Qdrant Managed Cloud",
        "cloud",
        "creating",
        "for",
        "inference",
        "managed",
        "other",
        "process",
        "qdrant",
        "regions",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5085714285714286,
      "overall": 0.7028571428571428
    }
  },
  {
    "text": "## Supported Models\n\nYou can see the list of supported models in the Inference tab of the Cluster Detail page in the Qdrant Cloud Console. The list includes models for text, both to produce dense and sparse vectors, as well as multi-modal models for images.",
    "metadata": {
      "chunk_id": "c5533cbbb261-0009",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Supported Models"
      ],
      "heading_text": "Supported Models",
      "token_count": 54,
      "char_count": 257,
      "start_char": 8498,
      "end_char": 8755,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5033333333333333,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.863789",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 54,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Supported Models",
      "chunk_hash": "c2faf16c3c897577",
      "content_digest": "c2faf16c3c897577",
      "chunk_length": 257,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "models",
          "supported",
          "list",
          "for",
          "you",
          "can",
          "see",
          "inference",
          "tab",
          "cluster",
          "detail",
          "page",
          "qdrant",
          "cloud",
          "console",
          "includes",
          "text",
          "both",
          "produce"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 5,
            "weight": 0.131579
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.105263
          },
          {
            "term": "supported",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "list",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "see",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "tab",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "cluster",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "detail",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "page",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "console",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "includes",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "text",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "both",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "produce",
            "tf": 1,
            "weight": 0.026316
          }
        ],
        "unique_terms": 28,
        "total_terms": 38
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Supported Models",
        "can",
        "for",
        "inference",
        "list",
        "models",
        "see",
        "supported",
        "tab",
        "the",
        "you"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5033333333333333,
      "overall": 0.7344444444444443
    }
  },
  {
    "text": "## Enabling/Disabling Inference\n\nInference is enabled by default for all new clusters, created after July, 7th 2025. You can enable it for existing clusters directly from the Inference tab of the Cluster Detail page in the Qdrant Cloud Console. Activating inference will trigger a restart of your cluster to apply the new configuration.",
    "metadata": {
      "chunk_id": "c5533cbbb261-0010",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Enabling/Disabling Inference"
      ],
      "heading_text": "Enabling/Disabling Inference",
      "token_count": 73,
      "char_count": 336,
      "start_char": 8757,
      "end_char": 9093,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5333962264150943,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.871112",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 73,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Enabling/Disabling Inference",
      "chunk_hash": "9ccc1d0e2aee8dda",
      "content_digest": "9ccc1d0e2aee8dda",
      "chunk_length": 336,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "inference",
          "the",
          "for",
          "new",
          "clusters",
          "cluster",
          "enabling",
          "disabling",
          "enabled",
          "default",
          "all",
          "created",
          "after",
          "july",
          "7th",
          "2025",
          "you",
          "can",
          "enable",
          "existing"
        ],
        "term_weights": [
          {
            "term": "inference",
            "tf": 4,
            "weight": 0.088889
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.088889
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "new",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "clusters",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "cluster",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "enabling",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "disabling",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "enabled",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "default",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "created",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "after",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "july",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "7th",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "2025",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "enable",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "existing",
            "tf": 1,
            "weight": 0.022222
          }
        ],
        "unique_terms": 35,
        "total_terms": 45
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Enabling/Disabling Inference",
        "cluster",
        "clusters",
        "default",
        "disabling",
        "enabled",
        "enabling",
        "for",
        "inference",
        "new",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5333962264150943,
      "overall": 0.711132075471698
    }
  },
  {
    "text": "## Billing\n\nInference is billed based on the number of tokens processed by the model. The cost is calculated per 1,000,000 tokens. The price depends on the model and is displayed ont the Inference tab of the Cluster Detail page. You also can see the current usage of each model there.",
    "metadata": {
      "chunk_id": "c5533cbbb261-0011",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Billing"
      ],
      "heading_text": "Billing",
      "token_count": 63,
      "char_count": 284,
      "start_char": 9095,
      "end_char": 9379,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5076470588235293,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.871616",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 63,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Billing",
      "chunk_hash": "1d1f69a58a777413",
      "content_digest": "1d1f69a58a777413",
      "chunk_length": 284,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "model",
          "inference",
          "tokens",
          "000",
          "billing",
          "billed",
          "based",
          "number",
          "processed",
          "cost",
          "calculated",
          "per",
          "price",
          "depends",
          "and",
          "displayed",
          "ont",
          "tab",
          "cluster"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 8,
            "weight": 0.190476
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.071429
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "tokens",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "000",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "billing",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "billed",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "number",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "processed",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "cost",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "calculated",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "per",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "price",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "depends",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "displayed",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "ont",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "tab",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "cluster",
            "tf": 1,
            "weight": 0.02381
          }
        ],
        "unique_terms": 30,
        "total_terms": 42
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "000",
        "Billing",
        "based",
        "billed",
        "billing",
        "inference",
        "model",
        "number",
        "processed",
        "the",
        "tokens"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5076470588235293,
      "overall": 0.7025490196078431
    }
  },
  {
    "text": "## Using Inference  Inference can be easily used through the Qdrant SDKs and the REST or GRPC APIs when upserting points and when querying the database. Instead of a vector, you can use special *Interface Objects*:  - **`Document`** object, used for text inference ```js // Document {     // Text input     text: \"Your text\",     // Name of the model, to do inference with     model: \"<the-model-to-use>\",     // Extra parameters for the model, Optional     options: {} } ``` - **`Image`** object, used for image inference ```js // Image {     // Image input     image: \"<url>\", // Or base64 encoded image     // Name of the model, to do inference with     model: \"<the-model-to-use>\",     // Extra parameters for the model, Optional     options: {} } ``` - **`Object`** object, reserved for other types of input, which might be implemented in the future. The Qdrant API supports usage of these Inference Objects in all places, where regular vectors can be used. For example: ```http POST /collections/<your-collection>/points/query {   \"query\": {     \"nearest\": [0.12, 0.34, 0.56, 0.78, ...]   } } ``` Can be replaced with ```http POST /collections/<your-collection>/points/query {   \"query\": {     \"nearest\": {       \"text\": \"My Query Text\",       \"model\": \"<the-model-to-use>\"     }   } } ``` In this case, the Qdrant Cloud will use the configured embedding model to automatically create a vector from the Inference Object and then perform the search query with it. All of this happens within a low-latency network. The input used for inference will not be saved anywhere. If you want to persist it in Qdrant, make sure to explicitly include it in the payload.",
    "metadata": {
      "chunk_id": "c5533cbbb261-0012",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Using Inference"
      ],
      "heading_text": "Using Inference",
      "token_count": 405,
      "char_count": 1663,
      "start_char": 9381,
      "end_char": 11044,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6791470588235293,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.879449",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 405,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Using Inference",
      "chunk_hash": "af696d3f7e97b052",
      "content_digest": "af696d3f7e97b052",
      "chunk_length": 1663,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "model",
          "inference",
          "for",
          "text",
          "image",
          "query",
          "used",
          "use",
          "object",
          "can",
          "qdrant",
          "input",
          "with",
          "and",
          "points",
          "your",
          "when",
          "vector",
          "you"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 18,
            "weight": 0.091371
          },
          {
            "term": "model",
            "tf": 11,
            "weight": 0.055838
          },
          {
            "term": "inference",
            "tf": 9,
            "weight": 0.045685
          },
          {
            "term": "for",
            "tf": 7,
            "weight": 0.035533
          },
          {
            "term": "text",
            "tf": 6,
            "weight": 0.030457
          },
          {
            "term": "image",
            "tf": 6,
            "weight": 0.030457
          },
          {
            "term": "query",
            "tf": 6,
            "weight": 0.030457
          },
          {
            "term": "used",
            "tf": 5,
            "weight": 0.025381
          },
          {
            "term": "use",
            "tf": 5,
            "weight": 0.025381
          },
          {
            "term": "object",
            "tf": 5,
            "weight": 0.025381
          },
          {
            "term": "can",
            "tf": 4,
            "weight": 0.020305
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.020305
          },
          {
            "term": "input",
            "tf": 4,
            "weight": 0.020305
          },
          {
            "term": "with",
            "tf": 4,
            "weight": 0.020305
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "points",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "your",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "when",
            "tf": 2,
            "weight": 0.010152
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.010152
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.010152
          }
        ],
        "unique_terms": 93,
        "total_terms": 197
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Using Inference",
        "for",
        "image",
        "inference",
        "model",
        "object",
        "query",
        "text",
        "the",
        "use",
        "used"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6791470588235293,
      "overall": 0.7930490196078429
    }
  },
  {
    "text": "### Text Inference  Let’s consider an example of using Cloud Inference with a text model producing dense vectors. Here, we create one point and use a simple search query with a `Document` Inference Object. ```http",
    "metadata": {
      "chunk_id": "c5533cbbb261-0013",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Text Inference"
      ],
      "heading_text": "Text Inference",
      "token_count": 46,
      "char_count": 213,
      "start_char": 11058,
      "end_char": 11271,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7385714285714285,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.881325",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 46,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Text Inference",
      "chunk_hash": "51e9099803431c47",
      "content_digest": "51e9099803431c47",
      "chunk_length": 213,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "inference",
          "text",
          "with",
          "let",
          "consider",
          "example",
          "using",
          "cloud",
          "model",
          "producing",
          "dense",
          "vectors",
          "here",
          "create",
          "one",
          "point",
          "and",
          "use",
          "simple",
          "search"
        ],
        "term_weights": [
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.107143
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "let",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "consider",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "example",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "producing",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "dense",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "vectors",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "here",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "create",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "one",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "point",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.035714
          }
        ],
        "unique_terms": 24,
        "total_terms": 28
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Text Inference",
        "cloud",
        "consider",
        "example",
        "inference",
        "let",
        "model",
        "producing",
        "text",
        "using",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7385714285714285,
      "overall": 0.7795238095238095
    }
  },
  {
    "text": "# Insert new points with cloud-side inference PUT /collections/<your-collection>/points?wait=true {   \"points\": [     {       \"id\": 1,       \"payload\": { \"topic\": \"cooking\", \"type\": \"dessert\" },       \"vector\": {         \"text\": \"Recipe for baking chocolate chip cookies\",         \"model\": \"<the-model-to-use>\"       }     }   ] }",
    "metadata": {
      "chunk_id": "c5533cbbb261-0014",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Insert new points with cloud-side inference"
      ],
      "heading_text": "Insert new points with cloud-side inference",
      "token_count": 88,
      "char_count": 330,
      "start_char": 11274,
      "end_char": 11604,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5494594594594595,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.882447",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 88,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Insert new points with cloud-side inference",
      "chunk_hash": "10ebae60fdcc8a28",
      "content_digest": "10ebae60fdcc8a28",
      "chunk_length": 330,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "points",
          "model",
          "insert",
          "new",
          "with",
          "cloud",
          "side",
          "inference",
          "put",
          "collections",
          "your",
          "collection",
          "wait",
          "true",
          "payload",
          "topic",
          "cooking",
          "type",
          "dessert",
          "vector"
        ],
        "term_weights": [
          {
            "term": "points",
            "tf": 3,
            "weight": 0.09375
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "insert",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "new",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "side",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "put",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "your",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "collection",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "wait",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "true",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "payload",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "topic",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "cooking",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "type",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "dessert",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.03125
          }
        ],
        "unique_terms": 29,
        "total_terms": 32
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Insert new points with cloud-side inference",
        "cloud",
        "collections",
        "inference",
        "insert",
        "model",
        "new",
        "points",
        "put",
        "side",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5494594594594595,
      "overall": 0.7498198198198199
    }
  },
  {
    "text": "# Search in the collection using cloud-side inference POST /collections/<your-collection>/points/query {   \"query\": {     \"text\": \"How to bake cookies?\",     \"model\": \"<the-model-to-use>\"   } } ``` ```bash",
    "metadata": {
      "chunk_id": "c5533cbbb261-0015",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Search in the collection using cloud-side inference"
      ],
      "heading_text": "Search in the collection using cloud-side inference",
      "token_count": 50,
      "char_count": 205,
      "start_char": 11606,
      "end_char": 11811,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.765,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.883309",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 50,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Search in the collection using cloud-side inference",
      "chunk_hash": "ab141599196f5eff",
      "content_digest": "ab141599196f5eff",
      "chunk_length": 205,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "collection",
          "query",
          "model",
          "search",
          "using",
          "cloud",
          "side",
          "inference",
          "post",
          "collections",
          "your",
          "points",
          "text",
          "how",
          "bake",
          "cookies",
          "use",
          "bash"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "collection",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "side",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "post",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "your",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "points",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "text",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "how",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "bake",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "cookies",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "bash",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 19,
        "total_terms": 23
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Search in the collection using cloud-side inference",
        "cloud",
        "collection",
        "inference",
        "model",
        "post",
        "query",
        "search",
        "side",
        "the",
        "using"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.765,
      "overall": 0.8216666666666667
    }
  },
  {
    "text": "# Create a new vector curl -X PUT \"https://xyz-example.qdrant.io:6333/collections/<your-collection>/points?wait=true\" \\   -H \"Content-Type: application/json\" \\   -H \"api-key: <paste-your-api-key-here>\" \\   -d '{     \"points\": [       {         \"id\": 1,         \"payload\": { \"topic\": \"cooking\", \"type\": \"dessert\" },         \"vector\": {           \"text\": \"Recipe for baking chocolate chip cookies\",           \"model\": \"<the-model-to-use>\"         }       }     ]   }'",
    "metadata": {
      "chunk_id": "c5533cbbb261-0016",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Create a new vector"
      ],
      "heading_text": "Create a new vector",
      "token_count": 134,
      "char_count": 465,
      "start_char": 11813,
      "end_char": 12278,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7517021276595744,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.884678",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 134,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Create a new vector",
      "chunk_hash": "34dc92f1dd676957",
      "content_digest": "34dc92f1dd676957",
      "chunk_length": 465,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "vector",
          "your",
          "points",
          "type",
          "api",
          "key",
          "model",
          "create",
          "new",
          "curl",
          "put",
          "https",
          "xyz",
          "example",
          "qdrant",
          "6333",
          "collections",
          "collection",
          "wait",
          "true"
        ],
        "term_weights": [
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "your",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "points",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "type",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "api",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "key",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "create",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "new",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "curl",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "put",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "xyz",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "example",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "6333",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "collection",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "wait",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "true",
            "tf": 1,
            "weight": 0.022222
          }
        ],
        "unique_terms": 38,
        "total_terms": 45
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Create a new vector",
        "api",
        "create",
        "curl",
        "key",
        "model",
        "new",
        "points",
        "type",
        "vector",
        "your"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7517021276595744,
      "overall": 0.8172340425531913
    }
  },
  {
    "text": "# Perform a search query curl -X POST \"https://xyz-example.qdrant.io:6333/collections/<your-collection>/points/query\" \\   -H \"Content-Type: application/json\" \\   -H \"api-key: <paste-your-api-key-here>\" \\   -d '{     \"query\": {       \"text\": \"How to bake cookies?\",       \"model\": \"<the-model-to-use>\"     }   }' ``` ```python from qdrant_client import QdrantClient from qdrant_client.models import PointStruct, Document  client = QdrantClient(     url=\"https://xyz-example.qdrant.io:6333\",     api_key=\"<paste-your-api-key-here>\",     # IMPORTANT     # If not enabled, inference will be performed locally     cloud_inference=True, )  points = [     PointStruct(         id=1,         payload={\"topic\": \"cooking\", \"type\": \"dessert\"},         vector=Document(             text=\"Recipe for baking chocolate chip cookies\",             model=\"<the-model-to-use>\"         )     ) ]  client.upsert(collection_name=\"<your-collection>\", points=points)  result = client.query_points(     collection_name=\"<your-collection>\",     query=Document(         text=\"How to bake cookies?\",         model=\"<the-model-to-use>\"     ) )  print(result) ``` ```typescript import {QdrantClient} from \"@qdrant/js-client-rest\";  const client = new QdrantClient({     url: 'https://xyz-example.qdrant.io:6333',     apiKey: '<paste-your-api-key-here>', });  const points = [   {     id: 1,     payload: { topic: \"cooking\", type: \"dessert\" },     vector: {         text: \"Recipe for baking chocolate chip cookies\",         model: \"<the-model-to-use>\"       }   } ];  await client.upsert(\"<your-collection>\", { wait: true, points });  const result = await client.query(     \"<your-collection>\",     {       query: {           text: \"How to bake cookies?\",           model: \"<the-model-to-use>\"       },     } )  console.log(result); ``` ```rust use qdrant_client::qdrant::Query; use qdrant_client::qdrant::QueryPointsBuilder; use qdrant_client::Payload; use qdrant_client::Qdrant; use qdrant_client::qdrant::{Document}; use qdrant_client::qdrant::{PointStruct, UpsertPointsBuilder};  #[tokio::main] async fn main() {     let client = Qdrant::from_url(\"https://xyz-example.qdrant.io:6334\")         .api_key(\"<paste-your-api-key-here>\")         .build()         .unwrap();      let points = vec![         PointStruct::new(             1,             Document::new(                 \"Recipe for baking chocolate chip cookies\",                 \"<the-model-to-use>\"             ),             Payload::try_from(serde_json::json!(                 {\"topic\": \"cooking\", \"type\": \"dessert\"}             )).unwrap(),         )     ];      let upsert_request = UpsertPointsBuilder::new(         \"<your-collection>\",         points     ).wait(true);      let _ = client.upsert_points(upsert_request).await;      let query_document = Document::new(         \"How to bake cookies?\",         \"<the-model-to-use>\"     );      let query_request = QueryPointsBuilder::new(\"<your-collection>\")         .query(Query::new_nearest(query_document));      let result = client.query(query_request).await.unwrap();     println!(\"Result: {:?}\", result); } ``` ```java package org.example;  import static io.qdrant.client.PointIdFactory.id; import static io.qdrant.client.QueryFactory.nearest; import static io.qdrant.client.ValueFactory.value; import static io.qdrant.client.VectorsFactory.vectors;  import io.qdrant.client.grpc.Points; import io.qdrant.client.grpc.Points.Document; import io.qdrant.client.grpc.Points.PointStruct; import java.util.List; import java.util.Map; import java.util.concurrent.ExecutionException;  public class Main {   public static void main(String[] args)       throws ExecutionException, InterruptedException {     QdrantClient client =       new QdrantClient(         QdrantGrpcClient.newBuilder(\"xyz-example.qdrant.io\", 6334, true)         .withApiKey(\"<paste-your-api-key-here>\")         .build());      client       .upsertAsync(         \"<your-collection>\",         List.of(           PointStruct.newBuilder()           .setId(id(1))           .setVectors(             vectors(               Document.newBuilder()               .setText(\"Recipe for baking chocolate chip cookies\")               .setModel(\"<the-model-to-use>\")               .build()))           .putAllPayload(Map.of(\"topic\", value(\"cooking\"), \"type\", value(\"dessert\")))           .build()))       .get();      List <Points.ScoredPoint> points =       client       .queryAsync(         Points.QueryPoints.newBuilder()         .setCollectionName(\"<your-collection>\")         .setQuery(           nearest(             Document.newBuilder()             .setText(\"How to bake cookies?\")             .setModel(\"<the-model-to-use>\")             .build()))         .build())       .get();      System.out.printf(points.toString());   } } ``` ```csharp using Qdrant.Client; using Qdrant.Client.Grpc; using Value = Qdrant.Client.Grpc.Value;  var client = new QdrantClient(   host: \"xyz-example.qdrant.io\",   port: 6334,   https: true,   apiKey: \"<paste-your-api-key-here>\" );  await client.UpsertAsync(   collectionName: \"<your-collection>\",   points: new List <PointStruct> {     new() {       Id = 1,         Vectors = new Document() {           Text = \"Recipe for baking chocolate chip cookies\",           Model = \"<the-model-to-use>\",         },         Payload = {           [\"topic\"] = \"cooking\",           [\"type\"] = \"dessert\"         },     },   } );  var points = await client.QueryAsync(   collectionName: \"<your-collection>\",   query: new Document() {     Text = \"How to bake cookies?\",     Model = \"<the-model-to-use>\"   } );  foreach(var point in points) {   Console.WriteLine(point); } ``` ```go package main  import (     \"context\"     \"log\"     \"time\"      \"github.com/qdrant/go-client/qdrant\" )  func main() {     ctx, cancel := context.WithTimeout(context.Background(), time.Second)     defer cancel()      client, err := qdrant.NewClient(&qdrant.Config{         Host:   \"xyz-example.qdrant.io\",         Port:   6334,         APIKey: \"<paste-your-api-key-here>\",         UseTLS: true,     })     if err != nil {         log.Fatalf(\"did not connect: %v\", err)     }     defer client.Close()      _, err = client.GetPointsClient().Upsert(ctx, &qdrant.UpsertPoints{         CollectionName: \"<your-collection>\",         Points: []*qdrant.PointStruct{             {                 Id: qdrant.NewIDNum(uint64(1)),                 Vectors: qdrant.NewVectorsDocument(&qdrant.Document{                     Text:  \"Recipe for baking chocolate chip cookies\",                     Model: \"<the-model-to-use>\",                 }),                 Payload: qdrant.NewValueMap(map[string]any{                     \"topic\": \"cooking\",                     \"type\":  \"dessert\",                 }),             },         },     })     if err != nil {         log.Fatalf(\"error creating point: %v\", err)     }      points, err := client.Query(ctx, &qdrant.QueryPoints{         CollectionName: \"<your-collection>\",         Query: qdrant.NewQueryNearest(             qdrant.NewVectorInputDocument(&qdrant.Document{                 Text:  \"How to bake cookies?\",                 Model: \"<the-model-to-use>\",             }),         ),     })     log.Printf(\"List of points: %s\", points) } ``` Usage examples, specific to each cluster and model, can also be found in the Inference tab of the Cluster Detail page in the Qdrant Cloud Console. Note that each model has a context window, which is the maximum number of tokens that can be processed by the model in a single request. If the input text exceeds the context window, it will be truncated to fit within the limit. The context window size is displayed in the Inference tab of the Cluster Detail page. For dense vector models, you also have to ensure that the vector size configured in the collection matches the output size of the model. If the vector size does not match, the upsert will fail with an error.",
    "metadata": {
      "chunk_id": "c5533cbbb261-0017",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Perform a search query"
      ],
      "heading_text": "Perform a search query",
      "token_count": 1888,
      "char_count": 7890,
      "start_char": 12280,
      "end_char": 20170,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6413157894736842,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.902883",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 1888,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Perform a search query",
      "chunk_hash": "6609d102aa0d1a5e",
      "content_digest": "6609d102aa0d1a5e",
      "chunk_length": 7890,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "the",
          "model",
          "points",
          "your",
          "use",
          "query",
          "collection",
          "document",
          "import",
          "cookies",
          "new",
          "api",
          "key",
          "text",
          "example",
          "pointstruct",
          "xyz",
          "type"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 47,
            "weight": 0.059119
          },
          {
            "term": "client",
            "tf": 39,
            "weight": 0.049057
          },
          {
            "term": "the",
            "tf": 30,
            "weight": 0.037736
          },
          {
            "term": "model",
            "tf": 26,
            "weight": 0.032704
          },
          {
            "term": "points",
            "tf": 24,
            "weight": 0.030189
          },
          {
            "term": "your",
            "tf": 20,
            "weight": 0.025157
          },
          {
            "term": "use",
            "tf": 19,
            "weight": 0.023899
          },
          {
            "term": "query",
            "tf": 18,
            "weight": 0.022642
          },
          {
            "term": "collection",
            "tf": 16,
            "weight": 0.020126
          },
          {
            "term": "document",
            "tf": 15,
            "weight": 0.018868
          },
          {
            "term": "import",
            "tf": 14,
            "weight": 0.01761
          },
          {
            "term": "cookies",
            "tf": 13,
            "weight": 0.016352
          },
          {
            "term": "new",
            "tf": 13,
            "weight": 0.016352
          },
          {
            "term": "api",
            "tf": 10,
            "weight": 0.012579
          },
          {
            "term": "key",
            "tf": 10,
            "weight": 0.012579
          },
          {
            "term": "text",
            "tf": 10,
            "weight": 0.012579
          },
          {
            "term": "example",
            "tf": 8,
            "weight": 0.010063
          },
          {
            "term": "pointstruct",
            "tf": 8,
            "weight": 0.010063
          },
          {
            "term": "xyz",
            "tf": 7,
            "weight": 0.008805
          },
          {
            "term": "type",
            "tf": 7,
            "weight": 0.008805
          }
        ],
        "unique_terms": 209,
        "total_terms": 795
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Perform a search query",
        "client",
        "collection",
        "document",
        "model",
        "points",
        "qdrant",
        "query",
        "the",
        "use",
        "your"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6413157894736842,
      "overall": 0.7471052631578946
    }
  },
  {
    "text": "### Image Inference  Here is another example of using Cloud Inference with an image model. This time, we will use the `CLIP` model to encode an image and then use a text query to search for it. Since the `CLIP` model is multimodal, we can use both image and text inputs on the same vector field. ```http",
    "metadata": {
      "chunk_id": "c5533cbbb261-0018",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Image Inference"
      ],
      "heading_text": "Image Inference",
      "token_count": 73,
      "char_count": 303,
      "start_char": 20181,
      "end_char": 20484,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7057894736842105,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.907840",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 73,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Image Inference",
      "chunk_hash": "5e8358d6309a7dd1",
      "content_digest": "5e8358d6309a7dd1",
      "chunk_length": 303,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "image",
          "model",
          "use",
          "the",
          "inference",
          "clip",
          "and",
          "text",
          "here",
          "another",
          "example",
          "using",
          "cloud",
          "with",
          "this",
          "time",
          "will",
          "encode",
          "then",
          "query"
        ],
        "term_weights": [
          {
            "term": "image",
            "tf": 4,
            "weight": 0.090909
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "use",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "clip",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "here",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "another",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "example",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "time",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "will",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "encode",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "then",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "query",
            "tf": 1,
            "weight": 0.022727
          }
        ],
        "unique_terms": 31,
        "total_terms": 44
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Image Inference",
        "and",
        "another",
        "clip",
        "here",
        "image",
        "inference",
        "model",
        "text",
        "the",
        "use"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7057894736842105,
      "overall": 0.7685964912280702
    }
  },
  {
    "text": "# Insert new points with cloud-side inference PUT /collections/<your-collection>/points?wait=true {   \"points\": [     {       \"id\": 1,       \"vector\": {         \"image\": \"https://qdrant.tech/example.png\",         \"model\": \"qdrant/clip-vit-b-32-vision\"       },       \"payload\": {         \"title\": \"Example Image\"       }     }   ] }",
    "metadata": {
      "chunk_id": "c5533cbbb261-0019",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Insert new points with cloud-side inference"
      ],
      "heading_text": "Insert new points with cloud-side inference",
      "token_count": 93,
      "char_count": 332,
      "start_char": 20487,
      "end_char": 20819,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7416129032258064,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.909326",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 93,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Insert new points with cloud-side inference",
      "chunk_hash": "98afa0e4db8e0655",
      "content_digest": "98afa0e4db8e0655",
      "chunk_length": 332,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "points",
          "image",
          "qdrant",
          "example",
          "insert",
          "new",
          "with",
          "cloud",
          "side",
          "inference",
          "put",
          "collections",
          "your",
          "collection",
          "wait",
          "true",
          "vector",
          "https",
          "tech",
          "png"
        ],
        "term_weights": [
          {
            "term": "points",
            "tf": 3,
            "weight": 0.096774
          },
          {
            "term": "image",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "example",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "insert",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "new",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "side",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "put",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "your",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "collection",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "wait",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "true",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "tech",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "png",
            "tf": 1,
            "weight": 0.032258
          }
        ],
        "unique_terms": 26,
        "total_terms": 31
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Insert new points with cloud-side inference",
        "cloud",
        "example",
        "image",
        "inference",
        "insert",
        "new",
        "points",
        "qdrant",
        "side",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7416129032258064,
      "overall": 0.780537634408602
    }
  },
  {
    "text": "# Search in the collection using cloud-side inference POST /collections/<your-collection>/points/query {   \"query\": {     \"text\": \"Mission to Mars\",     \"model\": \"qdrant/clip-vit-b-32-text\"   } } ``` ```bash",
    "metadata": {
      "chunk_id": "c5533cbbb261-0020",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Search in the collection using cloud-side inference"
      ],
      "heading_text": "Search in the collection using cloud-side inference",
      "token_count": 56,
      "char_count": 207,
      "start_char": 20821,
      "end_char": 21028,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5639130434782609,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.910243",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 56,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Search in the collection using cloud-side inference",
      "chunk_hash": "36229e2820373d19",
      "content_digest": "36229e2820373d19",
      "chunk_length": 207,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "collection",
          "query",
          "text",
          "search",
          "the",
          "using",
          "cloud",
          "side",
          "inference",
          "post",
          "collections",
          "your",
          "points",
          "mission",
          "mars",
          "model",
          "qdrant",
          "clip",
          "vit",
          "bash"
        ],
        "term_weights": [
          {
            "term": "collection",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "side",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "post",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "your",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "points",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "mission",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "mars",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "clip",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "vit",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "bash",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 20,
        "total_terms": 23
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Search in the collection using cloud-side inference",
        "cloud",
        "collection",
        "inference",
        "post",
        "query",
        "search",
        "side",
        "text",
        "the",
        "using"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5639130434782609,
      "overall": 0.7546376811594202
    }
  },
  {
    "text": "# Create a new vector curl -X PUT \"https://xyz-example.qdrant.io:6333/collections/<your-collection>/points?wait=true\" \\   -H \"Content-Type: application/json\" \\   -H \"api-key: <paste-your-api-key-here>\" \\   -d '{     \"points\": [       {         \"id\": 1,         \"vector\": {           \"image\": \"https://qdrant.tech/example.png\",           \"model\": \"qdrant/clip-vit-b-32-vision\"         },         \"payload\": {           \"title\": \"Example Image\"         }       }     ]   }'",
    "metadata": {
      "chunk_id": "c5533cbbb261-0021",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Create a new vector"
      ],
      "heading_text": "Create a new vector",
      "token_count": 139,
      "char_count": 471,
      "start_char": 21030,
      "end_char": 21501,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7460975609756098,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.911590",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 139,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Create a new vector",
      "chunk_hash": "c089964132ddb429",
      "content_digest": "c089964132ddb429",
      "chunk_length": 471,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "example",
          "qdrant",
          "vector",
          "https",
          "your",
          "points",
          "api",
          "key",
          "image",
          "create",
          "new",
          "curl",
          "put",
          "xyz",
          "6333",
          "collections",
          "collection",
          "wait",
          "true",
          "content"
        ],
        "term_weights": [
          {
            "term": "example",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "your",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "points",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "api",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "key",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "image",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "create",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "new",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "curl",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "put",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "xyz",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "6333",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "collection",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "wait",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "true",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "content",
            "tf": 1,
            "weight": 0.022727
          }
        ],
        "unique_terms": 33,
        "total_terms": 44
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Create a new vector",
        "api",
        "create",
        "example",
        "https",
        "image",
        "key",
        "points",
        "qdrant",
        "vector",
        "your"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7460975609756098,
      "overall": 0.7820325203252031
    }
  },
  {
    "text": "# Perform a search query curl -X POST \"https://xyz-example.qdrant.io:6333/collections/<your-collection>/points/query\" \\   -H \"Content-Type: application/json\" \\   -H \"api-key: <paste-your-api-key-here>\" \\   -d '{     \"query\": {       \"text\": \"Mission to Mars\",       \"model\": \"qdrant/clip-vit-b-32-text\"     }   }' ``` ```python from qdrant_client import QdrantClient from qdrant_client.models import PointStruct, Image, Document  client = QdrantClient(     url=\"https://xyz-example.qdrant.io:6333\",     api_key=\"<paste-your-api-key-here>\",     # IMPORTANT     # If not enabled, inference will be performed locally     cloud_inference=True, )  points = [     PointStruct(         id=1,         vector=Image(             image=\"https://qdrant.tech/example.png\",             model=\"qdrant/clip-vit-b-32-vision\"         ),         payload={             \"title\": \"Example Image\"         }     ) ]  client.upsert(collection_name=\"<your-collection>\", points=points)  result = client.query_points(     collection_name=\"<your-collection>\",     query=Document(         text=\"Mission to Mars\",         model=\"qdrant/clip-vit-b-32-text\"     ) )  print(result) ``` ```typescript import {QdrantClient} from \"@qdrant/js-client-rest\";  const client = new QdrantClient({     url: 'https://xyz-example.qdrant.io:6333',     apiKey: '<paste-your-api-key-here>', });  const points = [   {     id: 1,     vector: {       image: \"https://qdrant.tech/example.png\",       model: \"qdrant/clip-vit-b-32-vision\"     },     payload: {       title: \"Example Image\"     }   } ];  await client.upsert(\"<your-collection>\", { wait: true, points });  const result = await client.query(     \"<your-collection>\",     {       query: {           text: \"Mission to Mars\",           model: \"qdrant/clip-vit-b-32-text\"       },     } )  console.log(result); ``` ```rust use qdrant_client::qdrant::Query; use qdrant_client::qdrant::QueryPointsBuilder; use qdrant_client::Payload; use qdrant_client::Qdrant; use qdrant_client::qdrant::{Document, Image}; use qdrant_client::qdrant::{PointStruct, UpsertPointsBuilder};  #[tokio::main] async fn main() {     let client = Qdrant::from_url(\"https://xyz-example.qdrant.io:6334\")         .api_key(\"<paste-your-api-key-here>\")         .build()         .unwrap();      let points = vec![         PointStruct::new(             1,             Image::new_from_url(                 \"https://qdrant.tech/example.png\",                 \"qdrant/clip-vit-b-32-vision\"             ),             Payload::try_from(serde_json::json!({                 \"title\": \"Example Image\"             })).unwrap(),         )     ];      let upsert_request = UpsertPointsBuilder::new(         \"<your-collection>\",         points     ).wait(true);      let _ = client.upsert_points(upsert_request).await;      let query_document = Document::new(         \"Mission to Mars\",         \"qdrant/clip-vit-b-32-text\"     );      let query_request = QueryPointsBuilder::new(\"<your-collection>\")         .query(Query::new_nearest(query_document));      let result = client.query(query_request).await.unwrap();     println!(\"Result: {:?}\", result); } ``` ```java package org.example;  import static io.qdrant.client.PointIdFactory.id; import static io.qdrant.client.QueryFactory.nearest; import static io.qdrant.client.ValueFactory.value; import static io.qdrant.client.VectorsFactory.vectors;  import io.qdrant.client.grpc.Points; import io.qdrant.client.grpc.Points.Document; import io.qdrant.client.grpc.Points.Image; import io.qdrant.client.grpc.Points.PointStruct; import java.util.List; import java.util.Map; import java.util.concurrent.ExecutionException;  public class Main {   public static void main(String[] args)       throws ExecutionException, InterruptedException {     QdrantClient client =       new QdrantClient(         QdrantGrpcClient.newBuilder(\"xyz-example.qdrant.io\", 6334, true)         .withApiKey(\"<paste-your-api-key-here>\")         .build());      client       .upsertAsync(         \"<your-collection>\",         List.of(           PointStruct.newBuilder()           .setId(id(1))           .setVectors(             vectors(               Image.newBuilder()               .setImage(\"https://qdrant.tech/example.png\")               .setModel(\"qdrant/clip-vit-b-32-vision\")               .build()))           .putAllPayload(Map.of(\"title\", value(\"Example Image\")))           .build()))       .get();      List <Points.ScoredPoint> points =       client       .queryAsync(         Points.QueryPoints.newBuilder()         .setCollectionName(\"<your-collection>\")         .setQuery(           nearest(             Document.newBuilder()             .setText(\"Mission to Mars\")             .setModel(\"qdrant/clip-vit-b-32-text\")             .build()))         .build())       .get();      System.out.printf(points.toString());   } } ``` ```csharp using Qdrant.Client; using Qdrant.Client.Grpc; using Value = Qdrant.Client.Grpc.Value;  var client = new QdrantClient(   host: \"xyz-example.qdrant.io\",   port: 6334,   https: true,   apiKey: \"<paste-your-api-key-here>\" );  await client.UpsertAsync(   collectionName: \"<your-collection>\",   points: new List <PointStruct> {     new() {       Id = 1,         Vectors = new Image() {           Image = \"https://qdrant.tech/example.png\",           Model = \"qdrant/clip-vit-b-32-vision\",         },         Payload = {           [\"title\"] = \"Example Image\"         },     },   } );  var points = await client.QueryAsync(   collectionName: \"<your-collection>\",   query: new Document() {     Text = \"Mission to Mars\",     Model = \"qdrant/clip-vit-b-32-text\"   } );  foreach(var point in points) {   Console.WriteLine(point); } ``` ```go package main  import (     \"context\"     \"log\"     \"time\"      \"github.com/qdrant/go-client/qdrant\" )  func main() {     ctx, cancel := context.WithTimeout(context.Background(), time.Second)     defer cancel()      client, err := qdrant.NewClient(&qdrant.Config{         Host:   \"xyz-example.qdrant.io\",         Port:   6334,         APIKey: \"<paste-your-api-key-here>\",         UseTLS: true,     })     if err != nil {         log.Fatalf(\"did not connect: %v\", err)     }     defer client.Close()      _, err = client.GetPointsClient().Upsert(ctx, &qdrant.UpsertPoints{         CollectionName: \"<your-collection>\",         Points: []*qdrant.PointStruct{             {                 Id: qdrant.NewIDNum(uint64(1)),                 Vectors: qdrant.NewVectorsImage(&qdrant.Image{                     Image: \"https://qdrant.tech/example.png\",                     Model: \"qdrant/clip-vit-b-32-vision\",                 }),                 Payload: qdrant.NewValueMap(map[string]any{                     \"title\": \"Example image\",                 }),             },         },     })     if err != nil {         log.Fatalf(\"error creating point: %v\", err)     }      points, err := client.Query(ctx, &qdrant.QueryPoints{         CollectionName: \"<your-collection>\",         Query: qdrant.NewQueryNearest(             qdrant.NewVectorInputDocument(&qdrant.Document{                 Text:  \"Mission to Mars\",                 Model: \"qdrant/clip-vit-b-32-text\",             }),         ),     })     log.Printf(\"List of points: %s\", points) } ``` Qdrant Cloud Inference server will download the images using the provided link. Alternatively, you can upload the image as a base64 encoded string. Note that each model has limitations on the file size and extensions it can work with. Please refer to the model card for details.",
    "metadata": {
      "chunk_id": "c5533cbbb261-0022",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Perform a search query"
      ],
      "heading_text": "Perform a search query",
      "token_count": 1881,
      "char_count": 7474,
      "start_char": 21503,
      "end_char": 28977,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6565499124343258,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.931572",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 1881,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Perform a search query",
      "chunk_hash": "2800f3b24c0fa0a8",
      "content_digest": "2800f3b24c0fa0a8",
      "chunk_length": 7474,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "points",
          "example",
          "your",
          "image",
          "query",
          "collection",
          "import",
          "clip",
          "vit",
          "new",
          "text",
          "https",
          "model",
          "api",
          "key",
          "document",
          "pointstruct",
          "xyz"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 67,
            "weight": 0.090296
          },
          {
            "term": "client",
            "tf": 40,
            "weight": 0.053908
          },
          {
            "term": "points",
            "tf": 25,
            "weight": 0.033693
          },
          {
            "term": "example",
            "tf": 20,
            "weight": 0.026954
          },
          {
            "term": "your",
            "tf": 20,
            "weight": 0.026954
          },
          {
            "term": "image",
            "tf": 19,
            "weight": 0.025606
          },
          {
            "term": "query",
            "tf": 18,
            "weight": 0.024259
          },
          {
            "term": "collection",
            "tf": 15,
            "weight": 0.020216
          },
          {
            "term": "import",
            "tf": 15,
            "weight": 0.020216
          },
          {
            "term": "clip",
            "tf": 13,
            "weight": 0.01752
          },
          {
            "term": "vit",
            "tf": 13,
            "weight": 0.01752
          },
          {
            "term": "new",
            "tf": 13,
            "weight": 0.01752
          },
          {
            "term": "text",
            "tf": 12,
            "weight": 0.016173
          },
          {
            "term": "https",
            "tf": 11,
            "weight": 0.014825
          },
          {
            "term": "model",
            "tf": 11,
            "weight": 0.014825
          },
          {
            "term": "api",
            "tf": 10,
            "weight": 0.013477
          },
          {
            "term": "key",
            "tf": 10,
            "weight": 0.013477
          },
          {
            "term": "document",
            "tf": 10,
            "weight": 0.013477
          },
          {
            "term": "pointstruct",
            "tf": 8,
            "weight": 0.010782
          },
          {
            "term": "xyz",
            "tf": 7,
            "weight": 0.009434
          }
        ],
        "unique_terms": 194,
        "total_terms": 742
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Perform a search query",
        "client",
        "clip",
        "collection",
        "example",
        "image",
        "import",
        "points",
        "qdrant",
        "query",
        "your"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6565499124343258,
      "overall": 0.7521833041447752
    }
  },
  {
    "text": "### Local Inference Compatibility  The Python SDK offers a unique capability: it supports both [local](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/) and cloud inference through an identical interface. You can easily switch between local and cloud inference by setting the cloud\\_inference flag when initializing the QdrantClient. For example: ```python client = QdrantClient(     url=\"https://your-cluster.qdrant.io\",     api_key=\"<your-api-key>\",     cloud_inference=True,  # Set to False to use local inference ) ``` This flexibility allows you to develop and test your applications locally or in continuous integration (CI) environments without requiring access to cloud inference resources. - When `cloud_inference` is set to `False`, inference is performed locally usign `fastembed`. - When set to `True`, inference requests are handled by Qdrant Cloud.",
    "metadata": {
      "chunk_id": "c5533cbbb261-0023",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 23,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Local Inference Compatibility"
      ],
      "heading_text": "Local Inference Compatibility",
      "token_count": 184,
      "char_count": 884,
      "start_char": 28988,
      "end_char": 29872,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5122222222222222,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.938310",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 184,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Local Inference Compatibility",
      "chunk_hash": "3abfea7951440bc3",
      "content_digest": "3abfea7951440bc3",
      "chunk_length": 884,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "inference",
          "cloud",
          "local",
          "the",
          "qdrant",
          "fastembed",
          "and",
          "when",
          "your",
          "set",
          "python",
          "https",
          "you",
          "qdrantclient",
          "api",
          "key",
          "true",
          "false",
          "locally",
          "compatibility"
        ],
        "term_weights": [
          {
            "term": "inference",
            "tf": 10,
            "weight": 0.095238
          },
          {
            "term": "cloud",
            "tf": 7,
            "weight": 0.066667
          },
          {
            "term": "local",
            "tf": 4,
            "weight": 0.038095
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "when",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "your",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "set",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "python",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "qdrantclient",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "api",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "key",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "true",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "false",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "locally",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "compatibility",
            "tf": 1,
            "weight": 0.009524
          }
        ],
        "unique_terms": 64,
        "total_terms": 105
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Local Inference Compatibility",
        "and",
        "cloud",
        "fastembed",
        "inference",
        "local",
        "qdrant",
        "set",
        "the",
        "when",
        "your"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5122222222222222,
      "overall": 0.7374074074074074
    }
  },
  {
    "text": "##### Was this page useful? Yes No  Thank you for your feedback! 🙏  We are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/inference.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue. On this page:  - [Inference in Qdrant Managed Cloud](#inference-in-qdrant-managed-cloud.md)    - [Supported Models](#supported-models.md)    - [Enabling/Disabling Inference](#enablingdisabling-inference.md)    - [Billing](#billing.md)    - [Using Inference](#using-inference.md)      - [Text Inference](#text-inference.md)     - [Image Inference](#image-inference.md)     - [Local Inference Compatibility](#local-inference-compatibility.md)  * [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/inference.md) * [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)",
    "metadata": {
      "chunk_id": "c5533cbbb261-0024",
      "source_file": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 24,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Was this page useful?"
      ],
      "heading_text": "Was this page useful?",
      "token_count": 261,
      "char_count": 972,
      "start_char": 29878,
      "end_char": 30850,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.53,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:16.941491",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 261,
      "document_id": "c5533cbbb261",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\Qdrant\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Was this page useful?",
      "chunk_hash": "5cc5c6f5382f3cb9",
      "content_digest": "5cc5c6f5382f3cb9",
      "chunk_length": 972,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "inference",
          "qdrant",
          "page",
          "github",
          "landing",
          "https",
          "com",
          "cloud",
          "this",
          "you",
          "edit",
          "tree",
          "master",
          "content",
          "documentation",
          "create",
          "issues",
          "new",
          "choose",
          "issue"
        ],
        "term_weights": [
          {
            "term": "inference",
            "tf": 14,
            "weight": 0.125
          },
          {
            "term": "qdrant",
            "tf": 8,
            "weight": 0.071429
          },
          {
            "term": "page",
            "tf": 7,
            "weight": 0.0625
          },
          {
            "term": "github",
            "tf": 7,
            "weight": 0.0625
          },
          {
            "term": "landing",
            "tf": 6,
            "weight": 0.053571
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.035714
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.035714
          },
          {
            "term": "cloud",
            "tf": 4,
            "weight": 0.035714
          },
          {
            "term": "this",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "edit",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "tree",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "master",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "content",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "documentation",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "create",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "issues",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "new",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "choose",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "issue",
            "tf": 2,
            "weight": 0.017857
          }
        ],
        "unique_terms": 44,
        "total_terms": 112
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Was this page useful?",
        "cloud",
        "com",
        "github",
        "https",
        "inference",
        "landing",
        "page",
        "qdrant",
        "this",
        "you"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.53,
      "overall": 0.6766666666666667
    }
  }
]
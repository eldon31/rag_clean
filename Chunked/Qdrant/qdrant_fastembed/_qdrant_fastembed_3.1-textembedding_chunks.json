[
  {
    "text": "# TextEmbedding  Relevant source files  - [docs/Getting Started.ipynb](<https://github.com/qdrant/fastembed/blob/b785640b/docs/Getting Started.ipynb>) - [docs/index.md](https://github.com/qdrant/fastembed/blob/b785640b/docs/index.md) - [fastembed/embedding.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/embedding.py) - [fastembed/text/text\\_embedding.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/text_embedding.py) - [tests/test\\_text\\_onnx\\_embeddings.py](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_text_onnx_embeddings.py)  The `TextEmbedding` class is the primary entry point for generating dense vector representations (embeddings) from text in the FastEmbed library. It provides a unified interface to multiple underlying embedding implementations while maintaining high performance through ONNX Runtime integration. For sparse text embeddings, see [SparseTextEmbedding](qdrant/fastembed/3.2-sparsetextembedding.md), and for late interaction models, see [LateInteractionTextEmbedding](qdrant/fastembed/3.3-lateinteractiontextembedding.md).",
    "metadata": {
      "chunk_id": "44a765604797-0000",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "filename": "_qdrant_fastembed_3.1-textembedding.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "TextEmbedding"
      ],
      "heading_text": "TextEmbedding",
      "token_count": 269,
      "char_count": 1104,
      "start_char": 2277,
      "end_char": 3381,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5458823529411765,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.423539",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 269,
      "document_id": "44a765604797",
      "document_name": "_qdrant_fastembed_3.1-textembedding",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "source_filename": "_qdrant_fastembed_3.1-textembedding.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "hierarchy_path": "TextEmbedding",
      "chunk_hash": "d1f312e8e9cdd276",
      "content_digest": "d1f312e8e9cdd276",
      "chunk_length": 1104,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "text",
          "qdrant",
          "https",
          "github",
          "com",
          "blob",
          "b785640b",
          "embedding",
          "docs",
          "embeddings",
          "onnx",
          "the",
          "for",
          "textembedding",
          "getting",
          "started",
          "ipynb",
          "index",
          "tests"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 12,
            "weight": 0.096
          },
          {
            "term": "text",
            "tf": 8,
            "weight": 0.064
          },
          {
            "term": "qdrant",
            "tf": 7,
            "weight": 0.056
          },
          {
            "term": "https",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "github",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "com",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "blob",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "b785640b",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "embedding",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "docs",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "embeddings",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "onnx",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "textembedding",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "getting",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "started",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "ipynb",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "index",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "tests",
            "tf": 2,
            "weight": 0.016
          }
        ],
        "unique_terms": 55,
        "total_terms": 125
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "TextEmbedding",
        "b785640b",
        "blob",
        "com",
        "docs",
        "embedding",
        "fastembed",
        "github",
        "https",
        "qdrant",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5458823529411765,
      "overall": 0.6819607843137255
    }
  },
  {
    "text": "## Embedding Generation Process ``` ``` Sources: [fastembed/text/text\\_embedding.py111-126](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/text_embedding.py#L111-L126) [fastembed/text/text\\_embedding.py131-153](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/text_embedding.py#L131-L153)",
    "metadata": {
      "chunk_id": "44a765604797-0003",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "filename": "_qdrant_fastembed_3.1-textembedding.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Embedding Generation Process"
      ],
      "heading_text": "Embedding Generation Process",
      "token_count": 85,
      "char_count": 322,
      "start_char": 5293,
      "end_char": 5615,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.430163",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 85,
      "document_id": "44a765604797",
      "document_name": "_qdrant_fastembed_3.1-textembedding",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "source_filename": "_qdrant_fastembed_3.1-textembedding.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "hierarchy_path": "Embedding Generation Process",
      "chunk_hash": "64a54111d4a86ab1",
      "content_digest": "64a54111d4a86ab1",
      "chunk_length": 322,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "text",
          "fastembed",
          "embedding",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "generation",
          "process",
          "sources",
          "py111",
          "126",
          "l111",
          "l126",
          "py131",
          "153",
          "l131",
          "l153"
        ],
        "term_weights": [
          {
            "term": "text",
            "tf": 8,
            "weight": 0.190476
          },
          {
            "term": "fastembed",
            "tf": 6,
            "weight": 0.142857
          },
          {
            "term": "embedding",
            "tf": 5,
            "weight": 0.119048
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "b785640b",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "generation",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "py111",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "126",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "l111",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "l126",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "py131",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "153",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "l131",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "l153",
            "tf": 1,
            "weight": 0.02381
          }
        ],
        "unique_terms": 20,
        "total_terms": 42
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Embedding Generation Process",
        "b785640b",
        "blob",
        "com",
        "embedding",
        "fastembed",
        "generation",
        "github",
        "https",
        "qdrant",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "overall": 0.6855555555555556
    }
  },
  {
    "text": "## Core Methods",
    "metadata": {
      "chunk_id": "44a765604797-0004",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "filename": "_qdrant_fastembed_3.1-textembedding.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Core Methods"
      ],
      "heading_text": "Core Methods",
      "token_count": 3,
      "char_count": 15,
      "start_char": 5619,
      "end_char": 5634,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.430506",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 3,
      "document_id": "44a765604797",
      "document_name": "_qdrant_fastembed_3.1-textembedding",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "source_filename": "_qdrant_fastembed_3.1-textembedding.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "hierarchy_path": "Core Methods",
      "chunk_hash": "12d12273568f0fd6",
      "content_digest": "12d12273568f0fd6",
      "chunk_length": 15,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "core",
          "methods"
        ],
        "term_weights": [
          {
            "term": "core",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "methods",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Core Methods",
        "core",
        "methods"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Embedding Documents  The primary method for generating embeddings is `embed()`, which accepts documents and returns an iterator of embedding vectors: ``` ``` The method signature is: ``` ``` Parameters:  - `documents`: A single text document or an iterable of documents - `batch_size`: Number of documents to process at once (default: 256) - `parallel`: Number of parallel processes to use (if > 0)  Sources: [fastembed/text/text\\_embedding.py131-153](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/text_embedding.py#L131-L153) [docs/Getting Started.ipynb116-121](<https://github.com/qdrant/fastembed/blob/b785640b/docs/Getting Started.ipynb#L116-L121>)",
    "metadata": {
      "chunk_id": "44a765604797-0005",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "filename": "_qdrant_fastembed_3.1-textembedding.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Embedding Documents"
      ],
      "heading_text": "Embedding Documents",
      "token_count": 167,
      "char_count": 675,
      "start_char": 5636,
      "end_char": 6311,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.515,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.432837",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 167,
      "document_id": "44a765604797",
      "document_name": "_qdrant_fastembed_3.1-textembedding",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "source_filename": "_qdrant_fastembed_3.1-textembedding.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "hierarchy_path": "Embedding Documents",
      "chunk_hash": "40169c053dd6583c",
      "content_digest": "40169c053dd6583c",
      "chunk_length": 675,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "documents",
          "text",
          "embedding",
          "fastembed",
          "the",
          "method",
          "number",
          "parallel",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "docs",
          "getting",
          "started",
          "primary",
          "for",
          "generating"
        ],
        "term_weights": [
          {
            "term": "documents",
            "tf": 5,
            "weight": 0.064103
          },
          {
            "term": "text",
            "tf": 5,
            "weight": 0.064103
          },
          {
            "term": "embedding",
            "tf": 4,
            "weight": 0.051282
          },
          {
            "term": "fastembed",
            "tf": 4,
            "weight": 0.051282
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "method",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "number",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "parallel",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "b785640b",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "getting",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "started",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "primary",
            "tf": 1,
            "weight": 0.012821
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.012821
          },
          {
            "term": "generating",
            "tf": 1,
            "weight": 0.012821
          }
        ],
        "unique_terms": 51,
        "total_terms": 78
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Embedding Documents",
        "documents",
        "embedding",
        "fastembed",
        "github",
        "https",
        "method",
        "number",
        "parallel",
        "text",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.515,
      "overall": 0.705
    }
  },
  {
    "text": "### Query and Passage Embedding  For retrieval tasks, `TextEmbedding` provides specialized methods for queries and passages: ``` ``` These methods are particularly useful for models that have different embedding strategies for queries versus passages. Sources: [fastembed/text/text\\_embedding.py155-180](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/text_embedding.py#L155-L180) [docs/index.md27-36](https://github.com/qdrant/fastembed/blob/b785640b/docs/index.md#L27-L36)",
    "metadata": {
      "chunk_id": "44a765604797-0006",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "filename": "_qdrant_fastembed_3.1-textembedding.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Query and Passage Embedding"
      ],
      "heading_text": "Query and Passage Embedding",
      "token_count": 114,
      "char_count": 491,
      "start_char": 6317,
      "end_char": 6808,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5251351351351351,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.435043",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 114,
      "document_id": "44a765604797",
      "document_name": "_qdrant_fastembed_3.1-textembedding",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "source_filename": "_qdrant_fastembed_3.1-textembedding.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "hierarchy_path": "Query and Passage Embedding",
      "chunk_hash": "96e59fe1b3e8220f",
      "content_digest": "96e59fe1b3e8220f",
      "chunk_length": 491,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "embedding",
          "for",
          "fastembed",
          "text",
          "and",
          "methods",
          "queries",
          "passages",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "docs",
          "index",
          "query",
          "passage",
          "retrieval",
          "tasks"
        ],
        "term_weights": [
          {
            "term": "embedding",
            "tf": 4,
            "weight": 0.061538
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.061538
          },
          {
            "term": "fastembed",
            "tf": 4,
            "weight": 0.061538
          },
          {
            "term": "text",
            "tf": 4,
            "weight": 0.061538
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "methods",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "queries",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "passages",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "b785640b",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "index",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "query",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "passage",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "retrieval",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "tasks",
            "tf": 1,
            "weight": 0.015385
          }
        ],
        "unique_terms": 41,
        "total_terms": 65
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Query and Passage Embedding",
        "and",
        "embedding",
        "fastembed",
        "for",
        "github",
        "https",
        "methods",
        "passages",
        "queries",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5251351351351351,
      "overall": 0.7083783783783782
    }
  },
  {
    "text": "### Batch Processing  For large datasets, you can process documents in batches to conserve memory: ``` ```",
    "metadata": {
      "chunk_id": "44a765604797-0009",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "filename": "_qdrant_fastembed_3.1-textembedding.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Batch Processing"
      ],
      "heading_text": "Batch Processing",
      "token_count": 20,
      "char_count": 106,
      "start_char": 7107,
      "end_char": 7213,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5723529411764706,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.438077",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 20,
      "document_id": "44a765604797",
      "document_name": "_qdrant_fastembed_3.1-textembedding",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "source_filename": "_qdrant_fastembed_3.1-textembedding.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "hierarchy_path": "Batch Processing",
      "chunk_hash": "1b42754aab1f463e",
      "content_digest": "1b42754aab1f463e",
      "chunk_length": 106,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "batch",
          "processing",
          "for",
          "large",
          "datasets",
          "you",
          "can",
          "process",
          "documents",
          "batches",
          "conserve",
          "memory"
        ],
        "term_weights": [
          {
            "term": "batch",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "large",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "datasets",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "batches",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "conserve",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "memory",
            "tf": 1,
            "weight": 0.083333
          }
        ],
        "unique_terms": 12,
        "total_terms": 12
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Batch Processing",
        "batch",
        "batches",
        "can",
        "datasets",
        "documents",
        "for",
        "large",
        "process",
        "processing",
        "you"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5723529411764706,
      "overall": 0.7574509803921569
    }
  },
  {
    "text": "### Parallel Processing  To speed up embedding generation, you can use parallel processing: ``` ``` Sources: [tests/test\\_text\\_onnx\\_embeddings.py119-139](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_text_onnx_embeddings.py#L119-L139)",
    "metadata": {
      "chunk_id": "44a765604797-0010",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "filename": "_qdrant_fastembed_3.1-textembedding.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Parallel Processing"
      ],
      "heading_text": "Parallel Processing",
      "token_count": 63,
      "char_count": 251,
      "start_char": 7216,
      "end_char": 7467,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5547058823529412,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.439852",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 63,
      "document_id": "44a765604797",
      "document_name": "_qdrant_fastembed_3.1-textembedding",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "source_filename": "_qdrant_fastembed_3.1-textembedding.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "hierarchy_path": "Parallel Processing",
      "chunk_hash": "7270f7f474885d67",
      "content_digest": "7270f7f474885d67",
      "chunk_length": 251,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "parallel",
          "processing",
          "tests",
          "test",
          "text",
          "onnx",
          "embeddings",
          "speed",
          "embedding",
          "generation",
          "you",
          "can",
          "use",
          "sources",
          "py119",
          "139",
          "https",
          "github",
          "com",
          "qdrant"
        ],
        "term_weights": [
          {
            "term": "parallel",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "processing",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "tests",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "onnx",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "speed",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "generation",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "py119",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "139",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "github",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "com",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.03125
          }
        ],
        "unique_terms": 25,
        "total_terms": 32
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Parallel Processing",
        "embedding",
        "embeddings",
        "generation",
        "onnx",
        "parallel",
        "processing",
        "speed",
        "test",
        "tests",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5547058823529412,
      "overall": 0.718235294117647
    }
  },
  {
    "text": "### Lazy Loading  To conserve memory when working with multiple models, you can use lazy loading, which only loads the model when it's first used: ``` ``` Sources: [tests/test\\_text\\_onnx\\_embeddings.py142-158](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_text_onnx_embeddings.py#L142-L158)",
    "metadata": {
      "chunk_id": "44a765604797-0011",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "filename": "_qdrant_fastembed_3.1-textembedding.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Lazy Loading"
      ],
      "heading_text": "Lazy Loading",
      "token_count": 77,
      "char_count": 306,
      "start_char": 7471,
      "end_char": 7777,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5589655172413793,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.441576",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 77,
      "document_id": "44a765604797",
      "document_name": "_qdrant_fastembed_3.1-textembedding",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "source_filename": "_qdrant_fastembed_3.1-textembedding.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "hierarchy_path": "Lazy Loading",
      "chunk_hash": "726238df9b87664e",
      "content_digest": "726238df9b87664e",
      "chunk_length": 306,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "lazy",
          "loading",
          "when",
          "tests",
          "test",
          "text",
          "onnx",
          "embeddings",
          "conserve",
          "memory",
          "working",
          "with",
          "multiple",
          "models",
          "you",
          "can",
          "use",
          "which",
          "only",
          "loads"
        ],
        "term_weights": [
          {
            "term": "lazy",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "loading",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "when",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "tests",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "onnx",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "conserve",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "memory",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "working",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "which",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "only",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "loads",
            "tf": 1,
            "weight": 0.022727
          }
        ],
        "unique_terms": 36,
        "total_terms": 44
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Lazy Loading",
        "conserve",
        "embeddings",
        "lazy",
        "loading",
        "memory",
        "onnx",
        "test",
        "tests",
        "text",
        "when"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5589655172413793,
      "overall": 0.7196551724137931
    }
  },
  {
    "text": "## Supported Models  `TextEmbedding` supports a wide range of models, including:  | Model Category        | Examples                                                                                            | | --------------------- | --------------------------------------------------------------------------------------------------- | | BGE Embeddings        | BAAI/bge-small-en-v1.5, BAAI/bge-base-en, BAAI/bge-large-en-v1.5                                    | | Sentence Transformers | sentence-transformers/all-MiniLM-L6-v2, sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 | | Jina AI Models        | jinaai/jina-embeddings-v2-base-en, jinaai/jina-embeddings-v3                                        | | Nomic AI Models       | nomic-ai/nomic-embed-text-v1, nomic-ai/nomic-embed-text-v1.5                                        | | Others                | thenlper/gte-large, mixedbread-ai/mxbai-embed-large-v1, snowflake/snowflake-arctic-embed models     |  Each model produces embeddings of different dimensions and with different characteristics. The default model (BAAI/bge-small-en-v1.5) produces 384-dimensional vectors. Sources: [tests/test\\_text\\_onnx\\_embeddings.py10-70](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_text_onnx_embeddings.py#L10-L70) [docs/Getting Started.ipynb150-162](<https://github.com/qdrant/fastembed/blob/b785640b/docs/Getting Started.ipynb#L150-L162>)",
    "metadata": {
      "chunk_id": "44a765604797-0012",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "filename": "_qdrant_fastembed_3.1-textembedding.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Supported Models"
      ],
      "heading_text": "Supported Models",
      "token_count": 329,
      "char_count": 1420,
      "start_char": 7781,
      "end_char": 9201,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.691557142857143,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.443967",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 329,
      "document_id": "44a765604797",
      "document_name": "_qdrant_fastembed_3.1-textembedding",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "source_filename": "_qdrant_fastembed_3.1-textembedding.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "hierarchy_path": "Supported Models",
      "chunk_hash": "4483dbc6d57eb261",
      "content_digest": "4483dbc6d57eb261",
      "chunk_length": 1420,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "embeddings",
          "models",
          "bge",
          "nomic",
          "baai",
          "embed",
          "text",
          "model",
          "large",
          "sentence",
          "transformers",
          "jina",
          "small",
          "base",
          "minilm",
          "jinaai",
          "snowflake",
          "produces",
          "different",
          "tests"
        ],
        "term_weights": [
          {
            "term": "embeddings",
            "tf": 6,
            "weight": 0.048
          },
          {
            "term": "models",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "bge",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "nomic",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "baai",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "text",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "large",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "jina",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "small",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "base",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "minilm",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "jinaai",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "snowflake",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "produces",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "different",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "tests",
            "tf": 2,
            "weight": 0.016
          }
        ],
        "unique_terms": 69,
        "total_terms": 125
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Supported Models",
        "baai",
        "bge",
        "embed",
        "embeddings",
        "large",
        "model",
        "models",
        "nomic",
        "sentence",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.691557142857143,
      "overall": 0.7638523809523811
    }
  },
  {
    "text": "## Integration with Vector Databases  `TextEmbedding` is designed to work seamlessly with vector databases like Qdrant. For detailed examples, see [Integration with Qdrant](qdrant/fastembed/9-integration-with-qdrant.md). ``` ``` Sources: [docs/index.md39-75](https://github.com/qdrant/fastembed/blob/b785640b/docs/index.md#L39-L75)",
    "metadata": {
      "chunk_id": "44a765604797-0013",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "filename": "_qdrant_fastembed_3.1-textembedding.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration with Vector Databases"
      ],
      "heading_text": "Integration with Vector Databases",
      "token_count": 87,
      "char_count": 331,
      "start_char": 9204,
      "end_char": 9535,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5344444444444444,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.446090",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 87,
      "document_id": "44a765604797",
      "document_name": "_qdrant_fastembed_3.1-textembedding",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "source_filename": "_qdrant_fastembed_3.1-textembedding.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "hierarchy_path": "Integration with Vector Databases",
      "chunk_hash": "8df16904dab63ab9",
      "content_digest": "8df16904dab63ab9",
      "chunk_length": 331,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "with",
          "integration",
          "vector",
          "databases",
          "fastembed",
          "docs",
          "index",
          "textembedding",
          "designed",
          "work",
          "seamlessly",
          "like",
          "for",
          "detailed",
          "examples",
          "see",
          "sources",
          "md39",
          "https"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 5,
            "weight": 0.125
          },
          {
            "term": "with",
            "tf": 4,
            "weight": 0.1
          },
          {
            "term": "integration",
            "tf": 3,
            "weight": 0.075
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.05
          },
          {
            "term": "databases",
            "tf": 2,
            "weight": 0.05
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.05
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.05
          },
          {
            "term": "index",
            "tf": 2,
            "weight": 0.05
          },
          {
            "term": "textembedding",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "designed",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "work",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "seamlessly",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "like",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "detailed",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "examples",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "see",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "md39",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.025
          }
        ],
        "unique_terms": 26,
        "total_terms": 40
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration with Vector Databases",
        "databases",
        "designed",
        "docs",
        "fastembed",
        "index",
        "integration",
        "qdrant",
        "textembedding",
        "vector",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5344444444444444,
      "overall": 0.6781481481481482
    }
  },
  {
    "text": "## Performance Considerations  The `TextEmbedding` class is designed for high performance through:  1. **ONNX Runtime**: All models are converted to ONNX format for efficient inference 2. **Batch Processing**: Documents are processed in batches for memory efficiency 3. **Parallel Processing**: Multiple CPU cores can be used for faster processing 4. **Lazy Loading**: Models are loaded only when needed 5. **Model Quantization**: Some models have quantized versions for faster inference  For more details on optimizing performance, see [Performance Optimization](qdrant/fastembed/8-performance-optimization.md). Dismiss  Refresh this wiki  Enter email to refresh",
    "metadata": {
      "chunk_id": "44a765604797-0014",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "filename": "_qdrant_fastembed_3.1-textembedding.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Considerations"
      ],
      "heading_text": "Performance Considerations",
      "token_count": 137,
      "char_count": 663,
      "start_char": 9539,
      "end_char": 10202,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5370588235294117,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.449757",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 137,
      "document_id": "44a765604797",
      "document_name": "_qdrant_fastembed_3.1-textembedding",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "source_filename": "_qdrant_fastembed_3.1-textembedding.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "hierarchy_path": "Performance Considerations",
      "chunk_hash": "05d1dc9f0427a9e9",
      "content_digest": "05d1dc9f0427a9e9",
      "chunk_length": 663,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "for",
          "performance",
          "models",
          "are",
          "processing",
          "onnx",
          "inference",
          "faster",
          "optimization",
          "refresh",
          "considerations",
          "the",
          "textembedding",
          "class",
          "designed",
          "high",
          "through",
          "runtime",
          "all",
          "converted"
        ],
        "term_weights": [
          {
            "term": "for",
            "tf": 6,
            "weight": 0.077922
          },
          {
            "term": "performance",
            "tf": 5,
            "weight": 0.064935
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.038961
          },
          {
            "term": "are",
            "tf": 3,
            "weight": 0.038961
          },
          {
            "term": "processing",
            "tf": 3,
            "weight": 0.038961
          },
          {
            "term": "onnx",
            "tf": 2,
            "weight": 0.025974
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.025974
          },
          {
            "term": "faster",
            "tf": 2,
            "weight": 0.025974
          },
          {
            "term": "optimization",
            "tf": 2,
            "weight": 0.025974
          },
          {
            "term": "refresh",
            "tf": 2,
            "weight": 0.025974
          },
          {
            "term": "considerations",
            "tf": 1,
            "weight": 0.012987
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.012987
          },
          {
            "term": "textembedding",
            "tf": 1,
            "weight": 0.012987
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.012987
          },
          {
            "term": "designed",
            "tf": 1,
            "weight": 0.012987
          },
          {
            "term": "high",
            "tf": 1,
            "weight": 0.012987
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.012987
          },
          {
            "term": "runtime",
            "tf": 1,
            "weight": 0.012987
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.012987
          },
          {
            "term": "converted",
            "tf": 1,
            "weight": 0.012987
          }
        ],
        "unique_terms": 57,
        "total_terms": 77
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Considerations",
        "are",
        "faster",
        "for",
        "inference",
        "models",
        "onnx",
        "optimization",
        "performance",
        "processing",
        "refresh"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5370588235294117,
      "overall": 0.7123529411764705
    }
  },
  {
    "text": "### On this page  - [TextEmbedding](#textembedding.md) - [Class Architecture](#class-architecture.md) - [Initialization and Configuration](#initialization-and-configuration.md) - [Embedding Generation Process](#embedding-generation-process.md) - [Core Methods](#core-methods.md) - [Embedding Documents](#embedding-documents.md) - [Query and Passage Embedding](#query-and-passage-embedding.md) - [Model Management](#model-management.md) - [Advanced Usage Patterns](#advanced-usage-patterns.md) - [Batch Processing](#batch-processing.md) - [Parallel Processing](#parallel-processing.md) - [Lazy Loading](#lazy-loading.md) - [Supported Models](#supported-models.md) - [Integration with Vector Databases](#integration-with-vector-databases.md) - [Performance Considerations](#performance-considerations.md)",
    "metadata": {
      "chunk_id": "44a765604797-0015",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "filename": "_qdrant_fastembed_3.1-textembedding.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "On this page"
      ],
      "heading_text": "On this page",
      "token_count": 188,
      "char_count": 802,
      "start_char": 10205,
      "end_char": 11007,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5027272727272727,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.451483",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 188,
      "document_id": "44a765604797",
      "document_name": "_qdrant_fastembed_3.1-textembedding",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "source_filename": "_qdrant_fastembed_3.1-textembedding.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.1-textembedding.md",
      "hierarchy_path": "On this page",
      "chunk_hash": "df6a3477357eddf0",
      "content_digest": "df6a3477357eddf0",
      "chunk_length": 802,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "embedding",
          "and",
          "processing",
          "textembedding",
          "class",
          "architecture",
          "initialization",
          "configuration",
          "generation",
          "process",
          "core",
          "methods",
          "documents",
          "query",
          "passage",
          "model",
          "management",
          "advanced",
          "usage",
          "patterns"
        ],
        "term_weights": [
          {
            "term": "embedding",
            "tf": 6,
            "weight": 0.081081
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.054054
          },
          {
            "term": "processing",
            "tf": 4,
            "weight": 0.054054
          },
          {
            "term": "textembedding",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "class",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "architecture",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "initialization",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "configuration",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "generation",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "process",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "core",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "methods",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "documents",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "passage",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "management",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "advanced",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "usage",
            "tf": 2,
            "weight": 0.027027
          },
          {
            "term": "patterns",
            "tf": 2,
            "weight": 0.027027
          }
        ],
        "unique_terms": 34,
        "total_terms": 74
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "On this page",
        "and",
        "architecture",
        "class",
        "configuration",
        "embedding",
        "generation",
        "initialization",
        "process",
        "processing",
        "textembedding"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5027272727272727,
      "overall": 0.6675757575757576
    }
  }
]
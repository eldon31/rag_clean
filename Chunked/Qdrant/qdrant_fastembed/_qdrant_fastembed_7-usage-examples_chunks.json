[
  {
    "text": "## Basic Text Embedding  The most common use case for FastEmbed is generating dense text embeddings using the `TextEmbedding` class. ``` ``` Each embedding is a numpy array with the default model's dimension (384 for BAAI/bge-small-en-v1.5): ``` ```",
    "metadata": {
      "chunk_id": "4e2e37f899f2-0001",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Basic Text Embedding"
      ],
      "heading_text": "Basic Text Embedding",
      "token_count": 59,
      "char_count": 249,
      "start_char": 3453,
      "end_char": 3702,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5189473684210526,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.494508",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 59,
      "document_id": "4e2e37f899f2",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Basic Text Embedding",
      "chunk_hash": "34240f3521f84347",
      "content_digest": "34240f3521f84347",
      "chunk_length": 249,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "text",
          "embedding",
          "for",
          "basic",
          "most",
          "common",
          "use",
          "case",
          "fastembed",
          "generating",
          "dense",
          "embeddings",
          "using",
          "textembedding",
          "class",
          "each",
          "numpy",
          "array",
          "with"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 3,
            "weight": 0.09375
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "basic",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "most",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "common",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "case",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "generating",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "dense",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "textembedding",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "each",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "numpy",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "array",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.03125
          }
        ],
        "unique_terms": 27,
        "total_terms": 32
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Basic Text Embedding",
        "basic",
        "case",
        "common",
        "embedding",
        "fastembed",
        "for",
        "most",
        "text",
        "the",
        "use"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5189473684210526,
      "overall": 0.7063157894736841
    }
  },
  {
    "text": "### Using Different Models  FastEmbed supports various embedding models with different capabilities: ``` ```",
    "metadata": {
      "chunk_id": "4e2e37f899f2-0002",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Using Different Models"
      ],
      "heading_text": "Using Different Models",
      "token_count": 17,
      "char_count": 108,
      "start_char": 3707,
      "end_char": 3815,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5257142857142857,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.495026",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 17,
      "document_id": "4e2e37f899f2",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Using Different Models",
      "chunk_hash": "2572deac203f0691",
      "content_digest": "2572deac203f0691",
      "chunk_length": 108,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "different",
          "models",
          "using",
          "fastembed",
          "supports",
          "various",
          "embedding",
          "with",
          "capabilities"
        ],
        "term_weights": [
          {
            "term": "different",
            "tf": 2,
            "weight": 0.181818
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.181818
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "various",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "capabilities",
            "tf": 1,
            "weight": 0.090909
          }
        ],
        "unique_terms": 9,
        "total_terms": 11
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Using Different Models",
        "capabilities",
        "different",
        "embedding",
        "fastembed",
        "models",
        "supports",
        "using",
        "various",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5257142857142857,
      "overall": 0.7419047619047618
    }
  },
  {
    "text": "### Query vs Passage Embedding  For retrieval tasks, it's recommended to use specific embedding methods for queries and passages: ``` ``` Sources: [docs/Getting Started.ipynb68-86](<https://github.com/qdrant/fastembed/blob/b785640b/docs/Getting Started.ipynb#L68-L86>) [docs/Getting Started.ipynb116-120](<https://github.com/qdrant/fastembed/blob/b785640b/docs/Getting Started.ipynb#L116-L120>) [docs/qdrant/Retrieval\\_with\\_FastEmbed.ipynb73-93](https://github.com/qdrant/fastembed/blob/b785640b/docs/qdrant/Retrieval_with_FastEmbed.ipynb#L73-L93) [docs/qdrant/Retrieval\\_with\\_FastEmbed.ipynb111-114](https://github.com/qdrant/fastembed/blob/b785640b/docs/qdrant/Retrieval_with_FastEmbed.ipynb#L111-L114)",
    "metadata": {
      "chunk_id": "4e2e37f899f2-0003",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Query vs Passage Embedding"
      ],
      "heading_text": "Query vs Passage Embedding",
      "token_count": 220,
      "char_count": 706,
      "start_char": 3818,
      "end_char": 4524,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.55,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.496650",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 220,
      "document_id": "4e2e37f899f2",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Query vs Passage Embedding",
      "chunk_hash": "5bcb948681cf248e",
      "content_digest": "5bcb948681cf248e",
      "chunk_length": 706,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "docs",
          "qdrant",
          "fastembed",
          "retrieval",
          "getting",
          "started",
          "https",
          "github",
          "com",
          "blob",
          "b785640b",
          "ipynb",
          "with",
          "embedding",
          "for",
          "query",
          "passage",
          "tasks",
          "recommended",
          "use"
        ],
        "term_weights": [
          {
            "term": "docs",
            "tf": 8,
            "weight": 0.085106
          },
          {
            "term": "qdrant",
            "tf": 8,
            "weight": 0.085106
          },
          {
            "term": "fastembed",
            "tf": 8,
            "weight": 0.085106
          },
          {
            "term": "retrieval",
            "tf": 5,
            "weight": 0.053191
          },
          {
            "term": "getting",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "started",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "github",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "blob",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "b785640b",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "ipynb",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "with",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "query",
            "tf": 1,
            "weight": 0.010638
          },
          {
            "term": "passage",
            "tf": 1,
            "weight": 0.010638
          },
          {
            "term": "tasks",
            "tf": 1,
            "weight": 0.010638
          },
          {
            "term": "recommended",
            "tf": 1,
            "weight": 0.010638
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.010638
          }
        ],
        "unique_terms": 40,
        "total_terms": 94
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Query vs Passage Embedding",
        "blob",
        "com",
        "docs",
        "fastembed",
        "getting",
        "github",
        "https",
        "qdrant",
        "retrieval",
        "started"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.55,
      "overall": 0.6833333333333332
    }
  },
  {
    "text": "### Hybrid Search with Qdrant  Combining dense and sparse embeddings enables hybrid search using Qdrant: ``` ``` The hybrid search workflow: ``` ``` Sources: [docs/examples/Hybrid\\_Search.ipynb52-73](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Hybrid_Search.ipynb#L52-L73) [docs/examples/Hybrid\\_Search.ipynb442-470](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Hybrid_Search.ipynb#L442-L470) [docs/examples/Hybrid\\_Search.ipynb874-922](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Hybrid_Search.ipynb#L874-L922)",
    "metadata": {
      "chunk_id": "4e2e37f899f2-0006",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Hybrid Search with Qdrant"
      ],
      "heading_text": "Hybrid Search with Qdrant",
      "token_count": 159,
      "char_count": 570,
      "start_char": 4830,
      "end_char": 5400,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5122222222222222,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.499793",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 159,
      "document_id": "4e2e37f899f2",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Hybrid Search with Qdrant",
      "chunk_hash": "4189b4444f0ca5fe",
      "content_digest": "4189b4444f0ca5fe",
      "chunk_length": 570,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "hybrid",
          "search",
          "docs",
          "examples",
          "qdrant",
          "https",
          "github",
          "com",
          "fastembed",
          "blob",
          "b785640b",
          "ipynb",
          "with",
          "combining",
          "dense",
          "and",
          "sparse",
          "embeddings",
          "enables",
          "using"
        ],
        "term_weights": [
          {
            "term": "hybrid",
            "tf": 9,
            "weight": 0.115385
          },
          {
            "term": "search",
            "tf": 9,
            "weight": 0.115385
          },
          {
            "term": "docs",
            "tf": 6,
            "weight": 0.076923
          },
          {
            "term": "examples",
            "tf": 6,
            "weight": 0.076923
          },
          {
            "term": "qdrant",
            "tf": 5,
            "weight": 0.064103
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.038462
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.038462
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.038462
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.038462
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.038462
          },
          {
            "term": "b785640b",
            "tf": 3,
            "weight": 0.038462
          },
          {
            "term": "ipynb",
            "tf": 3,
            "weight": 0.038462
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.012821
          },
          {
            "term": "combining",
            "tf": 1,
            "weight": 0.012821
          },
          {
            "term": "dense",
            "tf": 1,
            "weight": 0.012821
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.012821
          },
          {
            "term": "sparse",
            "tf": 1,
            "weight": 0.012821
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.012821
          },
          {
            "term": "enables",
            "tf": 1,
            "weight": 0.012821
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.012821
          }
        ],
        "unique_terms": 34,
        "total_terms": 78
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Hybrid Search with Qdrant",
        "blob",
        "com",
        "docs",
        "examples",
        "fastembed",
        "github",
        "https",
        "hybrid",
        "qdrant",
        "search"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5122222222222222,
      "overall": 0.6707407407407407
    }
  },
  {
    "text": "## ColBERT and Late Interaction Models  FastEmbed supports late interaction models through the `LateInteractionTextEmbedding` class, which enables more precise retrieval by preserving token-level interactions.",
    "metadata": {
      "chunk_id": "4e2e37f899f2-0007",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ColBERT and Late Interaction Models"
      ],
      "heading_text": "ColBERT and Late Interaction Models",
      "token_count": 36,
      "char_count": 209,
      "start_char": 5406,
      "end_char": 5615,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.500764",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 36,
      "document_id": "4e2e37f899f2",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "ColBERT and Late Interaction Models",
      "chunk_hash": "3bb1f33c4442a042",
      "content_digest": "3bb1f33c4442a042",
      "chunk_length": 209,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "late",
          "interaction",
          "models",
          "colbert",
          "and",
          "fastembed",
          "supports",
          "through",
          "the",
          "lateinteractiontextembedding",
          "class",
          "which",
          "enables",
          "more",
          "precise",
          "retrieval",
          "preserving",
          "token",
          "level",
          "interactions"
        ],
        "term_weights": [
          {
            "term": "late",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "interaction",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "colbert",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "lateinteractiontextembedding",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "which",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "enables",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "more",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "precise",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "retrieval",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "preserving",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "token",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "level",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "interactions",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 20,
        "total_terms": 23
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ColBERT and Late Interaction Models",
        "and",
        "colbert",
        "fastembed",
        "interaction",
        "late",
        "lateinteractiontextembedding",
        "models",
        "supports",
        "the",
        "through"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "overall": 0.7508333333333334
    }
  },
  {
    "text": "### Understanding Late Interaction  Late interaction models like ColBERT compute embeddings for each token in queries and documents, rather than pooling them into a single vector: ``` ```",
    "metadata": {
      "chunk_id": "4e2e37f899f2-0008",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Understanding Late Interaction"
      ],
      "heading_text": "Understanding Late Interaction",
      "token_count": 32,
      "char_count": 187,
      "start_char": 5617,
      "end_char": 5804,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5578571428571428,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.501526",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 32,
      "document_id": "4e2e37f899f2",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Understanding Late Interaction",
      "chunk_hash": "9de1ae862f4bb561",
      "content_digest": "9de1ae862f4bb561",
      "chunk_length": 187,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "late",
          "interaction",
          "understanding",
          "models",
          "like",
          "colbert",
          "compute",
          "embeddings",
          "for",
          "each",
          "token",
          "queries",
          "and",
          "documents",
          "rather",
          "than",
          "pooling",
          "them",
          "into",
          "single"
        ],
        "term_weights": [
          {
            "term": "late",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "interaction",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "understanding",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "like",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "colbert",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "compute",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "each",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "token",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "queries",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "rather",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "than",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "pooling",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "them",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "into",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "single",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 21,
        "total_terms": 23
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Understanding Late Interaction",
        "colbert",
        "compute",
        "each",
        "embeddings",
        "for",
        "interaction",
        "late",
        "like",
        "models",
        "understanding"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5578571428571428,
      "overall": 0.7526190476190475
    }
  },
  {
    "text": "### Using ColBERT Model ``` ```",
    "metadata": {
      "chunk_id": "4e2e37f899f2-0009",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Using ColBERT Model"
      ],
      "heading_text": "Using ColBERT Model",
      "token_count": 7,
      "char_count": 31,
      "start_char": 5807,
      "end_char": 5838,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.54,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.501791",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 7,
      "document_id": "4e2e37f899f2",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Using ColBERT Model",
      "chunk_hash": "2cd0fee19272a423",
      "content_digest": "2cd0fee19272a423",
      "chunk_length": 31,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "using",
          "colbert",
          "model"
        ],
        "term_weights": [
          {
            "term": "using",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "colbert",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.333333
          }
        ],
        "unique_terms": 3,
        "total_terms": 3
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Using ColBERT Model",
        "colbert",
        "model",
        "using"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.54,
      "overall": 0.7466666666666667
    }
  },
  {
    "text": "### Maximal Similarity (MaxSim) Scoring  Late interaction models require a specific similarity computation called MaxSim: ``` ``` The MaxSim operation workflow: ``` ``` Sources: [docs/examples/ColBERT\\_with\\_FastEmbed.ipynb72-74](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/ColBERT_with_FastEmbed.ipynb#L72-L74) [docs/examples/ColBERT\\_with\\_FastEmbed.ipynb168-205](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/ColBERT_with_FastEmbed.ipynb#L168-L205) [docs/examples/ColBERT\\_with\\_FastEmbed.ipynb280-309](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/ColBERT_with_FastEmbed.ipynb#L280-L309)",
    "metadata": {
      "chunk_id": "4e2e37f899f2-0010",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Maximal Similarity (MaxSim) Scoring"
      ],
      "heading_text": "Maximal Similarity (MaxSim) Scoring",
      "token_count": 186,
      "char_count": 647,
      "start_char": 5841,
      "end_char": 6488,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7455555555555555,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.503251",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 186,
      "document_id": "4e2e37f899f2",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Maximal Similarity (MaxSim) Scoring",
      "chunk_hash": "0ad6c44c9d64721d",
      "content_digest": "0ad6c44c9d64721d",
      "chunk_length": 647,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "docs",
          "examples",
          "colbert",
          "with",
          "maxsim",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "ipynb",
          "similarity",
          "maximal",
          "scoring",
          "late",
          "interaction",
          "models",
          "require"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 9,
            "weight": 0.108434
          },
          {
            "term": "docs",
            "tf": 6,
            "weight": 0.072289
          },
          {
            "term": "examples",
            "tf": 6,
            "weight": 0.072289
          },
          {
            "term": "colbert",
            "tf": 6,
            "weight": 0.072289
          },
          {
            "term": "with",
            "tf": 6,
            "weight": 0.072289
          },
          {
            "term": "maxsim",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "b785640b",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "ipynb",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "similarity",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "maximal",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "scoring",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "late",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "interaction",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "require",
            "tf": 1,
            "weight": 0.012048
          }
        ],
        "unique_terms": 38,
        "total_terms": 83
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Maximal Similarity (MaxSim) Scoring",
        "colbert",
        "com",
        "docs",
        "examples",
        "fastembed",
        "github",
        "https",
        "maxsim",
        "qdrant",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7455555555555555,
      "overall": 0.7818518518518518
    }
  },
  {
    "text": "## Performance Comparison\n\nFastEmbed is designed to be faster than traditional embedding libraries by utilizing ONNX Runtime for inference and optimized model implementations.",
    "metadata": {
      "chunk_id": "4e2e37f899f2-0011",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Comparison"
      ],
      "heading_text": "Performance Comparison",
      "token_count": 27,
      "char_count": 175,
      "start_char": 6494,
      "end_char": 6669,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.503785",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 27,
      "document_id": "4e2e37f899f2",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Performance Comparison",
      "chunk_hash": "032c161cb6ce8f52",
      "content_digest": "032c161cb6ce8f52",
      "chunk_length": 175,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "performance",
          "comparison",
          "fastembed",
          "designed",
          "faster",
          "than",
          "traditional",
          "embedding",
          "libraries",
          "utilizing",
          "onnx",
          "runtime",
          "for",
          "inference",
          "and",
          "optimized",
          "model",
          "implementations"
        ],
        "term_weights": [
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "comparison",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "designed",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "faster",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "than",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "traditional",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "libraries",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "utilizing",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "onnx",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "runtime",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "optimized",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "implementations",
            "tf": 1,
            "weight": 0.055556
          }
        ],
        "unique_terms": 18,
        "total_terms": 18
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Comparison",
        "comparison",
        "designed",
        "embedding",
        "fastembed",
        "faster",
        "libraries",
        "performance",
        "than",
        "traditional",
        "utilizing"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Parallelization Benefits\n\nFastEmbed uses data parallelism to speed up embedding generation, significantly reducing processing time for large datasets. In testing with sparse embeddings, parallelization reduced processing time by approximately 50-60% on a multi-core system.\n\nSources: [docs/examples/FastEmbed\\_vs\\_HF\\_Comparison.ipynb149-166](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_vs_HF_Comparison.ipynb#L149-L166) [docs/examples/FastEmbed\\_vs\\_HF\\_Comparison.ipynb256-278](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_vs_HF_Comparison.ipynb#L256-L278)",
    "metadata": {
      "chunk_id": "4e2e37f899f2-0013",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Parallelization Benefits"
      ],
      "heading_text": "Parallelization Benefits",
      "token_count": 155,
      "char_count": 621,
      "start_char": 7330,
      "end_char": 7951,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7663157894736842,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.508538",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 155,
      "document_id": "4e2e37f899f2",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Parallelization Benefits",
      "chunk_hash": "d5fd63667077a522",
      "content_digest": "d5fd63667077a522",
      "chunk_length": 621,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "docs",
          "examples",
          "comparison",
          "parallelization",
          "processing",
          "time",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "ipynb",
          "benefits",
          "uses",
          "data",
          "parallelism",
          "speed",
          "embedding"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 7,
            "weight": 0.101449
          },
          {
            "term": "docs",
            "tf": 4,
            "weight": 0.057971
          },
          {
            "term": "examples",
            "tf": 4,
            "weight": 0.057971
          },
          {
            "term": "comparison",
            "tf": 4,
            "weight": 0.057971
          },
          {
            "term": "parallelization",
            "tf": 2,
            "weight": 0.028986
          },
          {
            "term": "processing",
            "tf": 2,
            "weight": 0.028986
          },
          {
            "term": "time",
            "tf": 2,
            "weight": 0.028986
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.028986
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.028986
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.028986
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.028986
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.028986
          },
          {
            "term": "b785640b",
            "tf": 2,
            "weight": 0.028986
          },
          {
            "term": "ipynb",
            "tf": 2,
            "weight": 0.028986
          },
          {
            "term": "benefits",
            "tf": 1,
            "weight": 0.014493
          },
          {
            "term": "uses",
            "tf": 1,
            "weight": 0.014493
          },
          {
            "term": "data",
            "tf": 1,
            "weight": 0.014493
          },
          {
            "term": "parallelism",
            "tf": 1,
            "weight": 0.014493
          },
          {
            "term": "speed",
            "tf": 1,
            "weight": 0.014493
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.014493
          }
        ],
        "unique_terms": 44,
        "total_terms": 69
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Parallelization Benefits",
        "com",
        "comparison",
        "docs",
        "examples",
        "fastembed",
        "github",
        "https",
        "parallelization",
        "processing",
        "time"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7663157894736842,
      "overall": 0.7221052631578947
    }
  },
  {
    "text": "### On this page  - [Usage Examples](#usage-examples.md) - [Basic Text Embedding](#basic-text-embedding.md) - [Using Different Models](#using-different-models.md) - [Query vs Passage Embedding](#query-vs-passage-embedding.md) - [Sparse and Hybrid Search](#sparse-and-hybrid-search.md) - [Sparse Embedding Generation](#sparse-embedding-generation.md) - [Hybrid Search with Qdrant](#hybrid-search-with-qdrant.md) - [ColBERT and Late Interaction Models](#colbert-and-late-interaction-models.md) - [Understanding Late Interaction](#understanding-late-interaction.md) - [Using ColBERT Model](#using-colbert-model.md) - [Maximal Similarity (MaxSim) Scoring](#maximal-similarity-maxsim-scoring.md) - [Performance Comparison](#performance-comparison.md) - [Benchmarking with Hugging Face Transformers](#benchmarking-with-hugging-face-transformers.md) - [Parallelization Benefits](#parallelization-benefits.md) - [Integration with Qdrant](#integration-with-qdrant.md) - [Cross-Encoder Reranking](#cross-encoder-reranking.md)",
    "metadata": {
      "chunk_id": "4e2e37f899f2-0016",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "On this page"
      ],
      "heading_text": "On this page",
      "token_count": 265,
      "char_count": 1015,
      "start_char": 8399,
      "end_char": 9414,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7025,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.512780",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 265,
      "document_id": "4e2e37f899f2",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "On this page",
      "chunk_hash": "64a63aff495dd867",
      "content_digest": "64a63aff495dd867",
      "chunk_length": 1015,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "embedding",
          "with",
          "using",
          "models",
          "sparse",
          "and",
          "hybrid",
          "search",
          "qdrant",
          "colbert",
          "late",
          "interaction",
          "usage",
          "examples",
          "basic",
          "text",
          "different",
          "query",
          "passage",
          "generation"
        ],
        "term_weights": [
          {
            "term": "embedding",
            "tf": 6,
            "weight": 0.056604
          },
          {
            "term": "with",
            "tf": 6,
            "weight": 0.056604
          },
          {
            "term": "using",
            "tf": 4,
            "weight": 0.037736
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.037736
          },
          {
            "term": "sparse",
            "tf": 4,
            "weight": 0.037736
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.037736
          },
          {
            "term": "hybrid",
            "tf": 4,
            "weight": 0.037736
          },
          {
            "term": "search",
            "tf": 4,
            "weight": 0.037736
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.037736
          },
          {
            "term": "colbert",
            "tf": 4,
            "weight": 0.037736
          },
          {
            "term": "late",
            "tf": 4,
            "weight": 0.037736
          },
          {
            "term": "interaction",
            "tf": 4,
            "weight": 0.037736
          },
          {
            "term": "usage",
            "tf": 2,
            "weight": 0.018868
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.018868
          },
          {
            "term": "basic",
            "tf": 2,
            "weight": 0.018868
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.018868
          },
          {
            "term": "different",
            "tf": 2,
            "weight": 0.018868
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.018868
          },
          {
            "term": "passage",
            "tf": 2,
            "weight": 0.018868
          },
          {
            "term": "generation",
            "tf": 2,
            "weight": 0.018868
          }
        ],
        "unique_terms": 40,
        "total_terms": 106
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "On this page",
        "and",
        "colbert",
        "embedding",
        "hybrid",
        "models",
        "qdrant",
        "search",
        "sparse",
        "using",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7025,
      "overall": 0.7675
    }
  }
]
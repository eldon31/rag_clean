[
  {
    "text": "## Overview of ONNX in FastEmbed  FastEmbed uses ONNX Runtime as its underlying inference engine for all embedding models. This provides substantial performance benefits over traditional PyTorch or TensorFlow implementations while maintaining compatibility with models originally trained in those frameworks. ``` ``` Sources: [fastembed/common/onnx\\_model.py26-109](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L26-L109) [fastembed/text/onnx\\_text\\_model.py17-91](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_text_model.py#L17-L91) [fastembed/image/onnx\\_image\\_model.py21-79](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/image/onnx_image_model.py#L21-L79) [fastembed/rerank/cross\\_encoder/onnx\\_text\\_model.py21-77](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/rerank/cross_encoder/onnx_text_model.py#L21-L77)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0001",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Overview of ONNX in FastEmbed"
      ],
      "heading_text": "Overview of ONNX in FastEmbed",
      "token_count": 233,
      "char_count": 901,
      "start_char": 3536,
      "end_char": 4437,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.564468085106383,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.164690",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 233,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Overview of ONNX in FastEmbed",
      "chunk_hash": "6c21b15f0d6151cd",
      "content_digest": "6c21b15f0d6151cd",
      "chunk_length": 901,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "onnx",
          "model",
          "text",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "image",
          "models",
          "common",
          "py21",
          "l21",
          "rerank",
          "cross",
          "encoder",
          "overview",
          "uses"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 14,
            "weight": 0.118644
          },
          {
            "term": "onnx",
            "tf": 10,
            "weight": 0.084746
          },
          {
            "term": "model",
            "tf": 8,
            "weight": 0.067797
          },
          {
            "term": "text",
            "tf": 6,
            "weight": 0.050847
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.033898
          },
          {
            "term": "github",
            "tf": 4,
            "weight": 0.033898
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.033898
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.033898
          },
          {
            "term": "blob",
            "tf": 4,
            "weight": 0.033898
          },
          {
            "term": "b785640b",
            "tf": 4,
            "weight": 0.033898
          },
          {
            "term": "image",
            "tf": 4,
            "weight": 0.033898
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.016949
          },
          {
            "term": "common",
            "tf": 2,
            "weight": 0.016949
          },
          {
            "term": "py21",
            "tf": 2,
            "weight": 0.016949
          },
          {
            "term": "l21",
            "tf": 2,
            "weight": 0.016949
          },
          {
            "term": "rerank",
            "tf": 2,
            "weight": 0.016949
          },
          {
            "term": "cross",
            "tf": 2,
            "weight": 0.016949
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.016949
          },
          {
            "term": "overview",
            "tf": 1,
            "weight": 0.008475
          },
          {
            "term": "uses",
            "tf": 1,
            "weight": 0.008475
          }
        ],
        "unique_terms": 56,
        "total_terms": 118
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Overview of ONNX in FastEmbed",
        "b785640b",
        "blob",
        "com",
        "fastembed",
        "github",
        "https",
        "model",
        "onnx",
        "qdrant",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.564468085106383,
      "overall": 0.6881560283687943
    }
  },
  {
    "text": "## ONNX Model Hierarchy  FastEmbed implements a hierarchical structure for its ONNX-based models, with a common base class and specialized subclasses for different modalities.",
    "metadata": {
      "chunk_id": "c123e96a71a8-0002",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ONNX Model Hierarchy"
      ],
      "heading_text": "ONNX Model Hierarchy",
      "token_count": 33,
      "char_count": 175,
      "start_char": 4441,
      "end_char": 4616,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.565,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.165699",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 33,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "ONNX Model Hierarchy",
      "chunk_hash": "41abc6a2f4a2e81b",
      "content_digest": "41abc6a2f4a2e81b",
      "chunk_length": 175,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "onnx",
          "for",
          "model",
          "hierarchy",
          "fastembed",
          "implements",
          "hierarchical",
          "structure",
          "its",
          "based",
          "models",
          "with",
          "common",
          "base",
          "class",
          "and",
          "specialized",
          "subclasses",
          "different",
          "modalities"
        ],
        "term_weights": [
          {
            "term": "onnx",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "hierarchy",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "implements",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "hierarchical",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "structure",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "its",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "common",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "base",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "specialized",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "subclasses",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "modalities",
            "tf": 1,
            "weight": 0.045455
          }
        ],
        "unique_terms": 20,
        "total_terms": 22
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ONNX Model Hierarchy",
        "based",
        "fastembed",
        "for",
        "hierarchical",
        "hierarchy",
        "implements",
        "its",
        "model",
        "onnx",
        "structure"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.565,
      "overall": 0.7549999999999999
    }
  },
  {
    "text": "### Base Class: OnnxModel  The `OnnxModel` class serves as the foundation for all ONNX-based models in FastEmbed. It provides:  - Generic ONNX session management - Provider configuration - Common input/output processing interfaces - Base methods for model loading and inference ``` ``` Sources: [fastembed/common/onnx\\_model.py26-112](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L26-L112) [fastembed/text/onnx\\_text\\_model.py17-91](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_text_model.py#L17-L91) [fastembed/image/onnx\\_image\\_model.py21-79](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/image/onnx_image_model.py#L21-L79) [fastembed/rerank/cross\\_encoder/onnx\\_text\\_model.py21-146](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/rerank/cross_encoder/onnx_text_model.py#L21-L146)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0003",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Base Class: OnnxModel"
      ],
      "heading_text": "Base Class: OnnxModel",
      "token_count": 240,
      "char_count": 872,
      "start_char": 4618,
      "end_char": 5490,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5453191489361702,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.167385",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 240,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Base Class: OnnxModel",
      "chunk_hash": "0a711e9232c45801",
      "content_digest": "0a711e9232c45801",
      "chunk_length": 872,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "onnx",
          "model",
          "text",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "image",
          "common",
          "base",
          "class",
          "onnxmodel",
          "the",
          "for",
          "py21",
          "l21",
          "rerank"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 13,
            "weight": 0.109244
          },
          {
            "term": "onnx",
            "tf": 10,
            "weight": 0.084034
          },
          {
            "term": "model",
            "tf": 9,
            "weight": 0.07563
          },
          {
            "term": "text",
            "tf": 6,
            "weight": 0.05042
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.033613
          },
          {
            "term": "github",
            "tf": 4,
            "weight": 0.033613
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.033613
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.033613
          },
          {
            "term": "blob",
            "tf": 4,
            "weight": 0.033613
          },
          {
            "term": "b785640b",
            "tf": 4,
            "weight": 0.033613
          },
          {
            "term": "image",
            "tf": 4,
            "weight": 0.033613
          },
          {
            "term": "common",
            "tf": 3,
            "weight": 0.02521
          },
          {
            "term": "base",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "class",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "onnxmodel",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "py21",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "l21",
            "tf": 2,
            "weight": 0.016807
          },
          {
            "term": "rerank",
            "tf": 2,
            "weight": 0.016807
          }
        ],
        "unique_terms": 52,
        "total_terms": 119
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Base Class: OnnxModel",
        "b785640b",
        "blob",
        "com",
        "fastembed",
        "github",
        "https",
        "model",
        "onnx",
        "qdrant",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5453191489361702,
      "overall": 0.7151063829787233
    }
  },
  {
    "text": "## ONNX Session Configuration\n\nFastEmbed offers flexible configuration of ONNX Runtime sessions, enabling users to optimize for their specific hardware and performance requirements.",
    "metadata": {
      "chunk_id": "c123e96a71a8-0004",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ONNX Session Configuration"
      ],
      "heading_text": "ONNX Session Configuration",
      "token_count": 29,
      "char_count": 181,
      "start_char": 5494,
      "end_char": 5675,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5639130434782609,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.168082",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 29,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "ONNX Session Configuration",
      "chunk_hash": "66374b01b5ac6198",
      "content_digest": "66374b01b5ac6198",
      "chunk_length": 181,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "onnx",
          "configuration",
          "session",
          "fastembed",
          "offers",
          "flexible",
          "runtime",
          "sessions",
          "enabling",
          "users",
          "optimize",
          "for",
          "their",
          "specific",
          "hardware",
          "and",
          "performance",
          "requirements"
        ],
        "term_weights": [
          {
            "term": "onnx",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "configuration",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "session",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "offers",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "flexible",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "runtime",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "sessions",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "enabling",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "users",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "optimize",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "their",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "specific",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "hardware",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "requirements",
            "tf": 1,
            "weight": 0.05
          }
        ],
        "unique_terms": 18,
        "total_terms": 20
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ONNX Session Configuration",
        "configuration",
        "enabling",
        "fastembed",
        "flexible",
        "offers",
        "onnx",
        "runtime",
        "session",
        "sessions",
        "users"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5639130434782609,
      "overall": 0.7546376811594202
    }
  },
  {
    "text": "### Provider Selection  The library allows specifying which ONNX Runtime execution providers to use: ``` ``` Sources: [fastembed/common/onnx\\_model.py46-106](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L46-L106)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0005",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Provider Selection"
      ],
      "heading_text": "Provider Selection",
      "token_count": 61,
      "char_count": 248,
      "start_char": 5677,
      "end_char": 5925,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5733333333333334,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.169106",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 61,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Provider Selection",
      "chunk_hash": "4be732d0cb7ee103",
      "content_digest": "4be732d0cb7ee103",
      "chunk_length": 248,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "onnx",
          "fastembed",
          "common",
          "model",
          "provider",
          "selection",
          "the",
          "library",
          "allows",
          "specifying",
          "which",
          "runtime",
          "execution",
          "providers",
          "use",
          "sources",
          "py46",
          "106",
          "https",
          "github"
        ],
        "term_weights": [
          {
            "term": "onnx",
            "tf": 3,
            "weight": 0.09375
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.09375
          },
          {
            "term": "common",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "provider",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "selection",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "allows",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "specifying",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "which",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "runtime",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "execution",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "providers",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "py46",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "106",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "github",
            "tf": 1,
            "weight": 0.03125
          }
        ],
        "unique_terms": 26,
        "total_terms": 32
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Provider Selection",
        "allows",
        "common",
        "fastembed",
        "library",
        "model",
        "onnx",
        "provider",
        "selection",
        "specifying",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5733333333333334,
      "overall": 0.7244444444444444
    }
  },
  {
    "text": "### Session Options and Optimization  FastEmbed applies several optimizations to the ONNX Runtime session:  - Sets graph optimization level to `ORT_ENABLE_ALL` - Configures thread counts for intra-op and inter-op parallelism when specified - Validates providers against available execution providers in the runtime ``` ``` Sources: [fastembed/common/onnx\\_model.py86-95](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L86-L95)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0006",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Session Options and Optimization"
      ],
      "heading_text": "Session Options and Optimization",
      "token_count": 99,
      "char_count": 460,
      "start_char": 5929,
      "end_char": 6389,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5313043478260869,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.171590",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 99,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Session Options and Optimization",
      "chunk_hash": "ad1171cbb016c181",
      "content_digest": "ad1171cbb016c181",
      "chunk_length": 460,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "onnx",
          "session",
          "and",
          "optimization",
          "the",
          "runtime",
          "providers",
          "common",
          "model",
          "options",
          "applies",
          "several",
          "optimizations",
          "sets",
          "graph",
          "level",
          "ort",
          "enable",
          "all"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 4,
            "weight": 0.071429
          },
          {
            "term": "onnx",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "session",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "optimization",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "runtime",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "providers",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "common",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "options",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "applies",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "several",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "optimizations",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "sets",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "graph",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "level",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "ort",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "enable",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.017857
          }
        ],
        "unique_terms": 43,
        "total_terms": 56
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Session Options and Optimization",
        "and",
        "common",
        "fastembed",
        "model",
        "onnx",
        "optimization",
        "providers",
        "runtime",
        "session",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5313043478260869,
      "overall": 0.7104347826086955
    }
  },
  {
    "text": "## Inference Pipeline  The ONNX-based inference pipeline in FastEmbed follows a consistent pattern across different model types, with modality-specific preprocessing and postprocessing steps. ``` ``` Sources: [fastembed/text/onnx\\_text\\_model.py62-90](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_text_model.py#L62-L90) [fastembed/image/onnx\\_image\\_model.py63-79](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/image/onnx_image_model.py#L63-L79) [fastembed/rerank/cross\\_encoder/onnx\\_text\\_model.py66-77](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/rerank/cross_encoder/onnx_text_model.py#L66-L77)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0007",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Inference Pipeline"
      ],
      "heading_text": "Inference Pipeline",
      "token_count": 177,
      "char_count": 653,
      "start_char": 6393,
      "end_char": 7046,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7589655172413793,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.173864",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 177,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Inference Pipeline",
      "chunk_hash": "7cecbb346cc578dd",
      "content_digest": "7cecbb346cc578dd",
      "chunk_length": 653,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "onnx",
          "model",
          "text",
          "image",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "inference",
          "pipeline",
          "rerank",
          "cross",
          "encoder",
          "the",
          "based",
          "follows",
          "consistent"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 10,
            "weight": 0.114943
          },
          {
            "term": "onnx",
            "tf": 7,
            "weight": 0.08046
          },
          {
            "term": "model",
            "tf": 7,
            "weight": 0.08046
          },
          {
            "term": "text",
            "tf": 6,
            "weight": 0.068966
          },
          {
            "term": "image",
            "tf": 4,
            "weight": 0.045977
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "b785640b",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "pipeline",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "rerank",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "cross",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "follows",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "consistent",
            "tf": 1,
            "weight": 0.011494
          }
        ],
        "unique_terms": 41,
        "total_terms": 87
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Inference Pipeline",
        "blob",
        "com",
        "fastembed",
        "github",
        "https",
        "image",
        "model",
        "onnx",
        "qdrant",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7589655172413793,
      "overall": 0.7529885057471265
    }
  },
  {
    "text": "### Text Model Inference  For text models, the inference process includes:  1. Tokenization of input text documents 2. Conversion of tokens to input tensors (input\\_ids, attention\\_mask, etc.) 3. Model inference via ONNX Runtime 4. Post-processing of output embeddings (first token extraction, normalization) ``` ``` Sources: [fastembed/text/onnx\\_text\\_model.py65-90](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_text_model.py#L65-L90) [fastembed/text/onnx\\_embedding.py298-315](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L298-L315)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0008",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Text Model Inference"
      ],
      "heading_text": "Text Model Inference",
      "token_count": 156,
      "char_count": 598,
      "start_char": 7050,
      "end_char": 7648,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5325531914893616,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.177372",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 156,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Text Model Inference",
      "chunk_hash": "7b4dc41bfe1e1351",
      "content_digest": "7b4dc41bfe1e1351",
      "chunk_length": 598,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "text",
          "fastembed",
          "onnx",
          "model",
          "inference",
          "input",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "embedding",
          "for",
          "models",
          "the",
          "process",
          "includes",
          "tokenization",
          "documents"
        ],
        "term_weights": [
          {
            "term": "text",
            "tf": 9,
            "weight": 0.118421
          },
          {
            "term": "fastembed",
            "tf": 6,
            "weight": 0.078947
          },
          {
            "term": "onnx",
            "tf": 5,
            "weight": 0.065789
          },
          {
            "term": "model",
            "tf": 4,
            "weight": 0.052632
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.039474
          },
          {
            "term": "input",
            "tf": 3,
            "weight": 0.039474
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "b785640b",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.013158
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.013158
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.013158
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.013158
          },
          {
            "term": "includes",
            "tf": 1,
            "weight": 0.013158
          },
          {
            "term": "tokenization",
            "tf": 1,
            "weight": 0.013158
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.013158
          }
        ],
        "unique_terms": 45,
        "total_terms": 76
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Text Model Inference",
        "com",
        "fastembed",
        "github",
        "https",
        "inference",
        "input",
        "model",
        "onnx",
        "qdrant",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5325531914893616,
      "overall": 0.6775177304964539
    }
  },
  {
    "text": "### Image Model Inference\n\nFor image models, the inference process includes:\n\n1. Loading and preprocessing images\n2. Building ONNX input dictionary\n3. Model inference via ONNX Runtime\n4. Reshaping and post-processing output embeddings\n\nSources: [fastembed/image/onnx\\_image\\_model.py63-79](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/image/onnx_image_model.py#L63-L79)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0009",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Image Model Inference"
      ],
      "heading_text": "Image Model Inference",
      "token_count": 95,
      "char_count": 384,
      "start_char": 7652,
      "end_char": 8036,
      "semantic_score": 0.6,
      "structural_score": 0.7,
      "retrieval_quality": 0.5385714285714286,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.178486",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 95,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Image Model Inference",
      "chunk_hash": "9357c783f143e1e7",
      "content_digest": "9357c783f143e1e7",
      "chunk_length": 384,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "image",
          "model",
          "onnx",
          "inference",
          "fastembed",
          "and",
          "for",
          "models",
          "the",
          "process",
          "includes",
          "loading",
          "preprocessing",
          "images",
          "building",
          "input",
          "dictionary",
          "via",
          "runtime",
          "reshaping"
        ],
        "term_weights": [
          {
            "term": "image",
            "tf": 6,
            "weight": 0.12
          },
          {
            "term": "model",
            "tf": 4,
            "weight": 0.08
          },
          {
            "term": "onnx",
            "tf": 4,
            "weight": 0.08
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.06
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.06
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "includes",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "loading",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "preprocessing",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "images",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "building",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "input",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "dictionary",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "via",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "runtime",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "reshaping",
            "tf": 1,
            "weight": 0.02
          }
        ],
        "unique_terms": 34,
        "total_terms": 50
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Image Model Inference",
        "and",
        "fastembed",
        "for",
        "image",
        "inference",
        "model",
        "models",
        "onnx",
        "process",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7,
      "retrieval_quality": 0.5385714285714286,
      "overall": 0.6128571428571429
    }
  },
  {
    "text": "### CUDA Configuration  Users can enable CUDA execution by:  1. Setting the `cuda=True` parameter during model initialization 2. Specifying `device_id` for particular GPU selection 3. Providing multiple `device_ids` for parallel processing ``` ``` Sources: [fastembed/common/onnx\\_model.py58-73](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L58-L73)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0011",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "CUDA Configuration"
      ],
      "heading_text": "CUDA Configuration",
      "token_count": 94,
      "char_count": 385,
      "start_char": 8156,
      "end_char": 8541,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5642857142857143,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.181088",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 94,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "CUDA Configuration",
      "chunk_hash": "0fa3d3fdbfeaea97",
      "content_digest": "0fa3d3fdbfeaea97",
      "chunk_length": 385,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cuda",
          "model",
          "fastembed",
          "device",
          "for",
          "common",
          "onnx",
          "configuration",
          "users",
          "can",
          "enable",
          "execution",
          "setting",
          "the",
          "true",
          "parameter",
          "during",
          "initialization",
          "specifying",
          "particular"
        ],
        "term_weights": [
          {
            "term": "cuda",
            "tf": 3,
            "weight": 0.06383
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.06383
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.06383
          },
          {
            "term": "device",
            "tf": 2,
            "weight": 0.042553
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.042553
          },
          {
            "term": "common",
            "tf": 2,
            "weight": 0.042553
          },
          {
            "term": "onnx",
            "tf": 2,
            "weight": 0.042553
          },
          {
            "term": "configuration",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "users",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "enable",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "execution",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "setting",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "true",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "parameter",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "during",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "initialization",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "specifying",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "particular",
            "tf": 1,
            "weight": 0.021277
          }
        ],
        "unique_terms": 37,
        "total_terms": 47
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "CUDA Configuration",
        "can",
        "common",
        "configuration",
        "cuda",
        "device",
        "fastembed",
        "for",
        "model",
        "onnx",
        "users"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5642857142857143,
      "overall": 0.688095238095238
    }
  },
  {
    "text": "### Multi-GPU Support  For parallel processing across multiple GPUs, FastEmbed provides:  1. Device ID specification through `device_ids` parameter 2. Worker process allocation to specific GPUs 3. Load balancing across available GPUs ``` ``` Sources: [fastembed/parallel\\_processor.py120-126](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L120-L126)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0012",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Multi-GPU Support"
      ],
      "heading_text": "Multi-GPU Support",
      "token_count": 89,
      "char_count": 385,
      "start_char": 8545,
      "end_char": 8930,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5642857142857143,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.182986",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 89,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Multi-GPU Support",
      "chunk_hash": "23fcf298e69e2b06",
      "content_digest": "23fcf298e69e2b06",
      "chunk_length": 385,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "parallel",
          "gpus",
          "across",
          "device",
          "processor",
          "multi",
          "gpu",
          "support",
          "for",
          "processing",
          "multiple",
          "provides",
          "specification",
          "through",
          "ids",
          "parameter",
          "worker",
          "process",
          "allocation"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 4,
            "weight": 0.088889
          },
          {
            "term": "parallel",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "gpus",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "across",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "device",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "processor",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "multi",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "gpu",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "specification",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "ids",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "parameter",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "worker",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "allocation",
            "tf": 1,
            "weight": 0.022222
          }
        ],
        "unique_terms": 35,
        "total_terms": 45
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Multi-GPU Support",
        "across",
        "device",
        "fastembed",
        "for",
        "gpu",
        "gpus",
        "multi",
        "parallel",
        "processor",
        "support"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5642857142857143,
      "overall": 0.688095238095238
    }
  },
  {
    "text": "## Implementation Details",
    "metadata": {
      "chunk_id": "c123e96a71a8-0014",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Implementation Details"
      ],
      "heading_text": "Implementation Details",
      "token_count": 3,
      "char_count": 25,
      "start_char": 9917,
      "end_char": 9942,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.184286",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 3,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Implementation Details",
      "chunk_hash": "812a10c977ea5550",
      "content_digest": "812a10c977ea5550",
      "chunk_length": 25,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "implementation",
          "details"
        ],
        "term_weights": [
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "details",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Implementation Details",
        "details",
        "implementation"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Model Loading and Caching\n\nThe ONNX model loading process includes:\n\n1. Model download and caching\n2. Loading the ONNX model file\n3. Setting up the ONNX Runtime session with appropriate providers\n4. Loading supporting components (tokenizers, image processors)\n\nSources: [fastembed/text/onnx\\_embedding.py248-325](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L248-L325)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0015",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Loading and Caching"
      ],
      "heading_text": "Model Loading and Caching",
      "token_count": 98,
      "char_count": 410,
      "start_char": 9944,
      "end_char": 10354,
      "semantic_score": 0.6,
      "structural_score": 0.7,
      "retrieval_quality": 0.5021951219512195,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.184613",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 98,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Model Loading and Caching",
      "chunk_hash": "7dc09e2537619263",
      "content_digest": "7dc09e2537619263",
      "chunk_length": 410,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "onnx",
          "model",
          "loading",
          "the",
          "fastembed",
          "and",
          "caching",
          "text",
          "embedding",
          "process",
          "includes",
          "download",
          "file",
          "setting",
          "runtime",
          "session",
          "with",
          "appropriate",
          "providers",
          "supporting"
        ],
        "term_weights": [
          {
            "term": "onnx",
            "tf": 5,
            "weight": 0.09434
          },
          {
            "term": "model",
            "tf": 4,
            "weight": 0.075472
          },
          {
            "term": "loading",
            "tf": 4,
            "weight": 0.075472
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.056604
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.056604
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "caching",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "includes",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "download",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "file",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "setting",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "runtime",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "session",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "appropriate",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "providers",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "supporting",
            "tf": 1,
            "weight": 0.018868
          }
        ],
        "unique_terms": 35,
        "total_terms": 53
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Loading and Caching",
        "and",
        "caching",
        "embedding",
        "fastembed",
        "loading",
        "model",
        "onnx",
        "process",
        "text",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7,
      "retrieval_quality": 0.5021951219512195,
      "overall": 0.6007317073170731
    }
  },
  {
    "text": "### Lazy Loading  FastEmbed supports lazy loading of ONNX models, which defers model loading until the first inference request. This is particularly useful for multi-GPU scenarios where models should be loaded in worker processes. ``` ``` Sources: [fastembed/text/onnx\\_embedding.py256-258](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L256-L258)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0016",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Lazy Loading"
      ],
      "heading_text": "Lazy Loading",
      "token_count": 87,
      "char_count": 384,
      "start_char": 10356,
      "end_char": 10740,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5584210526315789,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.186433",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 87,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Lazy Loading",
      "chunk_hash": "8b5e764ee5743cc6",
      "content_digest": "8b5e764ee5743cc6",
      "chunk_length": 384,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "loading",
          "onnx",
          "lazy",
          "models",
          "text",
          "embedding",
          "supports",
          "which",
          "defers",
          "model",
          "until",
          "the",
          "first",
          "inference",
          "request",
          "this",
          "particularly",
          "useful",
          "for"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 4,
            "weight": 0.08
          },
          {
            "term": "loading",
            "tf": 3,
            "weight": 0.06
          },
          {
            "term": "onnx",
            "tf": 3,
            "weight": 0.06
          },
          {
            "term": "lazy",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "which",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "defers",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "until",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "first",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "request",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "particularly",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "useful",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.02
          }
        ],
        "unique_terms": 39,
        "total_terms": 50
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Lazy Loading",
        "defers",
        "embedding",
        "fastembed",
        "lazy",
        "loading",
        "models",
        "onnx",
        "supports",
        "text",
        "which"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5584210526315789,
      "overall": 0.7194736842105263
    }
  },
  {
    "text": "### Error Handling  FastEmbed includes error handling for ONNX Runtime provider configuration:  1. Validation of requested providers against available providers 2. Warning for CUDA provider failures 3. Suggestion for CUDA 12.x compatibility ``` ``` Sources: [fastembed/common/onnx\\_model.py96-105](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L96-L105)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0017",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Error Handling"
      ],
      "heading_text": "Error Handling",
      "token_count": 90,
      "char_count": 388,
      "start_char": 10744,
      "end_char": 11132,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5233333333333333,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.188082",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 90,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Error Handling",
      "chunk_hash": "947cf7ab6c503ca4",
      "content_digest": "947cf7ab6c503ca4",
      "chunk_length": 388,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "for",
          "onnx",
          "error",
          "handling",
          "provider",
          "providers",
          "cuda",
          "common",
          "model",
          "includes",
          "runtime",
          "configuration",
          "validation",
          "requested",
          "against",
          "available",
          "warning",
          "failures",
          "suggestion"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 4,
            "weight": 0.086957
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.065217
          },
          {
            "term": "onnx",
            "tf": 3,
            "weight": 0.065217
          },
          {
            "term": "error",
            "tf": 2,
            "weight": 0.043478
          },
          {
            "term": "handling",
            "tf": 2,
            "weight": 0.043478
          },
          {
            "term": "provider",
            "tf": 2,
            "weight": 0.043478
          },
          {
            "term": "providers",
            "tf": 2,
            "weight": 0.043478
          },
          {
            "term": "cuda",
            "tf": 2,
            "weight": 0.043478
          },
          {
            "term": "common",
            "tf": 2,
            "weight": 0.043478
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.043478
          },
          {
            "term": "includes",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "runtime",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "configuration",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "validation",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "requested",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "against",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "available",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "warning",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "failures",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "suggestion",
            "tf": 1,
            "weight": 0.021739
          }
        ],
        "unique_terms": 32,
        "total_terms": 46
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Error Handling",
        "common",
        "cuda",
        "error",
        "fastembed",
        "for",
        "handling",
        "model",
        "onnx",
        "provider",
        "providers"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5233333333333333,
      "overall": 0.6744444444444445
    }
  },
  {
    "text": "## Integration with Embedding Classes  The ONNX Runtime integration is exposed through higher-level embedding classes that provide user-friendly interfaces for generating embeddings: ``` ``` Sources: [fastembed/text/onnx\\_embedding.py186-340](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L186-L340) [fastembed/common/onnx\\_model.py114-136](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L114-L136) [fastembed/parallel\\_processor.py26-34](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L26-L34)",
    "metadata": {
      "chunk_id": "c123e96a71a8-0018",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration with Embedding Classes"
      ],
      "heading_text": "Integration with Embedding Classes",
      "token_count": 150,
      "char_count": 600,
      "start_char": 11136,
      "end_char": 11736,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5471428571428572,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.190158",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 150,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Integration with Embedding Classes",
      "chunk_hash": "032ba043794b57b4",
      "content_digest": "032ba043794b57b4",
      "chunk_length": 600,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "onnx",
          "embedding",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "integration",
          "classes",
          "text",
          "common",
          "model",
          "parallel",
          "processor",
          "with",
          "the",
          "runtime",
          "exposed"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 9,
            "weight": 0.116883
          },
          {
            "term": "onnx",
            "tf": 5,
            "weight": 0.064935
          },
          {
            "term": "embedding",
            "tf": 4,
            "weight": 0.051948
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.038961
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.038961
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.038961
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.038961
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.038961
          },
          {
            "term": "b785640b",
            "tf": 3,
            "weight": 0.038961
          },
          {
            "term": "integration",
            "tf": 2,
            "weight": 0.025974
          },
          {
            "term": "classes",
            "tf": 2,
            "weight": 0.025974
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.025974
          },
          {
            "term": "common",
            "tf": 2,
            "weight": 0.025974
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.025974
          },
          {
            "term": "parallel",
            "tf": 2,
            "weight": 0.025974
          },
          {
            "term": "processor",
            "tf": 2,
            "weight": 0.025974
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.012987
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.012987
          },
          {
            "term": "runtime",
            "tf": 1,
            "weight": 0.012987
          },
          {
            "term": "exposed",
            "tf": 1,
            "weight": 0.012987
          }
        ],
        "unique_terms": 43,
        "total_terms": 77
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration with Embedding Classes",
        "b785640b",
        "blob",
        "com",
        "embedding",
        "fastembed",
        "github",
        "https",
        "integration",
        "onnx",
        "qdrant"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5471428571428572,
      "overall": 0.6823809523809524
    }
  },
  {
    "text": "## Conclusion\n\nThe ONNX Runtime integration in FastEmbed provides significant performance benefits through:\n\n1. Hardware-specific optimizations via execution providers\n2. Efficient model loading and caching\n3. Support for parallel and distributed processing\n4. Consistent API across different model types and modalities\n\nBy leveraging ONNX Runtime's capabilities, FastEmbed achieves faster inference speeds compared to traditional embedding frameworks, making it suitable for production environments where performance is critical.\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh",
    "metadata": {
      "chunk_id": "c123e96a71a8-0019",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Conclusion"
      ],
      "heading_text": "Conclusion",
      "token_count": 97,
      "char_count": 582,
      "start_char": 11740,
      "end_char": 12322,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5535135135135135,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.190726",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 97,
      "document_id": "c123e96a71a8",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Conclusion",
      "chunk_hash": "7da770e5cf6b16a7",
      "content_digest": "7da770e5cf6b16a7",
      "chunk_length": 582,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "and",
          "onnx",
          "runtime",
          "fastembed",
          "performance",
          "model",
          "for",
          "refresh",
          "conclusion",
          "the",
          "integration",
          "provides",
          "significant",
          "benefits",
          "through",
          "hardware",
          "specific",
          "optimizations",
          "via",
          "execution"
        ],
        "term_weights": [
          {
            "term": "and",
            "tf": 3,
            "weight": 0.046875
          },
          {
            "term": "onnx",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "runtime",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "performance",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "refresh",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "conclusion",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "significant",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "benefits",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "hardware",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "specific",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "optimizations",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "via",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "execution",
            "tf": 1,
            "weight": 0.015625
          }
        ],
        "unique_terms": 55,
        "total_terms": 64
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Conclusion",
        "and",
        "conclusion",
        "fastembed",
        "for",
        "model",
        "onnx",
        "performance",
        "refresh",
        "runtime",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5535135135135135,
      "overall": 0.6511711711711712
    }
  }
]
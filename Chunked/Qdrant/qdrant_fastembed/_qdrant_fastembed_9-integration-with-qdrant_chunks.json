[
  {
    "text": "# Integration with Qdrant  Relevant source files  - [README.md](https://github.com/qdrant/fastembed/blob/b785640b/README.md) - [docs/examples/FastEmbed\\_GPU.ipynb](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_GPU.ipynb)",
    "metadata": {
      "chunk_id": "01f7d36ae8a7-0000",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration with Qdrant"
      ],
      "heading_text": "Integration with Qdrant",
      "token_count": 71,
      "char_count": 248,
      "start_char": 2287,
      "end_char": 2535,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5627272727272727,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.830092",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 71,
      "document_id": "01f7d36ae8a7",
      "document_name": "_qdrant_fastembed_9-integration-with-qdrant",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "hierarchy_path": "Integration with Qdrant",
      "chunk_hash": "8984229e31006bdc",
      "content_digest": "8984229e31006bdc",
      "chunk_length": 248,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "qdrant",
          "readme",
          "https",
          "github",
          "com",
          "blob",
          "b785640b",
          "docs",
          "examples",
          "gpu",
          "ipynb",
          "integration",
          "with",
          "relevant",
          "source",
          "files"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 4,
            "weight": 0.125
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.09375
          },
          {
            "term": "readme",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "b785640b",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "gpu",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "ipynb",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "relevant",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "source",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "files",
            "tf": 1,
            "weight": 0.03125
          }
        ],
        "unique_terms": 17,
        "total_terms": 32
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration with Qdrant",
        "b785640b",
        "blob",
        "com",
        "docs",
        "examples",
        "fastembed",
        "github",
        "https",
        "qdrant",
        "readme"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5627272727272727,
      "overall": 0.6875757575757575
    }
  },
  {
    "text": "## Purpose and Scope\n\nThis document explains how to integrate the FastEmbed library with Qdrant, a vector database designed for efficient similarity search. FastEmbed generates embeddings, and Qdrant stores and searches them. This integration allows for seamless vector search capabilities in your applications, combining FastEmbed's efficient embedding generation with Qdrant's optimized vector storage and retrieval.",
    "metadata": {
      "chunk_id": "01f7d36ae8a7-0001",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Purpose and Scope"
      ],
      "heading_text": "Purpose and Scope",
      "token_count": 73,
      "char_count": 418,
      "start_char": 2537,
      "end_char": 2955,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5354545454545454,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.830932",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 73,
      "document_id": "01f7d36ae8a7",
      "document_name": "_qdrant_fastembed_9-integration-with-qdrant",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "hierarchy_path": "Purpose and Scope",
      "chunk_hash": "b13a3367c09958cb",
      "content_digest": "b13a3367c09958cb",
      "chunk_length": 418,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "and",
          "fastembed",
          "qdrant",
          "vector",
          "this",
          "with",
          "for",
          "efficient",
          "search",
          "purpose",
          "scope",
          "document",
          "explains",
          "how",
          "integrate",
          "the",
          "library",
          "database",
          "designed",
          "similarity"
        ],
        "term_weights": [
          {
            "term": "and",
            "tf": 4,
            "weight": 0.078431
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.058824
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.058824
          },
          {
            "term": "vector",
            "tf": 3,
            "weight": 0.058824
          },
          {
            "term": "this",
            "tf": 2,
            "weight": 0.039216
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.039216
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.039216
          },
          {
            "term": "efficient",
            "tf": 2,
            "weight": 0.039216
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.039216
          },
          {
            "term": "purpose",
            "tf": 1,
            "weight": 0.019608
          },
          {
            "term": "scope",
            "tf": 1,
            "weight": 0.019608
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.019608
          },
          {
            "term": "explains",
            "tf": 1,
            "weight": 0.019608
          },
          {
            "term": "how",
            "tf": 1,
            "weight": 0.019608
          },
          {
            "term": "integrate",
            "tf": 1,
            "weight": 0.019608
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.019608
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.019608
          },
          {
            "term": "database",
            "tf": 1,
            "weight": 0.019608
          },
          {
            "term": "designed",
            "tf": 1,
            "weight": 0.019608
          },
          {
            "term": "similarity",
            "tf": 1,
            "weight": 0.019608
          }
        ],
        "unique_terms": 37,
        "total_terms": 51
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Purpose and Scope",
        "and",
        "efficient",
        "fastembed",
        "for",
        "purpose",
        "qdrant",
        "search",
        "this",
        "vector",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5354545454545454,
      "overall": 0.7451515151515151
    }
  },
  {
    "text": "### Adding Documents with Automatic Embedding  The integration provides a simplified workflow where Qdrant client handles embedding generation internally: ``` ``` Code example: ``` ```",
    "metadata": {
      "chunk_id": "01f7d36ae8a7-0006",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Adding Documents with Automatic Embedding"
      ],
      "heading_text": "Adding Documents with Automatic Embedding",
      "token_count": 31,
      "char_count": 184,
      "start_char": 3646,
      "end_char": 3830,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.542,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.836185",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 31,
      "document_id": "01f7d36ae8a7",
      "document_name": "_qdrant_fastembed_9-integration-with-qdrant",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "hierarchy_path": "Adding Documents with Automatic Embedding",
      "chunk_hash": "0c831b284481ded3",
      "content_digest": "0c831b284481ded3",
      "chunk_length": 184,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "embedding",
          "adding",
          "documents",
          "with",
          "automatic",
          "the",
          "integration",
          "provides",
          "simplified",
          "workflow",
          "where",
          "qdrant",
          "client",
          "handles",
          "generation",
          "internally",
          "code",
          "example"
        ],
        "term_weights": [
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.105263
          },
          {
            "term": "adding",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "automatic",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "simplified",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "workflow",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "client",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "handles",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "generation",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "internally",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "code",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "example",
            "tf": 1,
            "weight": 0.052632
          }
        ],
        "unique_terms": 18,
        "total_terms": 19
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Adding Documents with Automatic Embedding",
        "adding",
        "automatic",
        "documents",
        "embedding",
        "integration",
        "provides",
        "simplified",
        "the",
        "with",
        "workflow"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.542,
      "overall": 0.7473333333333333
    }
  },
  {
    "text": "## Model Configuration  By default, the integration uses FastEmbed's default embedding model. You can customize this: ``` ``` Sources: [README.md263-265](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L263-L265)",
    "metadata": {
      "chunk_id": "01f7d36ae8a7-0008",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Configuration"
      ],
      "heading_text": "Model Configuration",
      "token_count": 56,
      "char_count": 224,
      "start_char": 3981,
      "end_char": 4205,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.575,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.838886",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 56,
      "document_id": "01f7d36ae8a7",
      "document_name": "_qdrant_fastembed_9-integration-with-qdrant",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "hierarchy_path": "Model Configuration",
      "chunk_hash": "c54d257ddb318868",
      "content_digest": "c54d257ddb318868",
      "chunk_length": 224,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "default",
          "fastembed",
          "readme",
          "configuration",
          "the",
          "integration",
          "uses",
          "embedding",
          "you",
          "can",
          "customize",
          "this",
          "sources",
          "md263",
          "265",
          "https",
          "github",
          "com",
          "qdrant"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "default",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "readme",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "configuration",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "uses",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "customize",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "md263",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "265",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "github",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "com",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.035714
          }
        ],
        "unique_terms": 24,
        "total_terms": 28
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Configuration",
        "configuration",
        "default",
        "embedding",
        "fastembed",
        "integration",
        "model",
        "readme",
        "the",
        "uses",
        "you"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.575,
      "overall": 0.6916666666666668
    }
  },
  {
    "text": "## Performance Considerations",
    "metadata": {
      "chunk_id": "01f7d36ae8a7-0010",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Considerations"
      ],
      "heading_text": "Performance Considerations",
      "token_count": 4,
      "char_count": 29,
      "start_char": 4430,
      "end_char": 4459,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.840554",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 4,
      "document_id": "01f7d36ae8a7",
      "document_name": "_qdrant_fastembed_9-integration-with-qdrant",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "hierarchy_path": "Performance Considerations",
      "chunk_hash": "f0c6f691b1d6938e",
      "content_digest": "f0c6f691b1d6938e",
      "chunk_length": 29,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "performance",
          "considerations"
        ],
        "term_weights": [
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "considerations",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Considerations",
        "considerations",
        "performance"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### GPU Acceleration  If you're working with large datasets or need real-time embedding generation, you can use GPU acceleration:  1. Install with GPU support: `pip install qdrant-client[fastembed-gpu]` 2. Ensure you have the proper CUDA drivers installed  See the [FastEmbed GPU documentation](qdrant/fastembed/8-performance-optimization.md) for more details on GPU setup and requirements. Note: GPU acceleration can significantly improve embedding generation performance, as shown in the comparison below:  | Platform | Processing Time for 500 Documents | | -------- | --------------------------------- | | CPU      | \\~4.33 seconds                    | | GPU      | \\~43.4 milliseconds               |  This represents approximately a 100x speedup when using GPU acceleration. Sources: [docs/examples/FastEmbed\\_GPU.ipynb20-33](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_GPU.ipynb#L20-L33) [docs/examples/FastEmbed\\_GPU.ipynb411-512](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_GPU.ipynb#L411-L512)",
    "metadata": {
      "chunk_id": "01f7d36ae8a7-0011",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "GPU Acceleration"
      ],
      "heading_text": "GPU Acceleration",
      "token_count": 254,
      "char_count": 1062,
      "start_char": 4461,
      "end_char": 5523,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7113592233009708,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.841643",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 254,
      "document_id": "01f7d36ae8a7",
      "document_name": "_qdrant_fastembed_9-integration-with-qdrant",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "hierarchy_path": "GPU Acceleration",
      "chunk_hash": "a2e54d2d69743fbb",
      "content_digest": "a2e54d2d69743fbb",
      "chunk_length": 1062,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "gpu",
          "fastembed",
          "acceleration",
          "qdrant",
          "docs",
          "examples",
          "you",
          "the",
          "with",
          "time",
          "embedding",
          "generation",
          "can",
          "install",
          "performance",
          "for",
          "https",
          "github",
          "com",
          "blob"
        ],
        "term_weights": [
          {
            "term": "gpu",
            "tf": 13,
            "weight": 0.105691
          },
          {
            "term": "fastembed",
            "tf": 9,
            "weight": 0.073171
          },
          {
            "term": "acceleration",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "docs",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "examples",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "you",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "time",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "generation",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "can",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "install",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "performance",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.01626
          }
        ],
        "unique_terms": 73,
        "total_terms": 123
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "GPU Acceleration",
        "acceleration",
        "docs",
        "examples",
        "fastembed",
        "gpu",
        "qdrant",
        "the",
        "time",
        "with",
        "you"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7113592233009708,
      "overall": 0.7704530744336568
    }
  },
  {
    "text": "### Late Interaction Models\n\nFor late interaction models (like ColBERT), Qdrant uses a multi-vector approach where multiple vectors represent a single document.",
    "metadata": {
      "chunk_id": "01f7d36ae8a7-0015",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Late Interaction Models"
      ],
      "heading_text": "Late Interaction Models",
      "token_count": 30,
      "char_count": 160,
      "start_char": 5839,
      "end_char": 5999,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5354545454545454,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.843454",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 30,
      "document_id": "01f7d36ae8a7",
      "document_name": "_qdrant_fastembed_9-integration-with-qdrant",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "hierarchy_path": "Late Interaction Models",
      "chunk_hash": "2feb6d7845df649a",
      "content_digest": "2feb6d7845df649a",
      "chunk_length": 160,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "late",
          "interaction",
          "models",
          "for",
          "like",
          "colbert",
          "qdrant",
          "uses",
          "multi",
          "vector",
          "approach",
          "where",
          "multiple",
          "vectors",
          "represent",
          "single",
          "document"
        ],
        "term_weights": [
          {
            "term": "late",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "interaction",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "like",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "colbert",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "uses",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "multi",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "approach",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "vectors",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "represent",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "single",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.05
          }
        ],
        "unique_terms": 17,
        "total_terms": 20
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Late Interaction Models",
        "colbert",
        "for",
        "interaction",
        "late",
        "like",
        "models",
        "multi",
        "qdrant",
        "uses",
        "vector"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5354545454545454,
      "overall": 0.7451515151515151
    }
  },
  {
    "text": "## Conclusion\n\nThe integration between FastEmbed and Qdrant provides a seamless way to implement vector search in your applications. By leveraging FastEmbed's efficient embedding generation and Qdrant's optimized vector storage and search capabilities, you can build powerful semantic search, recommendation systems, and other AI-powered applications.\n\nFor more information on specific embedding models, see [Supported Models](qdrant/fastembed/6-supported-models.md).\n\nFor examples of using different embedding types, see [Usage Examples](qdrant/fastembed/7-usage-examples.md).\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh",
    "metadata": {
      "chunk_id": "01f7d36ae8a7-0017",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Conclusion"
      ],
      "heading_text": "Conclusion",
      "token_count": 121,
      "char_count": 629,
      "start_char": 6195,
      "end_char": 6824,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7,
      "retrieval_quality": 0.7406849315068492,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.844368",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 121,
      "document_id": "01f7d36ae8a7",
      "document_name": "_qdrant_fastembed_9-integration-with-qdrant",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_filename": "_qdrant_fastembed_9-integration-with-qdrant.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_9-integration-with-qdrant.md",
      "hierarchy_path": "Conclusion",
      "chunk_hash": "ea16ebbb77f64116",
      "content_digest": "ea16ebbb77f64116",
      "chunk_length": 629,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "and",
          "qdrant",
          "search",
          "embedding",
          "models",
          "examples",
          "vector",
          "applications",
          "for",
          "see",
          "supported",
          "usage",
          "refresh",
          "conclusion",
          "the",
          "integration",
          "between",
          "provides",
          "seamless"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 4,
            "weight": 0.054795
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.054795
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.054795
          },
          {
            "term": "search",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "embedding",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "examples",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "applications",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "see",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "supported",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "usage",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "refresh",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "conclusion",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "between",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "seamless",
            "tf": 1,
            "weight": 0.013699
          }
        ],
        "unique_terms": 49,
        "total_terms": 73
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Conclusion",
        "and",
        "applications",
        "embedding",
        "examples",
        "fastembed",
        "for",
        "models",
        "qdrant",
        "search",
        "vector"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7,
      "retrieval_quality": 0.7406849315068492,
      "overall": 0.7468949771689498
    }
  }
]
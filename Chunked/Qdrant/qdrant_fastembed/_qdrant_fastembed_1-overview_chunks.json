[
  {
    "text": "# Overview  Relevant source files  - [.pre-commit-config.yaml](https://github.com/qdrant/fastembed/blob/b785640b/.pre-commit-config.yaml) - [README.md](https://github.com/qdrant/fastembed/blob/b785640b/README.md) - [docs/examples/FastEmbed\\_GPU.ipynb](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_GPU.ipynb) - [fastembed/\\_\\_init\\_\\_.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/__init__.py) - [pyproject.toml](https://github.com/qdrant/fastembed/blob/b785640b/pyproject.toml) - [tests/test\\_late\\_interaction\\_multimodal.py](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_late_interaction_multimodal.py)  FastEmbed is a lightweight, fast Python library designed for generating high-quality embeddings from text and images. It focuses on performance optimization through ONNX Runtime integration, providing a more efficient alternative to traditional embedding libraries like PyTorch-based Sentence Transformers. This overview introduces the core concepts, architecture, and components of FastEmbed. For installation instructions, see [Installation and Setup](qdrant/fastembed/2-installation-and-setup.md). Sources: [README.md1-14](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L1-L14) [pyproject.toml1-12](https://github.com/qdrant/fastembed/blob/b785640b/pyproject.toml#L1-L12)",
    "metadata": {
      "chunk_id": "d77e2f23fbb6-0000",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "filename": "_qdrant_fastembed_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Overview"
      ],
      "heading_text": "Overview",
      "token_count": 344,
      "char_count": 1355,
      "start_char": 2261,
      "end_char": 3616,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7637263157894736,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.253257",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 344,
      "document_id": "d77e2f23fbb6",
      "document_name": "_qdrant_fastembed_1-overview",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "source_filename": "_qdrant_fastembed_1-overview.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "hierarchy_path": "Overview",
      "chunk_hash": "514ff38cbed4e716",
      "content_digest": "514ff38cbed4e716",
      "chunk_length": 1355,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "qdrant",
          "https",
          "github",
          "com",
          "blob",
          "b785640b",
          "readme",
          "pyproject",
          "and",
          "toml",
          "installation",
          "overview",
          "pre",
          "commit",
          "config",
          "yaml",
          "docs",
          "examples",
          "gpu"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 15,
            "weight": 0.091463
          },
          {
            "term": "qdrant",
            "tf": 9,
            "weight": 0.054878
          },
          {
            "term": "https",
            "tf": 8,
            "weight": 0.04878
          },
          {
            "term": "github",
            "tf": 8,
            "weight": 0.04878
          },
          {
            "term": "com",
            "tf": 8,
            "weight": 0.04878
          },
          {
            "term": "blob",
            "tf": 8,
            "weight": 0.04878
          },
          {
            "term": "b785640b",
            "tf": 8,
            "weight": 0.04878
          },
          {
            "term": "readme",
            "tf": 4,
            "weight": 0.02439
          },
          {
            "term": "pyproject",
            "tf": 4,
            "weight": 0.02439
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.02439
          },
          {
            "term": "toml",
            "tf": 3,
            "weight": 0.018293
          },
          {
            "term": "installation",
            "tf": 3,
            "weight": 0.018293
          },
          {
            "term": "overview",
            "tf": 2,
            "weight": 0.012195
          },
          {
            "term": "pre",
            "tf": 2,
            "weight": 0.012195
          },
          {
            "term": "commit",
            "tf": 2,
            "weight": 0.012195
          },
          {
            "term": "config",
            "tf": 2,
            "weight": 0.012195
          },
          {
            "term": "yaml",
            "tf": 2,
            "weight": 0.012195
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.012195
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.012195
          },
          {
            "term": "gpu",
            "tf": 2,
            "weight": 0.012195
          }
        ],
        "unique_terms": 77,
        "total_terms": 164
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Overview",
        "and",
        "b785640b",
        "blob",
        "com",
        "fastembed",
        "github",
        "https",
        "pyproject",
        "qdrant",
        "readme"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7637263157894736,
      "overall": 0.7545754385964912
    }
  },
  {
    "text": "## Core Features\n\nFastEmbed offers several key advantages over other embedding libraries:\n\n1. **Lightweight**: Minimal external dependencies, making it suitable for resource-constrained environments like serverless functions\n\n2. **Fast**: ONNX Runtime integration and data parallelism for efficient embedding generation, providing significant performance gains over PyTorch-based alternatives\n\n3. **Accurate**: Support for state-of-the-art embedding models that deliver performance comparable to or better than commercial options like OpenAI's Ada-002\n\n4. **Versatile**: Support for multiple embedding strategies including dense, sparse, late interaction, and multimodal approaches\n\n5. **GPU Acceleration**: Optional GPU support through the `fastembed-gpu` package\n\nSources: [README.md7-14](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L7-L14) [pyproject.toml13-34](https://github.com/qdrant/fastembed/blob/b785640b/pyproject.toml#L13-L34) [docs/examples/FastEmbed\\_GPU.ipynb9-21](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_GPU.ipynb#L9-L21)",
    "metadata": {
      "chunk_id": "d77e2f23fbb6-0001",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "filename": "_qdrant_fastembed_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Core Features"
      ],
      "heading_text": "Core Features",
      "token_count": 252,
      "char_count": 1087,
      "start_char": 3620,
      "end_char": 4707,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7517021276595744,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.254593",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 252,
      "document_id": "d77e2f23fbb6",
      "document_name": "_qdrant_fastembed_1-overview",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "source_filename": "_qdrant_fastembed_1-overview.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "hierarchy_path": "Core Features",
      "chunk_hash": "56cd5d3dc597aa0d",
      "content_digest": "56cd5d3dc597aa0d",
      "chunk_length": 1087,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "gpu",
          "embedding",
          "for",
          "support",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "over",
          "like",
          "and",
          "performance",
          "the",
          "readme",
          "pyproject",
          "docs",
          "examples"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 7,
            "weight": 0.053846
          },
          {
            "term": "gpu",
            "tf": 5,
            "weight": 0.038462
          },
          {
            "term": "embedding",
            "tf": 4,
            "weight": 0.030769
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.030769
          },
          {
            "term": "support",
            "tf": 3,
            "weight": 0.023077
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.023077
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.023077
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.023077
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.023077
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.023077
          },
          {
            "term": "b785640b",
            "tf": 3,
            "weight": 0.023077
          },
          {
            "term": "over",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "like",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "performance",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "readme",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "pyproject",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.015385
          }
        ],
        "unique_terms": 91,
        "total_terms": 130
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Core Features",
        "blob",
        "com",
        "embedding",
        "fastembed",
        "for",
        "github",
        "gpu",
        "https",
        "qdrant",
        "support"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7517021276595744,
      "overall": 0.7172340425531915
    }
  },
  {
    "text": "## System Architecture\n\nFastEmbed is organized around a modular architecture with specialized classes for different embedding approaches and modalities.",
    "metadata": {
      "chunk_id": "d77e2f23fbb6-0002",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "filename": "_qdrant_fastembed_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "System Architecture"
      ],
      "heading_text": "System Architecture",
      "token_count": 23,
      "char_count": 152,
      "start_char": 4709,
      "end_char": 4861,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5742105263157895,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.254865",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 23,
      "document_id": "d77e2f23fbb6",
      "document_name": "_qdrant_fastembed_1-overview",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "source_filename": "_qdrant_fastembed_1-overview.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "hierarchy_path": "System Architecture",
      "chunk_hash": "32a43de0b6ad6e6d",
      "content_digest": "32a43de0b6ad6e6d",
      "chunk_length": 152,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "architecture",
          "system",
          "fastembed",
          "organized",
          "around",
          "modular",
          "with",
          "specialized",
          "classes",
          "for",
          "different",
          "embedding",
          "approaches",
          "and",
          "modalities"
        ],
        "term_weights": [
          {
            "term": "architecture",
            "tf": 2,
            "weight": 0.125
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "organized",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "around",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "modular",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "specialized",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "classes",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "approaches",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "modalities",
            "tf": 1,
            "weight": 0.0625
          }
        ],
        "unique_terms": 15,
        "total_terms": 16
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "System Architecture",
        "architecture",
        "around",
        "classes",
        "fastembed",
        "for",
        "modular",
        "organized",
        "specialized",
        "system",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5742105263157895,
      "overall": 0.7580701754385964
    }
  },
  {
    "text": "### Embedding Process Flow ``` ``` Sources: [README.md28-190](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L28-L190)",
    "metadata": {
      "chunk_id": "d77e2f23fbb6-0004",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "filename": "_qdrant_fastembed_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Embedding Process Flow"
      ],
      "heading_text": "Embedding Process Flow",
      "token_count": 39,
      "char_count": 131,
      "start_char": 5023,
      "end_char": 5154,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.256595",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 39,
      "document_id": "d77e2f23fbb6",
      "document_name": "_qdrant_fastembed_1-overview",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "source_filename": "_qdrant_fastembed_1-overview.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "hierarchy_path": "Embedding Process Flow",
      "chunk_hash": "97e31183b57753f8",
      "content_digest": "97e31183b57753f8",
      "chunk_length": 131,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "readme",
          "embedding",
          "process",
          "flow",
          "sources",
          "md28",
          "190",
          "https",
          "github",
          "com",
          "qdrant",
          "fastembed",
          "blob",
          "b785640b",
          "l28",
          "l190"
        ],
        "term_weights": [
          {
            "term": "readme",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "flow",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "md28",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "190",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "github",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "com",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "blob",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "b785640b",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "l28",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "l190",
            "tf": 1,
            "weight": 0.058824
          }
        ],
        "unique_terms": 16,
        "total_terms": 17
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "190",
        "Embedding Process Flow",
        "com",
        "embedding",
        "flow",
        "github",
        "https",
        "md28",
        "process",
        "readme",
        "sources"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "overall": 0.6841666666666667
    }
  },
  {
    "text": "### Text Embeddings  The `TextEmbedding` class is the most commonly used component, providing dense vector representations for text: ``` ``` Key features:  - Default model is \"BAAI/bge-small-en-v1.5\", a performant English embedding model - Automatic model downloading and caching - Parallel processing for large batches of documents - Optional GPU acceleration with the `fastembed-gpu` package  Sources: [README.md28-47](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L28-L47)",
    "metadata": {
      "chunk_id": "d77e2f23fbb6-0006",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "filename": "_qdrant_fastembed_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Text Embeddings"
      ],
      "heading_text": "Text Embeddings",
      "token_count": 115,
      "char_count": 489,
      "start_char": 6704,
      "end_char": 7193,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5364285714285714,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.261368",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 115,
      "document_id": "d77e2f23fbb6",
      "document_name": "_qdrant_fastembed_1-overview",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "source_filename": "_qdrant_fastembed_1-overview.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "hierarchy_path": "Text Embeddings",
      "chunk_hash": "9fd8643448199169",
      "content_digest": "9fd8643448199169",
      "chunk_length": 489,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "model",
          "text",
          "for",
          "gpu",
          "fastembed",
          "readme",
          "embeddings",
          "textembedding",
          "class",
          "most",
          "commonly",
          "used",
          "component",
          "providing",
          "dense",
          "vector",
          "representations",
          "key",
          "features"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 3,
            "weight": 0.050847
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.050847
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "gpu",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "readme",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "textembedding",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "most",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "commonly",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "used",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "component",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "providing",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "dense",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "representations",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "features",
            "tf": 1,
            "weight": 0.016949
          }
        ],
        "unique_terms": 50,
        "total_terms": 59
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Text Embeddings",
        "class",
        "embeddings",
        "fastembed",
        "for",
        "gpu",
        "model",
        "readme",
        "text",
        "textembedding",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5364285714285714,
      "overall": 0.7121428571428571
    }
  },
  {
    "text": "### Late Interaction Models  The `LateInteractionTextEmbedding` class implements ColBERT-style embeddings with token-level representations: ``` ``` These models produce a matrix of embeddings per document (one vector per token), enabling more sophisticated matching during retrieval. Sources: [README.md119-136](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L119-L136)",
    "metadata": {
      "chunk_id": "d77e2f23fbb6-0008",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "filename": "_qdrant_fastembed_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Late Interaction Models"
      ],
      "heading_text": "Late Interaction Models",
      "token_count": 80,
      "char_count": 382,
      "start_char": 7549,
      "end_char": 7931,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.265150",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 80,
      "document_id": "d77e2f23fbb6",
      "document_name": "_qdrant_fastembed_1-overview",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "source_filename": "_qdrant_fastembed_1-overview.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "hierarchy_path": "Late Interaction Models",
      "chunk_hash": "1a7ef5569eadd84c",
      "content_digest": "1a7ef5569eadd84c",
      "chunk_length": 382,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "models",
          "embeddings",
          "token",
          "per",
          "readme",
          "late",
          "interaction",
          "the",
          "lateinteractiontextembedding",
          "class",
          "implements",
          "colbert",
          "style",
          "with",
          "level",
          "representations",
          "these",
          "produce",
          "matrix",
          "document"
        ],
        "term_weights": [
          {
            "term": "models",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "token",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "per",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "readme",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "late",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "interaction",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "lateinteractiontextembedding",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "implements",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "colbert",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "style",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "level",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "representations",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "these",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "produce",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "matrix",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.022222
          }
        ],
        "unique_terms": 40,
        "total_terms": 45
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Late Interaction Models",
        "class",
        "embeddings",
        "interaction",
        "late",
        "lateinteractiontextembedding",
        "models",
        "per",
        "readme",
        "the",
        "token"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "overall": 0.7188888888888888
    }
  },
  {
    "text": "## Performance Optimization  FastEmbed focuses on performance through several key optimizations:  1. **ONNX Runtime**: Uses ONNX models for efficient inference without requiring PyTorch/TensorFlow 2. **Parallel Processing**: Automatically distributes embedding generation across CPU cores 3. **GPU Acceleration**: Optional GPU support through `fastembed-gpu` package 4. **Model Caching**: Automatic downloading and caching of models 5. **Batching**: Efficient batching of inputs for optimized throughput  A simple benchmark comparing CPU vs GPU performance shows orders of magnitude improvement: ``` CPU execution time: 4.33s (500 documents) GPU execution time: 43.4ms (500 documents) ``` Sources: [docs/examples/FastEmbed\\_GPU.ipynb390-511](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_GPU.ipynb#L390-L511)",
    "metadata": {
      "chunk_id": "d77e2f23fbb6-0012",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "filename": "_qdrant_fastembed_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Optimization"
      ],
      "heading_text": "Performance Optimization",
      "token_count": 188,
      "char_count": 836,
      "start_char": 8996,
      "end_char": 9832,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7326966292134831,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.274806",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 188,
      "document_id": "d77e2f23fbb6",
      "document_name": "_qdrant_fastembed_1-overview",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "source_filename": "_qdrant_fastembed_1-overview.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "hierarchy_path": "Performance Optimization",
      "chunk_hash": "9b57f07608c9728f",
      "content_digest": "9b57f07608c9728f",
      "chunk_length": 836,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "gpu",
          "fastembed",
          "performance",
          "cpu",
          "through",
          "onnx",
          "models",
          "for",
          "efficient",
          "caching",
          "batching",
          "execution",
          "time",
          "500",
          "documents",
          "docs",
          "examples",
          "optimization",
          "focuses",
          "several"
        ],
        "term_weights": [
          {
            "term": "gpu",
            "tf": 7,
            "weight": 0.072917
          },
          {
            "term": "fastembed",
            "tf": 5,
            "weight": 0.052083
          },
          {
            "term": "performance",
            "tf": 3,
            "weight": 0.03125
          },
          {
            "term": "cpu",
            "tf": 3,
            "weight": 0.03125
          },
          {
            "term": "through",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "onnx",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "efficient",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "caching",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "batching",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "execution",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "time",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "500",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "documents",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.020833
          },
          {
            "term": "optimization",
            "tf": 1,
            "weight": 0.010417
          },
          {
            "term": "focuses",
            "tf": 1,
            "weight": 0.010417
          },
          {
            "term": "several",
            "tf": 1,
            "weight": 0.010417
          }
        ],
        "unique_terms": 69,
        "total_terms": 96
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Optimization",
        "caching",
        "cpu",
        "efficient",
        "fastembed",
        "for",
        "gpu",
        "models",
        "onnx",
        "performance",
        "through"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7326966292134831,
      "overall": 0.777565543071161
    }
  },
  {
    "text": "## Supported Models\n\nFastEmbed supports a wide range of embedding models:\n\n1. **Dense Text Models**: BGE embeddings, Sentence Transformers, CLIP text models\n2. **Sparse Text Models**: SPLADE, BM25, BM42\n3. **Late Interaction Models**: ColBERT, Jina ColBERT\n4. **Image Models**: CLIP vision models\n5. **Multimodal Models**: ColPali\n\nFor a complete list of supported models and their configuration details, see [Supported Models](qdrant/fastembed/6-supported-models.md).\n\nThe library also supports extending with custom models through API methods like `TextEmbedding.add_custom_model()`.\n\nSources: [README.md66-82](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L66-L82) [README.md196-207](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L196-L207)\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh",
    "metadata": {
      "chunk_id": "d77e2f23fbb6-0014",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "filename": "_qdrant_fastembed_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Supported Models"
      ],
      "heading_text": "Supported Models",
      "token_count": 210,
      "char_count": 823,
      "start_char": 10196,
      "end_char": 11019,
      "semantic_score": 0.6,
      "structural_score": 0.7,
      "retrieval_quality": 0.5328571428571428,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:41.277709",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 210,
      "document_id": "d77e2f23fbb6",
      "document_name": "_qdrant_fastembed_1-overview",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "source_filename": "_qdrant_fastembed_1-overview.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_1-overview.md",
      "hierarchy_path": "Supported Models",
      "chunk_hash": "a85ce8478c673089",
      "content_digest": "a85ce8478c673089",
      "chunk_length": 823,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "models",
          "supported",
          "fastembed",
          "readme",
          "text",
          "qdrant",
          "supports",
          "clip",
          "colbert",
          "custom",
          "https",
          "github",
          "com",
          "blob",
          "b785640b",
          "refresh",
          "wide",
          "range",
          "embedding",
          "dense"
        ],
        "term_weights": [
          {
            "term": "models",
            "tf": 13,
            "weight": 0.126214
          },
          {
            "term": "supported",
            "tf": 4,
            "weight": 0.038835
          },
          {
            "term": "fastembed",
            "tf": 4,
            "weight": 0.038835
          },
          {
            "term": "readme",
            "tf": 4,
            "weight": 0.038835
          },
          {
            "term": "text",
            "tf": 3,
            "weight": 0.029126
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.029126
          },
          {
            "term": "supports",
            "tf": 2,
            "weight": 0.019417
          },
          {
            "term": "clip",
            "tf": 2,
            "weight": 0.019417
          },
          {
            "term": "colbert",
            "tf": 2,
            "weight": 0.019417
          },
          {
            "term": "custom",
            "tf": 2,
            "weight": 0.019417
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.019417
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.019417
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.019417
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.019417
          },
          {
            "term": "b785640b",
            "tf": 2,
            "weight": 0.019417
          },
          {
            "term": "refresh",
            "tf": 2,
            "weight": 0.019417
          },
          {
            "term": "wide",
            "tf": 1,
            "weight": 0.009709
          },
          {
            "term": "range",
            "tf": 1,
            "weight": 0.009709
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.009709
          },
          {
            "term": "dense",
            "tf": 1,
            "weight": 0.009709
          }
        ],
        "unique_terms": 68,
        "total_terms": 103
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Supported Models",
        "clip",
        "colbert",
        "custom",
        "fastembed",
        "models",
        "qdrant",
        "readme",
        "supported",
        "supports",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7,
      "retrieval_quality": 0.5328571428571428,
      "overall": 0.6109523809523809
    }
  }
]
[
  {
    "text": "## Implementation Architecture Overview  FastEmbed uses a consistent implementation pattern across all embedding types, with specialized classes extending base classes that provide common functionality. The implementation is designed around ONNX Runtime for optimized inference. ``` ``` Sources: [fastembed/text/pooled\\_embedding.py93-120](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_embedding.py#L93-L120) [fastembed/text/pooled\\_normalized\\_embedding.py127-147](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_normalized_embedding.py#L127-L147) [fastembed/text/clip\\_embedding.py24-39](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/clip_embedding.py#L24-L39) [fastembed/sparse/splade\\_pp.py36-52](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/splade_pp.py#L36-L52) [fastembed/late\\_interaction/colbert.py39-65](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction/colbert.py#L39-L65)",
    "metadata": {
      "chunk_id": "9fdd22547e8a-0001",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "filename": "_qdrant_fastembed_5-implementation-details.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Implementation Architecture Overview"
      ],
      "heading_text": "Implementation Architecture Overview",
      "token_count": 255,
      "char_count": 1001,
      "start_char": 3518,
      "end_char": 4519,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5614285714285714,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.251202",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 255,
      "document_id": "9fdd22547e8a",
      "document_name": "_qdrant_fastembed_5-implementation-details",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "source_filename": "_qdrant_fastembed_5-implementation-details.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "hierarchy_path": "Implementation Architecture Overview",
      "chunk_hash": "19f7a5ca63fa0842",
      "content_digest": "19f7a5ca63fa0842",
      "chunk_length": 1001,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "embedding",
          "text",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "pooled",
          "implementation",
          "classes",
          "normalized",
          "clip",
          "l39",
          "sparse",
          "splade",
          "late",
          "interaction",
          "colbert"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 16,
            "weight": 0.129032
          },
          {
            "term": "embedding",
            "tf": 7,
            "weight": 0.056452
          },
          {
            "term": "text",
            "tf": 6,
            "weight": 0.048387
          },
          {
            "term": "https",
            "tf": 5,
            "weight": 0.040323
          },
          {
            "term": "github",
            "tf": 5,
            "weight": 0.040323
          },
          {
            "term": "com",
            "tf": 5,
            "weight": 0.040323
          },
          {
            "term": "qdrant",
            "tf": 5,
            "weight": 0.040323
          },
          {
            "term": "blob",
            "tf": 5,
            "weight": 0.040323
          },
          {
            "term": "b785640b",
            "tf": 5,
            "weight": 0.040323
          },
          {
            "term": "pooled",
            "tf": 4,
            "weight": 0.032258
          },
          {
            "term": "implementation",
            "tf": 3,
            "weight": 0.024194
          },
          {
            "term": "classes",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "normalized",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "clip",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "l39",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "splade",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "late",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "interaction",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "colbert",
            "tf": 2,
            "weight": 0.016129
          }
        ],
        "unique_terms": 60,
        "total_terms": 124
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Implementation Architecture Overview",
        "b785640b",
        "blob",
        "com",
        "embedding",
        "fastembed",
        "github",
        "https",
        "pooled",
        "qdrant",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5614285714285714,
      "overall": 0.6871428571428572
    }
  },
  {
    "text": "## Embedding Processing Flow  All embedding types follow a general embedding process flow, with variations in their pre-processing and post-processing steps: ``` ``` Sources: [fastembed/text/pooled\\_embedding.py113-119](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_embedding.py#L113-L119) [fastembed/text/pooled\\_normalized\\_embedding.py141-147](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_normalized_embedding.py#L141-L147) [fastembed/sparse/splade\\_pp.py37-52](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/splade_pp.py#L37-L52) [fastembed/late\\_interaction/colbert.py45-65](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction/colbert.py#L45-L65)",
    "metadata": {
      "chunk_id": "9fdd22547e8a-0002",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "filename": "_qdrant_fastembed_5-implementation-details.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Embedding Processing Flow"
      ],
      "heading_text": "Embedding Processing Flow",
      "token_count": 202,
      "char_count": 749,
      "start_char": 4523,
      "end_char": 5272,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7578571428571429,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.252463",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 202,
      "document_id": "9fdd22547e8a",
      "document_name": "_qdrant_fastembed_5-implementation-details",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "source_filename": "_qdrant_fastembed_5-implementation-details.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "hierarchy_path": "Embedding Processing Flow",
      "chunk_hash": "a8ea833aba50a1ec",
      "content_digest": "a8ea833aba50a1ec",
      "chunk_length": 749,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "embedding",
          "text",
          "pooled",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "processing",
          "flow",
          "normalized",
          "sparse",
          "splade",
          "late",
          "interaction",
          "colbert",
          "all",
          "types"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 12,
            "weight": 0.126316
          },
          {
            "term": "embedding",
            "tf": 7,
            "weight": 0.073684
          },
          {
            "term": "text",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "pooled",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "github",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "blob",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "b785640b",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "processing",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "flow",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "normalized",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "splade",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "late",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "interaction",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "colbert",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.010526
          },
          {
            "term": "types",
            "tf": 1,
            "weight": 0.010526
          }
        ],
        "unique_terms": 45,
        "total_terms": 95
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Embedding Processing Flow",
        "b785640b",
        "blob",
        "com",
        "embedding",
        "fastembed",
        "github",
        "https",
        "pooled",
        "qdrant",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7578571428571429,
      "overall": 0.7526190476190476
    }
  },
  {
    "text": "### Pooled Normalized Embedding  The `PooledNormalizedEmbedding` class extends `PooledEmbedding` with an additional normalization step:  1. Perform mean pooling as in the base class 2. Apply L2 normalization to the resulting embeddings  This implementation is particularly useful for models where cosine similarity is the preferred distance metric. Sources: [fastembed/text/pooled\\_normalized\\_embedding.py127-147](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_normalized_embedding.py#L127-L147)",
    "metadata": {
      "chunk_id": "9fdd22547e8a-0005",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "filename": "_qdrant_fastembed_5-implementation-details.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Pooled Normalized Embedding"
      ],
      "heading_text": "Pooled Normalized Embedding",
      "token_count": 115,
      "char_count": 521,
      "start_char": 5846,
      "end_char": 6367,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.255393",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 115,
      "document_id": "9fdd22547e8a",
      "document_name": "_qdrant_fastembed_5-implementation-details",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "source_filename": "_qdrant_fastembed_5-implementation-details.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "hierarchy_path": "Pooled Normalized Embedding",
      "chunk_hash": "bd3cbe498ff6b706",
      "content_digest": "bd3cbe498ff6b706",
      "chunk_length": 521,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "pooled",
          "normalized",
          "embedding",
          "fastembed",
          "class",
          "normalization",
          "text",
          "poolednormalizedembedding",
          "extends",
          "pooledembedding",
          "with",
          "additional",
          "step",
          "perform",
          "mean",
          "pooling",
          "base",
          "apply",
          "resulting"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "pooled",
            "tf": 3,
            "weight": 0.051724
          },
          {
            "term": "normalized",
            "tf": 3,
            "weight": 0.051724
          },
          {
            "term": "embedding",
            "tf": 3,
            "weight": 0.051724
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.051724
          },
          {
            "term": "class",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "normalization",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "poolednormalizedembedding",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "extends",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "pooledembedding",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "additional",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "step",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "perform",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "mean",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "pooling",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "base",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "apply",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "resulting",
            "tf": 1,
            "weight": 0.017241
          }
        ],
        "unique_terms": 44,
        "total_terms": 58
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Pooled Normalized Embedding",
        "class",
        "embedding",
        "extends",
        "fastembed",
        "normalization",
        "normalized",
        "pooled",
        "poolednormalizedembedding",
        "text",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "overall": 0.7174999999999999
    }
  },
  {
    "text": "### SPLADE++ Implementation  The `SpladePP` class implements the SPLADE++ algorithm for sparse embeddings:  1. Tokenize input text and run ONNX model 2. Apply ReLU and log transformation to output scores 3. Apply attention mask to handle variable-length inputs 4. Take maximum value for each vocabulary term across all tokens 5. Extract non-zero values and indices as sparse embedding ``` ``` The resulting sparse embeddings contain only non-zero values and their corresponding indices, significantly reducing memory requirements. Sources: [fastembed/sparse/splade\\_pp.py37-52](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/splade_pp.py#L37-L52)",
    "metadata": {
      "chunk_id": "9fdd22547e8a-0007",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "filename": "_qdrant_fastembed_5-implementation-details.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "SPLADE++ Implementation"
      ],
      "heading_text": "SPLADE++ Implementation",
      "token_count": 151,
      "char_count": 666,
      "start_char": 6397,
      "end_char": 7063,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5361538461538461,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.257227",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 151,
      "document_id": "9fdd22547e8a",
      "document_name": "_qdrant_fastembed_5-implementation-details",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "source_filename": "_qdrant_fastembed_5-implementation-details.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "hierarchy_path": "SPLADE++ Implementation",
      "chunk_hash": "250026e94b11356a",
      "content_digest": "250026e94b11356a",
      "chunk_length": 666,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparse",
          "splade",
          "and",
          "the",
          "fastembed",
          "for",
          "embeddings",
          "apply",
          "non",
          "zero",
          "values",
          "indices",
          "implementation",
          "spladepp",
          "class",
          "implements",
          "algorithm",
          "tokenize",
          "input",
          "text"
        ],
        "term_weights": [
          {
            "term": "sparse",
            "tf": 5,
            "weight": 0.058824
          },
          {
            "term": "splade",
            "tf": 4,
            "weight": 0.047059
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.047059
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "apply",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "non",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "zero",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "values",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "indices",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "spladepp",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "implements",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "algorithm",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "tokenize",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "input",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "text",
            "tf": 1,
            "weight": 0.011765
          }
        ],
        "unique_terms": 64,
        "total_terms": 85
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "SPLADE++ Implementation",
        "and",
        "apply",
        "embeddings",
        "fastembed",
        "for",
        "non",
        "sparse",
        "splade",
        "the",
        "zero"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5361538461538461,
      "overall": 0.712051282051282
    }
  },
  {
    "text": "## Late Interaction Models",
    "metadata": {
      "chunk_id": "9fdd22547e8a-0008",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "filename": "_qdrant_fastembed_5-implementation-details.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Late Interaction Models"
      ],
      "heading_text": "Late Interaction Models",
      "token_count": 4,
      "char_count": 26,
      "start_char": 7068,
      "end_char": 7094,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.257465",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 4,
      "document_id": "9fdd22547e8a",
      "document_name": "_qdrant_fastembed_5-implementation-details",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "source_filename": "_qdrant_fastembed_5-implementation-details.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "hierarchy_path": "Late Interaction Models",
      "chunk_hash": "ada5c3f274c56e31",
      "content_digest": "ada5c3f274c56e31",
      "chunk_length": 26,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "late",
          "interaction",
          "models"
        ],
        "term_weights": [
          {
            "term": "late",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "interaction",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.333333
          }
        ],
        "unique_terms": 3,
        "total_terms": 3
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Late Interaction Models",
        "interaction",
        "late",
        "models"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "## Implementation Optimizations",
    "metadata": {
      "chunk_id": "9fdd22547e8a-0010",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "filename": "_qdrant_fastembed_5-implementation-details.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Implementation Optimizations"
      ],
      "heading_text": "Implementation Optimizations",
      "token_count": 4,
      "char_count": 31,
      "start_char": 7971,
      "end_char": 8002,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.259781",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 4,
      "document_id": "9fdd22547e8a",
      "document_name": "_qdrant_fastembed_5-implementation-details",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "source_filename": "_qdrant_fastembed_5-implementation-details.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "hierarchy_path": "Implementation Optimizations",
      "chunk_hash": "5b786a75f185f7c0",
      "content_digest": "5b786a75f185f7c0",
      "chunk_length": 31,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "implementation",
          "optimizations"
        ],
        "term_weights": [
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "optimizations",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Implementation Optimizations",
        "implementation",
        "optimizations"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### ONNX Runtime Integration  All embeddings in FastEmbed leverage ONNX Runtime for optimized inference:  - Models are exported and optimized for the ONNX format - Support for CPU and GPU acceleration - Optimized operator fusion and graph optimization",
    "metadata": {
      "chunk_id": "9fdd22547e8a-0011",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "filename": "_qdrant_fastembed_5-implementation-details.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ONNX Runtime Integration"
      ],
      "heading_text": "ONNX Runtime Integration",
      "token_count": 46,
      "char_count": 251,
      "start_char": 8004,
      "end_char": 8255,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5031578947368421,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.259936",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 46,
      "document_id": "9fdd22547e8a",
      "document_name": "_qdrant_fastembed_5-implementation-details",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "source_filename": "_qdrant_fastembed_5-implementation-details.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "hierarchy_path": "ONNX Runtime Integration",
      "chunk_hash": "416c8452aca26d2c",
      "content_digest": "416c8452aca26d2c",
      "chunk_length": 251,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "onnx",
          "for",
          "optimized",
          "and",
          "runtime",
          "integration",
          "all",
          "embeddings",
          "fastembed",
          "leverage",
          "inference",
          "models",
          "are",
          "exported",
          "the",
          "format",
          "support",
          "cpu",
          "gpu",
          "acceleration"
        ],
        "term_weights": [
          {
            "term": "onnx",
            "tf": 3,
            "weight": 0.090909
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.090909
          },
          {
            "term": "optimized",
            "tf": 3,
            "weight": 0.090909
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.090909
          },
          {
            "term": "runtime",
            "tf": 2,
            "weight": 0.060606
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "leverage",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "exported",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "format",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "cpu",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "gpu",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "acceleration",
            "tf": 1,
            "weight": 0.030303
          }
        ],
        "unique_terms": 24,
        "total_terms": 33
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ONNX Runtime Integration",
        "all",
        "and",
        "embeddings",
        "fastembed",
        "for",
        "integration",
        "leverage",
        "onnx",
        "optimized",
        "runtime"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5031578947368421,
      "overall": 0.7343859649122807
    }
  },
  {
    "text": "### Parallel Processing  FastEmbed implements efficient parallel processing:  - Worker processes handle subsets of data in parallel - Each implementation has its worker class (e.g., `PooledEmbeddingWorker`, `SpladePPEmbeddingWorker`, `ColbertEmbeddingWorker`) - Workers can be distributed across multiple GPUs ``` ``` Sources: [fastembed/text/pooled\\_embedding.py122-134](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_embedding.py#L122-L134) [fastembed/sparse/splade\\_pp.py169-181](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/splade_pp.py#L169-L181) [fastembed/late\\_interaction/colbert.py252-263](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction/colbert.py#L252-L263)",
    "metadata": {
      "chunk_id": "9fdd22547e8a-0012",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "filename": "_qdrant_fastembed_5-implementation-details.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Parallel Processing"
      ],
      "heading_text": "Parallel Processing",
      "token_count": 196,
      "char_count": 745,
      "start_char": 8257,
      "end_char": 9002,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5471428571428572,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.261250",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 196,
      "document_id": "9fdd22547e8a",
      "document_name": "_qdrant_fastembed_5-implementation-details",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "source_filename": "_qdrant_fastembed_5-implementation-details.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "hierarchy_path": "Parallel Processing",
      "chunk_hash": "5621259c201919e6",
      "content_digest": "5621259c201919e6",
      "chunk_length": 745,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "parallel",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "processing",
          "worker",
          "text",
          "pooled",
          "embedding",
          "sparse",
          "splade",
          "late",
          "interaction",
          "colbert",
          "implements",
          "efficient"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "parallel",
            "tf": 3,
            "weight": 0.035714
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.035714
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.035714
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.035714
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.035714
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.035714
          },
          {
            "term": "b785640b",
            "tf": 3,
            "weight": 0.035714
          },
          {
            "term": "processing",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "worker",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "pooled",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "splade",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "late",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "interaction",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "colbert",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "implements",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "efficient",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 51,
        "total_terms": 84
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Parallel Processing",
        "b785640b",
        "blob",
        "com",
        "fastembed",
        "github",
        "https",
        "parallel",
        "processing",
        "qdrant",
        "worker"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5471428571428572,
      "overall": 0.7157142857142856
    }
  },
  {
    "text": "### Lazy Loading  Models can be lazily loaded to optimize resource usage:  1. Models are only loaded when needed for inference 2. Particularly useful in multi-GPU setups where each worker loads its own model copy 3. Controlled via the `lazy_load` parameter in model constructors  This optimization is implemented across all embedding classes through a common pattern: ``` ``` Sources: [fastembed/text/pooled\\_embedding.py122-134](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_embedding.py#L122-L134) [fastembed/sparse/splade\\_pp.py122-133](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/splade_pp.py#L122-L133) [fastembed/late\\_interaction/colbert.py183-204](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction/colbert.py#L183-L204)",
    "metadata": {
      "chunk_id": "9fdd22547e8a-0013",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "filename": "_qdrant_fastembed_5-implementation-details.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Lazy Loading"
      ],
      "heading_text": "Lazy Loading",
      "token_count": 205,
      "char_count": 803,
      "start_char": 9006,
      "end_char": 9809,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5658064516129032,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.263188",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 205,
      "document_id": "9fdd22547e8a",
      "document_name": "_qdrant_fastembed_5-implementation-details",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "source_filename": "_qdrant_fastembed_5-implementation-details.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "hierarchy_path": "Lazy Loading",
      "chunk_hash": "e6cb1da1dd18ddee",
      "content_digest": "e6cb1da1dd18ddee",
      "chunk_length": 803,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "embedding",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "lazy",
          "models",
          "loaded",
          "model",
          "text",
          "pooled",
          "py122",
          "l122",
          "sparse",
          "splade",
          "late",
          "interaction"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 9,
            "weight": 0.086538
          },
          {
            "term": "embedding",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "b785640b",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "lazy",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "loaded",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "pooled",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "py122",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "l122",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "splade",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "late",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "interaction",
            "tf": 2,
            "weight": 0.019231
          }
        ],
        "unique_terms": 69,
        "total_terms": 104
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Lazy Loading",
        "b785640b",
        "blob",
        "com",
        "embedding",
        "fastembed",
        "github",
        "https",
        "lazy",
        "models",
        "qdrant"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5658064516129032,
      "overall": 0.7219354838709676
    }
  },
  {
    "text": "## Model Registration System  FastEmbed uses a registry system to maintain lists of supported models for each embedding type: ``` ``` Each embedding type registers supported models in class variables, along with model metadata such as:  - Embedding dimension - Model description - License information - Model size - Source locations  Sources: [fastembed/sparse/sparse\\_text\\_embedding.py16-68](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/sparse_text_embedding.py#L16-L68) [fastembed/sparse/splade\\_pp.py14-33](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/splade_pp.py#L14-L33) [fastembed/text/pooled\\_embedding.py12-90](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_embedding.py#L12-L90) [fastembed/text/pooled\\_normalized\\_embedding.py11-124](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_normalized_embedding.py#L11-L124) [fastembed/late\\_interaction/colbert.py17-36](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction/colbert.py#L17-L36)",
    "metadata": {
      "chunk_id": "9fdd22547e8a-0014",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "filename": "_qdrant_fastembed_5-implementation-details.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Registration System"
      ],
      "heading_text": "Model Registration System",
      "token_count": 277,
      "char_count": 1063,
      "start_char": 9813,
      "end_char": 10876,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5163157894736842,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.264781",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 277,
      "document_id": "9fdd22547e8a",
      "document_name": "_qdrant_fastembed_5-implementation-details",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "source_filename": "_qdrant_fastembed_5-implementation-details.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "hierarchy_path": "Model Registration System",
      "chunk_hash": "ca212d927b1dfac9",
      "content_digest": "ca212d927b1dfac9",
      "chunk_length": 1063,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "embedding",
          "sparse",
          "text",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "model",
          "pooled",
          "system",
          "supported",
          "models",
          "each",
          "type",
          "splade",
          "normalized",
          "late"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 16,
            "weight": 0.121212
          },
          {
            "term": "embedding",
            "tf": 9,
            "weight": 0.068182
          },
          {
            "term": "sparse",
            "tf": 6,
            "weight": 0.045455
          },
          {
            "term": "text",
            "tf": 6,
            "weight": 0.045455
          },
          {
            "term": "https",
            "tf": 5,
            "weight": 0.037879
          },
          {
            "term": "github",
            "tf": 5,
            "weight": 0.037879
          },
          {
            "term": "com",
            "tf": 5,
            "weight": 0.037879
          },
          {
            "term": "qdrant",
            "tf": 5,
            "weight": 0.037879
          },
          {
            "term": "blob",
            "tf": 5,
            "weight": 0.037879
          },
          {
            "term": "b785640b",
            "tf": 5,
            "weight": 0.037879
          },
          {
            "term": "model",
            "tf": 4,
            "weight": 0.030303
          },
          {
            "term": "pooled",
            "tf": 4,
            "weight": 0.030303
          },
          {
            "term": "system",
            "tf": 2,
            "weight": 0.015152
          },
          {
            "term": "supported",
            "tf": 2,
            "weight": 0.015152
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.015152
          },
          {
            "term": "each",
            "tf": 2,
            "weight": 0.015152
          },
          {
            "term": "type",
            "tf": 2,
            "weight": 0.015152
          },
          {
            "term": "splade",
            "tf": 2,
            "weight": 0.015152
          },
          {
            "term": "normalized",
            "tf": 2,
            "weight": 0.015152
          },
          {
            "term": "late",
            "tf": 2,
            "weight": 0.015152
          }
        ],
        "unique_terms": 59,
        "total_terms": 132
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Registration System",
        "b785640b",
        "blob",
        "com",
        "embedding",
        "fastembed",
        "github",
        "https",
        "qdrant",
        "sparse",
        "text"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5163157894736842,
      "overall": 0.705438596491228
    }
  },
  {
    "text": "## Conclusion\n\nFastEmbed's implementation details showcase a well-designed architecture that balances flexibility, performance, and ease of use. The library provides specialized implementations for different embedding types while maintaining consistent interfaces and optimizations across the board. The use of ONNX Runtime, parallel processing, and other performance optimizations enables FastEmbed to deliver high-performance embedding generation for various applications.\n\nFor specific model support information, see [Supported Models](qdrant/fastembed/6-supported-models.md), and for usage examples, see [Usage Examples](qdrant/fastembed/7-usage-examples.md).\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh",
    "metadata": {
      "chunk_id": "9fdd22547e8a-0015",
      "source_file": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "filename": "_qdrant_fastembed_5-implementation-details.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Conclusion"
      ],
      "heading_text": "Conclusion",
      "token_count": 126,
      "char_count": 715,
      "start_char": 10880,
      "end_char": 11595,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7368354430379748,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:42.265591",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 126,
      "document_id": "9fdd22547e8a",
      "document_name": "_qdrant_fastembed_5-implementation-details",
      "source_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "source_filename": "_qdrant_fastembed_5-implementation-details.md",
      "source_directory": "Docs\\Qdrant\\qdrant_fastembed",
      "relative_path": "Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5-implementation-details.md",
      "hierarchy_path": "Conclusion",
      "chunk_hash": "7620e09ebf0aba88",
      "content_digest": "7620e09ebf0aba88",
      "chunk_length": 715,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "and",
          "for",
          "performance",
          "the",
          "usage",
          "examples",
          "use",
          "embedding",
          "optimizations",
          "see",
          "supported",
          "models",
          "qdrant",
          "refresh",
          "conclusion",
          "implementation",
          "details",
          "showcase",
          "well"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 4,
            "weight": 0.048193
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.048193
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.048193
          },
          {
            "term": "performance",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "usage",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "examples",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "use",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "optimizations",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "see",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "supported",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "refresh",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "conclusion",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "details",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "showcase",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "well",
            "tf": 1,
            "weight": 0.012048
          }
        ],
        "unique_terms": 58,
        "total_terms": 83
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Conclusion",
        "and",
        "embedding",
        "examples",
        "fastembed",
        "for",
        "optimizations",
        "performance",
        "the",
        "usage",
        "use"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7368354430379748,
      "overall": 0.7122784810126582
    }
  }
]
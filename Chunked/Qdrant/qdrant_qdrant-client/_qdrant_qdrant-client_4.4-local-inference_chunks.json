[
  {
    "text": "## Purpose and Scope\n\nThis document describes the Local Inference system in qdrant-client, which enables automatic embedding of documents and images directly within the client application, without requiring an external embedding service. This system allows seamless integration of embedding models into vector search workflows by automatically detecting and processing objects that require inference.\n\nFor information about the FastEmbed integration, which provides pre-configured models, see [FastEmbed Integration](qdrant/qdrant-client/4.1-fastembed-integration.md).",
    "metadata": {
      "chunk_id": "5c7eb506a337-0001",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Purpose and Scope"
      ],
      "heading_text": "Purpose and Scope",
      "token_count": 100,
      "char_count": 568,
      "start_char": 2671,
      "end_char": 3239,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5445454545454546,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.346019",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 100,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Purpose and Scope",
      "chunk_hash": "3c6dfa72a594df1e",
      "content_digest": "3c6dfa72a594df1e",
      "chunk_length": 568,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "integration",
          "and",
          "the",
          "qdrant",
          "client",
          "embedding",
          "fastembed",
          "this",
          "inference",
          "system",
          "which",
          "models",
          "purpose",
          "scope",
          "document",
          "describes",
          "local",
          "enables",
          "automatic",
          "documents"
        ],
        "term_weights": [
          {
            "term": "integration",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "client",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "embedding",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "this",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "system",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "which",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "purpose",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "scope",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "describes",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "local",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "enables",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "automatic",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.014925
          }
        ],
        "unique_terms": 47,
        "total_terms": 67
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Purpose and Scope",
        "and",
        "client",
        "embedding",
        "fastembed",
        "inference",
        "integration",
        "qdrant",
        "system",
        "the",
        "this"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5445454545454546,
      "overall": 0.7481818181818181
    }
  },
  {
    "text": "## Overview  The Local Inference system transparently converts high-level objects like text documents and images into vector embeddings that can be stored and searched in Qdrant. When you provide a `Document` or `Image` object to methods like `upsert()` or `query_points()`, the system automatically:  1. Detects fields requiring embedding 2. Loads the appropriate model 3. Generates embeddings 4. Replaces the original objects with their vector representations  **Local Inference System Architecture** ``` ``` Sources: [qdrant\\_client/embed/model\\_embedder.py42-444](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L42-L444) [qdrant\\_client/embed/embedder.py29-388](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L29-L388) [qdrant\\_client/fastembed\\_common.py36-267](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/fastembed_common.py#L36-L267)",
    "metadata": {
      "chunk_id": "5c7eb506a337-0002",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Overview"
      ],
      "heading_text": "Overview",
      "token_count": 249,
      "char_count": 948,
      "start_char": 3241,
      "end_char": 4189,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.538,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.348343",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 249,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Overview",
      "chunk_hash": "d18d8718e31b47aa",
      "content_digest": "d18d8718e31b47aa",
      "chunk_length": 948,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "the",
          "embed",
          "embedder",
          "system",
          "model",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "local",
          "inference",
          "objects",
          "like",
          "and",
          "vector",
          "embeddings",
          "fastembed"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 13,
            "weight": 0.105691
          },
          {
            "term": "client",
            "tf": 9,
            "weight": 0.073171
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "embedder",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "system",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "ac6f6cd2",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "local",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "objects",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "like",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.01626
          }
        ],
        "unique_terms": 71,
        "total_terms": 123
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Overview",
        "client",
        "com",
        "embed",
        "embedder",
        "github",
        "https",
        "model",
        "qdrant",
        "system",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.538,
      "overall": 0.7126666666666667
    }
  },
  {
    "text": "### ModelEmbedder  The `ModelEmbedder` class is the primary entry point for local inference. It coordinates the inspection, batching, and embedding processes:  **Core Classes and Methods** ``` ``` Sources: [qdrant\\_client/embed/model\\_embedder.py21-444](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L21-L444) [qdrant\\_client/embed/embedder.py23-388](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L23-L388) [qdrant\\_client/fastembed\\_common.py36-267](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/fastembed_common.py#L36-L267)",
    "metadata": {
      "chunk_id": "5c7eb506a337-0004",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ModelEmbedder"
      ],
      "heading_text": "ModelEmbedder",
      "token_count": 185,
      "char_count": 634,
      "start_char": 4213,
      "end_char": 4847,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5512903225806451,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.350297",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 185,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "ModelEmbedder",
      "chunk_hash": "000a2102c8c17266",
      "content_digest": "000a2102c8c17266",
      "chunk_length": 634,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "embed",
          "embedder",
          "the",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "modelembedder",
          "and",
          "model",
          "fastembed",
          "common",
          "class",
          "primary",
          "entry",
          "point",
          "for"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 12,
            "weight": 0.141176
          },
          {
            "term": "client",
            "tf": 9,
            "weight": 0.105882
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.047059
          },
          {
            "term": "embedder",
            "tf": 4,
            "weight": 0.047059
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "ac6f6cd2",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "modelembedder",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "common",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "primary",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "entry",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "point",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011765
          }
        ],
        "unique_terms": 43,
        "total_terms": 85
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ModelEmbedder",
        "ac6f6cd2",
        "blob",
        "client",
        "com",
        "embed",
        "embedder",
        "github",
        "https",
        "qdrant",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5512903225806451,
      "overall": 0.683763440860215
    }
  },
  {
    "text": "### Type Inspection System  The type inspection system identifies fields in models that require inference: ``` ``` Sources: [qdrant\\_client/embed/type\\_inspector.py12-149](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/type_inspector.py#L12-L149) [qdrant\\_client/embed/embed\\_inspector.py13-176](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embed_inspector.py#L13-L176) [qdrant\\_client/embed/schema\\_parser.py29-305](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/schema_parser.py#L29-L305)",
    "metadata": {
      "chunk_id": "5c7eb506a337-0006",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Type Inspection System"
      ],
      "heading_text": "Type Inspection System",
      "token_count": 166,
      "char_count": 573,
      "start_char": 5297,
      "end_char": 5870,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5328571428571428,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.352739",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 166,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Type Inspection System",
      "chunk_hash": "00ac8fffae90de3b",
      "content_digest": "00ac8fffae90de3b",
      "chunk_length": 573,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "embed",
          "type",
          "inspector",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "inspection",
          "system",
          "schema",
          "parser",
          "the",
          "identifies",
          "fields",
          "models",
          "that",
          "require"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 12,
            "weight": 0.15
          },
          {
            "term": "client",
            "tf": 9,
            "weight": 0.1125
          },
          {
            "term": "embed",
            "tf": 8,
            "weight": 0.1
          },
          {
            "term": "type",
            "tf": 4,
            "weight": 0.05
          },
          {
            "term": "inspector",
            "tf": 4,
            "weight": 0.05
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.0375
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.0375
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.0375
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.0375
          },
          {
            "term": "ac6f6cd2",
            "tf": 3,
            "weight": 0.0375
          },
          {
            "term": "inspection",
            "tf": 2,
            "weight": 0.025
          },
          {
            "term": "system",
            "tf": 2,
            "weight": 0.025
          },
          {
            "term": "schema",
            "tf": 2,
            "weight": 0.025
          },
          {
            "term": "parser",
            "tf": 2,
            "weight": 0.025
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.0125
          },
          {
            "term": "identifies",
            "tf": 1,
            "weight": 0.0125
          },
          {
            "term": "fields",
            "tf": 1,
            "weight": 0.0125
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.0125
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.0125
          },
          {
            "term": "require",
            "tf": 1,
            "weight": 0.0125
          }
        ],
        "unique_terms": 34,
        "total_terms": 80
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Type Inspection System",
        "ac6f6cd2",
        "blob",
        "client",
        "com",
        "embed",
        "github",
        "https",
        "inspector",
        "qdrant",
        "type"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5328571428571428,
      "overall": 0.6776190476190477
    }
  },
  {
    "text": "## Inference Workflow  **Local Inference Processing Flow** ``` ``` Sources: [qdrant\\_client/embed/model\\_embedder.py124-156](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L124-L156) [qdrant\\_client/embed/embedder.py222-267](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L222-L267) [tests/embed\\_tests/test\\_local\\_inference.py133-237](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L133-L237)",
    "metadata": {
      "chunk_id": "5c7eb506a337-0007",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Inference Workflow"
      ],
      "heading_text": "Inference Workflow",
      "token_count": 159,
      "char_count": 527,
      "start_char": 5874,
      "end_char": 6401,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5438461538461539,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.353665",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 159,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Inference Workflow",
      "chunk_hash": "38dd9e55c29db896",
      "content_digest": "38dd9e55c29db896",
      "chunk_length": 527,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "embed",
          "inference",
          "embedder",
          "tests",
          "local",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "model",
          "test",
          "workflow",
          "processing",
          "flow",
          "sources",
          "py124",
          "156"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.136986
          },
          {
            "term": "client",
            "tf": 7,
            "weight": 0.09589
          },
          {
            "term": "embed",
            "tf": 6,
            "weight": 0.082192
          },
          {
            "term": "inference",
            "tf": 4,
            "weight": 0.054795
          },
          {
            "term": "embedder",
            "tf": 4,
            "weight": 0.054795
          },
          {
            "term": "tests",
            "tf": 4,
            "weight": 0.054795
          },
          {
            "term": "local",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "ac6f6cd2",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "workflow",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "flow",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "py124",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "156",
            "tf": 1,
            "weight": 0.013699
          }
        ],
        "unique_terms": 30,
        "total_terms": 73
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Inference Workflow",
        "client",
        "com",
        "embed",
        "embedder",
        "github",
        "https",
        "inference",
        "local",
        "qdrant",
        "tests"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5438461538461539,
      "overall": 0.6812820512820513
    }
  },
  {
    "text": "## Supported Inference Objects  **Inference Object Types** ``` ``` The constant `INFERENCE_OBJECT_NAMES` contains the string names: `{\"Document\", \"Image\", \"InferenceObject\"}` and `INFERENCE_OBJECT_TYPES` is a Union type used throughout the system for type checking. Sources: [qdrant\\_client/embed/common.py5-6](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/common.py#L5-L6)",
    "metadata": {
      "chunk_id": "5c7eb506a337-0009",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Supported Inference Objects"
      ],
      "heading_text": "Supported Inference Objects",
      "token_count": 105,
      "char_count": 401,
      "start_char": 7319,
      "end_char": 7720,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5547058823529412,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.355675",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 105,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Supported Inference Objects",
      "chunk_hash": "f1ba6f24b078e046",
      "content_digest": "f1ba6f24b078e046",
      "chunk_length": 401,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "inference",
          "qdrant",
          "object",
          "the",
          "client",
          "types",
          "names",
          "type",
          "embed",
          "common",
          "supported",
          "objects",
          "constant",
          "contains",
          "string",
          "document",
          "image",
          "inferenceobject",
          "and",
          "union"
        ],
        "term_weights": [
          {
            "term": "inference",
            "tf": 4,
            "weight": 0.081633
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.081633
          },
          {
            "term": "object",
            "tf": 3,
            "weight": 0.061224
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.061224
          },
          {
            "term": "client",
            "tf": 3,
            "weight": 0.061224
          },
          {
            "term": "types",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "names",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "type",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "embed",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "common",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "supported",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "objects",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "constant",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "contains",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "string",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "image",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "inferenceobject",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "union",
            "tf": 1,
            "weight": 0.020408
          }
        ],
        "unique_terms": 32,
        "total_terms": 49
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Supported Inference Objects",
        "client",
        "common",
        "embed",
        "inference",
        "names",
        "object",
        "qdrant",
        "the",
        "type",
        "types"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5547058823529412,
      "overall": 0.718235294117647
    }
  },
  {
    "text": "### Basic Usage  Local inference happens automatically when you provide `Document` or `Image` objects to client methods: ``` ``` Sources: [tests/embed\\_tests/test\\_local\\_inference.py133-165](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L133-L165)",
    "metadata": {
      "chunk_id": "5c7eb506a337-0011",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Basic Usage"
      ],
      "heading_text": "Basic Usage",
      "token_count": 75,
      "char_count": 298,
      "start_char": 7751,
      "end_char": 8049,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5757142857142857,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.356844",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 75,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Basic Usage",
      "chunk_hash": "4b9962dafeb247c4",
      "content_digest": "4b9962dafeb247c4",
      "chunk_length": 298,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "tests",
          "local",
          "inference",
          "client",
          "embed",
          "test",
          "qdrant",
          "basic",
          "usage",
          "happens",
          "automatically",
          "when",
          "you",
          "provide",
          "document",
          "image",
          "objects",
          "methods",
          "sources",
          "py133"
        ],
        "term_weights": [
          {
            "term": "tests",
            "tf": 4,
            "weight": 0.102564
          },
          {
            "term": "local",
            "tf": 3,
            "weight": 0.076923
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.076923
          },
          {
            "term": "client",
            "tf": 2,
            "weight": 0.051282
          },
          {
            "term": "embed",
            "tf": 2,
            "weight": 0.051282
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.051282
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.051282
          },
          {
            "term": "basic",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "usage",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "happens",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "automatically",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "when",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "provide",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "image",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "objects",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "methods",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "py133",
            "tf": 1,
            "weight": 0.025641
          }
        ],
        "unique_terms": 28,
        "total_terms": 39
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Basic Usage",
        "basic",
        "client",
        "embed",
        "happens",
        "inference",
        "local",
        "qdrant",
        "test",
        "tests",
        "usage"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5757142857142857,
      "overall": 0.7252380952380952
    }
  },
  {
    "text": "### Query-Time Inference  The system distinguishes between document and query embedding for models that have different embedding methods for documents and queries: ``` ``` Sources: [qdrant\\_client/embed/embedder.py278-287](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L278-L287) [tests/embed\\_tests/test\\_local\\_inference.py352-581](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L352-L581)",
    "metadata": {
      "chunk_id": "5c7eb506a337-0013",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Query-Time Inference"
      ],
      "heading_text": "Query-Time Inference",
      "token_count": 125,
      "char_count": 480,
      "start_char": 8306,
      "end_char": 8786,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5455555555555556,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.358671",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 125,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Query-Time Inference",
      "chunk_hash": "115e3922a6c2faed",
      "content_digest": "115e3922a6c2faed",
      "chunk_length": 480,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "embed",
          "tests",
          "inference",
          "query",
          "and",
          "embedding",
          "for",
          "embedder",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "test",
          "local",
          "time",
          "the",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.089552
          },
          {
            "term": "client",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "tests",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "embedder",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "ac6f6cd2",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "local",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "time",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.014925
          }
        ],
        "unique_terms": 39,
        "total_terms": 67
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Query-Time Inference",
        "and",
        "client",
        "embed",
        "embedder",
        "embedding",
        "for",
        "inference",
        "qdrant",
        "query",
        "tests"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5455555555555556,
      "overall": 0.715185185185185
    }
  },
  {
    "text": "### Model Configuration Options  You can pass additional options to the embedding models: ``` ``` Sources: [qdrant\\_client/embed/embedder.py61-67](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L61-L67) [tests/embed\\_tests/test\\_local\\_inference.py916-976](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L916-L976)",
    "metadata": {
      "chunk_id": "5c7eb506a337-0015",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Configuration Options"
      ],
      "heading_text": "Model Configuration Options",
      "token_count": 113,
      "char_count": 402,
      "start_char": 8812,
      "end_char": 9214,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.359612",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 113,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Model Configuration Options",
      "chunk_hash": "e5530c0a47f114d6",
      "content_digest": "e5530c0a47f114d6",
      "chunk_length": 402,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "embed",
          "tests",
          "options",
          "embedder",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "test",
          "local",
          "inference",
          "model",
          "configuration",
          "you",
          "can",
          "pass",
          "additional"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.109091
          },
          {
            "term": "client",
            "tf": 4,
            "weight": 0.072727
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.072727
          },
          {
            "term": "tests",
            "tf": 4,
            "weight": 0.072727
          },
          {
            "term": "options",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "embedder",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "ac6f6cd2",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "local",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "configuration",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "pass",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "additional",
            "tf": 1,
            "weight": 0.018182
          }
        ],
        "unique_terms": 31,
        "total_terms": 55
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Configuration Options",
        "blob",
        "client",
        "com",
        "embed",
        "embedder",
        "github",
        "https",
        "options",
        "qdrant",
        "tests"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "overall": 0.6855555555555556
    }
  },
  {
    "text": "### Parallel Processing  For large batches of documents, you can use parallel processing: ``` ``` Sources: [qdrant\\_client/embed/model\\_embedder.py75-123](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L75-L123) [tests/embed\\_tests/test\\_local\\_inference.py310-350](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L310-L350)",
    "metadata": {
      "chunk_id": "5c7eb506a337-0016",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Parallel Processing"
      ],
      "heading_text": "Parallel Processing",
      "token_count": 117,
      "char_count": 417,
      "start_char": 9218,
      "end_char": 9635,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.360526",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 117,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Parallel Processing",
      "chunk_hash": "d6ad380a141858f4",
      "content_digest": "d6ad380a141858f4",
      "chunk_length": 417,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "embed",
          "tests",
          "parallel",
          "processing",
          "model",
          "embedder",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "test",
          "local",
          "inference",
          "for",
          "large",
          "batches",
          "documents"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.103448
          },
          {
            "term": "client",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "tests",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "parallel",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "processing",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "embedder",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "ac6f6cd2",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "local",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "large",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "batches",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.017241
          }
        ],
        "unique_terms": 32,
        "total_terms": 58
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Parallel Processing",
        "client",
        "embed",
        "embedder",
        "github",
        "https",
        "model",
        "parallel",
        "processing",
        "qdrant",
        "tests"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "overall": 0.6855555555555556
    }
  },
  {
    "text": "### Object Detection and Processing  The system uses a multi-step process to detect and process objects requiring inference:  1. **Model Processing**: The `ModelEmbedder._process_model()` method traverses model structures to find inference objects. 2. **Object Accumulation**: The `_accumulate()` method collects `Document`, `Image`, and `InferenceObject` instances into batches grouped by model name. 3. **Batch Embedding**: The `_embed_accumulator()` method calls `Embedder.embed()` to generate embeddings for accumulated objects. 4. **Model Resolution**: The `_resolve_inference_object()` method converts `InferenceObject` instances to `Document` or `Image` objects. 5. **Replacement**: The `_drain_accumulator()` method replaces original objects with their vector representations. **Processing Pipeline** ``` ``` Sources: [qdrant\\_client/embed/model\\_embedder.py141-156](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L141-L156) [qdrant\\_client/embed/model\\_embedder.py247-275](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L247-L275) [qdrant\\_client/embed/model\\_embedder.py277-317](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L277-L317)",
    "metadata": {
      "chunk_id": "5c7eb506a337-0019",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Object Detection and Processing"
      ],
      "heading_text": "Object Detection and Processing",
      "token_count": 319,
      "char_count": 1281,
      "start_char": 12419,
      "end_char": 13700,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5245659793814432,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.370840",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 319,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Object Detection and Processing",
      "chunk_hash": "ad38206e76174d08",
      "content_digest": "ad38206e76174d08",
      "chunk_length": 1281,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "model",
          "client",
          "embed",
          "embedder",
          "the",
          "objects",
          "method",
          "object",
          "and",
          "processing",
          "process",
          "inference",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "document",
          "image"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 12,
            "weight": 0.078431
          },
          {
            "term": "model",
            "tf": 11,
            "weight": 0.071895
          },
          {
            "term": "client",
            "tf": 9,
            "weight": 0.058824
          },
          {
            "term": "embed",
            "tf": 8,
            "weight": 0.052288
          },
          {
            "term": "embedder",
            "tf": 7,
            "weight": 0.045752
          },
          {
            "term": "the",
            "tf": 6,
            "weight": 0.039216
          },
          {
            "term": "objects",
            "tf": 5,
            "weight": 0.03268
          },
          {
            "term": "method",
            "tf": 5,
            "weight": 0.03268
          },
          {
            "term": "object",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "processing",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "process",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "ac6f6cd2",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "document",
            "tf": 2,
            "weight": 0.013072
          },
          {
            "term": "image",
            "tf": 2,
            "weight": 0.013072
          }
        ],
        "unique_terms": 73,
        "total_terms": 153
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Object Detection and Processing",
        "and",
        "client",
        "embed",
        "embedder",
        "method",
        "model",
        "object",
        "objects",
        "qdrant",
        "the"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5245659793814432,
      "overall": 0.7081886597938144
    }
  },
  {
    "text": "### Model Management  The `Embedder` class efficiently manages embedding models through `ModelInstance` containers:  - **Model Caching**: Each model type has its own dictionary (e.g., `embedding_models`, `sparse_embedding_models`) storing lists of `ModelInstance[T]` objects - **Configuration Tracking**: `ModelInstance` objects store model instances with their initialization options and deprecation status - **Lazy Loading**: Models are loaded only when first requested via `get_or_init_*` methods - **Option Matching**: Multiple instances of the same model with different configurations are supported by comparing options dictionaries - **Model Validation**: `FastEmbedMisc` provides validation methods for all supported model types  **Model Instance Management** ``` ``` Sources: [qdrant\\_client/embed/embedder.py23-27](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L23-L27) [qdrant\\_client/embed/embedder.py29-44](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L29-L44) [qdrant\\_client/embed/embedder.py46-221](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L46-L221)",
    "metadata": {
      "chunk_id": "5c7eb506a337-0020",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Management"
      ],
      "heading_text": "Model Management",
      "token_count": 285,
      "char_count": 1190,
      "start_char": 13705,
      "end_char": 14895,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5226530612244897,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.401804",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 285,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Model Management",
      "chunk_hash": "de706aa73a159cbf",
      "content_digest": "de706aa73a159cbf",
      "chunk_length": 1190,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "model",
          "embedder",
          "embed",
          "models",
          "embedding",
          "modelinstance",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "management",
          "the",
          "objects",
          "instances",
          "with",
          "options",
          "are"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 12,
            "weight": 0.082759
          },
          {
            "term": "client",
            "tf": 9,
            "weight": 0.062069
          },
          {
            "term": "model",
            "tf": 8,
            "weight": 0.055172
          },
          {
            "term": "embedder",
            "tf": 7,
            "weight": 0.048276
          },
          {
            "term": "embed",
            "tf": 6,
            "weight": 0.041379
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.027586
          },
          {
            "term": "embedding",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "modelinstance",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "ac6f6cd2",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "management",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "objects",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "instances",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "options",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.013793
          }
        ],
        "unique_terms": 81,
        "total_terms": 145
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Management",
        "client",
        "embed",
        "embedder",
        "embedding",
        "github",
        "https",
        "model",
        "modelinstance",
        "models",
        "qdrant"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5226530612244897,
      "overall": 0.7075510204081632
    }
  },
  {
    "text": "## Compatibility  The Local Inference system is designed to work with:  - **Local in-memory Qdrant instances**: `QdrantClient(\":memory:\")` - **Local persistent Qdrant instances**: `QdrantClient(path=\"/path/to/db\")` - **Remote Qdrant servers**: `QdrantClient(host=\"localhost\", port=6333)`  The system automatically handles embedding generation regardless of the backend, with the same API working across all deployment modes. Sources: [tests/embed\\_tests/test\\_local\\_inference.py134](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L134-L134) [tests/embed\\_tests/test\\_local\\_inference.py256-259](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L256-L259)",
    "metadata": {
      "chunk_id": "5c7eb506a337-0021",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Compatibility"
      ],
      "heading_text": "Compatibility",
      "token_count": 195,
      "char_count": 751,
      "start_char": 14899,
      "end_char": 15650,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5311764705882352,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.406810",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 195,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Compatibility",
      "chunk_hash": "6a3cead5a2a3dbd5",
      "content_digest": "6a3cead5a2a3dbd5",
      "chunk_length": 751,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "tests",
          "local",
          "qdrant",
          "inference",
          "the",
          "embed",
          "test",
          "qdrantclient",
          "system",
          "with",
          "memory",
          "instances",
          "path",
          "https",
          "github",
          "com",
          "client",
          "blob",
          "ac6f6cd2",
          "l134"
        ],
        "term_weights": [
          {
            "term": "tests",
            "tf": 8,
            "weight": 0.084211
          },
          {
            "term": "local",
            "tf": 7,
            "weight": 0.073684
          },
          {
            "term": "qdrant",
            "tf": 7,
            "weight": 0.073684
          },
          {
            "term": "inference",
            "tf": 5,
            "weight": 0.052632
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "test",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "qdrantclient",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "system",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "memory",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "instances",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "path",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "client",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "ac6f6cd2",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "l134",
            "tf": 2,
            "weight": 0.021053
          }
        ],
        "unique_terms": 49,
        "total_terms": 95
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Compatibility",
        "embed",
        "inference",
        "local",
        "qdrant",
        "qdrantclient",
        "system",
        "test",
        "tests",
        "the",
        "with"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5311764705882352,
      "overall": 0.710392156862745
    }
  },
  {
    "text": "## Limitations  - The FastEmbed library must be installed to use Local Inference - Not all embedding models are supported, only those available in FastEmbed - Embedding large batches may require significant memory  Sources: [tests/embed\\_tests/test\\_local\\_inference.py134-136](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L134-L136) [qdrant\\_client/fastembed\\_common.py8-25](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/fastembed_common.py#L8-L25)  Dismiss  Refresh this wiki  Enter email to refresh",
    "metadata": {
      "chunk_id": "5c7eb506a337-0022",
      "source_file": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Limitations"
      ],
      "heading_text": "Limitations",
      "token_count": 150,
      "char_count": 574,
      "start_char": 15653,
      "end_char": 16227,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5490909090909091,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.408518",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 150,
      "document_id": "5c7eb506a337",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "Docs\\Qdrant\\qdrant_qdrant-client",
      "relative_path": "Docs\\Qdrant\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Limitations",
      "chunk_hash": "dff6926fd1d6acdc",
      "content_digest": "dff6926fd1d6acdc",
      "chunk_length": 574,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "fastembed",
          "tests",
          "client",
          "local",
          "inference",
          "embedding",
          "embed",
          "test",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "common",
          "refresh",
          "limitations",
          "the",
          "library",
          "must"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.078947
          },
          {
            "term": "fastembed",
            "tf": 4,
            "weight": 0.052632
          },
          {
            "term": "tests",
            "tf": 4,
            "weight": 0.052632
          },
          {
            "term": "client",
            "tf": 4,
            "weight": 0.052632
          },
          {
            "term": "local",
            "tf": 3,
            "weight": 0.039474
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.039474
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "embed",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "ac6f6cd2",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "common",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "refresh",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "limitations",
            "tf": 1,
            "weight": 0.013158
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.013158
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.013158
          },
          {
            "term": "must",
            "tf": 1,
            "weight": 0.013158
          }
        ],
        "unique_terms": 48,
        "total_terms": 76
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Limitations",
        "client",
        "embed",
        "embedding",
        "fastembed",
        "https",
        "inference",
        "local",
        "qdrant",
        "test",
        "tests"
      ],
      "collection_name": "Qdrant"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5490909090909091,
      "overall": 0.7163636363636363
    }
  }
]
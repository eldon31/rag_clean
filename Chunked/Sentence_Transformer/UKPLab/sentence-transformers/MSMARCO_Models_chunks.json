[
  {
    "text": "## Dataset Overview  MS MARCO (Microsoft Machine Reading Comprehension) is a large-scale information retrieval corpus created from real user search queries using the Bing search engine. The dataset consists of:  - **Training data**: Over 500,000 query-passage examples - **Complete corpus**: Over 8.8 million passages   - **Evaluation**: TREC Deep Learning 2019 and MS MARCO Passage Retrieval datasets - **Task type**: Asymmetric semantic search (short queries â†’ longer passages)  The dataset enables training models that can find semantically relevant passages given natural language queries, making it ideal for search and question-answering applications. **Sources:** [docs/pretrained-models/msmarco-v3.md:1-5](), [docs/pretrained-models/ce-msmarco.md:1-6]()",
    "metadata": {
      "chunk_id": "508e0308e8d2-0000",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "filename": "MSMARCO_Models.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Dataset Overview"
      ],
      "heading_text": "Dataset Overview",
      "token_count": 171,
      "char_count": 761,
      "start_char": 391,
      "end_char": 1152,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7351612903225807,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.761660",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 171,
      "document_id": "508e0308e8d2",
      "document_name": "MSMARCO_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "source_filename": "MSMARCO_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "hierarchy_path": "Dataset Overview",
      "chunk_hash": "da84210a317fa6f5",
      "content_digest": "da84210a317fa6f5",
      "chunk_length": 761,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "dataset",
          "queries",
          "the",
          "passages",
          "models",
          "marco",
          "retrieval",
          "corpus",
          "training",
          "over",
          "passage",
          "and",
          "docs",
          "pretrained",
          "msmarco",
          "overview",
          "microsoft",
          "machine",
          "reading"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 4,
            "weight": 0.044444
          },
          {
            "term": "dataset",
            "tf": 3,
            "weight": 0.033333
          },
          {
            "term": "queries",
            "tf": 3,
            "weight": 0.033333
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.033333
          },
          {
            "term": "passages",
            "tf": 3,
            "weight": 0.033333
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.033333
          },
          {
            "term": "marco",
            "tf": 2,
            "weight": 0.022222
          },
          {
            "term": "retrieval",
            "tf": 2,
            "weight": 0.022222
          },
          {
            "term": "corpus",
            "tf": 2,
            "weight": 0.022222
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.022222
          },
          {
            "term": "over",
            "tf": 2,
            "weight": 0.022222
          },
          {
            "term": "passage",
            "tf": 2,
            "weight": 0.022222
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.022222
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.022222
          },
          {
            "term": "pretrained",
            "tf": 2,
            "weight": 0.022222
          },
          {
            "term": "msmarco",
            "tf": 2,
            "weight": 0.022222
          },
          {
            "term": "overview",
            "tf": 1,
            "weight": 0.011111
          },
          {
            "term": "microsoft",
            "tf": 1,
            "weight": 0.011111
          },
          {
            "term": "machine",
            "tf": 1,
            "weight": 0.011111
          },
          {
            "term": "reading",
            "tf": 1,
            "weight": 0.011111
          }
        ],
        "unique_terms": 67,
        "total_terms": 90
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Dataset Overview",
        "corpus",
        "dataset",
        "marco",
        "models",
        "passages",
        "queries",
        "retrieval",
        "search",
        "the",
        "training"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7351612903225807,
      "overall": 0.8117204301075268
    }
  },
  {
    "text": "## Model Architecture Types\n\nMS MARCO models are available across multiple architectures, each optimized for different use cases in the retrieval pipeline:",
    "metadata": {
      "chunk_id": "508e0308e8d2-0001",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "filename": "MSMARCO_Models.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Architecture Types"
      ],
      "heading_text": "Model Architecture Types",
      "token_count": 26,
      "char_count": 155,
      "start_char": 1155,
      "end_char": 1310,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.762013",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 26,
      "document_id": "508e0308e8d2",
      "document_name": "MSMARCO_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "source_filename": "MSMARCO_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "hierarchy_path": "Model Architecture Types",
      "chunk_hash": "03b6c2900865b599",
      "content_digest": "03b6c2900865b599",
      "chunk_length": 155,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "architecture",
          "types",
          "marco",
          "models",
          "are",
          "available",
          "across",
          "multiple",
          "architectures",
          "each",
          "optimized",
          "for",
          "different",
          "use",
          "cases",
          "the",
          "retrieval",
          "pipeline"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "architecture",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "types",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "marco",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "available",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "across",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "architectures",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "each",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "optimized",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "cases",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "retrieval",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "pipeline",
            "tf": 1,
            "weight": 0.052632
          }
        ],
        "unique_terms": 19,
        "total_terms": 19
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Architecture Types",
        "across",
        "architecture",
        "architectures",
        "are",
        "available",
        "marco",
        "model",
        "models",
        "multiple",
        "types"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.59,
      "overall": 0.6966666666666667
    }
  },
  {
    "text": "### Training Components ```mermaid graph LR     subgraph \"Loss Functions\"         MSE_LOSS[\"MultipleNegativesRankingLoss\"]         COSENT_LOSS[\"CoSENTLoss\"]          MARGIN_MSE[\"MarginMSELoss\"]     end          subgraph \"Evaluators\"         IR_EVAL[\"InformationRetrievalEvaluator\"]         EMB_EVAL[\"EmbeddingSimilarityEvaluator\"]         CE_EVAL[\"CrossEncoderReranking\"]     end          subgraph \"Datasets\"         MSMARCO_TRAIN[\"sentence-transformers/msmarco-*\"]         TREC_DL[\"TREC Deep Learning 2019\"]         MSMARCO_DEV[\"MS MARCO Dev Set\"]     end          MSE_LOSS --> MSMARCO_TRAIN     MARGIN_MSE --> MSMARCO_TRAIN     IR_EVAL --> TREC_DL     IR_EVAL --> MSMARCO_DEV     CE_EVAL --> TREC_DL ``` **Sources:** [docs/pretrained-models/msmarco-v3.md:6-16](), [docs/cross_encoder/pretrained_models.md:27-44]()",
    "metadata": {
      "chunk_id": "508e0308e8d2-0003",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "filename": "MSMARCO_Models.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Training Components"
      ],
      "heading_text": "Training Components",
      "token_count": 216,
      "char_count": 815,
      "start_char": 2418,
      "end_char": 3233,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.524,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.765201",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 216,
      "document_id": "508e0308e8d2",
      "document_name": "MSMARCO_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "source_filename": "MSMARCO_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "hierarchy_path": "Training Components",
      "chunk_hash": "98c9c866653615a5",
      "content_digest": "98c9c866653615a5",
      "chunk_length": 815,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "msmarco",
          "eval",
          "loss",
          "mse",
          "trec",
          "subgraph",
          "end",
          "train",
          "dev",
          "margin",
          "docs",
          "pretrained",
          "models",
          "training",
          "components",
          "mermaid",
          "graph",
          "functions",
          "multiplenegativesrankingloss",
          "cosent"
        ],
        "term_weights": [
          {
            "term": "msmarco",
            "tf": 7,
            "weight": 0.1
          },
          {
            "term": "eval",
            "tf": 6,
            "weight": 0.085714
          },
          {
            "term": "loss",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "mse",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "trec",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "subgraph",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "end",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "train",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "dev",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "margin",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "pretrained",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "training",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "components",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "mermaid",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "graph",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "multiplenegativesrankingloss",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "cosent",
            "tf": 1,
            "weight": 0.014286
          }
        ],
        "unique_terms": 38,
        "total_terms": 70
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Training Components",
        "dev",
        "end",
        "eval",
        "loss",
        "margin",
        "mse",
        "msmarco",
        "subgraph",
        "train",
        "trec"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.524,
      "overall": 0.7413333333333333
    }
  },
  {
    "text": "## Dense Embedding Models  Dense embedding models use the `SentenceTransformer` class and encode queries and passages into dense vector representations for efficient similarity search:",
    "metadata": {
      "chunk_id": "508e0308e8d2-0004",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "filename": "MSMARCO_Models.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Dense Embedding Models"
      ],
      "heading_text": "Dense Embedding Models",
      "token_count": 30,
      "char_count": 184,
      "start_char": 3237,
      "end_char": 3421,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5275,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.765874",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 30,
      "document_id": "508e0308e8d2",
      "document_name": "MSMARCO_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "source_filename": "MSMARCO_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "hierarchy_path": "Dense Embedding Models",
      "chunk_hash": "83c5c1786ee173d3",
      "content_digest": "83c5c1786ee173d3",
      "chunk_length": 184,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "dense",
          "embedding",
          "models",
          "and",
          "use",
          "the",
          "sentencetransformer",
          "class",
          "encode",
          "queries",
          "passages",
          "into",
          "vector",
          "representations",
          "for",
          "efficient",
          "similarity",
          "search"
        ],
        "term_weights": [
          {
            "term": "dense",
            "tf": 3,
            "weight": 0.130435
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "sentencetransformer",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "encode",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "queries",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "passages",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "into",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "representations",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "efficient",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "similarity",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 18,
        "total_terms": 23
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Dense Embedding Models",
        "and",
        "class",
        "dense",
        "embedding",
        "encode",
        "models",
        "queries",
        "sentencetransformer",
        "the",
        "use"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5275,
      "overall": 0.7425
    }
  },
  {
    "text": "## Usage Examples",
    "metadata": {
      "chunk_id": "508e0308e8d2-0008",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "filename": "MSMARCO_Models.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Usage Examples"
      ],
      "heading_text": "Usage Examples",
      "token_count": 3,
      "char_count": 17,
      "start_char": 5649,
      "end_char": 5666,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.768243",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 3,
      "document_id": "508e0308e8d2",
      "document_name": "MSMARCO_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "source_filename": "MSMARCO_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "hierarchy_path": "Usage Examples",
      "chunk_hash": "40ba86df7413777b",
      "content_digest": "40ba86df7413777b",
      "chunk_length": 17,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "usage",
          "examples"
        ],
        "term_weights": [
          {
            "term": "usage",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "examples",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Usage Examples",
        "examples",
        "usage"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Dense Embedding Model Usage ```python from sentence_transformers import SentenceTransformer, util",
    "metadata": {
      "chunk_id": "508e0308e8d2-0009",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "filename": "MSMARCO_Models.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Dense Embedding Model Usage"
      ],
      "heading_text": "Dense Embedding Model Usage",
      "token_count": 17,
      "char_count": 101,
      "start_char": 5668,
      "end_char": 5769,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.768440",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 17,
      "document_id": "508e0308e8d2",
      "document_name": "MSMARCO_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "source_filename": "MSMARCO_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\MSMARCO_Models.md",
      "hierarchy_path": "Dense Embedding Model Usage",
      "chunk_hash": "c291aae796a606f0",
      "content_digest": "c291aae796a606f0",
      "chunk_length": 101,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "dense",
          "embedding",
          "model",
          "usage",
          "python",
          "from",
          "sentence",
          "transformers",
          "import",
          "sentencetransformer",
          "util"
        ],
        "term_weights": [
          {
            "term": "dense",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "usage",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "import",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "sentencetransformer",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "util",
            "tf": 1,
            "weight": 0.090909
          }
        ],
        "unique_terms": 11,
        "total_terms": 11
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Dense Embedding Model Usage",
        "dense",
        "embedding",
        "from",
        "import",
        "model",
        "python",
        "sentence",
        "sentencetransformer",
        "transformers",
        "usage"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  }
]
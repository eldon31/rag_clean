[
  {
    "text": "## Overview  Sparse search integration allows `SparseEncoder` models to work with external search systems that can efficiently handle sparse vector data. The integration supports both manual in-memory search and production-ready vector database solutions. ```mermaid graph TD     SparseEncoder[\"SparseEncoder\"]     EncodeDoc[\"encode_document()\"]     EncodeQuery[\"encode_query()\"]     SparseEmbeddings[\"Sparse Embeddings<br/>(COO Tensors)\"]          SparseEncoder --> EncodeDoc     SparseEncoder --> EncodeQuery     EncodeDoc --> SparseEmbeddings     EncodeQuery --> SparseEmbeddings          SparseEmbeddings --> ManualSearch[\"Manual Search<br/>util.semantic_search()\"]     SparseEmbeddings --> VectorDBs[\"Vector Databases\"]          VectorDBs --> Qdrant[\"semantic_search_qdrant()\"]     VectorDBs --> Elasticsearch[\"semantic_search_elasticsearch()\"]      VectorDBs --> OpenSearch[\"semantic_search_opensearch()\"]     VectorDBs --> Seismic[\"semantic_search_seismic()\"]     VectorDBs --> SpladeIndex[\"SPLADE-index\"] ``` **Architecture Components for Sparse Search Integration**  Sources: [sentence_transformers/sparse_encoder/search_engines.py:1-556](), [examples/sparse_encoder/applications/semantic_search/README.md:1-529]()",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0000",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Overview"
      ],
      "heading_text": "Overview",
      "token_count": 261,
      "char_count": 1223,
      "start_char": 482,
      "end_char": 1705,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.696896551724138,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.470682",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 261,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Overview",
      "chunk_hash": "3c67fe308301783a",
      "content_digest": "3c67fe308301783a",
      "chunk_length": 1223,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "sparse",
          "semantic",
          "vectordbs",
          "sparseencoder",
          "sparseembeddings",
          "integration",
          "vector",
          "encodedoc",
          "encodequery",
          "manual",
          "encode",
          "qdrant",
          "elasticsearch",
          "opensearch",
          "seismic",
          "encoder",
          "overview",
          "allows",
          "models"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 12,
            "weight": 0.107143
          },
          {
            "term": "sparse",
            "tf": 6,
            "weight": 0.053571
          },
          {
            "term": "semantic",
            "tf": 6,
            "weight": 0.053571
          },
          {
            "term": "vectordbs",
            "tf": 6,
            "weight": 0.053571
          },
          {
            "term": "sparseencoder",
            "tf": 5,
            "weight": 0.044643
          },
          {
            "term": "sparseembeddings",
            "tf": 5,
            "weight": 0.044643
          },
          {
            "term": "integration",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "vector",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "encodedoc",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "encodequery",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "manual",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "encode",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "elasticsearch",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "opensearch",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "seismic",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "overview",
            "tf": 1,
            "weight": 0.008929
          },
          {
            "term": "allows",
            "tf": 1,
            "weight": 0.008929
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.008929
          }
        ],
        "unique_terms": 63,
        "total_terms": 112
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Overview",
        "encodedoc",
        "encodequery",
        "integration",
        "search",
        "semantic",
        "sparse",
        "sparseembeddings",
        "sparseencoder",
        "vector",
        "vectordbs"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.696896551724138,
      "overall": 0.7989655172413793
    }
  },
  {
    "text": "### Vector Database Search Approach  Vector database search leverages specialized systems optimized for sparse vector operations, providing better scalability and performance for large corpora. | Search Engine | Function | Index Type | Key Features | |---------------|----------|------------|--------------| | Qdrant | `semantic_search_qdrant()` | Sparse vectors | Native sparse vector support | | Elasticsearch | `semantic_search_elasticsearch()` | rank_features | Elastic stack integration | | OpenSearch | `semantic_search_opensearch()` | neural_sparse | Amazon OpenSearch compatibility | | Seismic | `semantic_search_seismic()` | SeismicIndex | High-performance in-memory search | | SPLADE-index | External library | SciPy sparse matrices | BM25s-based implementation |  Sources: [examples/sparse_encoder/applications/semantic_search/README.md:11-132]()",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0003",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Vector Database Search Approach"
      ],
      "heading_text": "Vector Database Search Approach",
      "token_count": 169,
      "char_count": 857,
      "start_char": 2432,
      "end_char": 3289,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6644897959183673,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.472780",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 169,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Vector Database Search Approach",
      "chunk_hash": "ae9b4cf042c1a20b",
      "content_digest": "ae9b4cf042c1a20b",
      "chunk_length": 857,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "sparse",
          "semantic",
          "vector",
          "opensearch",
          "database",
          "for",
          "performance",
          "index",
          "features",
          "qdrant",
          "elasticsearch",
          "seismic",
          "approach",
          "leverages",
          "specialized",
          "systems",
          "optimized",
          "operations",
          "providing"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 9,
            "weight": 0.104651
          },
          {
            "term": "sparse",
            "tf": 6,
            "weight": 0.069767
          },
          {
            "term": "semantic",
            "tf": 5,
            "weight": 0.05814
          },
          {
            "term": "vector",
            "tf": 4,
            "weight": 0.046512
          },
          {
            "term": "opensearch",
            "tf": 3,
            "weight": 0.034884
          },
          {
            "term": "database",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "performance",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "index",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "features",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "elasticsearch",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "seismic",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "approach",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "leverages",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "specialized",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "systems",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "optimized",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "operations",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "providing",
            "tf": 1,
            "weight": 0.011628
          }
        ],
        "unique_terms": 56,
        "total_terms": 86
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Vector Database Search Approach",
        "database",
        "features",
        "for",
        "index",
        "opensearch",
        "performance",
        "search",
        "semantic",
        "sparse",
        "vector"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6644897959183673,
      "overall": 0.7881632653061224
    }
  },
  {
    "text": "## Search Engine Integration Functions",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0004",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Search Engine Integration Functions"
      ],
      "heading_text": "Search Engine Integration Functions",
      "token_count": 5,
      "char_count": 38,
      "start_char": 3292,
      "end_char": 3330,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.473234",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 5,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Search Engine Integration Functions",
      "chunk_hash": "67823a326051df34",
      "content_digest": "67823a326051df34",
      "chunk_length": 38,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "engine",
          "integration",
          "functions"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 1,
            "weight": 0.25
          },
          {
            "term": "engine",
            "tf": 1,
            "weight": 0.25
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.25
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.25
          }
        ],
        "unique_terms": 4,
        "total_terms": 4
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Search Engine Integration Functions",
        "engine",
        "functions",
        "integration",
        "search"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Qdrant Integration  The `semantic_search_qdrant()` function provides native integration with Qdrant's sparse vector capabilities. ```mermaid graph LR     QueryEmb[\"query_embeddings<br/>(COO Tensor)\"]     CorpusEmb[\"corpus_embeddings<br/>(COO Tensor)\"]          QueryEmb --> QdrantFunc[\"semantic_search_qdrant()\"]     CorpusEmb --> QdrantFunc          QdrantFunc --> QdrantClient[\"QdrantClient\"]     QdrantFunc --> Collection[\"Sparse Collection\"]     QdrantFunc --> SparseVector[\"SparseVector Models\"]          QdrantClient --> Results[\"Search Results<br/>[{'corpus_id': int, 'score': float}]\"] ``` **Qdrant Integration Data Flow**  The integration handles COO sparse tensors directly and creates collections with `SparseVectorParams` configuration. **Key Parameters:** - Input: PyTorch COO sparse tensors - Collection: Auto-generated with timestamp - Indexing: Batch processing with configurable `batch_size` - Search: Native sparse vector queries using `models.SparseVector`  Sources: [sentence_transformers/sparse_encoder/search_engines.py:32-158](), [examples/sparse_encoder/applications/semantic_search/semantic_search_qdrant.py:1-64]()",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0005",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Qdrant Integration"
      ],
      "heading_text": "Qdrant Integration",
      "token_count": 269,
      "char_count": 1144,
      "start_char": 3332,
      "end_char": 4476,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7070212765957448,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.477920",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 269,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Qdrant Integration",
      "chunk_hash": "b3415bd346c5e565",
      "content_digest": "b3415bd346c5e565",
      "chunk_length": 1144,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "sparse",
          "qdrant",
          "qdrantfunc",
          "integration",
          "semantic",
          "with",
          "coo",
          "qdrantclient",
          "collection",
          "sparsevector",
          "the",
          "native",
          "vector",
          "queryemb",
          "embeddings",
          "tensor",
          "corpusemb",
          "corpus",
          "models"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 7,
            "weight": 0.061404
          },
          {
            "term": "sparse",
            "tf": 7,
            "weight": 0.061404
          },
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.052632
          },
          {
            "term": "qdrantfunc",
            "tf": 5,
            "weight": 0.04386
          },
          {
            "term": "integration",
            "tf": 4,
            "weight": 0.035088
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.035088
          },
          {
            "term": "with",
            "tf": 4,
            "weight": 0.035088
          },
          {
            "term": "coo",
            "tf": 4,
            "weight": 0.035088
          },
          {
            "term": "qdrantclient",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "collection",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "sparsevector",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "native",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "queryemb",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "tensor",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "corpusemb",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "corpus",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.017544
          }
        ],
        "unique_terms": 62,
        "total_terms": 114
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Qdrant Integration",
        "collection",
        "coo",
        "integration",
        "qdrant",
        "qdrantclient",
        "qdrantfunc",
        "search",
        "semantic",
        "sparse",
        "with"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7070212765957448,
      "overall": 0.8023404255319148
    }
  },
  {
    "text": "### Elasticsearch Integration    The `semantic_search_elasticsearch()` function uses Elasticsearch's `rank_features` field type for sparse vector storage and search. ```mermaid graph LR     DecodedEmb[\"query_embeddings_decoded<br/>[[('token', value)]]\"]     CorpusDecoded[\"corpus_embeddings_decoded<br/>[[('token', value)]]\"]          DecodedEmb --> ESFunc[\"semantic_search_elasticsearch()\"]     CorpusDecoded --> ESFunc          ESFunc --> ESClient[\"Elasticsearch Client\"]     ESFunc --> RankFeatures[\"rank_features Mapping\"]     ESFunc --> RankFeatureQuery[\"rank_feature Queries\"]          ESClient --> ESResults[\"Search Results<br/>[{'corpus_id': int, '_score': float}]\"] ``` **Elasticsearch Integration Data Flow**  **Key Features:** - Input: Decoded embeddings in `[('token', value)]` format - Mapping: Uses `rank_features` field type for sparse vectors - Indexing: Bulk operations with configurable batch size - Search: `rank_feature` queries with `saturation` and `boost` parameters  Sources: [sentence_transformers/sparse_encoder/search_engines.py:160-297](), [examples/sparse_encoder/applications/semantic_search/semantic_search_elasticsearch.py:1-68]()",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0006",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Elasticsearch Integration"
      ],
      "heading_text": "Elasticsearch Integration",
      "token_count": 264,
      "char_count": 1162,
      "start_char": 4481,
      "end_char": 5643,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7222580645161291,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.483487",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 264,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Elasticsearch Integration",
      "chunk_hash": "87d6fe4c2407ae4c",
      "content_digest": "87d6fe4c2407ae4c",
      "chunk_length": 1162,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "elasticsearch",
          "rank",
          "esfunc",
          "semantic",
          "features",
          "sparse",
          "embeddings",
          "decoded",
          "token",
          "value",
          "integration",
          "uses",
          "field",
          "type",
          "for",
          "and",
          "decodedemb",
          "corpusdecoded",
          "corpus"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 8,
            "weight": 0.068376
          },
          {
            "term": "elasticsearch",
            "tf": 7,
            "weight": 0.059829
          },
          {
            "term": "rank",
            "tf": 5,
            "weight": 0.042735
          },
          {
            "term": "esfunc",
            "tf": 5,
            "weight": 0.042735
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.034188
          },
          {
            "term": "features",
            "tf": 4,
            "weight": 0.034188
          },
          {
            "term": "sparse",
            "tf": 4,
            "weight": 0.034188
          },
          {
            "term": "embeddings",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "decoded",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "token",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "value",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "integration",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "uses",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "field",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "type",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "decodedemb",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "corpusdecoded",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "corpus",
            "tf": 2,
            "weight": 0.017094
          }
        ],
        "unique_terms": 64,
        "total_terms": 117
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Elasticsearch Integration",
        "decoded",
        "elasticsearch",
        "embeddings",
        "esfunc",
        "features",
        "rank",
        "search",
        "semantic",
        "sparse",
        "token"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7222580645161291,
      "overall": 0.8074193548387095
    }
  },
  {
    "text": "### OpenSearch Integration  The `semantic_search_opensearch()` function leverages OpenSearch's `neural_sparse` query capabilities. **Key Differences from Elasticsearch:** - Uses `neural_sparse` query type instead of `rank_feature` - Compatible with Amazon OpenSearch Service - Supports asymmetric sparse encoder architectures  Sources: [sentence_transformers/sparse_encoder/search_engines.py:428-556](), [examples/sparse_encoder/applications/semantic_search/semantic_search_opensearch.py:1-87]()",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0007",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "OpenSearch Integration"
      ],
      "heading_text": "OpenSearch Integration",
      "token_count": 103,
      "char_count": 495,
      "start_char": 5647,
      "end_char": 6142,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7505263157894736,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.486074",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 103,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "OpenSearch Integration",
      "chunk_hash": "4d3461f063ac3349",
      "content_digest": "4d3461f063ac3349",
      "chunk_length": 495,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "opensearch",
          "sparse",
          "search",
          "semantic",
          "encoder",
          "neural",
          "query",
          "integration",
          "the",
          "function",
          "leverages",
          "capabilities",
          "key",
          "differences",
          "from",
          "elasticsearch",
          "uses",
          "type",
          "instead",
          "rank"
        ],
        "term_weights": [
          {
            "term": "opensearch",
            "tf": 5,
            "weight": 0.09434
          },
          {
            "term": "sparse",
            "tf": 5,
            "weight": 0.09434
          },
          {
            "term": "search",
            "tf": 4,
            "weight": 0.075472
          },
          {
            "term": "semantic",
            "tf": 3,
            "weight": 0.056604
          },
          {
            "term": "encoder",
            "tf": 3,
            "weight": 0.056604
          },
          {
            "term": "neural",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "function",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "leverages",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "capabilities",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "differences",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "elasticsearch",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "uses",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "type",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "instead",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "rank",
            "tf": 1,
            "weight": 0.018868
          }
        ],
        "unique_terms": 36,
        "total_terms": 53
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "OpenSearch Integration",
        "encoder",
        "function",
        "integration",
        "neural",
        "opensearch",
        "query",
        "search",
        "semantic",
        "sparse",
        "the"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7505263157894736,
      "overall": 0.8168421052631577
    }
  },
  {
    "text": "### Seismic Integration  The `semantic_search_seismic()` function provides integration with the high-performance Seismic library for in-memory sparse vector search. ```mermaid graph LR     DecodedQuery[\"query_embeddings_decoded\"]     DecodedCorpus[\"corpus_embeddings_decoded\"]          DecodedQuery --> SeismicFunc[\"semantic_search_seismic()\"]     DecodedCorpus --> SeismicFunc          SeismicFunc --> SeismicDataset[\"SeismicDataset.add_document()\"]     SeismicFunc --> SeismicIndex[\"SeismicIndex.build_from_dataset()\"]     SeismicFunc --> BatchSearch[\"SeismicIndex.batch_search()\"]          BatchSearch --> SeismicResults[\"Sorted Results<br/>[{'corpus_id': int, 'score': float}]\"] ``` **Seismic Integration Architecture**  **Performance Features:** - `SeismicDataset` for document management - `SeismicIndex.build_from_dataset()` with configurable index parameters - `batch_search()` with `query_cut` and `heap_factor` optimizations - Order-of-magnitude performance improvements over IVF approaches  Sources: [sentence_transformers/sparse_encoder/search_engines.py:299-426](), [examples/sparse_encoder/applications/semantic_search/semantic_search_seismic.py:1-66]()",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0008",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Seismic Integration"
      ],
      "heading_text": "Seismic Integration",
      "token_count": 256,
      "char_count": 1167,
      "start_char": 6145,
      "end_char": 7312,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7216455696202532,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.490957",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 256,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Seismic Integration",
      "chunk_hash": "733642378df3799f",
      "content_digest": "733642378df3799f",
      "chunk_length": 1167,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "seismic",
          "seismicfunc",
          "semantic",
          "seismicindex",
          "integration",
          "with",
          "performance",
          "sparse",
          "seismicdataset",
          "the",
          "for",
          "decodedquery",
          "query",
          "embeddings",
          "decoded",
          "decodedcorpus",
          "corpus",
          "document",
          "build"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 8,
            "weight": 0.071429
          },
          {
            "term": "seismic",
            "tf": 6,
            "weight": 0.053571
          },
          {
            "term": "seismicfunc",
            "tf": 5,
            "weight": 0.044643
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.035714
          },
          {
            "term": "seismicindex",
            "tf": 4,
            "weight": 0.035714
          },
          {
            "term": "integration",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "performance",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "seismicdataset",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "decodedquery",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "decoded",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "decodedcorpus",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "corpus",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "document",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "build",
            "tf": 2,
            "weight": 0.017857
          }
        ],
        "unique_terms": 65,
        "total_terms": 112
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Seismic Integration",
        "integration",
        "performance",
        "search",
        "seismic",
        "seismicdataset",
        "seismicfunc",
        "seismicindex",
        "semantic",
        "sparse",
        "with"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7216455696202532,
      "overall": 0.8072151898734177
    }
  },
  {
    "text": "### Encoding Workflow ```mermaid graph TD     TextInput[\"Text Input<br/>['query text', 'document text']\"]          TextInput --> EncodeQuery[\"model.encode_query()\"]     TextInput --> EncodeDoc[\"model.encode_document()\"]          EncodeQuery --> SparseQuery[\"Sparse Query Embeddings\"]     EncodeDoc --> SparseDoc[\"Sparse Document Embeddings\"]          SparseQuery --> QdrantFormat[\"COO Tensor<br/>(for Qdrant)\"]     SparseQuery --> DecodedFormat[\"Decoded Format<br/>(for ES/OpenSearch/Seismic)\"]          SparseDoc --> QdrantFormat     SparseDoc --> DecodedFormat          QdrantFormat --> QdrantSearch[\"semantic_search_qdrant()\"]     DecodedFormat --> OtherSearches[\"Other search_* functions\"] ``` **Data Format Conversion Pipeline**",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0011",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Encoding Workflow"
      ],
      "heading_text": "Encoding Workflow",
      "token_count": 168,
      "char_count": 733,
      "start_char": 7771,
      "end_char": 8504,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5096428571428571,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.494590",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 168,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Encoding Workflow",
      "chunk_hash": "0648ff57c03df3d0",
      "content_digest": "0648ff57c03df3d0",
      "chunk_length": 733,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "textinput",
          "text",
          "query",
          "document",
          "sparsequery",
          "sparsedoc",
          "qdrantformat",
          "decodedformat",
          "encodequery",
          "model",
          "encode",
          "encodedoc",
          "sparse",
          "embeddings",
          "for",
          "qdrant",
          "format",
          "search",
          "encoding",
          "workflow"
        ],
        "term_weights": [
          {
            "term": "textinput",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "text",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "query",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "document",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "sparsequery",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "sparsedoc",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "qdrantformat",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "decodedformat",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "encodequery",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "encode",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "encodedoc",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "format",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "encoding",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "workflow",
            "tf": 1,
            "weight": 0.016129
          }
        ],
        "unique_terms": 36,
        "total_terms": 62
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Encoding Workflow",
        "decodedformat",
        "document",
        "encodequery",
        "model",
        "qdrantformat",
        "query",
        "sparsedoc",
        "sparsequery",
        "text",
        "textinput"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5096428571428571,
      "overall": 0.7365476190476189
    }
  },
  {
    "text": "### Sparse Tensor Formats  **COO Sparse Tensor (Qdrant):** - Format: PyTorch coordinate format sparse tensor - Indices: `[row_indices, col_indices]` - Values: Sparse embedding values - Advantages: Direct tensor operations, GPU compatibility  **Decoded Format (Others):** - Format: `List[List[Tuple[str, float]]]` - Structure: `[[('token1', 0.5), ('token2', 0.3)], ...]` - Advantages: Human-readable, search engine compatible  Sources: [sentence_transformers/sparse_encoder/search_engines.py:67-76](), [examples/sparse_encoder/applications/semantic_search/README.md:53-83]()",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0012",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Sparse Tensor Formats"
      ],
      "heading_text": "Sparse Tensor Formats",
      "token_count": 150,
      "char_count": 573,
      "start_char": 8508,
      "end_char": 9081,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5066666666666666,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.497490",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 150,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Sparse Tensor Formats",
      "chunk_hash": "a8250a15647d9bb4",
      "content_digest": "a8250a15647d9bb4",
      "chunk_length": 573,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparse",
          "tensor",
          "format",
          "indices",
          "search",
          "values",
          "advantages",
          "list",
          "encoder",
          "formats",
          "coo",
          "qdrant",
          "pytorch",
          "coordinate",
          "row",
          "col",
          "embedding",
          "direct",
          "operations",
          "gpu"
        ],
        "term_weights": [
          {
            "term": "sparse",
            "tf": 6,
            "weight": 0.1
          },
          {
            "term": "tensor",
            "tf": 4,
            "weight": 0.066667
          },
          {
            "term": "format",
            "tf": 4,
            "weight": 0.066667
          },
          {
            "term": "indices",
            "tf": 3,
            "weight": 0.05
          },
          {
            "term": "search",
            "tf": 3,
            "weight": 0.05
          },
          {
            "term": "values",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "advantages",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "list",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "formats",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "coo",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "pytorch",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "coordinate",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "row",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "col",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "direct",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "operations",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "gpu",
            "tf": 1,
            "weight": 0.016667
          }
        ],
        "unique_terms": 41,
        "total_terms": 60
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Sparse Tensor Formats",
        "advantages",
        "encoder",
        "format",
        "formats",
        "indices",
        "list",
        "search",
        "sparse",
        "tensor",
        "values"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5066666666666666,
      "overall": 0.7022222222222222
    }
  },
  {
    "text": "### Reusable Index Pattern  All search engine integrations support index reuse through the `output_index` parameter: ```mermaid graph TD     FirstCall[\"First Function Call\"]     CreateIndex[\"Create Index<br/>(corpus_embeddings required)\"]     SearchResults1[\"Search Results + Index\"]          SecondCall[\"Subsequent Calls\"]     ReuseIndex[\"Reuse Existing Index<br/>(corpus_index provided)\"]     SearchResults2[\"Search Results Only\"]          FirstCall --> CreateIndex     CreateIndex --> SearchResults1          SecondCall --> ReuseIndex     ReuseIndex --> SearchResults2          SearchResults1 --> IndexStorage[\"Store Index Reference\"]     IndexStorage --> SecondCall ``` **Index Reuse Pattern for Production Workflows**",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0014",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Reusable Index Pattern"
      ],
      "heading_text": "Reusable Index Pattern",
      "token_count": 151,
      "char_count": 722,
      "start_char": 9108,
      "end_char": 9830,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.524375,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.499686",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 151,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Reusable Index Pattern",
      "chunk_hash": "764d55ad84c5c25c",
      "content_digest": "764d55ad84c5c25c",
      "chunk_length": 722,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "index",
          "search",
          "reuse",
          "createindex",
          "searchresults1",
          "secondcall",
          "reuseindex",
          "pattern",
          "firstcall",
          "corpus",
          "results",
          "searchresults2",
          "indexstorage",
          "reusable",
          "all",
          "engine",
          "integrations",
          "support",
          "through",
          "the"
        ],
        "term_weights": [
          {
            "term": "index",
            "tf": 9,
            "weight": 0.136364
          },
          {
            "term": "search",
            "tf": 3,
            "weight": 0.045455
          },
          {
            "term": "reuse",
            "tf": 3,
            "weight": 0.045455
          },
          {
            "term": "createindex",
            "tf": 3,
            "weight": 0.045455
          },
          {
            "term": "searchresults1",
            "tf": 3,
            "weight": 0.045455
          },
          {
            "term": "secondcall",
            "tf": 3,
            "weight": 0.045455
          },
          {
            "term": "reuseindex",
            "tf": 3,
            "weight": 0.045455
          },
          {
            "term": "pattern",
            "tf": 2,
            "weight": 0.030303
          },
          {
            "term": "firstcall",
            "tf": 2,
            "weight": 0.030303
          },
          {
            "term": "corpus",
            "tf": 2,
            "weight": 0.030303
          },
          {
            "term": "results",
            "tf": 2,
            "weight": 0.030303
          },
          {
            "term": "searchresults2",
            "tf": 2,
            "weight": 0.030303
          },
          {
            "term": "indexstorage",
            "tf": 2,
            "weight": 0.030303
          },
          {
            "term": "reusable",
            "tf": 1,
            "weight": 0.015152
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.015152
          },
          {
            "term": "engine",
            "tf": 1,
            "weight": 0.015152
          },
          {
            "term": "integrations",
            "tf": 1,
            "weight": 0.015152
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.015152
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.015152
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.015152
          }
        ],
        "unique_terms": 40,
        "total_terms": 66
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Reusable Index Pattern",
        "corpus",
        "createindex",
        "firstcall",
        "index",
        "pattern",
        "reuse",
        "reuseindex",
        "search",
        "searchresults1",
        "secondcall"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.524375,
      "overall": 0.7414583333333334
    }
  },
  {
    "text": "### Error Handling and Validation  All integration functions include comprehensive input validation:  - Sparse tensor format validation for Qdrant - Decoded embedding format validation for other engines   - Client availability checks with helpful error messages - Required dependency import validation  Sources: [sentence_transformers/sparse_encoder/search_engines.py:67-76](), [sentence_transformers/sparse_encoder/search_engines.py:204-218]()",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0015",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Error Handling and Validation"
      ],
      "heading_text": "Error Handling and Validation",
      "token_count": 83,
      "char_count": 444,
      "start_char": 9834,
      "end_char": 10278,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5272093023255814,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.500193",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 83,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Error Handling and Validation",
      "chunk_hash": "fcf98e46aca900e3",
      "content_digest": "fcf98e46aca900e3",
      "chunk_length": 444,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "validation",
          "sparse",
          "engines",
          "error",
          "format",
          "for",
          "sentence",
          "transformers",
          "encoder",
          "search",
          "handling",
          "and",
          "all",
          "integration",
          "functions",
          "include",
          "comprehensive",
          "input",
          "tensor",
          "qdrant"
        ],
        "term_weights": [
          {
            "term": "validation",
            "tf": 5,
            "weight": 0.1
          },
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.06
          },
          {
            "term": "engines",
            "tf": 3,
            "weight": 0.06
          },
          {
            "term": "error",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "format",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "handling",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "include",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "comprehensive",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "input",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "tensor",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.02
          }
        ],
        "unique_terms": 35,
        "total_terms": 50
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Error Handling and Validation",
        "encoder",
        "engines",
        "error",
        "for",
        "format",
        "search",
        "sentence",
        "sparse",
        "transformers",
        "validation"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5272093023255814,
      "overall": 0.7424031007751938
    }
  },
  {
    "text": "## Performance Considerations",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0016",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Considerations"
      ],
      "heading_text": "Performance Considerations",
      "token_count": 4,
      "char_count": 29,
      "start_char": 10280,
      "end_char": 10309,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.500535",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 4,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Performance Considerations",
      "chunk_hash": "f0c6f691b1d6938e",
      "content_digest": "f0c6f691b1d6938e",
      "chunk_length": 29,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "performance",
          "considerations"
        ],
        "term_weights": [
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "considerations",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Considerations",
        "considerations",
        "performance"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Scalability Recommendations  - **Small Corpora (< 10K docs):** Manual search with `util.semantic_search()` - **Medium Corpora (10K-1M docs):** Qdrant or Seismic for performance - **Large Corpora (> 1M docs):** Elasticsearch/OpenSearch with distributed setup - **Real-time Applications:** Seismic for lowest latency in-memory search  Sources: [examples/sparse_encoder/applications/semantic_search/README.md:127-132](), [examples/sparse_encoder/applications/semantic_search/README.md:388-396]()",
    "metadata": {
      "chunk_id": "47db77a6ec4e-0018",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Scalability Recommendations"
      ],
      "heading_text": "Scalability Recommendations",
      "token_count": 119,
      "char_count": 496,
      "start_char": 10803,
      "end_char": 11299,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7166666666666667,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.503117",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 119,
      "document_id": "47db77a6ec4e",
      "document_name": "Sparse_Search_Integration",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Scalability Recommendations",
      "chunk_hash": "e75a73d785958868",
      "content_digest": "e75a73d785958868",
      "chunk_length": 496,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "corpora",
          "docs",
          "semantic",
          "applications",
          "10k",
          "with",
          "seismic",
          "for",
          "examples",
          "sparse",
          "encoder",
          "readme",
          "scalability",
          "recommendations",
          "small",
          "manual",
          "util",
          "medium",
          "qdrant"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 5,
            "weight": 0.089286
          },
          {
            "term": "corpora",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "docs",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "semantic",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "applications",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "10k",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "seismic",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "readme",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "scalability",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "recommendations",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "small",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "manual",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "util",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "medium",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.017857
          }
        ],
        "unique_terms": 36,
        "total_terms": 56
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "10k",
        "Scalability Recommendations",
        "applications",
        "corpora",
        "docs",
        "examples",
        "for",
        "search",
        "seismic",
        "semantic",
        "with"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7166666666666667,
      "overall": 0.8055555555555555
    }
  }
]
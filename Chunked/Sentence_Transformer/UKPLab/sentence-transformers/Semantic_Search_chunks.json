[
  {
    "text": "### Semantic Search Flow ```mermaid flowchart TD     Query[\"Query Text\"] --> QueryEncode[\"model.encode()\"]     Docs[\"Document Collection\"] --> DocEncode[\"model.encode()\"]          QueryEncode --> QueryEmb[\"Query Embedding<br/>(dense vector)\"]     DocEncode --> DocEmb[\"Document Embeddings<br/>(dense vectors)\"]          QueryEmb --> Similarity[\"util.pytorch_cos_sim()\"]     DocEmb --> Similarity          Similarity --> Results[\"Ranked Results\"]          subgraph VectorDB [\"Vector Database Storage\"]         DocEmb --> Store[\"Store embeddings\"]         Store --> Retrieve[\"Similarity search\"]         QueryEmb --> Retrieve         Retrieve --> Results     end ``` Sources: [docs/pretrained-models/msmarco-v2.md:8-15]()",
    "metadata": {
      "chunk_id": "be078194b6de-0001",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "filename": "Semantic_Search.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Semantic Search Flow"
      ],
      "heading_text": "Semantic Search Flow",
      "token_count": 160,
      "char_count": 719,
      "start_char": 861,
      "end_char": 1580,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5175862068965517,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.385991",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 160,
      "document_id": "be078194b6de",
      "document_name": "Semantic_Search",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "source_filename": "Semantic_Search.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "hierarchy_path": "Semantic Search Flow",
      "chunk_hash": "98edfb70b6fa7c5a",
      "content_digest": "98edfb70b6fa7c5a",
      "chunk_length": 719,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "similarity",
          "query",
          "queryemb",
          "docemb",
          "results",
          "store",
          "retrieve",
          "search",
          "queryencode",
          "model",
          "encode",
          "docs",
          "document",
          "docencode",
          "dense",
          "vector",
          "embeddings",
          "semantic",
          "flow",
          "mermaid"
        ],
        "term_weights": [
          {
            "term": "similarity",
            "tf": 4,
            "weight": 0.0625
          },
          {
            "term": "query",
            "tf": 3,
            "weight": 0.046875
          },
          {
            "term": "queryemb",
            "tf": 3,
            "weight": 0.046875
          },
          {
            "term": "docemb",
            "tf": 3,
            "weight": 0.046875
          },
          {
            "term": "results",
            "tf": 3,
            "weight": 0.046875
          },
          {
            "term": "store",
            "tf": 3,
            "weight": 0.046875
          },
          {
            "term": "retrieve",
            "tf": 3,
            "weight": 0.046875
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "queryencode",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "encode",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "document",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "docencode",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "dense",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.03125
          },
          {
            "term": "semantic",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "flow",
            "tf": 1,
            "weight": 0.015625
          },
          {
            "term": "mermaid",
            "tf": 1,
            "weight": 0.015625
          }
        ],
        "unique_terms": 39,
        "total_terms": 64
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Semantic Search Flow",
        "docemb",
        "model",
        "query",
        "queryemb",
        "queryencode",
        "results",
        "retrieve",
        "search",
        "similarity",
        "store"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5175862068965517,
      "overall": 0.7391954022988504
    }
  },
  {
    "text": "## Basic Implementation Pattern\n\nThe fundamental pattern for semantic search involves three steps: encoding the query, encoding the document collection, and computing similarity scores.",
    "metadata": {
      "chunk_id": "be078194b6de-0002",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "filename": "Semantic_Search.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Basic Implementation Pattern"
      ],
      "heading_text": "Basic Implementation Pattern",
      "token_count": 29,
      "char_count": 185,
      "start_char": 1584,
      "end_char": 1769,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.74,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.386468",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 29,
      "document_id": "be078194b6de",
      "document_name": "Semantic_Search",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "source_filename": "Semantic_Search.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "hierarchy_path": "Basic Implementation Pattern",
      "chunk_hash": "bd31d0a62f77e9dd",
      "content_digest": "bd31d0a62f77e9dd",
      "chunk_length": 185,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "pattern",
          "encoding",
          "basic",
          "implementation",
          "fundamental",
          "for",
          "semantic",
          "search",
          "involves",
          "three",
          "steps",
          "query",
          "document",
          "collection",
          "and",
          "computing",
          "similarity",
          "scores"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 3,
            "weight": 0.130435
          },
          {
            "term": "pattern",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "encoding",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "basic",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "fundamental",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "semantic",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "involves",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "three",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "steps",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "query",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "collection",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "computing",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "similarity",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "scores",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 19,
        "total_terms": 23
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Basic Implementation Pattern",
        "basic",
        "encoding",
        "for",
        "fundamental",
        "implementation",
        "involves",
        "pattern",
        "search",
        "semantic",
        "the"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.74,
      "overall": 0.8133333333333334
    }
  },
  {
    "text": "### Model Selection  The choice of `SentenceTransformer` model significantly impacts search quality. Models trained on information retrieval datasets like MS MARCO provide better performance for search tasks compared to general-purpose models. | Model Type | Use Case | Example | |------------|----------|---------| | MSMARCO-trained | Information retrieval | `msmarco-distilroberta-base-v2` | | General-purpose | Broad semantic similarity | `all-MiniLM-L6-v2` | | Domain-specific | Specialized fields | BioBERT variants |  Sources: [docs/pretrained-models/msmarco-v2.md:10](), [docs/pretrained-models/msmarco-v2.md:27-32]()",
    "metadata": {
      "chunk_id": "be078194b6de-0004",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "filename": "Semantic_Search.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Selection"
      ],
      "heading_text": "Model Selection",
      "token_count": 145,
      "char_count": 624,
      "start_char": 2506,
      "end_char": 3130,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7000000000000001,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.388521",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 145,
      "document_id": "be078194b6de",
      "document_name": "Semantic_Search",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "source_filename": "Semantic_Search.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "hierarchy_path": "Model Selection",
      "chunk_hash": "e3a3aca8ed94a639",
      "content_digest": "e3a3aca8ed94a639",
      "chunk_length": 624,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "models",
          "msmarco",
          "model",
          "search",
          "trained",
          "information",
          "retrieval",
          "general",
          "purpose",
          "docs",
          "pretrained",
          "selection",
          "the",
          "choice",
          "sentencetransformer",
          "significantly",
          "impacts",
          "quality",
          "datasets",
          "like"
        ],
        "term_weights": [
          {
            "term": "models",
            "tf": 4,
            "weight": 0.065574
          },
          {
            "term": "msmarco",
            "tf": 4,
            "weight": 0.065574
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.04918
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.032787
          },
          {
            "term": "trained",
            "tf": 2,
            "weight": 0.032787
          },
          {
            "term": "information",
            "tf": 2,
            "weight": 0.032787
          },
          {
            "term": "retrieval",
            "tf": 2,
            "weight": 0.032787
          },
          {
            "term": "general",
            "tf": 2,
            "weight": 0.032787
          },
          {
            "term": "purpose",
            "tf": 2,
            "weight": 0.032787
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.032787
          },
          {
            "term": "pretrained",
            "tf": 2,
            "weight": 0.032787
          },
          {
            "term": "selection",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "choice",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "sentencetransformer",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "significantly",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "impacts",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "quality",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "datasets",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "like",
            "tf": 1,
            "weight": 0.016393
          }
        ],
        "unique_terms": 45,
        "total_terms": 61
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Selection",
        "docs",
        "general",
        "information",
        "model",
        "models",
        "msmarco",
        "purpose",
        "retrieval",
        "search",
        "trained"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7000000000000001,
      "overall": 0.7999999999999999
    }
  },
  {
    "text": "### Vector Database Architecture ```mermaid graph TB     subgraph Preprocessing [\"Offline Preprocessing\"]         Corpus[\"Document Corpus\"]         STModel[\"SentenceTransformer\"]         Corpus --> STModel         STModel --> Embeddings[\"Dense Embeddings\"]     end          subgraph VectorDB [\"Vector Database\"]         Embeddings --> Store[\"store() / index()\"]         Store --> Index[\"Vector Index<br/>(HNSW, IVF, etc.)\"]     end          subgraph Runtime [\"Query Runtime\"]         QueryText[\"Query Text\"]         QueryEmbed[\"Query Encoding\"]         QueryText --> QueryEmbed         QueryEmbed --> Search[\"similarity_search()\"]         Index --> Search         Search --> Results[\"Top-K Results\"]     end          subgraph Databases [\"Supported Databases\"]         Pinecone[\"Pinecone\"]         Weaviate[\"Weaviate\"]          Qdrant[\"Qdrant\"]         ChromaDB[\"ChromaDB\"]     end          Store -.-> Pinecone     Store -.-> Weaviate     Store -.-> Qdrant     Store -.-> ChromaDB ``` Sources: Based on integration patterns mentioned in the repository overview",
    "metadata": {
      "chunk_id": "be078194b6de-0006",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "filename": "Semantic_Search.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Vector Database Architecture"
      ],
      "heading_text": "Vector Database Architecture",
      "token_count": 234,
      "char_count": 1059,
      "start_char": 3389,
      "end_char": 4448,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.515,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.390893",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 234,
      "document_id": "be078194b6de",
      "document_name": "Semantic_Search",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "source_filename": "Semantic_Search.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "hierarchy_path": "Vector Database Architecture",
      "chunk_hash": "11bbc39c046639a2",
      "content_digest": "11bbc39c046639a2",
      "chunk_length": 1059,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "store",
          "subgraph",
          "end",
          "index",
          "search",
          "vector",
          "corpus",
          "stmodel",
          "embeddings",
          "query",
          "queryembed",
          "pinecone",
          "weaviate",
          "qdrant",
          "chromadb",
          "database",
          "preprocessing",
          "runtime",
          "querytext",
          "results"
        ],
        "term_weights": [
          {
            "term": "store",
            "tf": 7,
            "weight": 0.078652
          },
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.044944
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.044944
          },
          {
            "term": "index",
            "tf": 4,
            "weight": 0.044944
          },
          {
            "term": "search",
            "tf": 4,
            "weight": 0.044944
          },
          {
            "term": "vector",
            "tf": 3,
            "weight": 0.033708
          },
          {
            "term": "corpus",
            "tf": 3,
            "weight": 0.033708
          },
          {
            "term": "stmodel",
            "tf": 3,
            "weight": 0.033708
          },
          {
            "term": "embeddings",
            "tf": 3,
            "weight": 0.033708
          },
          {
            "term": "query",
            "tf": 3,
            "weight": 0.033708
          },
          {
            "term": "queryembed",
            "tf": 3,
            "weight": 0.033708
          },
          {
            "term": "pinecone",
            "tf": 3,
            "weight": 0.033708
          },
          {
            "term": "weaviate",
            "tf": 3,
            "weight": 0.033708
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.033708
          },
          {
            "term": "chromadb",
            "tf": 3,
            "weight": 0.033708
          },
          {
            "term": "database",
            "tf": 2,
            "weight": 0.022472
          },
          {
            "term": "preprocessing",
            "tf": 2,
            "weight": 0.022472
          },
          {
            "term": "runtime",
            "tf": 2,
            "weight": 0.022472
          },
          {
            "term": "querytext",
            "tf": 2,
            "weight": 0.022472
          },
          {
            "term": "results",
            "tf": 2,
            "weight": 0.022472
          }
        ],
        "unique_terms": 45,
        "total_terms": 89
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Vector Database Architecture",
        "corpus",
        "embeddings",
        "end",
        "index",
        "query",
        "search",
        "stmodel",
        "store",
        "subgraph",
        "vector"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.515,
      "overall": 0.7383333333333333
    }
  },
  {
    "text": "## Performance Considerations\n\nSemantic search performance depends on both model quality and computational efficiency. The choice of model affects both retrieval quality and inference speed.",
    "metadata": {
      "chunk_id": "be078194b6de-0007",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "filename": "Semantic_Search.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Considerations"
      ],
      "heading_text": "Performance Considerations",
      "token_count": 29,
      "char_count": 190,
      "start_char": 4452,
      "end_char": 4642,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.53,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.391353",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 29,
      "document_id": "be078194b6de",
      "document_name": "Semantic_Search",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "source_filename": "Semantic_Search.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "hierarchy_path": "Performance Considerations",
      "chunk_hash": "0c6f8f610e31747a",
      "content_digest": "0c6f8f610e31747a",
      "chunk_length": 190,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "performance",
          "both",
          "model",
          "quality",
          "and",
          "considerations",
          "semantic",
          "search",
          "depends",
          "computational",
          "efficiency",
          "the",
          "choice",
          "affects",
          "retrieval",
          "inference",
          "speed"
        ],
        "term_weights": [
          {
            "term": "performance",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "both",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "quality",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "considerations",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "semantic",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "depends",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "computational",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "efficiency",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "choice",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "affects",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "retrieval",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "speed",
            "tf": 1,
            "weight": 0.045455
          }
        ],
        "unique_terms": 17,
        "total_terms": 22
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Considerations",
        "and",
        "both",
        "computational",
        "considerations",
        "depends",
        "model",
        "performance",
        "quality",
        "search",
        "semantic"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.53,
      "overall": 0.71
    }
  },
  {
    "text": "### Model Performance Comparison  Based on evaluation against traditional keyword search (BM25), dense embedding models show significant improvements in retrieval quality:  | Approach | NDCG@10 (TREC DL 19) | MRR@10 (MS Marco) | |----------|---------------------|-------------------| | BM25 (Elasticsearch) | 45.46 | 17.29 | | `msmarco-distilroberta-base-v2` | 65.65 | 28.55 | | `msmarco-roberta-base-v2` | 67.18 | 29.17 | | `msmarco-distilbert-base-v2` | 68.35 | 30.77 |  The substantial improvement over BM25 demonstrates the effectiveness of semantic search for information retrieval tasks. Sources: [docs/pretrained-models/msmarco-v2.md:25-32]()",
    "metadata": {
      "chunk_id": "be078194b6de-0008",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "filename": "Semantic_Search.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Performance Comparison"
      ],
      "heading_text": "Model Performance Comparison",
      "token_count": 188,
      "char_count": 649,
      "start_char": 4644,
      "end_char": 5293,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.50375,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.391827",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 188,
      "document_id": "be078194b6de",
      "document_name": "Semantic_Search",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "source_filename": "Semantic_Search.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "hierarchy_path": "Model Performance Comparison",
      "chunk_hash": "076e66cfe461730e",
      "content_digest": "076e66cfe461730e",
      "chunk_length": 649,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "msmarco",
          "bm25",
          "base",
          "search",
          "models",
          "retrieval",
          "the",
          "model",
          "performance",
          "comparison",
          "based",
          "evaluation",
          "against",
          "traditional",
          "keyword",
          "dense",
          "embedding",
          "show",
          "significant",
          "improvements"
        ],
        "term_weights": [
          {
            "term": "msmarco",
            "tf": 4,
            "weight": 0.075472
          },
          {
            "term": "bm25",
            "tf": 3,
            "weight": 0.056604
          },
          {
            "term": "base",
            "tf": 3,
            "weight": 0.056604
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "retrieval",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "comparison",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "evaluation",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "against",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "traditional",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "keyword",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "dense",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "show",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "significant",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "improvements",
            "tf": 1,
            "weight": 0.018868
          }
        ],
        "unique_terms": 42,
        "total_terms": 53
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Performance Comparison",
        "base",
        "bm25",
        "comparison",
        "model",
        "models",
        "msmarco",
        "performance",
        "retrieval",
        "search",
        "the"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.50375,
      "overall": 0.7012499999999999
    }
  },
  {
    "text": "### Optimization Strategies\n\nFor production semantic search systems, several optimization techniques apply:\n\n1. **Model Selection**: Choose appropriately sized models balancing quality and speed\n2. **Batch Processing**: Encode multiple documents simultaneously for better throughput  \n3. **Caching**: Cache frequently accessed embeddings to reduce computation\n4. **Quantization**: Use reduced precision embeddings to decrease memory usage\n5. **Approximate Search**: Leverage vector database indexing for sub-linear search time",
    "metadata": {
      "chunk_id": "be078194b6de-0009",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "filename": "Semantic_Search.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Optimization Strategies"
      ],
      "heading_text": "Optimization Strategies",
      "token_count": 90,
      "char_count": 526,
      "start_char": 5296,
      "end_char": 5822,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5614285714285714,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.392303",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 90,
      "document_id": "be078194b6de",
      "document_name": "Semantic_Search",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "source_filename": "Semantic_Search.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "hierarchy_path": "Optimization Strategies",
      "chunk_hash": "d9d4acc7d1945a80",
      "content_digest": "d9d4acc7d1945a80",
      "chunk_length": 526,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "for",
          "search",
          "optimization",
          "embeddings",
          "strategies",
          "production",
          "semantic",
          "systems",
          "several",
          "techniques",
          "apply",
          "model",
          "selection",
          "choose",
          "appropriately",
          "sized",
          "models",
          "balancing",
          "quality",
          "and"
        ],
        "term_weights": [
          {
            "term": "for",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "search",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "optimization",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "strategies",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "production",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "semantic",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "systems",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "several",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "techniques",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "apply",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "selection",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "choose",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "appropriately",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "sized",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "balancing",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "quality",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.017857
          }
        ],
        "unique_terms": 50,
        "total_terms": 56
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Optimization Strategies",
        "embeddings",
        "for",
        "optimization",
        "production",
        "search",
        "semantic",
        "several",
        "strategies",
        "systems",
        "techniques"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5614285714285714,
      "overall": 0.6538095238095237
    }
  },
  {
    "text": "## Implementation Patterns",
    "metadata": {
      "chunk_id": "be078194b6de-0010",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "filename": "Semantic_Search.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Implementation Patterns"
      ],
      "heading_text": "Implementation Patterns",
      "token_count": 3,
      "char_count": 26,
      "start_char": 5824,
      "end_char": 5850,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.392391",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 3,
      "document_id": "be078194b6de",
      "document_name": "Semantic_Search",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "source_filename": "Semantic_Search.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "hierarchy_path": "Implementation Patterns",
      "chunk_hash": "83cab3c813f48a1f",
      "content_digest": "83cab3c813f48a1f",
      "chunk_length": 26,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "implementation",
          "patterns"
        ],
        "term_weights": [
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "patterns",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Implementation Patterns",
        "implementation",
        "patterns"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "# Referenced pattern from file model = SentenceTransformer(\"msmarco-distilroberta-base-v2\") query_embedding = model.encode(\"How big is London\") passage_embedding = model.encode(\"London has 9,787,426 inhabitants at the 2011 census\") similarity = util.pytorch_cos_sim(query_embedding, passage_embedding) ``` Sources: [docs/pretrained-models/msmarco-v2.md:10-15]()",
    "metadata": {
      "chunk_id": "be078194b6de-0012",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "filename": "Semantic_Search.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Referenced pattern from file"
      ],
      "heading_text": "Referenced pattern from file",
      "token_count": 89,
      "char_count": 361,
      "start_char": 6050,
      "end_char": 6411,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5609677419354838,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.393696",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 89,
      "document_id": "be078194b6de",
      "document_name": "Semantic_Search",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "source_filename": "Semantic_Search.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "hierarchy_path": "Referenced pattern from file",
      "chunk_hash": "2bb4728bb493a193",
      "content_digest": "2bb4728bb493a193",
      "chunk_length": 361,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "embedding",
          "model",
          "msmarco",
          "query",
          "encode",
          "london",
          "passage",
          "referenced",
          "pattern",
          "from",
          "file",
          "sentencetransformer",
          "distilroberta",
          "base",
          "how",
          "big",
          "has",
          "787",
          "426",
          "inhabitants"
        ],
        "term_weights": [
          {
            "term": "embedding",
            "tf": 4,
            "weight": 0.095238
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.071429
          },
          {
            "term": "msmarco",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "encode",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "london",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "passage",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "referenced",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "pattern",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "file",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "sentencetransformer",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "distilroberta",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "base",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "how",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "big",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "has",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "787",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "426",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "inhabitants",
            "tf": 1,
            "weight": 0.02381
          }
        ],
        "unique_terms": 32,
        "total_terms": 42
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Referenced pattern from file",
        "embedding",
        "encode",
        "from",
        "london",
        "model",
        "msmarco",
        "passage",
        "pattern",
        "query",
        "referenced"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5609677419354838,
      "overall": 0.7203225806451612
    }
  },
  {
    "text": "### Batch Processing\n\nFor processing multiple queries or documents, batch encoding provides better performance through parallelization within the model.",
    "metadata": {
      "chunk_id": "be078194b6de-0013",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "filename": "Semantic_Search.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Batch Processing"
      ],
      "heading_text": "Batch Processing",
      "token_count": 23,
      "char_count": 152,
      "start_char": 6414,
      "end_char": 6566,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5584210526315789,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.393962",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 23,
      "document_id": "be078194b6de",
      "document_name": "Semantic_Search",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "source_filename": "Semantic_Search.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "hierarchy_path": "Batch Processing",
      "chunk_hash": "af163c347f14696c",
      "content_digest": "af163c347f14696c",
      "chunk_length": 152,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "batch",
          "processing",
          "for",
          "multiple",
          "queries",
          "documents",
          "encoding",
          "provides",
          "better",
          "performance",
          "through",
          "parallelization",
          "within",
          "the",
          "model"
        ],
        "term_weights": [
          {
            "term": "batch",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "processing",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "queries",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "encoding",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "better",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "parallelization",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "within",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.058824
          }
        ],
        "unique_terms": 15,
        "total_terms": 17
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Batch Processing",
        "batch",
        "better",
        "documents",
        "encoding",
        "for",
        "multiple",
        "performance",
        "processing",
        "provides",
        "queries"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5584210526315789,
      "overall": 0.7528070175438596
    }
  },
  {
    "text": "### Cross-Lingual Search\n\n`SentenceTransformer` models trained on multilingual data enable semantic search across language boundaries, where queries in one language can retrieve relevant documents in another language.",
    "metadata": {
      "chunk_id": "be078194b6de-0014",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "filename": "Semantic_Search.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Cross-Lingual Search"
      ],
      "heading_text": "Cross-Lingual Search",
      "token_count": 37,
      "char_count": 217,
      "start_char": 6568,
      "end_char": 6785,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.394213",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 37,
      "document_id": "be078194b6de",
      "document_name": "Semantic_Search",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "source_filename": "Semantic_Search.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "hierarchy_path": "Cross-Lingual Search",
      "chunk_hash": "869ba986e8cadaa4",
      "content_digest": "869ba986e8cadaa4",
      "chunk_length": 217,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "language",
          "search",
          "cross",
          "lingual",
          "sentencetransformer",
          "models",
          "trained",
          "multilingual",
          "data",
          "enable",
          "semantic",
          "across",
          "boundaries",
          "where",
          "queries",
          "one",
          "can",
          "retrieve",
          "relevant",
          "documents"
        ],
        "term_weights": [
          {
            "term": "language",
            "tf": 3,
            "weight": 0.125
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.083333
          },
          {
            "term": "cross",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "lingual",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "sentencetransformer",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "trained",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "multilingual",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "data",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "enable",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "semantic",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "across",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "boundaries",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "queries",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "one",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "retrieve",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "relevant",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.041667
          }
        ],
        "unique_terms": 21,
        "total_terms": 24
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Cross-Lingual Search",
        "cross",
        "data",
        "enable",
        "language",
        "lingual",
        "models",
        "multilingual",
        "search",
        "sentencetransformer",
        "trained"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "overall": 0.7522222222222222
    }
  },
  {
    "text": "## Integration Examples  The MS MARCO models demonstrate effective semantic search for information retrieval tasks. These models are specifically trained on search query-passage pairs, making them well-suited for question-answering and document retrieval applications. Training data characteristics: - Over 500,000 query-passage examples   - Complete corpus of 8.8 million passages - Real user search queries from Bing search engine  Sources: [docs/pretrained-models/msmarco-v2.md:2-4]()",
    "metadata": {
      "chunk_id": "be078194b6de-0015",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "filename": "Semantic_Search.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration Examples"
      ],
      "heading_text": "Integration Examples",
      "token_count": 100,
      "char_count": 487,
      "start_char": 6787,
      "end_char": 7274,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7391525423728814,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:46.394584",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 100,
      "document_id": "be078194b6de",
      "document_name": "Semantic_Search",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "source_filename": "Semantic_Search.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Semantic_Search.md",
      "hierarchy_path": "Integration Examples",
      "chunk_hash": "183af5bd9adb7e94",
      "content_digest": "183af5bd9adb7e94",
      "chunk_length": 487,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "models",
          "examples",
          "for",
          "retrieval",
          "query",
          "passage",
          "integration",
          "the",
          "marco",
          "demonstrate",
          "effective",
          "semantic",
          "information",
          "tasks",
          "these",
          "are",
          "specifically",
          "trained",
          "pairs"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 4,
            "weight": 0.067797
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.050847
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "retrieval",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "passage",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "marco",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "demonstrate",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "effective",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "semantic",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "information",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "tasks",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "these",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "specifically",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "trained",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "pairs",
            "tf": 1,
            "weight": 0.016949
          }
        ],
        "unique_terms": 49,
        "total_terms": 59
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration Examples",
        "examples",
        "for",
        "integration",
        "marco",
        "models",
        "passage",
        "query",
        "retrieval",
        "search",
        "the"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7391525423728814,
      "overall": 0.7797175141242937
    }
  }
]
[
  {
    "text": "## Common Implementation Patterns\n\nAll learning-to-rank losses share several implementation patterns:",
    "metadata": {
      "chunk_id": "847ef7345741-0002",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "filename": "..._populate_matrices_....md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Common Implementation Patterns"
      ],
      "heading_text": "Common Implementation Patterns",
      "token_count": 16,
      "char_count": 101,
      "start_char": 833,
      "end_char": 934,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.5627272727272727,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.875391",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 16,
      "document_id": "847ef7345741",
      "document_name": "..._populate_matrices_...",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "source_filename": "..._populate_matrices_....md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "hierarchy_path": "Common Implementation Patterns",
      "chunk_hash": "4efd3d9055f619f2",
      "content_digest": "4efd3d9055f619f2",
      "chunk_length": 101,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "implementation",
          "patterns",
          "common",
          "all",
          "learning",
          "rank",
          "losses",
          "share",
          "several"
        ],
        "term_weights": [
          {
            "term": "implementation",
            "tf": 2,
            "weight": 0.181818
          },
          {
            "term": "patterns",
            "tf": 2,
            "weight": 0.181818
          },
          {
            "term": "common",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "learning",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "rank",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "losses",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "share",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "several",
            "tf": 1,
            "weight": 0.090909
          }
        ],
        "unique_terms": 9,
        "total_terms": 11
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Common Implementation Patterns",
        "all",
        "common",
        "implementation",
        "learning",
        "losses",
        "patterns",
        "rank",
        "several",
        "share"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.5627272727272727,
      "overall": 0.6875757575757575
    }
  },
  {
    "text": "### Mini-Batch Processing  Large document lists are processed in mini-batches to manage memory usage: ```python mini_batch_size = self.mini_batch_size or batch_size if mini_batch_size <= 0:     mini_batch_size = len(pairs)  for i in range(0, len(pairs), mini_batch_size):     mini_batch_pairs = pairs[i : i + mini_batch_size]     # Process mini-batch... ```",
    "metadata": {
      "chunk_id": "847ef7345741-0003",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "filename": "..._populate_matrices_....md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Mini-Batch Processing"
      ],
      "heading_text": "Mini-Batch Processing",
      "token_count": 89,
      "char_count": 357,
      "start_char": 936,
      "end_char": 1293,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5490909090909091,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.876109",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 89,
      "document_id": "847ef7345741",
      "document_name": "..._populate_matrices_...",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "source_filename": "..._populate_matrices_....md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "hierarchy_path": "Mini-Batch Processing",
      "chunk_hash": "9c49098e5c839756",
      "content_digest": "9c49098e5c839756",
      "chunk_length": 357,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "mini",
          "batch",
          "size",
          "pairs",
          "len",
          "processing",
          "large",
          "document",
          "lists",
          "are",
          "processed",
          "batches",
          "manage",
          "memory",
          "usage",
          "python",
          "self",
          "for",
          "range",
          "process"
        ],
        "term_weights": [
          {
            "term": "mini",
            "tf": 10,
            "weight": 0.208333
          },
          {
            "term": "batch",
            "tf": 10,
            "weight": 0.208333
          },
          {
            "term": "size",
            "tf": 7,
            "weight": 0.145833
          },
          {
            "term": "pairs",
            "tf": 4,
            "weight": 0.083333
          },
          {
            "term": "len",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "large",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "lists",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "processed",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "batches",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "manage",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "memory",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "usage",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "self",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "range",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.020833
          }
        ],
        "unique_terms": 20,
        "total_terms": 48
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Mini-Batch Processing",
        "are",
        "batch",
        "document",
        "large",
        "len",
        "lists",
        "mini",
        "pairs",
        "processing",
        "size"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5490909090909091,
      "overall": 0.7496969696969696
    }
  },
  {
    "text": "# Create padded matrices logits_matrix = torch.full((batch_size, max_docs), -1e16, device=self.model.device) labels_matrix = torch.full_like(logits_matrix, float(\"-inf\"))",
    "metadata": {
      "chunk_id": "847ef7345741-0005",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "filename": "..._populate_matrices_....md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Create padded matrices"
      ],
      "heading_text": "Create padded matrices",
      "token_count": 39,
      "char_count": 170,
      "start_char": 1403,
      "end_char": 1573,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5685714285714286,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.876805",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 39,
      "document_id": "847ef7345741",
      "document_name": "..._populate_matrices_...",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "source_filename": "..._populate_matrices_....md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "hierarchy_path": "Create padded matrices",
      "chunk_hash": "3577f7439ba095c9",
      "content_digest": "3577f7439ba095c9",
      "chunk_length": 170,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "matrix",
          "logits",
          "torch",
          "full",
          "device",
          "create",
          "padded",
          "matrices",
          "batch",
          "size",
          "max",
          "docs",
          "1e16",
          "self",
          "model",
          "labels",
          "like",
          "float",
          "inf"
        ],
        "term_weights": [
          {
            "term": "matrix",
            "tf": 3,
            "weight": 0.12
          },
          {
            "term": "logits",
            "tf": 2,
            "weight": 0.08
          },
          {
            "term": "torch",
            "tf": 2,
            "weight": 0.08
          },
          {
            "term": "full",
            "tf": 2,
            "weight": 0.08
          },
          {
            "term": "device",
            "tf": 2,
            "weight": 0.08
          },
          {
            "term": "create",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "padded",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "matrices",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "batch",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "size",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "max",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "docs",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "1e16",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "self",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "labels",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "like",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "float",
            "tf": 1,
            "weight": 0.04
          },
          {
            "term": "inf",
            "tf": 1,
            "weight": 0.04
          }
        ],
        "unique_terms": 19,
        "total_terms": 25
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Create padded matrices",
        "batch",
        "create",
        "device",
        "full",
        "logits",
        "matrices",
        "matrix",
        "padded",
        "size",
        "torch"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5685714285714286,
      "overall": 0.6895238095238095
    }
  },
  {
    "text": "## Configuration and Usage",
    "metadata": {
      "chunk_id": "847ef7345741-0007",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "filename": "..._populate_matrices_....md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Configuration and Usage"
      ],
      "heading_text": "Configuration and Usage",
      "token_count": 4,
      "char_count": 26,
      "start_char": 1989,
      "end_char": 2015,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.877768",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 4,
      "document_id": "847ef7345741",
      "document_name": "..._populate_matrices_...",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "source_filename": "..._populate_matrices_....md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "hierarchy_path": "Configuration and Usage",
      "chunk_hash": "6d90edbb3493ec73",
      "content_digest": "6d90edbb3493ec73",
      "chunk_length": 26,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "configuration",
          "and",
          "usage"
        ],
        "term_weights": [
          {
            "term": "configuration",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "usage",
            "tf": 1,
            "weight": 0.333333
          }
        ],
        "unique_terms": 3,
        "total_terms": 3
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Configuration and Usage",
        "and",
        "configuration",
        "usage"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Basic Usage Pattern ```python from sentence_transformers.cross_encoder import CrossEncoder, CrossEncoderTrainer, losses from datasets import Dataset  model = CrossEncoder(\"microsoft/mpnet-base\") train_dataset = Dataset.from_dict({     \"query\": [\"What are pandas?\", \"What is the capital of France?\"],     \"docs\": [         [\"Pandas are a kind of bear.\", \"Pandas are kind of like fish.\"],         [\"The capital of France is Paris.\", \"Paris is quite large.\"],     ],     \"labels\": [[1, 0], [1, 0]], })",
    "metadata": {
      "chunk_id": "847ef7345741-0008",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "filename": "..._populate_matrices_....md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Basic Usage Pattern"
      ],
      "heading_text": "Basic Usage Pattern",
      "token_count": 123,
      "char_count": 502,
      "start_char": 2017,
      "end_char": 2519,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5319354838709677,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.878641",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 123,
      "document_id": "847ef7345741",
      "document_name": "..._populate_matrices_...",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "source_filename": "..._populate_matrices_....md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "hierarchy_path": "Basic Usage Pattern",
      "chunk_hash": "4f3d3ef55a9be8a2",
      "content_digest": "4f3d3ef55a9be8a2",
      "chunk_length": 502,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "from",
          "dataset",
          "are",
          "pandas",
          "import",
          "crossencoder",
          "what",
          "the",
          "capital",
          "france",
          "kind",
          "paris",
          "basic",
          "usage",
          "pattern",
          "python",
          "sentence",
          "transformers",
          "cross",
          "encoder"
        ],
        "term_weights": [
          {
            "term": "from",
            "tf": 3,
            "weight": 0.056604
          },
          {
            "term": "dataset",
            "tf": 3,
            "weight": 0.056604
          },
          {
            "term": "are",
            "tf": 3,
            "weight": 0.056604
          },
          {
            "term": "pandas",
            "tf": 3,
            "weight": 0.056604
          },
          {
            "term": "import",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "crossencoder",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "what",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "capital",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "france",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "kind",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "paris",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "basic",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "usage",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "pattern",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "cross",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "encoder",
            "tf": 1,
            "weight": 0.018868
          }
        ],
        "unique_terms": 37,
        "total_terms": 53
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Basic Usage Pattern",
        "are",
        "capital",
        "crossencoder",
        "dataset",
        "france",
        "from",
        "import",
        "pandas",
        "the",
        "what"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5319354838709677,
      "overall": 0.7106451612903225
    }
  }
]
[
  {
    "text": "### Training Dependencies  For training workflows, additional dependencies provide enhanced functionality: ```mermaid graph LR     subgraph \"Core Training\"         SentenceTransformers[\"sentence-transformers[train]\"]         Accelerate[\"accelerate\"]         Datasets[\"datasets\"]     end          subgraph \"Optional Training Tools\"         WandB[\"wandb<br/>(tracking)\"]         CodeCarbon[\"codecarbon<br/>(emissions)\"]     end          subgraph \"Training Components\"         SentenceTransformers --> Trainers[\"SentenceTransformerTrainer<br/>SparseEncoderTrainer<br/>CrossEncoderTrainer\"]         Accelerate --> DistributedTraining[\"Distributed training\"]         Datasets --> DataLoading[\"Dataset loading\"]                  WandB --> LogTracking[\"Training log tracking\"]         CodeCarbon --> ModelCards[\"Automatic model card generation\"]     end ``` Install recommended training tools: ```bash pip install wandb        # For experiment tracking pip install codecarbon   # For carbon emissions tracking ```",
    "metadata": {
      "chunk_id": "3cc3e66b4126-0001",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Development_setup.md",
      "filename": "Development_setup.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Training Dependencies"
      ],
      "heading_text": "Training Dependencies",
      "token_count": 193,
      "char_count": 1006,
      "start_char": 281,
      "end_char": 1287,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5031578947368421,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.153730",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 193,
      "document_id": "3cc3e66b4126",
      "document_name": "Development_setup",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Development_setup.md",
      "source_filename": "Development_setup.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Development_setup.md",
      "hierarchy_path": "Training Dependencies",
      "chunk_hash": "2712ec31ff41afa1",
      "content_digest": "2712ec31ff41afa1",
      "chunk_length": 1006,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "training",
          "wandb",
          "tracking",
          "codecarbon",
          "for",
          "subgraph",
          "accelerate",
          "datasets",
          "end",
          "install",
          "dependencies",
          "sentencetransformers",
          "tools",
          "emissions",
          "pip",
          "workflows",
          "additional",
          "provide",
          "enhanced",
          "functionality"
        ],
        "term_weights": [
          {
            "term": "training",
            "tf": 8,
            "weight": 0.098765
          },
          {
            "term": "wandb",
            "tf": 4,
            "weight": 0.049383
          },
          {
            "term": "tracking",
            "tf": 4,
            "weight": 0.049383
          },
          {
            "term": "codecarbon",
            "tf": 4,
            "weight": 0.049383
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.037037
          },
          {
            "term": "subgraph",
            "tf": 3,
            "weight": 0.037037
          },
          {
            "term": "accelerate",
            "tf": 3,
            "weight": 0.037037
          },
          {
            "term": "datasets",
            "tf": 3,
            "weight": 0.037037
          },
          {
            "term": "end",
            "tf": 3,
            "weight": 0.037037
          },
          {
            "term": "install",
            "tf": 3,
            "weight": 0.037037
          },
          {
            "term": "dependencies",
            "tf": 2,
            "weight": 0.024691
          },
          {
            "term": "sentencetransformers",
            "tf": 2,
            "weight": 0.024691
          },
          {
            "term": "tools",
            "tf": 2,
            "weight": 0.024691
          },
          {
            "term": "emissions",
            "tf": 2,
            "weight": 0.024691
          },
          {
            "term": "pip",
            "tf": 2,
            "weight": 0.024691
          },
          {
            "term": "workflows",
            "tf": 1,
            "weight": 0.012346
          },
          {
            "term": "additional",
            "tf": 1,
            "weight": 0.012346
          },
          {
            "term": "provide",
            "tf": 1,
            "weight": 0.012346
          },
          {
            "term": "enhanced",
            "tf": 1,
            "weight": 0.012346
          },
          {
            "term": "functionality",
            "tf": 1,
            "weight": 0.012346
          }
        ],
        "unique_terms": 48,
        "total_terms": 81
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Training Dependencies",
        "accelerate",
        "codecarbon",
        "datasets",
        "end",
        "for",
        "install",
        "subgraph",
        "tracking",
        "training",
        "wandb"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5031578947368421,
      "overall": 0.7343859649122807
    }
  },
  {
    "text": "### PyTorch CUDA Installation  For GPU acceleration, install PyTorch with CUDA support before installing sentence-transformers: ```mermaid graph TD     subgraph \"CUDA Setup Process\"         CheckCUDA[\"Check CUDA availability\"]         InstallPyTorch[\"Install PyTorch with CUDA\"]         InstallST[\"Install sentence-transformers\"]         VerifyGPU[\"Verify GPU detection\"]     end          subgraph \"Verification Commands\"         CheckCUDA --> CUDACheck[\"torch.cuda.is_available()\"]         InstallPyTorch --> PyTorchInstall[\"pip install torch torchvision<br/>--index-url https://download.pytorch.org/whl/cu121\"]         VerifyGPU --> GPUCheck[\"model.device<br/>torch.cuda.device_count()\"]     end ``` Follow the [PyTorch installation guide](https://pytorch.org/get-started/locally/) for your specific CUDA version and system configuration. **Sources:** [docs/installation.md:175-177]()",
    "metadata": {
      "chunk_id": "3cc3e66b4126-0010",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Development_setup.md",
      "filename": "Development_setup.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "PyTorch CUDA Installation"
      ],
      "heading_text": "PyTorch CUDA Installation",
      "token_count": 195,
      "char_count": 886,
      "start_char": 2666,
      "end_char": 3552,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.728235294117647,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.161928",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 195,
      "document_id": "3cc3e66b4126",
      "document_name": "Development_setup",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Development_setup.md",
      "source_filename": "Development_setup.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Development_setup.md",
      "hierarchy_path": "PyTorch CUDA Installation",
      "chunk_hash": "d2793a6b28d3cf10",
      "content_digest": "d2793a6b28d3cf10",
      "chunk_length": 886,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cuda",
          "pytorch",
          "install",
          "installation",
          "torch",
          "for",
          "gpu",
          "with",
          "sentence",
          "transformers",
          "subgraph",
          "checkcuda",
          "installpytorch",
          "verifygpu",
          "end",
          "https",
          "org",
          "device",
          "acceleration",
          "support"
        ],
        "term_weights": [
          {
            "term": "cuda",
            "tf": 8,
            "weight": 0.085106
          },
          {
            "term": "pytorch",
            "tf": 6,
            "weight": 0.06383
          },
          {
            "term": "install",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "installation",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "torch",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "gpu",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "subgraph",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "checkcuda",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "installpytorch",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "verifygpu",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "org",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "device",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "acceleration",
            "tf": 1,
            "weight": 0.010638
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.010638
          }
        ],
        "unique_terms": 62,
        "total_terms": 94
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "PyTorch CUDA Installation",
        "cuda",
        "for",
        "gpu",
        "install",
        "installation",
        "pytorch",
        "sentence",
        "torch",
        "transformers",
        "with"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.728235294117647,
      "overall": 0.776078431372549
    }
  },
  {
    "text": "### Basic Functionality Test  After installation, verify the setup works correctly: ```python",
    "metadata": {
      "chunk_id": "3cc3e66b4126-0012",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Development_setup.md",
      "filename": "Development_setup.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Basic Functionality Test"
      ],
      "heading_text": "Basic Functionality Test",
      "token_count": 17,
      "char_count": 93,
      "start_char": 3587,
      "end_char": 3680,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.163053",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 17,
      "document_id": "3cc3e66b4126",
      "document_name": "Development_setup",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Development_setup.md",
      "source_filename": "Development_setup.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Development_setup.md",
      "hierarchy_path": "Basic Functionality Test",
      "chunk_hash": "ac78ace8b987547c",
      "content_digest": "ac78ace8b987547c",
      "chunk_length": 93,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "basic",
          "functionality",
          "test",
          "after",
          "installation",
          "verify",
          "the",
          "setup",
          "works",
          "correctly",
          "python"
        ],
        "term_weights": [
          {
            "term": "basic",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "functionality",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "test",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "after",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "installation",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "verify",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "setup",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "works",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "correctly",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.090909
          }
        ],
        "unique_terms": 11,
        "total_terms": 11
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Basic Functionality Test",
        "after",
        "basic",
        "correctly",
        "functionality",
        "installation",
        "setup",
        "test",
        "the",
        "verify",
        "works"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  }
]
[
  {
    "text": "### Configuration Parameters  Common parameters across learning-to-rank losses:  | Parameter | Type | Purpose | |-----------|------|---------| | `model` | `CrossEncoder` | Model to train | | `activation_fn` | `nn.Module` | Applied to logits before loss computation | | `mini_batch_size` | `int` | Controls memory usage and processing speed |  Sources: [examples/cross_encoder/training/ms_marco/training_ms_marco_listmle.py:93-94](), [examples/cross_encoder/training/ms_marco/training_ms_marco_plistmle.py:96]()",
    "metadata": {
      "chunk_id": "14493e9a2df7-0000",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Configuration Parameters"
      ],
      "heading_text": "Configuration Parameters",
      "token_count": 129,
      "char_count": 510,
      "start_char": 119,
      "end_char": 629,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.691923076923077,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.518013",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 129,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Configuration Parameters",
      "chunk_hash": "046915b66b14a05e",
      "content_digest": "046915b66b14a05e",
      "chunk_length": 510,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "training",
          "marco",
          "parameters",
          "model",
          "examples",
          "cross",
          "encoder",
          "configuration",
          "common",
          "across",
          "learning",
          "rank",
          "losses",
          "parameter",
          "type",
          "purpose",
          "crossencoder",
          "train",
          "activation",
          "module"
        ],
        "term_weights": [
          {
            "term": "training",
            "tf": 4,
            "weight": 0.081633
          },
          {
            "term": "marco",
            "tf": 4,
            "weight": 0.081633
          },
          {
            "term": "parameters",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "cross",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "configuration",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "common",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "across",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "learning",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "rank",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "losses",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "parameter",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "type",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "purpose",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "train",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "activation",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "module",
            "tf": 1,
            "weight": 0.020408
          }
        ],
        "unique_terms": 38,
        "total_terms": 49
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Configuration Parameters",
        "across",
        "common",
        "configuration",
        "cross",
        "encoder",
        "examples",
        "marco",
        "model",
        "parameters",
        "training"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.691923076923077,
      "overall": 0.7973076923076922
    }
  },
  {
    "text": "## Performance Recommendations\n\nBased on the documentation and implementation comments:\n\n1. **LambdaLoss with NDCGLoss2PPScheme**: Generally performs best for ranking tasks\n2. **PListMLELoss**: Outperforms standard ListMLELoss due to position weighting\n3. **Mini-batch size**: Critical for memory management when processing many documents per query\n4. **Hard negative mining**: Use `mine_hard_negatives` with `output_format=\"labeled-list\"` for better training data\n\nThe learning-to-rank losses are optimized for handling variable numbers of documents per query and support both binary and continuous relevance labels.\n\nSources: [sentence_transformers/cross_encoder/losses/LambdaLoss.py:175-176](), [sentence_transformers/cross_encoder/losses/PListMLELoss.py:105-111](), [examples/cross_encoder/training/ms_marco/training_ms_marco_cmnrl.py:62-71]()",
    "metadata": {
      "chunk_id": "14493e9a2df7-0001",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Recommendations"
      ],
      "heading_text": "Performance Recommendations",
      "token_count": 192,
      "char_count": 847,
      "start_char": 631,
      "end_char": 1478,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7520253164556961,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.519063",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 192,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Performance Recommendations",
      "chunk_hash": "bc954a1f227ec188",
      "content_digest": "bc954a1f227ec188",
      "chunk_length": 847,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "for",
          "and",
          "training",
          "losses",
          "cross",
          "encoder",
          "the",
          "lambdaloss",
          "with",
          "plistmleloss",
          "documents",
          "per",
          "query",
          "hard",
          "sentence",
          "transformers",
          "marco",
          "performance",
          "recommendations",
          "based"
        ],
        "term_weights": [
          {
            "term": "for",
            "tf": 4,
            "weight": 0.040404
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.030303
          },
          {
            "term": "training",
            "tf": 3,
            "weight": 0.030303
          },
          {
            "term": "losses",
            "tf": 3,
            "weight": 0.030303
          },
          {
            "term": "cross",
            "tf": 3,
            "weight": 0.030303
          },
          {
            "term": "encoder",
            "tf": 3,
            "weight": 0.030303
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "lambdaloss",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "plistmleloss",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "documents",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "per",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "hard",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "marco",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.010101
          },
          {
            "term": "recommendations",
            "tf": 1,
            "weight": 0.010101
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.010101
          }
        ],
        "unique_terms": 75,
        "total_terms": 99
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Recommendations",
        "and",
        "cross",
        "encoder",
        "for",
        "lambdaloss",
        "losses",
        "plistmleloss",
        "the",
        "training",
        "with"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7520253164556961,
      "overall": 0.7173417721518986
    }
  },
  {
    "text": "# Memory-Efficient Training\n\n\n\n\nThis document covers memory-efficient training techniques in sentence-transformers that allow training with large batch sizes and complex loss functions while maintaining reasonable memory usage. These techniques are essential for achieving optimal performance on modern embedding models without requiring excessive GPU memory.\n\nFor general training information, see [SentenceTransformer Training](#3.1). For specific loss functions, see [Loss Functions for SentenceTransformer](#3.4).",
    "metadata": {
      "chunk_id": "14493e9a2df7-0002",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Memory-Efficient Training"
      ],
      "heading_text": "Memory-Efficient Training",
      "token_count": 87,
      "char_count": 517,
      "start_char": 1480,
      "end_char": 1997,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.535,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.519537",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 87,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Memory-Efficient Training",
      "chunk_hash": "684dfcc4a0adab59",
      "content_digest": "684dfcc4a0adab59",
      "chunk_length": 517,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "training",
          "memory",
          "for",
          "loss",
          "functions",
          "efficient",
          "techniques",
          "see",
          "sentencetransformer",
          "this",
          "document",
          "covers",
          "sentence",
          "transformers",
          "that",
          "allow",
          "with",
          "large",
          "batch",
          "sizes"
        ],
        "term_weights": [
          {
            "term": "training",
            "tf": 5,
            "weight": 0.083333
          },
          {
            "term": "memory",
            "tf": 4,
            "weight": 0.066667
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.066667
          },
          {
            "term": "loss",
            "tf": 3,
            "weight": 0.05
          },
          {
            "term": "functions",
            "tf": 3,
            "weight": 0.05
          },
          {
            "term": "efficient",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "techniques",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "see",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "sentencetransformer",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "covers",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "allow",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "large",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "batch",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "sizes",
            "tf": 1,
            "weight": 0.016667
          }
        ],
        "unique_terms": 42,
        "total_terms": 60
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Memory-Efficient Training",
        "efficient",
        "for",
        "functions",
        "loss",
        "memory",
        "see",
        "sentencetransformer",
        "techniques",
        "this",
        "training"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.535,
      "overall": 0.745
    }
  },
  {
    "text": "## Cached Loss Functions\n\nThe primary memory-efficient training technique uses **GradCache**, which enables training with much larger effective batch sizes while maintaining constant memory usage. This is implemented through cached versions of standard loss functions.",
    "metadata": {
      "chunk_id": "14493e9a2df7-0003",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Cached Loss Functions"
      ],
      "heading_text": "Cached Loss Functions",
      "token_count": 42,
      "char_count": 268,
      "start_char": 1999,
      "end_char": 2267,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5642857142857143,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.519803",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 42,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Cached Loss Functions",
      "chunk_hash": "5b6a27ca6566f4ed",
      "content_digest": "5b6a27ca6566f4ed",
      "chunk_length": 268,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cached",
          "loss",
          "functions",
          "memory",
          "training",
          "the",
          "primary",
          "efficient",
          "technique",
          "uses",
          "gradcache",
          "which",
          "enables",
          "with",
          "much",
          "larger",
          "effective",
          "batch",
          "sizes",
          "while"
        ],
        "term_weights": [
          {
            "term": "cached",
            "tf": 2,
            "weight": 0.060606
          },
          {
            "term": "loss",
            "tf": 2,
            "weight": 0.060606
          },
          {
            "term": "functions",
            "tf": 2,
            "weight": 0.060606
          },
          {
            "term": "memory",
            "tf": 2,
            "weight": 0.060606
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.060606
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "primary",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "efficient",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "technique",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "uses",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "gradcache",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "which",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "enables",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "much",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "larger",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "effective",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "batch",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "sizes",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "while",
            "tf": 1,
            "weight": 0.030303
          }
        ],
        "unique_terms": 28,
        "total_terms": 33
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Cached Loss Functions",
        "cached",
        "efficient",
        "functions",
        "loss",
        "memory",
        "primary",
        "technique",
        "the",
        "training",
        "uses"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5642857142857143,
      "overall": 0.7547619047619047
    }
  },
  {
    "text": "### Available Cached Loss Functions  | Standard Loss | Cached Version | Memory Benefit | |---------------|----------------|----------------| | `MultipleNegativesRankingLoss` | `CachedMultipleNegativesRankingLoss` | Constant memory for any batch size | | `GISTEmbedLoss` | `CachedGISTEmbedLoss` | Large batch sizes with guide model | | `MultipleNegativesSymmetricRankingLoss` | `CachedMultipleNegativesSymmetricRankingLoss` | Symmetric loss with caching |  **Sources:** [sentence_transformers/losses/CachedMultipleNegativesRankingLoss.py:64](), [sentence_transformers/losses/CachedGISTEmbedLoss.py:65](), [sentence_transformers/losses/CachedMultipleNegativesSymmetricRankingLoss.py:41]()",
    "metadata": {
      "chunk_id": "14493e9a2df7-0005",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Available Cached Loss Functions"
      ],
      "heading_text": "Available Cached Loss Functions",
      "token_count": 166,
      "char_count": 686,
      "start_char": 3446,
      "end_char": 4132,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6733333333333333,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.523719",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 166,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Available Cached Loss Functions",
      "chunk_hash": "9189223d57bc0ad3",
      "content_digest": "9189223d57bc0ad3",
      "chunk_length": 686,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "loss",
          "sentence",
          "transformers",
          "losses",
          "cached",
          "memory",
          "cachedmultiplenegativesrankingloss",
          "batch",
          "cachedgistembedloss",
          "with",
          "cachedmultiplenegativessymmetricrankingloss",
          "available",
          "functions",
          "standard",
          "version",
          "benefit",
          "multiplenegativesrankingloss",
          "constant",
          "for",
          "any"
        ],
        "term_weights": [
          {
            "term": "loss",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "losses",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "cached",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "memory",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "cachedmultiplenegativesrankingloss",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "batch",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "cachedgistembedloss",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "cachedmultiplenegativessymmetricrankingloss",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "available",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "standard",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "version",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "benefit",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "multiplenegativesrankingloss",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "constant",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "any",
            "tf": 1,
            "weight": 0.022222
          }
        ],
        "unique_terms": 30,
        "total_terms": 45
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Available Cached Loss Functions",
        "batch",
        "cached",
        "cachedgistembedloss",
        "cachedmultiplenegativesrankingloss",
        "loss",
        "losses",
        "memory",
        "sentence",
        "transformers",
        "with"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6733333333333333,
      "overall": 0.791111111111111
    }
  },
  {
    "text": "### Mini-batch Processing Implementation ```mermaid graph LR     Batch[\"Full Batch\"] --> Iterator[\"embed_minibatch_iter()\"]     Iterator --> MB1[\"Mini-batch 1<br/>embed_minibatch()\"]     Iterator --> MB2[\"Mini-batch 2<br/>embed_minibatch()\"]     Iterator --> MB3[\"Mini-batch N<br/>embed_minibatch()\"]     MB1 --> RS1[\"RandContext<br/>(Random State)\"]     MB2 --> RS2[\"RandContext<br/>(Random State)\"]     MB3 --> RS3[\"RandContext<br/>(Random State)\"]     RS1 --> Cache1[\"Cached Embeddings\"]     RS2 --> Cache2[\"Cached Embeddings\"]     RS3 --> Cache3[\"Cached Embeddings\"] ``` The `mini_batch_size` parameter controls memory usage during training. Each mini-batch is processed through `embed_minibatch()` with `RandContext` ensuring reproducible embeddings across forward passes. **Sources:** [sentence_transformers/losses/CachedMultipleNegativesRankingLoss.py:175-223](), [sentence_transformers/losses/CachedMultipleNegativesRankingLoss.py:18-39]()",
    "metadata": {
      "chunk_id": "14493e9a2df7-0006",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Mini-batch Processing Implementation"
      ],
      "heading_text": "Mini-batch Processing Implementation",
      "token_count": 250,
      "char_count": 947,
      "start_char": 4134,
      "end_char": 5081,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5242465753424658,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.526842",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 250,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Mini-batch Processing Implementation",
      "chunk_hash": "ea1a94d6818bc22c",
      "content_digest": "ea1a94d6818bc22c",
      "chunk_length": 947,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "batch",
          "mini",
          "embed",
          "minibatch",
          "iterator",
          "randcontext",
          "embeddings",
          "random",
          "state",
          "cached",
          "mb1",
          "mb2",
          "mb3",
          "rs1",
          "rs2",
          "rs3",
          "sentence",
          "transformers",
          "losses",
          "cachedmultiplenegativesrankingloss"
        ],
        "term_weights": [
          {
            "term": "batch",
            "tf": 8,
            "weight": 0.085106
          },
          {
            "term": "mini",
            "tf": 6,
            "weight": 0.06383
          },
          {
            "term": "embed",
            "tf": 5,
            "weight": 0.053191
          },
          {
            "term": "minibatch",
            "tf": 5,
            "weight": 0.053191
          },
          {
            "term": "iterator",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "randcontext",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "embeddings",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "random",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "state",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "cached",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "mb1",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "mb2",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "mb3",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "rs1",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "rs2",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "rs3",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "losses",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "cachedmultiplenegativesrankingloss",
            "tf": 2,
            "weight": 0.021277
          }
        ],
        "unique_terms": 49,
        "total_terms": 94
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Mini-batch Processing Implementation",
        "batch",
        "cached",
        "embed",
        "embeddings",
        "iterator",
        "mini",
        "minibatch",
        "randcontext",
        "random",
        "state"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5242465753424658,
      "overall": 0.7414155251141552
    }
  },
  {
    "text": "## Matryoshka Training\n\nMatryoshka training allows models to work efficiently at multiple embedding dimensions, reducing storage and computation costs for downstream applications.",
    "metadata": {
      "chunk_id": "14493e9a2df7-0007",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Matryoshka Training"
      ],
      "heading_text": "Matryoshka Training",
      "token_count": 31,
      "char_count": 179,
      "start_char": 5086,
      "end_char": 5265,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5627272727272727,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.527476",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 31,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Matryoshka Training",
      "chunk_hash": "5f580320c05f3da4",
      "content_digest": "5f580320c05f3da4",
      "chunk_length": 179,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "matryoshka",
          "training",
          "allows",
          "models",
          "work",
          "efficiently",
          "multiple",
          "embedding",
          "dimensions",
          "reducing",
          "storage",
          "and",
          "computation",
          "costs",
          "for",
          "downstream",
          "applications"
        ],
        "term_weights": [
          {
            "term": "matryoshka",
            "tf": 2,
            "weight": 0.105263
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.105263
          },
          {
            "term": "allows",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "work",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "efficiently",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "dimensions",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "reducing",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "storage",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "computation",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "costs",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "downstream",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "applications",
            "tf": 1,
            "weight": 0.052632
          }
        ],
        "unique_terms": 17,
        "total_terms": 19
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Matryoshka Training",
        "allows",
        "dimensions",
        "efficiently",
        "embedding",
        "matryoshka",
        "models",
        "multiple",
        "reducing",
        "training",
        "work"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5627272727272727,
      "overall": 0.7542424242424243
    }
  },
  {
    "text": "### MatryoshkaLoss Architecture ```mermaid flowchart TD     Model[\"SentenceTransformer\"] --> Forward[\"ForwardDecorator\"]     Loss[\"Base Loss Function\"] --> Matryoshka[\"MatryoshkaLoss\"]     Dims[\"matryoshka_dims<br/>[768, 512, 256, 128, 64]\"] --> Matryoshka     Weights[\"matryoshka_weights<br/>[1, 1, 1, 1, 1]\"] --> Matryoshka          Forward --> Cache[\"Cache Full Embeddings\"]     Cache --> Shrink1[\"shrink(embeddings, 768)\"]     Cache --> Shrink2[\"shrink(embeddings, 512)\"]     Cache --> Shrink3[\"shrink(embeddings, 256)\"]     Cache --> Shrink4[\"shrink(embeddings, 128)\"]     Cache --> Shrink5[\"shrink(embeddings, 64)\"]          Shrink1 --> Loss1[\"Loss at 768d\"]     Shrink2 --> Loss2[\"Loss at 512d\"]     Shrink3 --> Loss3[\"Loss at 256d\"]     Shrink4 --> Loss4[\"Loss at 128d\"]     Shrink5 --> Loss5[\"Loss at 64d\"]          Loss1 --> Combine[\"Weighted Sum\"]     Loss2 --> Combine     Loss3 --> Combine     Loss4 --> Combine     Loss5 --> Combine ``` **Sources:** [sentence_transformers/losses/MatryoshkaLoss.py:113-253](), [sentence_transformers/losses/MatryoshkaLoss.py:30-111]()",
    "metadata": {
      "chunk_id": "14493e9a2df7-0008",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "MatryoshkaLoss Architecture"
      ],
      "heading_text": "MatryoshkaLoss Architecture",
      "token_count": 341,
      "char_count": 1081,
      "start_char": 5267,
      "end_char": 6348,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5012795918367347,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.530580",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 341,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "MatryoshkaLoss Architecture",
      "chunk_hash": "ed0c2cda2f90e4a0",
      "content_digest": "ed0c2cda2f90e4a0",
      "chunk_length": 1081,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "loss",
          "cache",
          "embeddings",
          "matryoshka",
          "shrink",
          "combine",
          "matryoshkaloss",
          "forward",
          "dims",
          "768",
          "512",
          "256",
          "128",
          "weights",
          "shrink1",
          "shrink2",
          "shrink3",
          "shrink4",
          "shrink5",
          "loss1"
        ],
        "term_weights": [
          {
            "term": "loss",
            "tf": 7,
            "weight": 0.070707
          },
          {
            "term": "cache",
            "tf": 7,
            "weight": 0.070707
          },
          {
            "term": "embeddings",
            "tf": 6,
            "weight": 0.060606
          },
          {
            "term": "matryoshka",
            "tf": 5,
            "weight": 0.050505
          },
          {
            "term": "shrink",
            "tf": 5,
            "weight": 0.050505
          },
          {
            "term": "combine",
            "tf": 5,
            "weight": 0.050505
          },
          {
            "term": "matryoshkaloss",
            "tf": 4,
            "weight": 0.040404
          },
          {
            "term": "forward",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "dims",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "768",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "512",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "256",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "128",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "weights",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "shrink1",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "shrink2",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "shrink3",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "shrink4",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "shrink5",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "loss1",
            "tf": 2,
            "weight": 0.020202
          }
        ],
        "unique_terms": 47,
        "total_terms": 99
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "768",
        "MatryoshkaLoss Architecture",
        "cache",
        "combine",
        "dims",
        "embeddings",
        "forward",
        "loss",
        "matryoshka",
        "matryoshkaloss",
        "shrink"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5012795918367347,
      "overall": 0.7337598639455781
    }
  },
  {
    "text": "## Router-based Asymmetric Models\n\nThe `Router` module enables memory-efficient asymmetric architectures where different encoders are used for queries and documents.",
    "metadata": {
      "chunk_id": "14493e9a2df7-0010",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Router-based Asymmetric Models"
      ],
      "heading_text": "Router-based Asymmetric Models",
      "token_count": 28,
      "char_count": 165,
      "start_char": 6935,
      "end_char": 7100,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.575,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.533802",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 28,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Router-based Asymmetric Models",
      "chunk_hash": "de3bfbaa2582efa1",
      "content_digest": "de3bfbaa2582efa1",
      "chunk_length": 165,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "router",
          "asymmetric",
          "based",
          "models",
          "the",
          "module",
          "enables",
          "memory",
          "efficient",
          "architectures",
          "where",
          "different",
          "encoders",
          "are",
          "used",
          "for",
          "queries",
          "and",
          "documents"
        ],
        "term_weights": [
          {
            "term": "router",
            "tf": 2,
            "weight": 0.095238
          },
          {
            "term": "asymmetric",
            "tf": 2,
            "weight": 0.095238
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "module",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "enables",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "memory",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "efficient",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "architectures",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "encoders",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "used",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "queries",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.047619
          }
        ],
        "unique_terms": 19,
        "total_terms": 21
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Router-based Asymmetric Models",
        "architectures",
        "asymmetric",
        "based",
        "efficient",
        "enables",
        "memory",
        "models",
        "module",
        "router",
        "the"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.575,
      "overall": 0.7583333333333333
    }
  },
  {
    "text": "### Router Architecture ```mermaid graph TD     Input[\"features: dict[str, Tensor]\"] --> RouterFwd[\"Router.forward()\"]     RouterFwd --> TaskCheck{\"task = features.get('task', self.default_route)\"}     TaskCheck -->|\"task='query'\"| QuerySeq[\"self.sub_modules['query']\"]     TaskCheck -->|\"task='document'\"| DocSeq[\"self.sub_modules['document']\"]     TaskCheck -->|\"None\"| DefaultRoute[\"self.default_route\"]          QuerySeq --> QMod1[\"SparseStaticEmbedding\"]     QuerySeq --> QMod2[\"Additional Query Modules\"]          DocSeq --> DMod1[\"MLMTransformer\"]     DocSeq --> DMod2[\"SpladePooling\"]          Training[\"Training Phase\"] --> RouterMap[\"router_mapping in TrainingArguments\"]     RouterMap --> DataCollator[\"SentenceTransformerDataCollator\"]     DataCollator --> TaskAssign[\"task = router_mapping.get(column_name)\"]     TaskAssign --> TokenizeFn[\"self.tokenize_fn(inputs, task=task)\"] ``` This enables memory-efficient asymmetric training where lightweight query encoders (e.g., `SparseStaticEmbedding`) can be combined with powerful document encoders, reducing both training and inference costs. **Sources:** [sentence_transformers/models/Router.py:217-245](), [sentence_transformers/models/Router.py:287-324](), [sentence_transformers/data_collator.py:90-118]()",
    "metadata": {
      "chunk_id": "14493e9a2df7-0011",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Router Architecture"
      ],
      "heading_text": "Router Architecture",
      "token_count": 298,
      "char_count": 1269,
      "start_char": 7102,
      "end_char": 8371,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5348275862068965,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.537798",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 298,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Router Architecture",
      "chunk_hash": "c76884d7457b04b9",
      "content_digest": "c76884d7457b04b9",
      "chunk_length": 1269,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "task",
          "router",
          "self",
          "taskcheck",
          "query",
          "training",
          "queryseq",
          "modules",
          "document",
          "docseq",
          "sentence",
          "transformers",
          "features",
          "routerfwd",
          "get",
          "default",
          "route",
          "sub",
          "sparsestaticembedding",
          "routermap"
        ],
        "term_weights": [
          {
            "term": "task",
            "tf": 7,
            "weight": 0.056911
          },
          {
            "term": "router",
            "tf": 6,
            "weight": 0.04878
          },
          {
            "term": "self",
            "tf": 5,
            "weight": 0.04065
          },
          {
            "term": "taskcheck",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "query",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "training",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "queryseq",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "modules",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "document",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "docseq",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "features",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "routerfwd",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "get",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "default",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "route",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "sub",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "sparsestaticembedding",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "routermap",
            "tf": 2,
            "weight": 0.01626
          }
        ],
        "unique_terms": 74,
        "total_terms": 123
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Router Architecture",
        "docseq",
        "document",
        "modules",
        "query",
        "queryseq",
        "router",
        "self",
        "task",
        "taskcheck",
        "training"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5348275862068965,
      "overall": 0.7116091954022988
    }
  },
  {
    "text": "### Data Collator Memory Optimizations  The `SentenceTransformerDataCollator` includes several memory-efficient features: ```mermaid graph TD     DataCollator[\"SentenceTransformerDataCollator.__call__()\"] --> RouterMap[\"self.router_mapping\"]     DataCollator --> Prompts[\"self.prompts\"]     DataCollator --> PromptCache[\"self._prompt_length_mapping\"]          RouterMap --> TaskAssign[\"task = router_mapping.get(column_name)\"]     Prompts --> PromptCheck[\"if isinstance(prompts, str)\"]     PromptCheck --> PromptPrefix[\"prompt + row[column_name]\"]          PromptCache --> GetPromptLen[\"_get_prompt_length()\"]     GetPromptLen --> TokenizeOnce[\"tokenize_fn([prompt], task=task)\"]     TokenizeOnce --> CacheLen[\"_prompt_length_mapping[(prompt, task)]\"]          TaskAssign --> TokenizeFn[\"tokenize_fn(inputs, task=task)\"]     TokenizeFn --> BatchKeys[\"batch[f'{column_name}_{key}'] = value\"] ``` The prompt length caching in `_get_prompt_length()` prevents repeated tokenization of the same prompts, significantly reducing memory overhead during data loading. **Sources:** [sentence_transformers/data_collator.py:35-119](), [sentence_transformers/data_collator.py:121-138]()",
    "metadata": {
      "chunk_id": "14493e9a2df7-0015",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Data Collator Memory Optimizations"
      ],
      "heading_text": "Data Collator Memory Optimizations",
      "token_count": 266,
      "char_count": 1173,
      "start_char": 10211,
      "end_char": 11384,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5278048780487805,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.546852",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 266,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Data Collator Memory Optimizations",
      "chunk_hash": "c6f22ea86b962d3a",
      "content_digest": "c6f22ea86b962d3a",
      "chunk_length": 1173,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "prompt",
          "task",
          "prompts",
          "length",
          "data",
          "mapping",
          "collator",
          "memory",
          "the",
          "datacollator",
          "self",
          "get",
          "column",
          "name",
          "sentencetransformerdatacollator",
          "routermap",
          "router",
          "promptcache",
          "taskassign",
          "promptcheck"
        ],
        "term_weights": [
          {
            "term": "prompt",
            "tf": 8,
            "weight": 0.071429
          },
          {
            "term": "task",
            "tf": 6,
            "weight": 0.053571
          },
          {
            "term": "prompts",
            "tf": 5,
            "weight": 0.044643
          },
          {
            "term": "length",
            "tf": 5,
            "weight": 0.044643
          },
          {
            "term": "data",
            "tf": 4,
            "weight": 0.035714
          },
          {
            "term": "mapping",
            "tf": 4,
            "weight": 0.035714
          },
          {
            "term": "collator",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "memory",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "datacollator",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "self",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "get",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "column",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "name",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "sentencetransformerdatacollator",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "routermap",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "router",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "promptcache",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "taskassign",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "promptcheck",
            "tf": 2,
            "weight": 0.017857
          }
        ],
        "unique_terms": 58,
        "total_terms": 112
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Data Collator Memory Optimizations",
        "collator",
        "data",
        "datacollator",
        "length",
        "mapping",
        "memory",
        "prompt",
        "prompts",
        "task",
        "the"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5278048780487805,
      "overall": 0.7426016260162601
    }
  },
  {
    "text": "## Implementation Examples",
    "metadata": {
      "chunk_id": "14493e9a2df7-0016",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Implementation Examples"
      ],
      "heading_text": "Implementation Examples",
      "token_count": 3,
      "char_count": 26,
      "start_char": 11389,
      "end_char": 11415,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7899999999999999,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.547259",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 3,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Implementation Examples",
      "chunk_hash": "d23cf64f34f6464e",
      "content_digest": "d23cf64f34f6464e",
      "chunk_length": 26,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "implementation",
          "examples"
        ],
        "term_weights": [
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "examples",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Implementation Examples",
        "examples",
        "implementation"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7899999999999999,
      "overall": 0.83
    }
  },
  {
    "text": "# Standard approach - memory scales with batch size loss = MultipleNegativesRankingLoss(model)",
    "metadata": {
      "chunk_id": "14493e9a2df7-0018",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Standard approach - memory scales with batch size"
      ],
      "heading_text": "Standard approach - memory scales with batch size",
      "token_count": 19,
      "char_count": 94,
      "start_char": 11452,
      "end_char": 11546,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.547597",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 19,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Standard approach - memory scales with batch size",
      "chunk_hash": "35c8a78a9513c2e7",
      "content_digest": "35c8a78a9513c2e7",
      "chunk_length": 94,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "standard",
          "approach",
          "memory",
          "scales",
          "with",
          "batch",
          "size",
          "loss",
          "multiplenegativesrankingloss",
          "model"
        ],
        "term_weights": [
          {
            "term": "standard",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "approach",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "memory",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "scales",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "batch",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "size",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "multiplenegativesrankingloss",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.1
          }
        ],
        "unique_terms": 10,
        "total_terms": 10
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Standard approach - memory scales with batch size",
        "approach",
        "batch",
        "loss",
        "memory",
        "model",
        "multiplenegativesrankingloss",
        "scales",
        "size",
        "standard",
        "with"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "# Cached approach - constant memory usage loss = CachedMultipleNegativesRankingLoss(     model,      mini_batch_size=32,  # Controls actual memory usage     show_progress_bar=True ) ```",
    "metadata": {
      "chunk_id": "14493e9a2df7-0019",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Cached approach - constant memory usage"
      ],
      "heading_text": "Cached approach - constant memory usage",
      "token_count": 40,
      "char_count": 185,
      "start_char": 11548,
      "end_char": 11733,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.545,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.547853",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 40,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Cached approach - constant memory usage",
      "chunk_hash": "9b1afb567ffebbd8",
      "content_digest": "9b1afb567ffebbd8",
      "chunk_length": 185,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "memory",
          "usage",
          "cached",
          "approach",
          "constant",
          "loss",
          "cachedmultiplenegativesrankingloss",
          "model",
          "mini",
          "batch",
          "size",
          "controls",
          "actual",
          "show",
          "progress",
          "bar",
          "true"
        ],
        "term_weights": [
          {
            "term": "memory",
            "tf": 2,
            "weight": 0.105263
          },
          {
            "term": "usage",
            "tf": 2,
            "weight": 0.105263
          },
          {
            "term": "cached",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "approach",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "constant",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "cachedmultiplenegativesrankingloss",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "mini",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "batch",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "size",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "controls",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "actual",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "show",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "progress",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "bar",
            "tf": 1,
            "weight": 0.052632
          },
          {
            "term": "true",
            "tf": 1,
            "weight": 0.052632
          }
        ],
        "unique_terms": 17,
        "total_terms": 19
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Cached approach - constant memory usage",
        "approach",
        "batch",
        "cached",
        "cachedmultiplenegativesrankingloss",
        "constant",
        "loss",
        "memory",
        "mini",
        "model",
        "usage"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.545,
      "overall": 0.7483333333333334
    }
  },
  {
    "text": "## Trainer Memory Optimizations\n\nThe `SentenceTransformerTrainer` includes several memory-efficient features beyond cached losses:",
    "metadata": {
      "chunk_id": "14493e9a2df7-0020",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Trainer Memory Optimizations"
      ],
      "heading_text": "Trainer Memory Optimizations",
      "token_count": 22,
      "char_count": 130,
      "start_char": 11735,
      "end_char": 11865,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.548053",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 22,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Trainer Memory Optimizations",
      "chunk_hash": "4aa99fc1aef6b603",
      "content_digest": "4aa99fc1aef6b603",
      "chunk_length": 130,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "memory",
          "trainer",
          "optimizations",
          "the",
          "sentencetransformertrainer",
          "includes",
          "several",
          "efficient",
          "features",
          "beyond",
          "cached",
          "losses"
        ],
        "term_weights": [
          {
            "term": "memory",
            "tf": 2,
            "weight": 0.153846
          },
          {
            "term": "trainer",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "optimizations",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "sentencetransformertrainer",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "includes",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "several",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "efficient",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "features",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "beyond",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "cached",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "losses",
            "tf": 1,
            "weight": 0.076923
          }
        ],
        "unique_terms": 12,
        "total_terms": 13
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Trainer Memory Optimizations",
        "beyond",
        "efficient",
        "features",
        "includes",
        "memory",
        "optimizations",
        "sentencetransformertrainer",
        "several",
        "the",
        "trainer"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.59,
      "overall": 0.6966666666666667
    }
  },
  {
    "text": "### Loss Component Tracking ```mermaid graph TD     ComputeLoss[\"SentenceTransformerTrainer.compute_loss()\"] --> TrackLoss[\"track_loss_components()\"]     TrackLoss --> AccumLoss[\"self.accum_loss_components[training_type]\"]     AccumLoss --> LogLoss[\"self.log()\"]     LogLoss --> NestedGather[\"self._nested_gather()\"]     NestedGather --> AvgLoss[\"value.sum() / steps\"]          LossDict[\"loss: dict[str, torch.Tensor]\"] --> Stack[\"torch.stack(list(loss.values())).sum()\"]     Stack --> SingleLoss[\"Final Loss Tensor\"] ``` This prevents memory spikes when losses return dictionaries with multiple components by accumulating and averaging them efficiently. **Sources:** [sentence_transformers/trainer.py:443-462](), [sentence_transformers/trainer.py:464-494](), [sentence_transformers/trainer.py:431-441]()",
    "metadata": {
      "chunk_id": "14493e9a2df7-0021",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Loss Component Tracking"
      ],
      "heading_text": "Loss Component Tracking",
      "token_count": 182,
      "char_count": 804,
      "start_char": 11867,
      "end_char": 12671,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.549397",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 182,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Loss Component Tracking",
      "chunk_hash": "ed16fca8fbdcfd1a",
      "content_digest": "ed16fca8fbdcfd1a",
      "chunk_length": 804,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "loss",
          "components",
          "self",
          "stack",
          "sentence",
          "transformers",
          "trainer",
          "trackloss",
          "accumloss",
          "logloss",
          "nestedgather",
          "sum",
          "torch",
          "tensor",
          "component",
          "tracking",
          "mermaid",
          "graph",
          "computeloss",
          "sentencetransformertrainer"
        ],
        "term_weights": [
          {
            "term": "loss",
            "tf": 7,
            "weight": 0.082353
          },
          {
            "term": "components",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "self",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "stack",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "trainer",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "trackloss",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "accumloss",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "logloss",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "nestedgather",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "sum",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "torch",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "tensor",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "component",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "tracking",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "mermaid",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "graph",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "computeloss",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "sentencetransformertrainer",
            "tf": 1,
            "weight": 0.011765
          }
        ],
        "unique_terms": 60,
        "total_terms": 85
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Loss Component Tracking",
        "accumloss",
        "components",
        "logloss",
        "loss",
        "self",
        "sentence",
        "stack",
        "trackloss",
        "trainer",
        "transformers"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "overall": 0.7174999999999999
    }
  },
  {
    "text": "### Training Arguments for Memory Efficiency ```python args = SentenceTransformerTrainingArguments(     per_device_train_batch_size=1024,  # Large effective batch size     gradient_accumulation_steps=1,     # No additional accumulation needed     dataloader_drop_last=True,         # Avoid uneven batches     batch_sampler=BatchSamplers.NO_DUPLICATES,  # Memory-efficient sampling     multi_dataset_batch_sampler=MultiDatasetBatchSamplers.PROPORTIONAL, ) ``` **Sources:** [sentence_transformers/trainer.py:623-684](), [sentence_transformers/training_args.py:37-39]()",
    "metadata": {
      "chunk_id": "14493e9a2df7-0022",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Training Arguments for Memory Efficiency"
      ],
      "heading_text": "Training Arguments for Memory Efficiency",
      "token_count": 122,
      "char_count": 566,
      "start_char": 12676,
      "end_char": 13242,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5656756756756757,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.550282",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 122,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Training Arguments for Memory Efficiency",
      "chunk_hash": "8d0b4751b9b06e38",
      "content_digest": "8d0b4751b9b06e38",
      "chunk_length": 566,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "batch",
          "training",
          "memory",
          "args",
          "size",
          "accumulation",
          "sampler",
          "sentence",
          "transformers",
          "arguments",
          "for",
          "efficiency",
          "python",
          "sentencetransformertrainingarguments",
          "per",
          "device",
          "train",
          "1024",
          "large",
          "effective"
        ],
        "term_weights": [
          {
            "term": "batch",
            "tf": 4,
            "weight": 0.074074
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "memory",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "args",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "size",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "accumulation",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "sampler",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "arguments",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "efficiency",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "sentencetransformertrainingarguments",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "per",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "device",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "train",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "1024",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "large",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "effective",
            "tf": 1,
            "weight": 0.018519
          }
        ],
        "unique_terms": 43,
        "total_terms": 54
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Training Arguments for Memory Efficiency",
        "accumulation",
        "args",
        "arguments",
        "batch",
        "memory",
        "sampler",
        "sentence",
        "size",
        "training",
        "transformers"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5656756756756757,
      "overall": 0.7218918918918918
    }
  },
  {
    "text": "### Router Training Configuration ```python",
    "metadata": {
      "chunk_id": "14493e9a2df7-0023",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "file_extension": ".md",
      "chunk_index": 23,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Router Training Configuration"
      ],
      "heading_text": "Router Training Configuration",
      "token_count": 6,
      "char_count": 43,
      "start_char": 13246,
      "end_char": 13289,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.550566",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 6,
      "document_id": "14493e9a2df7",
      "document_name": "loss__losses.PListMLELossmodel___Position-aware_MLE",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_filename": "loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\loss__losses.PListMLELossmodel___Position-aware_MLE.md",
      "hierarchy_path": "Router Training Configuration",
      "chunk_hash": "1e1aa01fae71f343",
      "content_digest": "1e1aa01fae71f343",
      "chunk_length": 43,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "router",
          "training",
          "configuration",
          "python"
        ],
        "term_weights": [
          {
            "term": "router",
            "tf": 1,
            "weight": 0.25
          },
          {
            "term": "training",
            "tf": 1,
            "weight": 0.25
          },
          {
            "term": "configuration",
            "tf": 1,
            "weight": 0.25
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.25
          }
        ],
        "unique_terms": 4,
        "total_terms": 4
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Router Training Configuration",
        "configuration",
        "python",
        "router",
        "training"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  }
]
[
  {
    "text": "### Cross-Encoder Model Usage ```python from sentence_transformers import CrossEncoder import torch",
    "metadata": {
      "chunk_id": "d48ac16ec1d4-0000",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Cross-Encoder Model Usage"
      ],
      "heading_text": "Cross-Encoder Model Usage",
      "token_count": 17,
      "char_count": 99,
      "start_char": 198,
      "end_char": 297,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5627272727272727,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.940172",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 17,
      "document_id": "d48ac16ec1d4",
      "document_name": "Calculate_similarity_choose_based_on_model_optimization",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "source_filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "hierarchy_path": "Cross-Encoder Model Usage",
      "chunk_hash": "d2aad1170b081c4a",
      "content_digest": "d2aad1170b081c4a",
      "chunk_length": 99,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "import",
          "cross",
          "encoder",
          "model",
          "usage",
          "python",
          "from",
          "sentence",
          "transformers",
          "crossencoder",
          "torch"
        ],
        "term_weights": [
          {
            "term": "import",
            "tf": 2,
            "weight": 0.166667
          },
          {
            "term": "cross",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "encoder",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "usage",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "torch",
            "tf": 1,
            "weight": 0.083333
          }
        ],
        "unique_terms": 11,
        "total_terms": 12
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Cross-Encoder Model Usage",
        "cross",
        "crossencoder",
        "encoder",
        "from",
        "import",
        "model",
        "python",
        "sentence",
        "transformers",
        "usage"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5627272727272727,
      "overall": 0.7542424242424243
    }
  },
  {
    "text": "# Load cross-encoder with sigmoid activation for 0-1 scores model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L6-v2\", activation_fn=torch.nn.Sigmoid())",
    "metadata": {
      "chunk_id": "d48ac16ec1d4-0001",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Load cross-encoder with sigmoid activation for 0-1 scores"
      ],
      "heading_text": "Load cross-encoder with sigmoid activation for 0-1 scores",
      "token_count": 40,
      "char_count": 153,
      "start_char": 300,
      "end_char": 453,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.940490",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 40,
      "document_id": "d48ac16ec1d4",
      "document_name": "Calculate_similarity_choose_based_on_model_optimization",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "source_filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "hierarchy_path": "Load cross-encoder with sigmoid activation for 0-1 scores",
      "chunk_hash": "ad07e7cc0e64c600",
      "content_digest": "ad07e7cc0e64c600",
      "chunk_length": 153,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cross",
          "encoder",
          "sigmoid",
          "activation",
          "load",
          "with",
          "for",
          "scores",
          "model",
          "crossencoder",
          "marco",
          "minilm",
          "torch"
        ],
        "term_weights": [
          {
            "term": "cross",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "sigmoid",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "activation",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "load",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "scores",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "marco",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "minilm",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "torch",
            "tf": 1,
            "weight": 0.058824
          }
        ],
        "unique_terms": 13,
        "total_terms": 17
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Load cross-encoder with sigmoid activation for 0-1 scores",
        "activation",
        "cross",
        "crossencoder",
        "encoder",
        "for",
        "load",
        "model",
        "scores",
        "sigmoid",
        "with"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "# Score query-passage pairs scores = model.predict([     (\"How big is London\", \"London has 9,787,426 inhabitants at the 2011 census\"),     (\"How big is London\", \"London is well known for its museums\") ])",
    "metadata": {
      "chunk_id": "d48ac16ec1d4-0002",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Score query-passage pairs"
      ],
      "heading_text": "Score query-passage pairs",
      "token_count": 52,
      "char_count": 203,
      "start_char": 455,
      "end_char": 658,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5319354838709677,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.940871",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 52,
      "document_id": "d48ac16ec1d4",
      "document_name": "Calculate_similarity_choose_based_on_model_optimization",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "source_filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "hierarchy_path": "Score query-passage pairs",
      "chunk_hash": "426f1828d2444439",
      "content_digest": "426f1828d2444439",
      "chunk_length": 203,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "london",
          "how",
          "big",
          "score",
          "query",
          "passage",
          "pairs",
          "scores",
          "model",
          "predict",
          "has",
          "787",
          "426",
          "inhabitants",
          "the",
          "2011",
          "census",
          "well",
          "known",
          "for"
        ],
        "term_weights": [
          {
            "term": "london",
            "tf": 4,
            "weight": 0.148148
          },
          {
            "term": "how",
            "tf": 2,
            "weight": 0.074074
          },
          {
            "term": "big",
            "tf": 2,
            "weight": 0.074074
          },
          {
            "term": "score",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "query",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "passage",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "pairs",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "scores",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "predict",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "has",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "787",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "426",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "inhabitants",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "2011",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "census",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "well",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "known",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.037037
          }
        ],
        "unique_terms": 22,
        "total_terms": 27
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Score query-passage pairs",
        "big",
        "how",
        "london",
        "model",
        "pairs",
        "passage",
        "predict",
        "query",
        "score",
        "scores"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5319354838709677,
      "overall": 0.7106451612903225
    }
  },
  {
    "text": "### Batch Processing for Production ```python",
    "metadata": {
      "chunk_id": "d48ac16ec1d4-0004",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Batch Processing for Production"
      ],
      "heading_text": "Batch Processing for Production",
      "token_count": 7,
      "char_count": 45,
      "start_char": 720,
      "end_char": 765,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:48.941279",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 7,
      "document_id": "d48ac16ec1d4",
      "document_name": "Calculate_similarity_choose_based_on_model_optimization",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "source_filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "hierarchy_path": "Batch Processing for Production",
      "chunk_hash": "00ab9438f5326531",
      "content_digest": "00ab9438f5326531",
      "chunk_length": 45,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "batch",
          "processing",
          "for",
          "production",
          "python"
        ],
        "term_weights": [
          {
            "term": "batch",
            "tf": 1,
            "weight": 0.2
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.2
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.2
          },
          {
            "term": "production",
            "tf": 1,
            "weight": 0.2
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.2
          }
        ],
        "unique_terms": 5,
        "total_terms": 5
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Batch Processing for Production",
        "batch",
        "for",
        "processing",
        "production",
        "python"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  }
]
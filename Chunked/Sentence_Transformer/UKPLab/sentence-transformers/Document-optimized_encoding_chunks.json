[
  {
    "text": "## SparseEncoder: Sparse Embeddings\n\n`SparseEncoder` models create sparse vector representations where most values are zero, enabling efficient neural lexical search and hybrid retrieval systems.",
    "metadata": {
      "chunk_id": "0eb06ffe27cd-0000",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Document-optimized_encoding.md",
      "filename": "Document-optimized_encoding.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "SparseEncoder: Sparse Embeddings"
      ],
      "heading_text": "SparseEncoder: Sparse Embeddings",
      "token_count": 33,
      "char_count": 195,
      "start_char": 298,
      "end_char": 493,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5775,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.192859",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 33,
      "document_id": "0eb06ffe27cd",
      "document_name": "Document-optimized_encoding",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Document-optimized_encoding.md",
      "source_filename": "Document-optimized_encoding.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Document-optimized_encoding.md",
      "hierarchy_path": "SparseEncoder: Sparse Embeddings",
      "chunk_hash": "ae008c6dddb7669f",
      "content_digest": "ae008c6dddb7669f",
      "chunk_length": 195,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparseencoder",
          "sparse",
          "embeddings",
          "models",
          "create",
          "vector",
          "representations",
          "where",
          "most",
          "values",
          "are",
          "zero",
          "enabling",
          "efficient",
          "neural",
          "lexical",
          "search",
          "and",
          "hybrid",
          "retrieval"
        ],
        "term_weights": [
          {
            "term": "sparseencoder",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "create",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "representations",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "most",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "values",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "zero",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "enabling",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "efficient",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "neural",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "lexical",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "hybrid",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "retrieval",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 21,
        "total_terms": 23
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "SparseEncoder: Sparse Embeddings",
        "create",
        "embeddings",
        "models",
        "most",
        "representations",
        "sparse",
        "sparseencoder",
        "values",
        "vector",
        "where"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5775,
      "overall": 0.7591666666666667
    }
  },
  {
    "text": "# Load a sparse encoder model\nmodel = SparseEncoder(\"naver/splade-cocondenser-ensembledistil\")\n\nsentences = [\n    \"The weather is lovely today.\",\n    \"It's so sunny outside!\",\n    \"He drove to the stadium.\",\n]",
    "metadata": {
      "chunk_id": "0eb06ffe27cd-0002",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Document-optimized_encoding.md",
      "filename": "Document-optimized_encoding.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Load a sparse encoder model"
      ],
      "heading_text": "Load a sparse encoder model",
      "token_count": 56,
      "char_count": 209,
      "start_char": 571,
      "end_char": 780,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5677777777777778,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.193732",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 56,
      "document_id": "0eb06ffe27cd",
      "document_name": "Document-optimized_encoding",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Document-optimized_encoding.md",
      "source_filename": "Document-optimized_encoding.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Document-optimized_encoding.md",
      "hierarchy_path": "Load a sparse encoder model",
      "chunk_hash": "7cf7d099b4070745",
      "content_digest": "7cf7d099b4070745",
      "chunk_length": 209,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "the",
          "load",
          "sparse",
          "encoder",
          "sparseencoder",
          "naver",
          "splade",
          "cocondenser",
          "ensembledistil",
          "sentences",
          "weather",
          "lovely",
          "today",
          "sunny",
          "outside",
          "drove",
          "stadium"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "load",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "sparse",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "encoder",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "sparseencoder",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "naver",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "splade",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "cocondenser",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "ensembledistil",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "sentences",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "weather",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "lovely",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "today",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "sunny",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "outside",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "drove",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "stadium",
            "tf": 1,
            "weight": 0.05
          }
        ],
        "unique_terms": 18,
        "total_terms": 20
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Load a sparse encoder model",
        "cocondenser",
        "encoder",
        "ensembledistil",
        "load",
        "model",
        "naver",
        "sparse",
        "sparseencoder",
        "splade",
        "the"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5677777777777778,
      "overall": 0.6559259259259259
    }
  },
  {
    "text": "# Generate sparse embeddings embeddings = model.encode(sentences) print(embeddings.shape)",
    "metadata": {
      "chunk_id": "0eb06ffe27cd-0003",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Document-optimized_encoding.md",
      "filename": "Document-optimized_encoding.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Generate sparse embeddings"
      ],
      "heading_text": "Generate sparse embeddings",
      "token_count": 16,
      "char_count": 89,
      "start_char": 782,
      "end_char": 871,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.194083",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 16,
      "document_id": "0eb06ffe27cd",
      "document_name": "Document-optimized_encoding",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Document-optimized_encoding.md",
      "source_filename": "Document-optimized_encoding.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Document-optimized_encoding.md",
      "hierarchy_path": "Generate sparse embeddings",
      "chunk_hash": "9937521f6490fd13",
      "content_digest": "9937521f6490fd13",
      "chunk_length": 89,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "embeddings",
          "generate",
          "sparse",
          "model",
          "encode",
          "sentences",
          "print",
          "shape"
        ],
        "term_weights": [
          {
            "term": "embeddings",
            "tf": 3,
            "weight": 0.3
          },
          {
            "term": "generate",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "sparse",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "encode",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "sentences",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "print",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "shape",
            "tf": 1,
            "weight": 0.1
          }
        ],
        "unique_terms": 8,
        "total_terms": 10
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Generate sparse embeddings",
        "embeddings",
        "encode",
        "generate",
        "model",
        "print",
        "sentences",
        "shape",
        "sparse"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "overall": 0.6841666666666667
    }
  },
  {
    "text": "# Calculate similarities (using dot product for sparse vectors) similarities = model.similarity(embeddings, embeddings) print(similarities)",
    "metadata": {
      "chunk_id": "0eb06ffe27cd-0005",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Document-optimized_encoding.md",
      "filename": "Document-optimized_encoding.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Calculate similarities (using dot product for sparse vectors)"
      ],
      "heading_text": "Calculate similarities (using dot product for sparse vectors)",
      "token_count": 26,
      "char_count": 139,
      "start_char": 915,
      "end_char": 1054,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5685714285714286,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:49.194726",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 26,
      "document_id": "0eb06ffe27cd",
      "document_name": "Document-optimized_encoding",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Document-optimized_encoding.md",
      "source_filename": "Document-optimized_encoding.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Document-optimized_encoding.md",
      "hierarchy_path": "Calculate similarities (using dot product for sparse vectors)",
      "chunk_hash": "c5a6beed3bc7c0da",
      "content_digest": "c5a6beed3bc7c0da",
      "chunk_length": 139,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "similarities",
          "embeddings",
          "calculate",
          "using",
          "dot",
          "product",
          "for",
          "sparse",
          "vectors",
          "model",
          "similarity",
          "print"
        ],
        "term_weights": [
          {
            "term": "similarities",
            "tf": 3,
            "weight": 0.2
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.133333
          },
          {
            "term": "calculate",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "dot",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "product",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "sparse",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "vectors",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "similarity",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "print",
            "tf": 1,
            "weight": 0.066667
          }
        ],
        "unique_terms": 12,
        "total_terms": 15
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Calculate similarities (using dot product for sparse vectors)",
        "calculate",
        "dot",
        "embeddings",
        "for",
        "model",
        "product",
        "similarities",
        "sparse",
        "using",
        "vectors"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5685714285714286,
      "overall": 0.7228571428571429
    }
  }
]
[
  {
    "text": "## Core SPLADE Models  Core SPLADE models use neural inference for both queries and documents, providing query expansion capabilities and optimal retrieval performance. These models are trained on datasets like MS MARCO Passage Retrieval and evaluated on BEIR benchmarks. | Model Name | MS MARCO MRR@10 | BEIR-13 avg nDCG@10 | Parameters | Architecture | |------------|:---------------:|:-------------------:|-----------:|-------------| | [opensearch-project/opensearch-neural-sparse-encoding-v2-distill](https://huggingface.co/opensearch-project/opensearch-neural-sparse-encoding-v2-distill) | NA | **52.8** | 67M | DistilBERT | | [opensearch-project/opensearch-neural-sparse-encoding-v1](https://huggingface.co/opensearch-project/opensearch-neural-sparse-encoding-v1) | NA | 52.4 | 133M | BERT | | [naver/splade-v3](https://huggingface.co/naver/splade-v3) | **40.2** | 51.7 | 109M | BERT | | [ibm-granite/granite-embedding-30m-sparse](https://huggingface.co/ibm-granite/granite-embedding-30m-sparse) | NA | 50.8 | 30M | Custom | | [naver/splade-cocondenser-selfdistil](https://huggingface.co/naver/splade-cocondenser-selfdistil) | 37.6 | 50.7 | 109M | BERT | | [naver/splade_v2_distil](https://huggingface.co/naver/splade_v2_distil) | 36.8 | 50.6 | 67M | DistilBERT | | [naver/splade-v3-distilbert](https://huggingface.co/naver/splade-v3-distilbert) | 38.7 | 50.0 | 67M | DistilBERT | | [naver/splade-v3-lexical](https://huggingface.co/naver/splade-v3-lexical) | 40.0 | 49.1 | 109M | BERT | | [rasyosef/splade-mini](https://huggingface.co/rasyosef/splade-mini) | 33.2 | 42.5 | 11M | Mini | | [rasyosef/splade-tiny](https://huggingface.co/rasyosef/splade-tiny) | 30.9 | 40.6 | 4M | Tiny |  **Note:** BM25 baseline achieves 18.4 MS MARCO MRR@10 and 45.6 BEIR-13 avg nDCG@10. Sources: [docs/sparse_encoder/pretrained_models.md:36-60]()",
    "metadata": {
      "chunk_id": "86736a928325-0001",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Core SPLADE Models"
      ],
      "heading_text": "Core SPLADE Models",
      "token_count": 637,
      "char_count": 1834,
      "start_char": 2141,
      "end_char": 3975,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6475138121546962,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.366430",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 637,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Core SPLADE Models",
      "chunk_hash": "9ebb41dae4f35e2d",
      "content_digest": "9ebb41dae4f35e2d",
      "chunk_length": 1834,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "splade",
          "https",
          "huggingface",
          "naver",
          "opensearch",
          "sparse",
          "neural",
          "distilbert",
          "models",
          "and",
          "project",
          "encoding",
          "bert",
          "granite",
          "rasyosef",
          "marco",
          "beir",
          "67m",
          "109m",
          "30m"
        ],
        "term_weights": [
          {
            "term": "splade",
            "tf": 16,
            "weight": 0.089385
          },
          {
            "term": "https",
            "tf": 10,
            "weight": 0.055866
          },
          {
            "term": "huggingface",
            "tf": 10,
            "weight": 0.055866
          },
          {
            "term": "naver",
            "tf": 10,
            "weight": 0.055866
          },
          {
            "term": "opensearch",
            "tf": 8,
            "weight": 0.044693
          },
          {
            "term": "sparse",
            "tf": 7,
            "weight": 0.039106
          },
          {
            "term": "neural",
            "tf": 5,
            "weight": 0.027933
          },
          {
            "term": "distilbert",
            "tf": 5,
            "weight": 0.027933
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "project",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "encoding",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "bert",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "granite",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "rasyosef",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "marco",
            "tf": 3,
            "weight": 0.01676
          },
          {
            "term": "beir",
            "tf": 3,
            "weight": 0.01676
          },
          {
            "term": "67m",
            "tf": 3,
            "weight": 0.01676
          },
          {
            "term": "109m",
            "tf": 3,
            "weight": 0.01676
          },
          {
            "term": "30m",
            "tf": 3,
            "weight": 0.01676
          }
        ],
        "unique_terms": 69,
        "total_terms": 179
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Core SPLADE Models",
        "and",
        "distilbert",
        "https",
        "huggingface",
        "models",
        "naver",
        "neural",
        "opensearch",
        "sparse",
        "splade"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6475138121546962,
      "overall": 0.749171270718232
    }
  },
  {
    "text": "## Basic Usage Pattern  All SparseEncoder models follow a consistent interface for encoding queries and documents: ```python from sentence_transformers import SparseEncoder",
    "metadata": {
      "chunk_id": "86736a928325-0003",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Basic Usage Pattern"
      ],
      "heading_text": "Basic Usage Pattern",
      "token_count": 28,
      "char_count": 172,
      "start_char": 5464,
      "end_char": 5636,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5757142857142857,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.368938",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 28,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Basic Usage Pattern",
      "chunk_hash": "1f9fa584e6b4e1e0",
      "content_digest": "1f9fa584e6b4e1e0",
      "chunk_length": 172,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparseencoder",
          "basic",
          "usage",
          "pattern",
          "all",
          "models",
          "follow",
          "consistent",
          "interface",
          "for",
          "encoding",
          "queries",
          "and",
          "documents",
          "python",
          "from",
          "sentence",
          "transformers",
          "import"
        ],
        "term_weights": [
          {
            "term": "sparseencoder",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "basic",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "usage",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "pattern",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "follow",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "consistent",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "interface",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "encoding",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "queries",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "import",
            "tf": 1,
            "weight": 0.05
          }
        ],
        "unique_terms": 19,
        "total_terms": 20
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Basic Usage Pattern",
        "all",
        "basic",
        "consistent",
        "follow",
        "for",
        "interface",
        "models",
        "pattern",
        "sparseencoder",
        "usage"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5757142857142857,
      "overall": 0.7585714285714286
    }
  },
  {
    "text": "# Load any SparseEncoder model model = SparseEncoder(\"naver/splade-v3\")",
    "metadata": {
      "chunk_id": "86736a928325-0004",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Load any SparseEncoder model"
      ],
      "heading_text": "Load any SparseEncoder model",
      "token_count": 19,
      "char_count": 71,
      "start_char": 5639,
      "end_char": 5710,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.369168",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 19,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Load any SparseEncoder model",
      "chunk_hash": "695f1580ddc73f56",
      "content_digest": "695f1580ddc73f56",
      "chunk_length": 71,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparseencoder",
          "model",
          "load",
          "any",
          "naver",
          "splade"
        ],
        "term_weights": [
          {
            "term": "sparseencoder",
            "tf": 2,
            "weight": 0.25
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.25
          },
          {
            "term": "load",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "any",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "naver",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "splade",
            "tf": 1,
            "weight": 0.125
          }
        ],
        "unique_terms": 6,
        "total_terms": 8
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Load any SparseEncoder model",
        "any",
        "load",
        "model",
        "naver",
        "sparseencoder",
        "splade"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "overall": 0.7508333333333334
    }
  },
  {
    "text": "# Encode queries and documents queries = [\"what causes aging fast\"] documents = [\"UV-A light causes skin aging...\", \"Alzheimer's disease...\"]  query_embeddings = model.encode_query(queries) document_embeddings = model.encode_document(documents)",
    "metadata": {
      "chunk_id": "86736a928325-0005",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Encode queries and documents"
      ],
      "heading_text": "Encode queries and documents",
      "token_count": 49,
      "char_count": 244,
      "start_char": 5712,
      "end_char": 5956,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5207692307692308,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.369549",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 49,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Encode queries and documents",
      "chunk_hash": "074e7767dbc2149a",
      "content_digest": "074e7767dbc2149a",
      "chunk_length": 244,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "encode",
          "queries",
          "documents",
          "causes",
          "aging",
          "query",
          "embeddings",
          "model",
          "document",
          "and",
          "what",
          "fast",
          "light",
          "skin",
          "alzheimer",
          "disease"
        ],
        "term_weights": [
          {
            "term": "encode",
            "tf": 3,
            "weight": 0.107143
          },
          {
            "term": "queries",
            "tf": 3,
            "weight": 0.107143
          },
          {
            "term": "documents",
            "tf": 3,
            "weight": 0.107143
          },
          {
            "term": "causes",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "aging",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "document",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "what",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "fast",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "light",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "skin",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "alzheimer",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "disease",
            "tf": 1,
            "weight": 0.035714
          }
        ],
        "unique_terms": 16,
        "total_terms": 28
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Encode queries and documents",
        "aging",
        "and",
        "causes",
        "document",
        "documents",
        "embeddings",
        "encode",
        "model",
        "queries",
        "query"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5207692307692308,
      "overall": 0.6735897435897437
    }
  },
  {
    "text": "# Compute similarities similarities = model.similarity(query_embeddings, document_embeddings) ``` The `encode_query()` and `encode_document()` methods return sparse tensors with shape `[batch_size, vocab_size]`, where non-zero values indicate token activations. Sources: [docs/sparse_encoder/pretrained_models.md:12-33]()",
    "metadata": {
      "chunk_id": "86736a928325-0006",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Compute similarities"
      ],
      "heading_text": "Compute similarities",
      "token_count": 63,
      "char_count": 321,
      "start_char": 5958,
      "end_char": 6279,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5792857142857143,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.370631",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 63,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Compute similarities",
      "chunk_hash": "5fcb97e121e0ba42",
      "content_digest": "5fcb97e121e0ba42",
      "chunk_length": 321,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "similarities",
          "query",
          "embeddings",
          "document",
          "encode",
          "sparse",
          "size",
          "compute",
          "model",
          "similarity",
          "the",
          "and",
          "methods",
          "return",
          "tensors",
          "with",
          "shape",
          "batch",
          "vocab",
          "where"
        ],
        "term_weights": [
          {
            "term": "similarities",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "document",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "encode",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "size",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "compute",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "similarity",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "methods",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "return",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "tensors",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "shape",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "batch",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "vocab",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.026316
          }
        ],
        "unique_terms": 31,
        "total_terms": 38
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Compute similarities",
        "compute",
        "document",
        "embeddings",
        "encode",
        "model",
        "query",
        "similarities",
        "similarity",
        "size",
        "sparse"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5792857142857143,
      "overall": 0.7264285714285714
    }
  },
  {
    "text": "## Integration with Search Systems  SparseEncoder models integrate seamlessly with various search infrastructures, leveraging their sparse vector representations for efficient retrieval. ```mermaid graph TD     subgraph \"SparseEncoder Integration Architecture\"         QueryInput[\"Query Input<br/>encode_query()\"]         DocInput[\"Document Corpus<br/>encode_document()\"]                  SparseModel[\"SparseEncoder<br/>(naver/splade-v3)\"]                  QueryInput --> SparseModel         DocInput --> SparseModel     end          subgraph \"Sparse Vector Processing\"         QuerySparse[\"Query Sparse Vector<br/>[1, 30522]\"]         DocSparse[\"Document Sparse Vectors<br/>[N, 30522]\"]                  SparseModel --> QuerySparse         SparseModel --> DocSparse     end          subgraph \"Search Engine Integration\"         Elasticsearch[\"Elasticsearch<br/>sparse_vector field\"]         OpenSearch[\"OpenSearch<br/>neural-sparse plugin\"]         Qdrant[\"Qdrant<br/>sparse vectors\"]         SpladeIndex[\"splade-index<br/>specialized library\"]     end          subgraph \"Application Layer\"         SemanticSearch[\"Semantic Search<br/>semantic_search_splade_index.py\"]         HybridRetrieval[\"Hybrid Retrieval<br/>Dense + Sparse\"]         NeuralLexical[\"Neural Lexical Search<br/>Token-level matching\"]     end          QuerySparse --> Elasticsearch     DocSparse --> Elasticsearch     QuerySparse --> OpenSearch     DocSparse --> OpenSearch     QuerySparse --> Qdrant     DocSparse --> Qdrant     QuerySparse --> SpladeIndex     DocSparse --> SpladeIndex          Elasticsearch --> SemanticSearch     OpenSearch --> SemanticSearch     SpladeIndex --> SemanticSearch          SemanticSearch --> HybridRetrieval     SemanticSearch --> NeuralLexical ``` **SparseEncoder Integration with Search Systems**  Sources: [examples/sparse_encoder/applications/semantic_search/semantic_search_splade_index.py:1-52](), [docs/sparse_encoder/pretrained_models.md:1-83]()",
    "metadata": {
      "chunk_id": "86736a928325-0007",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration with Search Systems"
      ],
      "heading_text": "Integration with Search Systems",
      "token_count": 407,
      "char_count": 1958,
      "start_char": 6283,
      "end_char": 8241,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7012044776119403,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.377607",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 407,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Integration with Search Systems",
      "chunk_hash": "d3d6a6e3453c312c",
      "content_digest": "d3d6a6e3453c312c",
      "chunk_length": 1958,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparse",
          "search",
          "querysparse",
          "docsparse",
          "semanticsearch",
          "sparsemodel",
          "elasticsearch",
          "opensearch",
          "integration",
          "sparseencoder",
          "vector",
          "subgraph",
          "splade",
          "end",
          "qdrant",
          "spladeindex",
          "semantic",
          "with",
          "query",
          "document"
        ],
        "term_weights": [
          {
            "term": "sparse",
            "tf": 10,
            "weight": 0.063291
          },
          {
            "term": "search",
            "tf": 9,
            "weight": 0.056962
          },
          {
            "term": "querysparse",
            "tf": 6,
            "weight": 0.037975
          },
          {
            "term": "docsparse",
            "tf": 6,
            "weight": 0.037975
          },
          {
            "term": "semanticsearch",
            "tf": 6,
            "weight": 0.037975
          },
          {
            "term": "sparsemodel",
            "tf": 5,
            "weight": 0.031646
          },
          {
            "term": "elasticsearch",
            "tf": 5,
            "weight": 0.031646
          },
          {
            "term": "opensearch",
            "tf": 5,
            "weight": 0.031646
          },
          {
            "term": "integration",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "sparseencoder",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "vector",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "splade",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "spladeindex",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.018987
          },
          {
            "term": "query",
            "tf": 3,
            "weight": 0.018987
          },
          {
            "term": "document",
            "tf": 3,
            "weight": 0.018987
          }
        ],
        "unique_terms": 67,
        "total_terms": 158
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration with Search Systems",
        "docsparse",
        "elasticsearch",
        "integration",
        "opensearch",
        "querysparse",
        "search",
        "semanticsearch",
        "sparse",
        "sparseencoder",
        "sparsemodel"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7012044776119403,
      "overall": 0.8004014925373134
    }
  },
  {
    "text": "## Model Selection Guidelines",
    "metadata": {
      "chunk_id": "86736a928325-0008",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Selection Guidelines"
      ],
      "heading_text": "Model Selection Guidelines",
      "token_count": 4,
      "char_count": 29,
      "start_char": 8245,
      "end_char": 8274,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7899999999999999,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.378641",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 4,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Model Selection Guidelines",
      "chunk_hash": "01d249a713ad3e0f",
      "content_digest": "01d249a713ad3e0f",
      "chunk_length": 29,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "selection",
          "guidelines"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "selection",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "guidelines",
            "tf": 1,
            "weight": 0.333333
          }
        ],
        "unique_terms": 3,
        "total_terms": 3
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Selection Guidelines",
        "guidelines",
        "model",
        "selection"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7899999999999999,
      "overall": 0.83
    }
  },
  {
    "text": "### Performance Considerations  - **Highest BEIR Performance**: `opensearch-project/opensearch-neural-sparse-encoding-v2-distill` (52.8 nDCG@10) - **Highest MS MARCO Performance**: `naver/splade-v3` (40.2 MRR@10) - **Best Efficiency Trade-off**: `rasyosef/splade-tiny` (4M parameters, 40.6 BEIR nDCG@10) - **Fastest Query Processing**: Inference-free models with `SparseStaticEmbedding`",
    "metadata": {
      "chunk_id": "86736a928325-0009",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Considerations"
      ],
      "heading_text": "Performance Considerations",
      "token_count": 120,
      "char_count": 386,
      "start_char": 8276,
      "end_char": 8662,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5316666666666666,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.380436",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 120,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Performance Considerations",
      "chunk_hash": "9a71c19fd560102d",
      "content_digest": "9a71c19fd560102d",
      "chunk_length": 386,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "performance",
          "highest",
          "beir",
          "opensearch",
          "ndcg",
          "splade",
          "considerations",
          "project",
          "neural",
          "sparse",
          "encoding",
          "distill",
          "marco",
          "naver",
          "mrr",
          "best",
          "efficiency",
          "trade",
          "off",
          "rasyosef"
        ],
        "term_weights": [
          {
            "term": "performance",
            "tf": 3,
            "weight": 0.081081
          },
          {
            "term": "highest",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "beir",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "opensearch",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "ndcg",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "splade",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "considerations",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "project",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "neural",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "sparse",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "encoding",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "distill",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "marco",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "naver",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "mrr",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "best",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "efficiency",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "trade",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "off",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "rasyosef",
            "tf": 1,
            "weight": 0.027027
          }
        ],
        "unique_terms": 30,
        "total_terms": 37
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Considerations",
        "beir",
        "considerations",
        "highest",
        "ndcg",
        "neural",
        "opensearch",
        "performance",
        "project",
        "sparse",
        "splade"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5316666666666666,
      "overall": 0.7105555555555555
    }
  },
  {
    "text": "## Model Collections  Pre-organized collections of SparseEncoder models are available on the Hugging Face Hub:  - **[SPLADE Models](https://huggingface.co/collections/sparse-encoder/splade-models-6862be100374b320d826eeaa)**: Complete collection of core SPLADE models - **[Inference-Free SPLADE Models](https://huggingface.co/collections/sparse-encoder/inference-free-splade-models-6862be3a1d72eab38920bc6a)**: Models optimized for query speed  These collections provide curated access to models with consistent naming conventions and documented performance characteristics. Sources: [docs/sparse_encoder/pretrained_models.md:77-83]()",
    "metadata": {
      "chunk_id": "86736a928325-0011",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Collections"
      ],
      "heading_text": "Model Collections",
      "token_count": 154,
      "char_count": 633,
      "start_char": 9281,
      "end_char": 9914,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.542,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.382169",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 154,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Model Collections",
      "chunk_hash": "3de40dab6f5c1070",
      "content_digest": "3de40dab6f5c1070",
      "chunk_length": 633,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "models",
          "collections",
          "splade",
          "sparse",
          "encoder",
          "https",
          "huggingface",
          "inference",
          "free",
          "model",
          "pre",
          "organized",
          "sparseencoder",
          "are",
          "available",
          "the",
          "hugging",
          "face",
          "hub",
          "6862be100374b320d826eeaa"
        ],
        "term_weights": [
          {
            "term": "models",
            "tf": 9,
            "weight": 0.134328
          },
          {
            "term": "collections",
            "tf": 5,
            "weight": 0.074627
          },
          {
            "term": "splade",
            "tf": 5,
            "weight": 0.074627
          },
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "encoder",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "huggingface",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "free",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "pre",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "organized",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "sparseencoder",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "available",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "hugging",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "face",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "hub",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "6862be100374b320d826eeaa",
            "tf": 1,
            "weight": 0.014925
          }
        ],
        "unique_terms": 43,
        "total_terms": 67
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Collections",
        "collections",
        "encoder",
        "free",
        "https",
        "huggingface",
        "inference",
        "model",
        "models",
        "sparse",
        "splade"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.542,
      "overall": 0.7473333333333333
    }
  },
  {
    "text": "# CrossEncoder Models\n\n\n\n\nThis document covers the pretrained CrossEncoder models available in the sentence-transformers library, their characteristics, performance metrics, and usage patterns. CrossEncoder models are designed for pairwise text scoring and classification tasks, making them particularly effective for reranking, semantic similarity measurement, and natural language inference.\n\nFor information about training CrossEncoder models, see [CrossEncoder Training](#3.3). For details about CrossEncoder evaluation methods, see [CrossEncoder Evaluators](#4.3).",
    "metadata": {
      "chunk_id": "86736a928325-0012",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "CrossEncoder Models"
      ],
      "heading_text": "CrossEncoder Models",
      "token_count": 100,
      "char_count": 569,
      "start_char": 9917,
      "end_char": 10486,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5196875,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.383518",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 100,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "CrossEncoder Models",
      "chunk_hash": "b87cf858fb3e6b65",
      "content_digest": "b87cf858fb3e6b65",
      "chunk_length": 569,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "crossencoder",
          "models",
          "for",
          "and",
          "the",
          "about",
          "training",
          "see",
          "this",
          "document",
          "covers",
          "pretrained",
          "available",
          "sentence",
          "transformers",
          "library",
          "their",
          "characteristics",
          "performance",
          "metrics"
        ],
        "term_weights": [
          {
            "term": "crossencoder",
            "tf": 7,
            "weight": 0.111111
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.063492
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.063492
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.047619
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "about",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "see",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "covers",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "pretrained",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "available",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "their",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "characteristics",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "metrics",
            "tf": 1,
            "weight": 0.015873
          }
        ],
        "unique_terms": 45,
        "total_terms": 63
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "CrossEncoder Models",
        "about",
        "and",
        "crossencoder",
        "document",
        "for",
        "models",
        "see",
        "the",
        "this",
        "training"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5196875,
      "overall": 0.7398958333333332
    }
  },
  {
    "text": "## Model Architecture and Purpose  CrossEncoder models process pairs of texts jointly through a single transformer model, producing similarity scores or classification outputs. Unlike bi-encoder architectures that encode texts independently, CrossEncoders perform cross-attention between the input texts, enabling more precise but computationally expensive comparisons. ```mermaid graph TD     subgraph \"CrossEncoder Architecture\"         TextPair[\"Text Pair Input<br/>(query, passage)\"] --> Tokenizer[\"Tokenizer\"]         Tokenizer --> CrossAttention[\"Cross-Attention<br/>Transformer\"]         CrossAttention --> Classifier[\"Classification Head\"]         Classifier --> ActivationFn[\"Activation Function<br/>(Sigmoid/Identity)\"]         ActivationFn --> Score[\"Relevance Score<br/>(0-1 or logit)\"]     end          subgraph \"Use Cases\"         Score --> Reranking[\"Reranking Pipeline\"]         Score --> STS[\"Semantic Similarity\"]         Score --> NLI[\"Natural Language Inference\"]         Score --> QA[\"Question Answering\"]     end ``` **Sources:** [docs/cross_encoder/pretrained_models.md:1-33](), [docs/pretrained-models/ce-msmarco.md:1-63]()",
    "metadata": {
      "chunk_id": "86736a928325-0013",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Architecture and Purpose"
      ],
      "heading_text": "Model Architecture and Purpose",
      "token_count": 241,
      "char_count": 1147,
      "start_char": 10488,
      "end_char": 11635,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5445454545454546,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.388879",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 241,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Model Architecture and Purpose",
      "chunk_hash": "c6cea6ebf25e1038",
      "content_digest": "c6cea6ebf25e1038",
      "chunk_length": 1147,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "score",
          "models",
          "texts",
          "cross",
          "tokenizer",
          "model",
          "architecture",
          "crossencoder",
          "transformer",
          "similarity",
          "classification",
          "encoder",
          "attention",
          "input",
          "subgraph",
          "crossattention",
          "classifier",
          "activationfn",
          "end",
          "reranking"
        ],
        "term_weights": [
          {
            "term": "score",
            "tf": 6,
            "weight": 0.057143
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "texts",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "cross",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "tokenizer",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "architecture",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "crossencoder",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "transformer",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "similarity",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "classification",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "attention",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "input",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "subgraph",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "crossattention",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "classifier",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "activationfn",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "reranking",
            "tf": 2,
            "weight": 0.019048
          }
        ],
        "unique_terms": 75,
        "total_terms": 105
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Architecture and Purpose",
        "architecture",
        "cross",
        "crossencoder",
        "model",
        "models",
        "score",
        "similarity",
        "texts",
        "tokenizer",
        "transformer"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5445454545454546,
      "overall": 0.7481818181818181
    }
  },
  {
    "text": "### MS MARCO Models  MS MARCO CrossEncoder models are specifically trained for information retrieval and reranking tasks using real user queries from Bing search engine. ```mermaid graph LR     subgraph \"MS MARCO Model Hierarchy\"         TinyBERT[\"cross-encoder/ms-marco-TinyBERT-L2-v2<br/>NDCG@10: 69.84<br/>9000 docs/sec\"]         MiniLM2[\"cross-encoder/ms-marco-MiniLM-L2-v2<br/>NDCG@10: 71.01<br/>4100 docs/sec\"]         MiniLM4[\"cross-encoder/ms-marco-MiniLM-L4-v2<br/>NDCG@10: 73.04<br/>2500 docs/sec\"]         MiniLM6[\"cross-encoder/ms-marco-MiniLM-L6-v2<br/>NDCG@10: 74.30<br/>1800 docs/sec\"]         MiniLM12[\"cross-encoder/ms-marco-MiniLM-L12-v2<br/>NDCG@10: 74.31<br/>960 docs/sec\"]     end          TinyBERT --> |\"Higher Performance\"| MiniLM2     MiniLM2 --> MiniLM4     MiniLM4 --> MiniLM6     MiniLM6 --> MiniLM12          TinyBERT --> |\"Higher Speed\"| MiniLM2 ``` **Sources:** [docs/cross_encoder/pretrained_models.md:35-42](), [docs/pretrained-models/ce-msmarco.md:41-48]()",
    "metadata": {
      "chunk_id": "86736a928325-0015",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "MS MARCO Models"
      ],
      "heading_text": "MS MARCO Models",
      "token_count": 316,
      "char_count": 989,
      "start_char": 12445,
      "end_char": 13434,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5197999999999999,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.394067",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 316,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "MS MARCO Models",
      "chunk_hash": "fd293e438b4a4bf9",
      "content_digest": "fd293e438b4a4bf9",
      "chunk_length": 989,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "marco",
          "docs",
          "cross",
          "encoder",
          "ndcg",
          "sec",
          "models",
          "tinybert",
          "minilm2",
          "minilm",
          "minilm4",
          "minilm6",
          "minilm12",
          "higher",
          "pretrained",
          "crossencoder",
          "are",
          "specifically",
          "trained",
          "for"
        ],
        "term_weights": [
          {
            "term": "marco",
            "tf": 8,
            "weight": 0.080808
          },
          {
            "term": "docs",
            "tf": 7,
            "weight": 0.070707
          },
          {
            "term": "cross",
            "tf": 6,
            "weight": 0.060606
          },
          {
            "term": "encoder",
            "tf": 6,
            "weight": 0.060606
          },
          {
            "term": "ndcg",
            "tf": 5,
            "weight": 0.050505
          },
          {
            "term": "sec",
            "tf": 5,
            "weight": 0.050505
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.040404
          },
          {
            "term": "tinybert",
            "tf": 4,
            "weight": 0.040404
          },
          {
            "term": "minilm2",
            "tf": 4,
            "weight": 0.040404
          },
          {
            "term": "minilm",
            "tf": 4,
            "weight": 0.040404
          },
          {
            "term": "minilm4",
            "tf": 3,
            "weight": 0.030303
          },
          {
            "term": "minilm6",
            "tf": 3,
            "weight": 0.030303
          },
          {
            "term": "minilm12",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "higher",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "pretrained",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.010101
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.010101
          },
          {
            "term": "specifically",
            "tf": 1,
            "weight": 0.010101
          },
          {
            "term": "trained",
            "tf": 1,
            "weight": 0.010101
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.010101
          }
        ],
        "unique_terms": 49,
        "total_terms": 99
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "MS MARCO Models",
        "cross",
        "docs",
        "encoder",
        "marco",
        "minilm",
        "minilm2",
        "models",
        "ndcg",
        "sec",
        "tinybert"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5197999999999999,
      "overall": 0.7065999999999999
    }
  },
  {
    "text": "### Community Models  The ecosystem includes high-quality community-contributed models for specialized domains:  - **BAAI BGE Rerankers**: `BAAI/bge-reranker-base`, `BAAI/bge-reranker-large`, `BAAI/bge-reranker-v2-m3` - **Jina AI Models**: `jinaai/jina-reranker-v1-tiny-en`, `jinaai/jina-reranker-v1-turbo-en` - **Mixedbread AI**: `mixedbread-ai/mxbai-rerank-base-v1`, `mixedbread-ai/mxbai-rerank-large-v1` - **Alibaba GTE**: `Alibaba-NLP/gte-reranker-modernbert-base`, `Alibaba-NLP/gte-multilingual-reranker-base`  **Sources:** [docs/cross_encoder/pretrained_models.md:114-130]()",
    "metadata": {
      "chunk_id": "86736a928325-0016",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Community Models"
      ],
      "heading_text": "Community Models",
      "token_count": 194,
      "char_count": 580,
      "start_char": 13438,
      "end_char": 14018,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5575675675675675,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.395366",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 194,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Community Models",
      "chunk_hash": "2cb9b879c1803310",
      "content_digest": "2cb9b879c1803310",
      "chunk_length": 580,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "reranker",
          "models",
          "baai",
          "bge",
          "base",
          "jina",
          "mixedbread",
          "alibaba",
          "gte",
          "community",
          "large",
          "jinaai",
          "mxbai",
          "rerank",
          "nlp",
          "the",
          "ecosystem",
          "includes",
          "high",
          "quality"
        ],
        "term_weights": [
          {
            "term": "reranker",
            "tf": 7,
            "weight": 0.102941
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.058824
          },
          {
            "term": "baai",
            "tf": 4,
            "weight": 0.058824
          },
          {
            "term": "bge",
            "tf": 4,
            "weight": 0.058824
          },
          {
            "term": "base",
            "tf": 4,
            "weight": 0.058824
          },
          {
            "term": "jina",
            "tf": 3,
            "weight": 0.044118
          },
          {
            "term": "mixedbread",
            "tf": 3,
            "weight": 0.044118
          },
          {
            "term": "alibaba",
            "tf": 3,
            "weight": 0.044118
          },
          {
            "term": "gte",
            "tf": 3,
            "weight": 0.044118
          },
          {
            "term": "community",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "large",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "jinaai",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "mxbai",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "rerank",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "nlp",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "ecosystem",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "includes",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "high",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "quality",
            "tf": 1,
            "weight": 0.014706
          }
        ],
        "unique_terms": 36,
        "total_terms": 68
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Community Models",
        "alibaba",
        "baai",
        "base",
        "bge",
        "community",
        "gte",
        "jina",
        "mixedbread",
        "models",
        "reranker"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5575675675675675,
      "overall": 0.7525225225225224
    }
  },
  {
    "text": "# Load with sigmoid activation for 0-1 scores model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L6-v2\", activation_fn=torch.nn.Sigmoid()) scores = model.predict([     (\"How many people live in Berlin?\", \"Berlin had a population of 3,520,031 registered inhabitants.\"),     (\"How many people live in Berlin?\", \"Berlin is well known for its museums.\"), ])",
    "metadata": {
      "chunk_id": "86736a928325-0019",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Load with sigmoid activation for 0-1 scores"
      ],
      "heading_text": "Load with sigmoid activation for 0-1 scores",
      "token_count": 85,
      "char_count": 354,
      "start_char": 14153,
      "end_char": 14507,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5202325581395348,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.396834",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 85,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Load with sigmoid activation for 0-1 scores",
      "chunk_hash": "9ba10839441583d7",
      "content_digest": "9ba10839441583d7",
      "chunk_length": 354,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "berlin",
          "sigmoid",
          "activation",
          "for",
          "scores",
          "model",
          "how",
          "many",
          "people",
          "live",
          "load",
          "with",
          "crossencoder",
          "cross",
          "encoder",
          "marco",
          "minilm",
          "torch",
          "predict",
          "had"
        ],
        "term_weights": [
          {
            "term": "berlin",
            "tf": 4,
            "weight": 0.097561
          },
          {
            "term": "sigmoid",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "activation",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "scores",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "how",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "many",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "people",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "live",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "load",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "cross",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "encoder",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "marco",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "minilm",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "torch",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "predict",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "had",
            "tf": 1,
            "weight": 0.02439
          }
        ],
        "unique_terms": 29,
        "total_terms": 41
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Load with sigmoid activation for 0-1 scores",
        "activation",
        "berlin",
        "for",
        "how",
        "live",
        "many",
        "model",
        "people",
        "scores",
        "sigmoid"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5202325581395348,
      "overall": 0.7067441860465116
    }
  },
  {
    "text": "### Integration with Transformers Library ```python from transformers import AutoTokenizer, AutoModelForSequenceClassification import torch  model = AutoModelForSequenceClassification.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L6-v2\") tokenizer = AutoTokenizer.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L6-v2\")  features = tokenizer([\"Query\", \"Query\"], [\"Paragraph1\", \"Paragraph2\"],                      padding=True, truncation=True, return_tensors=\"pt\")  with torch.no_grad():     scores = model(**features).logits ``` **Sources:** [docs/cross_encoder/pretrained_models.md:12-33](), [docs/pretrained-models/ce-msmarco.md:19-33]()",
    "metadata": {
      "chunk_id": "86736a928325-0021",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration with Transformers Library"
      ],
      "heading_text": "Integration with Transformers Library",
      "token_count": 150,
      "char_count": 640,
      "start_char": 14565,
      "end_char": 15205,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5413513513513514,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.398310",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 150,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Integration with Transformers Library",
      "chunk_hash": "e6cdc3c82e72d437",
      "content_digest": "e6cdc3c82e72d437",
      "chunk_length": 640,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "pretrained",
          "from",
          "cross",
          "encoder",
          "with",
          "transformers",
          "import",
          "autotokenizer",
          "automodelforsequenceclassification",
          "torch",
          "model",
          "marco",
          "minilm",
          "tokenizer",
          "features",
          "query",
          "true",
          "docs",
          "models",
          "integration"
        ],
        "term_weights": [
          {
            "term": "pretrained",
            "tf": 4,
            "weight": 0.070175
          },
          {
            "term": "from",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "cross",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "encoder",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "import",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "autotokenizer",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "automodelforsequenceclassification",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "torch",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "marco",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "minilm",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "tokenizer",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "features",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "true",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.017544
          }
        ],
        "unique_terms": 33,
        "total_terms": 57
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration with Transformers Library",
        "automodelforsequenceclassification",
        "autotokenizer",
        "cross",
        "encoder",
        "from",
        "import",
        "pretrained",
        "torch",
        "transformers",
        "with"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5413513513513514,
      "overall": 0.7137837837837838
    }
  },
  {
    "text": "## Performance Characteristics",
    "metadata": {
      "chunk_id": "86736a928325-0022",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Characteristics"
      ],
      "heading_text": "Performance Characteristics",
      "token_count": 3,
      "char_count": 30,
      "start_char": 15209,
      "end_char": 15239,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.398620",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 3,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Performance Characteristics",
      "chunk_hash": "f2053113b0f9431f",
      "content_digest": "f2053113b0f9431f",
      "chunk_length": 30,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "performance",
          "characteristics"
        ],
        "term_weights": [
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "characteristics",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Characteristics",
        "characteristics",
        "performance"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Speed vs Accuracy Trade-offs ```mermaid graph TD     subgraph \"Performance Matrix\"         FastLow[\"Fast & Lower Accuracy<br/>TinyBERT-L2: 9000 docs/sec<br/>NDCG@10: 69.84\"]         MediumMed[\"Medium Speed & Accuracy<br/>MiniLM-L6: 1800 docs/sec<br/>NDCG@10: 74.30\"]         SlowHigh[\"Slower & Higher Accuracy<br/>MiniLM-L12: 960 docs/sec<br/>NDCG@10: 74.31\"]     end          FastLow --> |\"Diminishing Returns\"| MediumMed     MediumMed --> SlowHigh          subgraph \"Use Case Mapping\"         RealTime[\"Real-time Applications\"] --> FastLow         BatchProcessing[\"Batch Processing\"] --> MediumMed         HighPrecision[\"High Precision Tasks\"] --> SlowHigh     end ```",
    "metadata": {
      "chunk_id": "86736a928325-0023",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 23,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Speed vs Accuracy Trade-offs"
      ],
      "heading_text": "Speed vs Accuracy Trade-offs",
      "token_count": 181,
      "char_count": 674,
      "start_char": 15241,
      "end_char": 15915,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.515,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.399708",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 181,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Speed vs Accuracy Trade-offs",
      "chunk_hash": "d39608d042141b70",
      "content_digest": "d39608d042141b70",
      "chunk_length": 674,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "accuracy",
          "mediummed",
          "fastlow",
          "docs",
          "sec",
          "ndcg",
          "slowhigh",
          "speed",
          "subgraph",
          "minilm",
          "end",
          "trade",
          "offs",
          "mermaid",
          "graph",
          "performance",
          "matrix",
          "fast",
          "lower",
          "tinybert"
        ],
        "term_weights": [
          {
            "term": "accuracy",
            "tf": 4,
            "weight": 0.063492
          },
          {
            "term": "mediummed",
            "tf": 4,
            "weight": 0.063492
          },
          {
            "term": "fastlow",
            "tf": 3,
            "weight": 0.047619
          },
          {
            "term": "docs",
            "tf": 3,
            "weight": 0.047619
          },
          {
            "term": "sec",
            "tf": 3,
            "weight": 0.047619
          },
          {
            "term": "ndcg",
            "tf": 3,
            "weight": 0.047619
          },
          {
            "term": "slowhigh",
            "tf": 3,
            "weight": 0.047619
          },
          {
            "term": "speed",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "subgraph",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "minilm",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "trade",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "offs",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "mermaid",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "graph",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "matrix",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "fast",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "lower",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "tinybert",
            "tf": 1,
            "weight": 0.015873
          }
        ],
        "unique_terms": 43,
        "total_terms": 63
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Speed vs Accuracy Trade-offs",
        "accuracy",
        "docs",
        "fastlow",
        "mediummed",
        "minilm",
        "ndcg",
        "sec",
        "slowhigh",
        "speed",
        "subgraph"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.515,
      "overall": 0.7383333333333333
    }
  },
  {
    "text": "## Integration with Retrieval Systems  CrossEncoder models are typically used in the reranking stage of two-stage retrieval systems, where they refine results from faster bi-encoder models. ```mermaid graph LR     subgraph \"Retrieve & Rerank Pipeline\"         Query[\"User Query\"] --> BiEncoder[\"Bi-Encoder<br/>SentenceTransformer\"]         Corpus[\"Document Corpus<br/>8.8M passages\"] --> BiEncoder         BiEncoder --> CandidateSet[\"Top-k Candidates<br/>(e.g., 100-1000)\"]         CandidateSet --> CrossEncoder[\"CrossEncoder<br/>cross-encoder/ms-marco-MiniLM-L6-v2\"]         CrossEncoder --> RankedResults[\"Final Ranked Results<br/>(e.g., top 10)\"]     end          subgraph \"Performance Benefits\"         BiEncoder --> |\"Fast Retrieval<br/>Dense Search\"| Speed[\"Speed: ~10k docs/sec\"]         CrossEncoder --> |\"Precise Reranking<br/>Cross-Attention\"| Accuracy[\"Accuracy: NDCG@10 74.30\"]     end ```",
    "metadata": {
      "chunk_id": "86736a928325-0025",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 25,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration with Retrieval Systems"
      ],
      "heading_text": "Integration with Retrieval Systems",
      "token_count": 222,
      "char_count": 901,
      "start_char": 16282,
      "end_char": 17183,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5406329113924051,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.403315",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 222,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Integration with Retrieval Systems",
      "chunk_hash": "0c448d63711f64f9",
      "content_digest": "0c448d63711f64f9",
      "chunk_length": 901,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "crossencoder",
          "biencoder",
          "retrieval",
          "encoder",
          "systems",
          "models",
          "reranking",
          "stage",
          "results",
          "subgraph",
          "query",
          "corpus",
          "candidateset",
          "top",
          "cross",
          "end",
          "speed",
          "accuracy",
          "integration",
          "with"
        ],
        "term_weights": [
          {
            "term": "crossencoder",
            "tf": 5,
            "weight": 0.060241
          },
          {
            "term": "biencoder",
            "tf": 4,
            "weight": 0.048193
          },
          {
            "term": "retrieval",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "encoder",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "systems",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "reranking",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "stage",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "results",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "subgraph",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "corpus",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "candidateset",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "top",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "cross",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "speed",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "accuracy",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.012048
          }
        ],
        "unique_terms": 58,
        "total_terms": 83
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration with Retrieval Systems",
        "biencoder",
        "crossencoder",
        "encoder",
        "models",
        "reranking",
        "results",
        "retrieval",
        "stage",
        "subgraph",
        "systems"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5406329113924051,
      "overall": 0.7468776371308016
    }
  },
  {
    "text": "### Hard Negatives Mining  CrossEncoder models are used to generate hard negatives for training bi-encoder models, creating a feedback loop for model improvement. ```mermaid graph TD     subgraph \"Hard Negatives Pipeline\"         BiEncoderV2[\"Bi-Encoder v2<br/>msmarco-distilbert-base-v2\"] --> SimilarPassages[\"Retrieved Similar Passages\"]         SimilarPassages --> CrossEncoderElectra[\"CrossEncoder<br/>electra-base-msmarco\"]         CrossEncoderElectra --> LowScores[\"Low Cross-Encoder Scores<br/>(Hard Negatives)\"]         LowScores --> TrainingData[\"Enhanced Training Data\"]         TrainingData --> BiEncoderV3[\"Bi-Encoder v3<br/>msmarco-distilbert-base-v3\"]     end ``` **Sources:** [docs/pretrained-models/msmarco-v3.md:53-58](), [docs/cross_encoder/pretrained_models.md:44]()",
    "metadata": {
      "chunk_id": "86736a928325-0026",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 26,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Hard Negatives Mining"
      ],
      "heading_text": "Hard Negatives Mining",
      "token_count": 195,
      "char_count": 785,
      "start_char": 17186,
      "end_char": 17971,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5442372881355932,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.405392",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 195,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Hard Negatives Mining",
      "chunk_hash": "3c29f1d98517603a",
      "content_digest": "3c29f1d98517603a",
      "chunk_length": 785,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "encoder",
          "hard",
          "negatives",
          "models",
          "msmarco",
          "base",
          "crossencoder",
          "for",
          "training",
          "distilbert",
          "similarpassages",
          "crossencoderelectra",
          "lowscores",
          "cross",
          "trainingdata",
          "docs",
          "pretrained",
          "mining",
          "are",
          "used"
        ],
        "term_weights": [
          {
            "term": "encoder",
            "tf": 5,
            "weight": 0.070423
          },
          {
            "term": "hard",
            "tf": 4,
            "weight": 0.056338
          },
          {
            "term": "negatives",
            "tf": 4,
            "weight": 0.056338
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.056338
          },
          {
            "term": "msmarco",
            "tf": 4,
            "weight": 0.056338
          },
          {
            "term": "base",
            "tf": 3,
            "weight": 0.042254
          },
          {
            "term": "crossencoder",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "distilbert",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "similarpassages",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "crossencoderelectra",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "lowscores",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "cross",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "trainingdata",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "pretrained",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "mining",
            "tf": 1,
            "weight": 0.014085
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.014085
          },
          {
            "term": "used",
            "tf": 1,
            "weight": 0.014085
          }
        ],
        "unique_terms": 42,
        "total_terms": 71
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Hard Negatives Mining",
        "base",
        "crossencoder",
        "distilbert",
        "encoder",
        "for",
        "hard",
        "models",
        "msmarco",
        "negatives",
        "training"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5442372881355932,
      "overall": 0.7480790960451976
    }
  },
  {
    "text": "## Model Selection Guidelines  | Task Type | Recommended Model | Key Considerations | |-----------|------------------|-------------------| | Information Retrieval | `cross-encoder/ms-marco-MiniLM-L6-v2` | Best balance of speed/accuracy | | Semantic Similarity | `cross-encoder/stsb-roberta-large` | Optimized for similarity scoring | | Question Answering | `cross-encoder/qnli-electra-base` | Passage-question relevance | | Duplicate Detection | `cross-encoder/quora-roberta-base` | Text pair classification | | Multilingual Tasks | `Alibaba-NLP/gte-multilingual-reranker-base` | Cross-lingual support |  **Sources:** [docs/cross_encoder/pretrained_models.md:1-130](), [docs/pretrained-models/ce-msmarco.md:1-63]()",
    "metadata": {
      "chunk_id": "86736a928325-0027",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 27,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Selection Guidelines"
      ],
      "heading_text": "Model Selection Guidelines",
      "token_count": 179,
      "char_count": 714,
      "start_char": 17975,
      "end_char": 18689,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6797058823529412,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.406048",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 179,
      "document_id": "86736a928325",
      "document_name": "SparseEncoder_Models",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Model Selection Guidelines",
      "chunk_hash": "dc08d0d482d0c4c6",
      "content_digest": "dc08d0d482d0c4c6",
      "chunk_length": 714,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cross",
          "encoder",
          "base",
          "model",
          "similarity",
          "roberta",
          "question",
          "multilingual",
          "docs",
          "pretrained",
          "models",
          "selection",
          "guidelines",
          "task",
          "type",
          "recommended",
          "key",
          "considerations",
          "information",
          "retrieval"
        ],
        "term_weights": [
          {
            "term": "cross",
            "tf": 6,
            "weight": 0.083333
          },
          {
            "term": "encoder",
            "tf": 5,
            "weight": 0.069444
          },
          {
            "term": "base",
            "tf": 3,
            "weight": 0.041667
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "similarity",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "roberta",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "question",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "multilingual",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "pretrained",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "selection",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "guidelines",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "task",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "type",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "recommended",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "considerations",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "information",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "retrieval",
            "tf": 1,
            "weight": 0.013889
          }
        ],
        "unique_terms": 53,
        "total_terms": 72
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Selection Guidelines",
        "base",
        "cross",
        "docs",
        "encoder",
        "model",
        "multilingual",
        "pretrained",
        "question",
        "roberta",
        "similarity"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6797058823529412,
      "overall": 0.7932352941176469
    }
  }
]
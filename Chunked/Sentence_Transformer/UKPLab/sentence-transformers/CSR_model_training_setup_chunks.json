[
  {
    "text": "### Architecture Requirements ```mermaid graph TD     subgraph \"Model Architecture Requirements\"         SPLADE[\"SPLADE Models\"]         CSR[\"CSR Models\"]                  MLMTransformer[\"MLMTransformer<br/>MLM head access\"]         SpladePooling[\"SpladePooling<br/>Sparse pooling\"]                  Autoencoder[\"Autoencoder Components<br/>encode/decode methods\"]         BackboneEmb[\"sentence_embedding_backbone\"]         DecodedEmb[\"decoded_embedding_k/4k/aux\"]                  SPLADE --> MLMTransformer         SPLADE --> SpladePooling                  CSR --> Autoencoder         CSR --> BackboneEmb         CSR --> DecodedEmb     end ``` Sources: [sentence_transformers/sparse_encoder/models/MLMTransformer.py:26-54](), [sentence_transformers/sparse_encoder/models/SpladePooling.py:13-39](), [sentence_transformers/sparse_encoder/losses/CSRLoss.py:68-98]()",
    "metadata": {
      "chunk_id": "616f22a602c0-0000",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\CSR_model_training_setup.md",
      "filename": "CSR_model_training_setup.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Architecture Requirements"
      ],
      "heading_text": "Architecture Requirements",
      "token_count": 187,
      "char_count": 862,
      "start_char": 221,
      "end_char": 1083,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.53,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.349937",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 187,
      "document_id": "616f22a602c0",
      "document_name": "CSR_model_training_setup",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\CSR_model_training_setup.md",
      "source_filename": "CSR_model_training_setup.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\CSR_model_training_setup.md",
      "hierarchy_path": "Architecture Requirements",
      "chunk_hash": "31a00e6ca06e3fbc",
      "content_digest": "31a00e6ca06e3fbc",
      "chunk_length": 862,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "csr",
          "splade",
          "models",
          "mlmtransformer",
          "spladepooling",
          "sparse",
          "sentence",
          "autoencoder",
          "transformers",
          "encoder",
          "architecture",
          "requirements",
          "backboneemb",
          "embedding",
          "decodedemb",
          "mermaid",
          "graph",
          "subgraph",
          "model",
          "mlm"
        ],
        "term_weights": [
          {
            "term": "csr",
            "tf": 5,
            "weight": 0.074627
          },
          {
            "term": "splade",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "mlmtransformer",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "spladepooling",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "sparse",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "sentence",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "autoencoder",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "encoder",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "architecture",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "requirements",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "backboneemb",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "decodedemb",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "mermaid",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "graph",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "subgraph",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "mlm",
            "tf": 1,
            "weight": 0.014925
          }
        ],
        "unique_terms": 34,
        "total_terms": 67
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Architecture Requirements",
        "autoencoder",
        "csr",
        "encoder",
        "mlmtransformer",
        "models",
        "sentence",
        "sparse",
        "splade",
        "spladepooling",
        "transformers"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.53,
      "overall": 0.7433333333333332
    }
  }
]
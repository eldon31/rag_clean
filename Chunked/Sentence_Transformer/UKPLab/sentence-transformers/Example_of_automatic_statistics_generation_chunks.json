[
  {
    "text": "### Template-Based Generation  Model cards are generated using Jinja2 templates that create standardized documentation:  | Template Section | Content Generated | Data Source | |------------------|-------------------|-------------| | **Model Description** | Base model, architecture, dimensions | `base_model`, `output_dimensionality` | | **Usage Examples** | Code snippets with actual model ID | `predict_example`, `model_id` | | **Training Details** | Dataset information, hyperparameters | `train_datasets`, `all_hyperparameters` | | **Evaluation Metrics** | Performance tables and charts | `eval_results_dict`, `training_logs` | | **Citations** | Automatic BibTeX generation | `citations` from loss functions |  Templates automatically adapt based on model type: - Information Retrieval models get separate `encode_query`/`encode_document` examples - Sparse encoders include sparsity and dimensionality information   - Cross encoders focus on reranking and classification use cases  Sources: [sentence_transformers/model_card_template.md:76-126](), [sentence_transformers/sparse_encoder/model_card_template.md:99-126]()",
    "metadata": {
      "chunk_id": "513d4c423c3e-0000",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Template-Based Generation"
      ],
      "heading_text": "Template-Based Generation",
      "token_count": 229,
      "char_count": 1122,
      "start_char": 562,
      "end_char": 1684,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7039344262295082,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.488519",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 229,
      "document_id": "513d4c423c3e",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Template-Based Generation",
      "chunk_hash": "3b793e97c361f201",
      "content_digest": "3b793e97c361f201",
      "chunk_length": 1122,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "template",
          "information",
          "and",
          "based",
          "generation",
          "generated",
          "templates",
          "base",
          "dimensionality",
          "examples",
          "training",
          "hyperparameters",
          "citations",
          "encode",
          "sparse",
          "encoders",
          "sentence",
          "transformers",
          "card"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 9,
            "weight": 0.078947
          },
          {
            "term": "template",
            "tf": 4,
            "weight": 0.035088
          },
          {
            "term": "information",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "based",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "generation",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "generated",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "templates",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "base",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "dimensionality",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "hyperparameters",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "citations",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "encode",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "encoders",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "card",
            "tf": 2,
            "weight": 0.017544
          }
        ],
        "unique_terms": 82,
        "total_terms": 114
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Template-Based Generation",
        "and",
        "base",
        "based",
        "dimensionality",
        "generated",
        "generation",
        "information",
        "model",
        "template",
        "templates"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7039344262295082,
      "overall": 0.801311475409836
    }
  },
  {
    "text": "## Backend Architecture and Optimization\n\nThe library supports multiple backend implementations for optimized inference across different deployment scenarios.",
    "metadata": {
      "chunk_id": "513d4c423c3e-0001",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Backend Architecture and Optimization"
      ],
      "heading_text": "Backend Architecture and Optimization",
      "token_count": 20,
      "char_count": 158,
      "start_char": 1686,
      "end_char": 1844,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5733333333333334,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.489408",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 20,
      "document_id": "513d4c423c3e",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Backend Architecture and Optimization",
      "chunk_hash": "44464fb6ab0992ac",
      "content_digest": "44464fb6ab0992ac",
      "chunk_length": 158,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "backend",
          "architecture",
          "and",
          "optimization",
          "the",
          "library",
          "supports",
          "multiple",
          "implementations",
          "for",
          "optimized",
          "inference",
          "across",
          "different",
          "deployment",
          "scenarios"
        ],
        "term_weights": [
          {
            "term": "backend",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "architecture",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "optimization",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "implementations",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "optimized",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "across",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "deployment",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "scenarios",
            "tf": 1,
            "weight": 0.058824
          }
        ],
        "unique_terms": 16,
        "total_terms": 17
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Backend Architecture and Optimization",
        "and",
        "architecture",
        "backend",
        "for",
        "implementations",
        "library",
        "multiple",
        "optimization",
        "supports",
        "the"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5733333333333334,
      "overall": 0.7577777777777778
    }
  },
  {
    "text": "### Custom Model Card Integration  Developers can extend the model card system for custom model types: ```python @dataclass class CustomModelCardData(SentenceTransformerModelCardData):     custom_field: str = \"default_value\"     custom_metrics: dict = field(default_factory=dict)          def get_model_specific_metadata(self) -> dict[str, Any]:         return {             \"custom_dimension\": self.model.get_custom_dimension(),             \"special_config\": self.model.get_special_config(),         } ```",
    "metadata": {
      "chunk_id": "513d4c423c3e-0005",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Custom Model Card Integration"
      ],
      "heading_text": "Custom Model Card Integration",
      "token_count": 98,
      "char_count": 506,
      "start_char": 3953,
      "end_char": 4459,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5534146341463415,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.495156",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 98,
      "document_id": "513d4c423c3e",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Custom Model Card Integration",
      "chunk_hash": "3afecffbe7fc6447",
      "content_digest": "3afecffbe7fc6447",
      "chunk_length": 506,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "custom",
          "model",
          "dict",
          "get",
          "self",
          "card",
          "field",
          "str",
          "default",
          "dimension",
          "special",
          "config",
          "integration",
          "developers",
          "can",
          "extend",
          "the",
          "system",
          "for",
          "types"
        ],
        "term_weights": [
          {
            "term": "custom",
            "tf": 6,
            "weight": 0.107143
          },
          {
            "term": "model",
            "tf": 6,
            "weight": 0.107143
          },
          {
            "term": "dict",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "get",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "self",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "card",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "field",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "str",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "default",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "dimension",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "special",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "config",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "developers",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "extend",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "types",
            "tf": 1,
            "weight": 0.017857
          }
        ],
        "unique_terms": 33,
        "total_terms": 56
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Custom Model Card Integration",
        "card",
        "custom",
        "default",
        "dict",
        "dimension",
        "field",
        "get",
        "model",
        "self",
        "str"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5534146341463415,
      "overall": 0.7511382113821137
    }
  },
  {
    "text": "# Model Card Generation\n\n\n\n\nThis document covers the automatic model card generation system in sentence-transformers, which creates comprehensive documentation and metadata for trained models. The system automatically tracks training data, hyperparameters, evaluation metrics, and generates standardized model cards during the training process.\n\nFor information about manual model configuration, see other training documentation pages. For details about evaluation metrics collection, see [4](#4).",
    "metadata": {
      "chunk_id": "513d4c423c3e-0008",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Card Generation"
      ],
      "heading_text": "Model Card Generation",
      "token_count": 79,
      "char_count": 497,
      "start_char": 5634,
      "end_char": 6131,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5063934426229508,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.497843",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 79,
      "document_id": "513d4c423c3e",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Model Card Generation",
      "chunk_hash": "d69730d38138243f",
      "content_digest": "d69730d38138243f",
      "chunk_length": 497,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "the",
          "for",
          "training",
          "card",
          "generation",
          "system",
          "documentation",
          "and",
          "evaluation",
          "metrics",
          "about",
          "see",
          "this",
          "document",
          "covers",
          "automatic",
          "sentence",
          "transformers",
          "which"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 4,
            "weight": 0.067797
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.050847
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.050847
          },
          {
            "term": "training",
            "tf": 3,
            "weight": 0.050847
          },
          {
            "term": "card",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "generation",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "system",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "documentation",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "evaluation",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "metrics",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "about",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "see",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "covers",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "automatic",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "which",
            "tf": 1,
            "weight": 0.016949
          }
        ],
        "unique_terms": 41,
        "total_terms": 59
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Card Generation",
        "and",
        "card",
        "documentation",
        "evaluation",
        "for",
        "generation",
        "model",
        "system",
        "the",
        "training"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5063934426229508,
      "overall": 0.7354644808743168
    }
  },
  {
    "text": "## Data Collection Process  The model card system automatically collects training metadata through callback integration with the trainer lifecycle: ```mermaid sequenceDiagram     participant Trainer as \"SentenceTransformerTrainer\"     participant Callback as \"SentenceTransformerModelCardCallback\"     participant ModelCard as \"SentenceTransformerModelCardData\"     participant Model as \"SentenceTransformer\"          Trainer->>Callback: on_init_end()     Callback->>ModelCard: extract_dataset_metadata()     Callback->>ModelCard: set_losses()     Callback->>ModelCard: set_widget_examples()          Trainer->>Callback: on_train_begin()     Callback->>ModelCard: store hyperparameters          loop During Training         Trainer->>Callback: on_log()         Callback->>ModelCard: track training_logs                  Trainer->>Callback: on_evaluate()         Callback->>ModelCard: track evaluation metrics     end          Model->>ModelCard: save()     ModelCard->>ModelCard: generate_model_card() ``` **Automatic Data Collection Timeline**  Note: The legacy `ModelCardCallback` class has been deprecated in favor of `SentenceTransformerModelCardCallback` ([sentence_transformers/model_card.py:193-199]()). Sources: [sentence_transformers/model_card.py:47-192](), [sentence_transformers/trainer.py:315-333]()",
    "metadata": {
      "chunk_id": "513d4c423c3e-0010",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Data Collection Process"
      ],
      "heading_text": "Data Collection Process",
      "token_count": 266,
      "char_count": 1311,
      "start_char": 7692,
      "end_char": 9003,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7133333333333333,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.503597",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 266,
      "document_id": "513d4c423c3e",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Data Collection Process",
      "chunk_hash": "34ce901f02ba6f4c",
      "content_digest": "34ce901f02ba6f4c",
      "chunk_length": 1311,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "callback",
          "modelcard",
          "trainer",
          "model",
          "card",
          "participant",
          "the",
          "training",
          "sentence",
          "transformers",
          "data",
          "collection",
          "metadata",
          "sentencetransformermodelcardcallback",
          "end",
          "set",
          "track",
          "process",
          "system",
          "automatically"
        ],
        "term_weights": [
          {
            "term": "callback",
            "tf": 12,
            "weight": 0.102564
          },
          {
            "term": "modelcard",
            "tf": 10,
            "weight": 0.08547
          },
          {
            "term": "trainer",
            "tf": 7,
            "weight": 0.059829
          },
          {
            "term": "model",
            "tf": 6,
            "weight": 0.051282
          },
          {
            "term": "card",
            "tf": 4,
            "weight": 0.034188
          },
          {
            "term": "participant",
            "tf": 4,
            "weight": 0.034188
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "training",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "collection",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "metadata",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "sentencetransformermodelcardcallback",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "set",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "track",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.008547
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.008547
          },
          {
            "term": "automatically",
            "tf": 1,
            "weight": 0.008547
          }
        ],
        "unique_terms": 65,
        "total_terms": 117
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Data Collection Process",
        "callback",
        "card",
        "model",
        "modelcard",
        "participant",
        "sentence",
        "the",
        "trainer",
        "training",
        "transformers"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7133333333333333,
      "overall": 0.8044444444444444
    }
  },
  {
    "text": "## Model Card Types and Features  The system supports three model card types with specialized features for each model architecture:  | Model Type | Data Class | Callback Class | Key Features | |------------|------------|----------------|--------------| | `SentenceTransformer` | `SentenceTransformerModelCardData` | `SentenceTransformerModelCardCallback` | Dense embeddings, similarity functions, widget examples | | `SparseEncoder` | `SparseEncoderModelCardData` | `SparseEncoderModelCardCallback` | Sparse embeddings, sparsity metrics, active dimensions | | `CrossEncoder` | `CrossEncoderModelCardData` | `CrossEncoderModelCardCallback` | Pairwise scoring, ranking metrics, text classification |  Sources: [sentence_transformers/model_card.py:266-355](), [sentence_transformers/sparse_encoder/model_card.py:23-132](), [sentence_transformers/cross_encoder/model_card.py:28-161]()",
    "metadata": {
      "chunk_id": "513d4c423c3e-0011",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Card Types and Features"
      ],
      "heading_text": "Model Card Types and Features",
      "token_count": 187,
      "char_count": 880,
      "start_char": 9008,
      "end_char": 9888,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.68125,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.504384",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 187,
      "document_id": "513d4c423c3e",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Model Card Types and Features",
      "chunk_hash": "5b152d23ee6ab01e",
      "content_digest": "5b152d23ee6ab01e",
      "chunk_length": 880,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "card",
          "features",
          "sentence",
          "transformers",
          "types",
          "class",
          "embeddings",
          "sparse",
          "metrics",
          "encoder",
          "and",
          "the",
          "system",
          "supports",
          "three",
          "with",
          "specialized",
          "for",
          "each"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 7,
            "weight": 0.093333
          },
          {
            "term": "card",
            "tf": 5,
            "weight": 0.066667
          },
          {
            "term": "features",
            "tf": 3,
            "weight": 0.04
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.04
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.04
          },
          {
            "term": "types",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "class",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "metrics",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "three",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "specialized",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "each",
            "tf": 1,
            "weight": 0.013333
          }
        ],
        "unique_terms": 53,
        "total_terms": 75
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Card Types and Features",
        "card",
        "class",
        "embeddings",
        "features",
        "metrics",
        "model",
        "sentence",
        "sparse",
        "transformers",
        "types"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.68125,
      "overall": 0.7937499999999998
    }
  },
  {
    "text": "### Training Metadata Collection  The `SentenceTransformerModelCardCallback` automatically captures training information through trainer hooks:  **Initialization Phase** ([sentence_transformers/model_card.py:52-88]()): - Dataset metadata extraction via `extract_dataset_metadata()` - Loss function registration via `set_losses()` - Widget example generation via `set_widget_examples()` - CodeCarbon integration for emissions tracking  **Training Phase** ([sentence_transformers/model_card.py:89-130]()): - Hyperparameter tracking (default vs. non-default values) - Training and validation loss logging - Information retrieval model detection  **Evaluation Phase** ([sentence_transformers/model_card.py:131-191]()): - Evaluation metrics collection - Primary metric identification for model selection - Training log consolidation",
    "metadata": {
      "chunk_id": "513d4c423c3e-0013",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Training Metadata Collection"
      ],
      "heading_text": "Training Metadata Collection",
      "token_count": 149,
      "char_count": 827,
      "start_char": 9918,
      "end_char": 10745,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7026582278481012,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.506690",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 149,
      "document_id": "513d4c423c3e",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Training Metadata Collection",
      "chunk_hash": "c581eb403daf7c9f",
      "content_digest": "c581eb403daf7c9f",
      "chunk_length": 827,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "training",
          "model",
          "metadata",
          "phase",
          "sentence",
          "transformers",
          "card",
          "via",
          "collection",
          "information",
          "dataset",
          "loss",
          "set",
          "widget",
          "for",
          "tracking",
          "default",
          "evaluation",
          "the",
          "sentencetransformermodelcardcallback"
        ],
        "term_weights": [
          {
            "term": "training",
            "tf": 5,
            "weight": 0.058824
          },
          {
            "term": "model",
            "tf": 5,
            "weight": 0.058824
          },
          {
            "term": "metadata",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "phase",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "card",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "via",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "collection",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "information",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "dataset",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "loss",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "set",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "widget",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "tracking",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "default",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "evaluation",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "sentencetransformermodelcardcallback",
            "tf": 1,
            "weight": 0.011765
          }
        ],
        "unique_terms": 55,
        "total_terms": 85
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Training Metadata Collection",
        "card",
        "collection",
        "information",
        "metadata",
        "model",
        "phase",
        "sentence",
        "training",
        "transformers",
        "via"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7026582278481012,
      "overall": 0.800886075949367
    }
  },
  {
    "text": "### Dataset Information Extraction  The system automatically infers dataset metadata from Hugging Face Hub information: ```python",
    "metadata": {
      "chunk_id": "513d4c423c3e-0014",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Dataset Information Extraction"
      ],
      "heading_text": "Dataset Information Extraction",
      "token_count": 21,
      "char_count": 129,
      "start_char": 10747,
      "end_char": 10876,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.57125,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.507163",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 21,
      "document_id": "513d4c423c3e",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Dataset Information Extraction",
      "chunk_hash": "0a08c846afdf040d",
      "content_digest": "0a08c846afdf040d",
      "chunk_length": 129,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "dataset",
          "information",
          "extraction",
          "the",
          "system",
          "automatically",
          "infers",
          "metadata",
          "from",
          "hugging",
          "face",
          "hub",
          "python"
        ],
        "term_weights": [
          {
            "term": "dataset",
            "tf": 2,
            "weight": 0.133333
          },
          {
            "term": "information",
            "tf": 2,
            "weight": 0.133333
          },
          {
            "term": "extraction",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "automatically",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "infers",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "metadata",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "hugging",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "face",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "hub",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.066667
          }
        ],
        "unique_terms": 13,
        "total_terms": 15
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Dataset Information Extraction",
        "automatically",
        "dataset",
        "extraction",
        "from",
        "hugging",
        "infers",
        "information",
        "metadata",
        "system",
        "the"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.57125,
      "overall": 0.7570833333333334
    }
  },
  {
    "text": "### Widget Example Generation\n\nThe `set_widget_examples()` method automatically creates interactive examples from training or evaluation datasets:\n\n**Example Selection Process** ([sentence_transformers/model_card.py:445-522]()):\n1. Sample 1000 examples from random datasets\n2. Sort by text length to find representative examples  \n3. Generate 4-text combinations for similarity demonstrations\n4. Handle Router module compatibility for asymmetric models\n\n**CrossEncoder Widget Handling** ([sentence_transformers/cross_encoder/model_card.py:90-136]()):\nCrossEncoder models have specialized widget handling that only generates prediction examples rather than interactive widgets, since HuggingFace Hub doesn't support pairwise text ranking widgets.",
    "metadata": {
      "chunk_id": "513d4c423c3e-0016",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Widget Example Generation"
      ],
      "heading_text": "Widget Example Generation",
      "token_count": 135,
      "char_count": 745,
      "start_char": 11278,
      "end_char": 12023,
      "semantic_score": 0.7,
      "structural_score": 0.9999999999999999,
      "retrieval_quality": 0.7520253164556961,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.508065",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 135,
      "document_id": "513d4c423c3e",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Widget Example Generation",
      "chunk_hash": "04065d0d2961fe9d",
      "content_digest": "04065d0d2961fe9d",
      "chunk_length": 745,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "examples",
          "widget",
          "text",
          "example",
          "interactive",
          "from",
          "datasets",
          "sentence",
          "transformers",
          "model",
          "card",
          "for",
          "models",
          "crossencoder",
          "handling",
          "widgets",
          "generation",
          "the",
          "set",
          "method"
        ],
        "term_weights": [
          {
            "term": "examples",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "widget",
            "tf": 4,
            "weight": 0.047619
          },
          {
            "term": "text",
            "tf": 3,
            "weight": 0.035714
          },
          {
            "term": "example",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "interactive",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "from",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "datasets",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "card",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "crossencoder",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "handling",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "widgets",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "generation",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "set",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "method",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 62,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Widget Example Generation",
        "datasets",
        "example",
        "examples",
        "from",
        "interactive",
        "model",
        "sentence",
        "text",
        "transformers",
        "widget"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.9999999999999999,
      "retrieval_quality": 0.7520253164556961,
      "overall": 0.8173417721518986
    }
  },
  {
    "text": "## Template System",
    "metadata": {
      "chunk_id": "513d4c423c3e-0017",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Template System"
      ],
      "heading_text": "Template System",
      "token_count": 3,
      "char_count": 18,
      "start_char": 12025,
      "end_char": 12043,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.508178",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 3,
      "document_id": "513d4c423c3e",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Template System",
      "chunk_hash": "a6b717fcaa8ed430",
      "content_digest": "a6b717fcaa8ed430",
      "chunk_length": 18,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "template",
          "system"
        ],
        "term_weights": [
          {
            "term": "template",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Template System",
        "system",
        "template"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Template Structure  Model cards are generated using Jinja2 templates with conditional sections:  **Base Template Features** ([sentence_transformers/model_card_template.md:1-277]()): - YAML metadata header with HuggingFace Hub integration - Model description with training dataset links - Usage examples with code snippets - Architecture documentation - Evaluation metrics tables - Training details and hyperparameters - Framework version tracking - Citation generation  **Sparse Encoder Specializations** ([sentence_transformers/sparse_encoder/model_card_template.md:1-276]()): - Sparsity statistics and active dimension reporting - Asymmetric model detection (Router/Asym modules) - SPLADE and CSR model type identification - Sparse retrieval usage examples",
    "metadata": {
      "chunk_id": "513d4c423c3e-0018",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Template Structure"
      ],
      "heading_text": "Template Structure",
      "token_count": 137,
      "char_count": 762,
      "start_char": 12045,
      "end_char": 12807,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.709767441860465,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.508536",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 137,
      "document_id": "513d4c423c3e",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Template Structure",
      "chunk_hash": "aee3d14c43d21390",
      "content_digest": "aee3d14c43d21390",
      "chunk_length": 762,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "template",
          "with",
          "and",
          "sparse",
          "sentence",
          "transformers",
          "card",
          "training",
          "usage",
          "examples",
          "encoder",
          "structure",
          "cards",
          "are",
          "generated",
          "using",
          "jinja2",
          "templates",
          "conditional"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 6,
            "weight": 0.069767
          },
          {
            "term": "template",
            "tf": 4,
            "weight": 0.046512
          },
          {
            "term": "with",
            "tf": 4,
            "weight": 0.046512
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.034884
          },
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.034884
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "card",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "usage",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "structure",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "cards",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "generated",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "jinja2",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "templates",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "conditional",
            "tf": 1,
            "weight": 0.011628
          }
        ],
        "unique_terms": 64,
        "total_terms": 86
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Template Structure",
        "and",
        "card",
        "model",
        "sentence",
        "sparse",
        "template",
        "training",
        "transformers",
        "usage",
        "with"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.709767441860465,
      "overall": 0.8032558139534882
    }
  },
  {
    "text": "### Model Type Detection  The system automatically detects model characteristics for specialized documentation: ```python",
    "metadata": {
      "chunk_id": "513d4c423c3e-0019",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Type Detection"
      ],
      "heading_text": "Model Type Detection",
      "token_count": 17,
      "char_count": 121,
      "start_char": 12809,
      "end_char": 12930,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5685714285714286,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T16:07:45.509308",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 17,
      "document_id": "513d4c423c3e",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Model Type Detection",
      "chunk_hash": "60af71c2bd3a08d7",
      "content_digest": "60af71c2bd3a08d7",
      "chunk_length": 121,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1536,
      "matryoshka_dimension": 1536,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "type",
          "detection",
          "the",
          "system",
          "automatically",
          "detects",
          "characteristics",
          "for",
          "specialized",
          "documentation",
          "python"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 2,
            "weight": 0.153846
          },
          {
            "term": "type",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "detection",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "automatically",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "detects",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "characteristics",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "specialized",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "documentation",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.076923
          }
        ],
        "unique_terms": 12,
        "total_terms": 13
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Type Detection",
        "automatically",
        "characteristics",
        "detection",
        "detects",
        "for",
        "model",
        "specialized",
        "system",
        "the",
        "type"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5685714285714286,
      "overall": 0.7561904761904762
    }
  }
]
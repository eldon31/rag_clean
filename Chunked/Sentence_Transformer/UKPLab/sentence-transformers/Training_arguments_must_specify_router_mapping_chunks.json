[
  {
    "text": "#### Sparse Module Pipeline ```mermaid graph LR     Text[\"Input Text\"] --> MLMTrans[\"MLMTransformer<br/>auto_model + MLM head\"]     MLMTrans --> TokenLogits[\"Token Logits<br/>[batch, seq_len, vocab_size]\"]     TokenLogits --> SpladePool[\"SpladePooling<br/>pooling_strategy + activation\"]     SpladePool --> SparseEmb[\"Sparse Embedding<br/>[batch, vocab_size]\"]          subgraph SparseModules[\"Sparse Module Types\"]         MLMTrans         SpladePool     end ```",
    "metadata": {
      "chunk_id": "6a8eb9825a69-0002",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "filename": "Training_arguments_must_specify_router_mapping.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Sparse Module Pipeline"
      ],
      "heading_text": "Sparse Module Pipeline",
      "token_count": 113,
      "char_count": 463,
      "start_char": 543,
      "end_char": 1006,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5268421052631579,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.650488",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 113,
      "document_id": "6a8eb9825a69",
      "document_name": "Training_arguments_must_specify_router_mapping",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "source_filename": "Training_arguments_must_specify_router_mapping.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "hierarchy_path": "Sparse Module Pipeline",
      "chunk_hash": "5727d14804a83cd7",
      "content_digest": "5727d14804a83cd7",
      "chunk_length": 463,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparse",
          "mlmtrans",
          "spladepool",
          "module",
          "text",
          "tokenlogits",
          "batch",
          "vocab",
          "size",
          "pipeline",
          "mermaid",
          "graph",
          "input",
          "mlmtransformer",
          "auto",
          "model",
          "mlm",
          "head",
          "token",
          "logits"
        ],
        "term_weights": [
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "mlmtrans",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "spladepool",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "module",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "tokenlogits",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "batch",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "vocab",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "size",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "pipeline",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "mermaid",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "graph",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "input",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "mlmtransformer",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "auto",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "mlm",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "head",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "token",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "logits",
            "tf": 1,
            "weight": 0.022727
          }
        ],
        "unique_terms": 32,
        "total_terms": 44
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Sparse Module Pipeline",
        "batch",
        "mlmtrans",
        "module",
        "pipeline",
        "size",
        "sparse",
        "spladepool",
        "text",
        "tokenlogits",
        "vocab"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5268421052631579,
      "overall": 0.7422807017543859
    }
  },
  {
    "text": "## Use Cases and Applications  The CrossEncoder is commonly used in several scenarios:  1. **Reranking**: As the second stage in a retrieve-and-rerank pipeline    ``` Query → SentenceTransformer (retrieval) → Top-k documents → CrossEncoder (reranking) → Reranked results    ``` 2. **Text Pair Classification**: Directly scoring or classifying pairs of texts    - Natural language inference (entailment/contradiction)    - Semantic textual similarity    - Question-answer relevance  3. **High-Precision Scoring**: When maximum accuracy is needed for a limited number of text pairs  CrossEncoder models typically achieve higher accuracy than SentenceTransformer models for direct text pair comparison tasks, but they are computationally more expensive for large-scale comparisons. Sources: [README.md:93-131]()",
    "metadata": {
      "chunk_id": "6a8eb9825a69-0010",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "filename": "Training_arguments_must_specify_router_mapping.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Use Cases and Applications"
      ],
      "heading_text": "Use Cases and Applications",
      "token_count": 171,
      "char_count": 808,
      "start_char": 3937,
      "end_char": 4745,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.528235294117647,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.663371",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 171,
      "document_id": "6a8eb9825a69",
      "document_name": "Training_arguments_must_specify_router_mapping",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "source_filename": "Training_arguments_must_specify_router_mapping.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "hierarchy_path": "Use Cases and Applications",
      "chunk_hash": "7bec5609a1c53d9c",
      "content_digest": "7bec5609a1c53d9c",
      "chunk_length": 808,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "crossencoder",
          "text",
          "for",
          "and",
          "the",
          "reranking",
          "sentencetransformer",
          "pair",
          "scoring",
          "pairs",
          "accuracy",
          "models",
          "use",
          "cases",
          "applications",
          "commonly",
          "used",
          "several",
          "scenarios",
          "second"
        ],
        "term_weights": [
          {
            "term": "crossencoder",
            "tf": 3,
            "weight": 0.034884
          },
          {
            "term": "text",
            "tf": 3,
            "weight": 0.034884
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.034884
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "reranking",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "sentencetransformer",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "pair",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "scoring",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "pairs",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "accuracy",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "cases",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "applications",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "commonly",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "used",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "several",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "scenarios",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "second",
            "tf": 1,
            "weight": 0.011628
          }
        ],
        "unique_terms": 71,
        "total_terms": 86
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Use Cases and Applications",
        "and",
        "crossencoder",
        "for",
        "pair",
        "pairs",
        "reranking",
        "scoring",
        "sentencetransformer",
        "text",
        "the"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.528235294117647,
      "overall": 0.7427450980392156
    }
  },
  {
    "text": "# Installation & Setup\n\n\n\n\nThis document covers installation procedures and dependency requirements for the sentence-transformers library. It explains the different installation options available for various use cases including basic inference, training, backend optimization, and development. For basic usage examples after installation, see [Quickstart Guide](#2.1). For training-specific setup details, see [Training](#3).",
    "metadata": {
      "chunk_id": "6a8eb9825a69-0012",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "filename": "Training_arguments_must_specify_router_mapping.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Installation & Setup"
      ],
      "heading_text": "Installation & Setup",
      "token_count": 74,
      "char_count": 425,
      "start_char": 5632,
      "end_char": 6057,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.73,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.665689",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 74,
      "document_id": "6a8eb9825a69",
      "document_name": "Training_arguments_must_specify_router_mapping",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "source_filename": "Training_arguments_must_specify_router_mapping.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "hierarchy_path": "Installation & Setup",
      "chunk_hash": "ab15192e1bab0ab1",
      "content_digest": "ab15192e1bab0ab1",
      "chunk_length": 425,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "installation",
          "for",
          "training",
          "setup",
          "and",
          "the",
          "basic",
          "see",
          "this",
          "document",
          "covers",
          "procedures",
          "dependency",
          "requirements",
          "sentence",
          "transformers",
          "library",
          "explains",
          "different",
          "options"
        ],
        "term_weights": [
          {
            "term": "installation",
            "tf": 4,
            "weight": 0.081633
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.081633
          },
          {
            "term": "training",
            "tf": 3,
            "weight": 0.061224
          },
          {
            "term": "setup",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "basic",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "see",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "covers",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "procedures",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "dependency",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "requirements",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "explains",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "options",
            "tf": 1,
            "weight": 0.020408
          }
        ],
        "unique_terms": 36,
        "total_terms": 49
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Installation & Setup",
        "and",
        "basic",
        "document",
        "for",
        "installation",
        "see",
        "setup",
        "the",
        "this",
        "training"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.73,
      "overall": 0.7766666666666667
    }
  },
  {
    "text": "## System Requirements\n\nThe sentence-transformers library requires **Python 3.9+**, **PyTorch 1.11.0+**, and **transformers v4.41.0+**. The library supports multiple backends and deployment scenarios through optional dependencies.",
    "metadata": {
      "chunk_id": "6a8eb9825a69-0013",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "filename": "Training_arguments_must_specify_router_mapping.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "System Requirements"
      ],
      "heading_text": "System Requirements",
      "token_count": 56,
      "char_count": 230,
      "start_char": 6059,
      "end_char": 6289,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.554,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.666061",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 56,
      "document_id": "6a8eb9825a69",
      "document_name": "Training_arguments_must_specify_router_mapping",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "source_filename": "Training_arguments_must_specify_router_mapping.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "hierarchy_path": "System Requirements",
      "chunk_hash": "d18a65b5c9aa4e87",
      "content_digest": "d18a65b5c9aa4e87",
      "chunk_length": 230,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "transformers",
          "library",
          "and",
          "system",
          "requirements",
          "sentence",
          "requires",
          "python",
          "pytorch",
          "supports",
          "multiple",
          "backends",
          "deployment",
          "scenarios",
          "through",
          "optional",
          "dependencies"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "library",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "requirements",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "requires",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "pytorch",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "backends",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "deployment",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "scenarios",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "optional",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "dependencies",
            "tf": 1,
            "weight": 0.045455
          }
        ],
        "unique_terms": 18,
        "total_terms": 22
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "System Requirements",
        "and",
        "library",
        "python",
        "pytorch",
        "requirements",
        "requires",
        "sentence",
        "system",
        "the",
        "transformers"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.554,
      "overall": 0.6846666666666668
    }
  },
  {
    "text": "### Installation Options Overview  The library provides five main installation configurations that correspond to different usage patterns: ```mermaid graph TB     subgraph \"Installation Options\"         Default[\"Default<br/>Basic inference\"]         ONNX[\"ONNX<br/>Optimized inference\"]         OpenVINO[\"OpenVINO<br/>Intel optimization\"]         Training[\"Default + Training<br/>Model training\"]         Development[\"Development<br/>Contributing\"]     end          subgraph \"Core Capabilities\"         Default --> LoadSave[\"Model loading/saving\"]         Default --> Inference[\"Embedding generation\"]                  ONNX --> ONNXOpt[\"ONNX optimization\"]         ONNX --> Quantization[\"Model quantization\"]                  OpenVINO --> IntelOpt[\"Intel hardware optimization\"]                  Training --> TrainLoop[\"Training loops\"]         Training --> Evaluation[\"Model evaluation\"]                  Development --> Testing[\"Unit testing\"]         Development --> Linting[\"Code formatting\"]     end          subgraph \"Backend Support\"         LoadSave --> PyTorchBackend[\"PyTorch backend\"]         ONNXOpt --> ONNXBackend[\"ONNX Runtime backend\"]         IntelOpt --> OpenVINOBackend[\"OpenVINO backend\"]     end          subgraph \"Model Types\"         PyTorchBackend --> SentenceTransformer[\"SentenceTransformer\"]         PyTorchBackend --> SparseEncoder[\"SparseEncoder\"]         PyTorchBackend --> CrossEncoder[\"CrossEncoder\"]                  ONNXBackend --> OptimizedModels[\"Optimized models\"]         OpenVINOBackend --> IntelModels[\"Intel-optimized models\"]     end ``` **Sources:** [docs/installation.md:3-8]()",
    "metadata": {
      "chunk_id": "6a8eb9825a69-0014",
      "source_file": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "filename": "Training_arguments_must_specify_router_mapping.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Installation Options Overview"
      ],
      "heading_text": "Installation Options Overview",
      "token_count": 325,
      "char_count": 1621,
      "start_char": 6291,
      "end_char": 7912,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5077564102564103,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "code_block",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1024,
      "processing_timestamp": "2025-10-20T18:30:50.671833",
      "model_aware_chunking": true,
      "within_token_limit": true,
      "estimated_tokens": 325,
      "document_id": "6a8eb9825a69",
      "document_name": "Training_arguments_must_specify_router_mapping",
      "source_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "source_filename": "Training_arguments_must_specify_router_mapping.md",
      "source_directory": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\Sentence_Transformer\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "hierarchy_path": "Installation Options Overview",
      "chunk_hash": "dafb604cda38c82b",
      "content_digest": "dafb604cda38c82b",
      "chunk_length": 1621,
      "payload_version": "1.3",
      "collection_hints": [
        "sentence_transformer"
      ],
      "target_model": "jina-code-embeddings-1.5b",
      "chunker_version": "v5_unified",
      "chunk_size_tokens": 26214,
      "chunk_overlap_tokens": 2621,
      "chunk_size_chars": 104856,
      "chunk_overlap_chars": 10484,
      "safety_margin": 0.8,
      "model_hf_id": "jinaai/jina-code-embeddings-1.5b",
      "model_max_tokens": 32768,
      "model_vector_dim": 1024,
      "recommended_batch_size": 16,
      "backend": "pytorch",
      "memory_efficient": true,
      "query_prefix": "Encode this code snippet for semantic retrieval: ",
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "onnx",
          "training",
          "default",
          "model",
          "installation",
          "subgraph",
          "openvino",
          "development",
          "end",
          "backend",
          "pytorchbackend",
          "inference",
          "optimized",
          "intel",
          "optimization",
          "options",
          "loadsave",
          "onnxopt",
          "quantization",
          "intelopt"
        ],
        "term_weights": [
          {
            "term": "onnx",
            "tf": 6,
            "weight": 0.048
          },
          {
            "term": "training",
            "tf": 6,
            "weight": 0.048
          },
          {
            "term": "default",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "model",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "installation",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "openvino",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "development",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "backend",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "pytorchbackend",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "optimized",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "intel",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "optimization",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "options",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "loadsave",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "onnxopt",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "quantization",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "intelopt",
            "tf": 2,
            "weight": 0.016
          }
        ],
        "unique_terms": 65,
        "total_terms": 125
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Installation Options Overview",
        "backend",
        "default",
        "development",
        "end",
        "installation",
        "model",
        "onnx",
        "openvino",
        "subgraph",
        "training"
      ],
      "collection_name": "Sentence_Transformer"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5077564102564103,
      "overall": 0.7359188034188033
    }
  }
]
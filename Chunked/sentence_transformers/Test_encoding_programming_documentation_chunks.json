[
  {
    "text": "# Test ONNX backend (if installed) from sentence_transformers import SentenceTransformer model = SentenceTransformer('all-MiniLM-L6-v2', backend='onnx')",
    "metadata": {
      "chunk_id": "26df4c2ab670-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "filename": "Test_encoding.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Test ONNX backend (if installed)"
      ],
      "heading_text": "Test ONNX backend (if installed)",
      "token_count": 35,
      "char_count": 152,
      "start_char": 0,
      "end_char": 152,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:23.285511",
      "document_id": "26df4c2ab670",
      "document_name": "Test_encoding",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "source_filename": "Test_encoding.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "hierarchy_path": "Test ONNX backend (if installed)",
      "chunk_hash": "fb8649215d084df0",
      "content_digest": "fb8649215d084df0",
      "chunk_length": 152,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "onnx",
          "backend",
          "sentencetransformer",
          "test",
          "installed",
          "from",
          "sentence",
          "transformers",
          "import",
          "model",
          "all",
          "minilm"
        ],
        "term_weights": [
          {
            "term": "onnx",
            "tf": 2,
            "weight": 0.133333
          },
          {
            "term": "backend",
            "tf": 2,
            "weight": 0.133333
          },
          {
            "term": "sentencetransformer",
            "tf": 2,
            "weight": 0.133333
          },
          {
            "term": "test",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "installed",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "import",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "minilm",
            "tf": 1,
            "weight": 0.066667
          }
        ],
        "unique_terms": 12,
        "total_terms": 15
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Test ONNX backend (if installed)",
        "backend",
        "from",
        "import",
        "installed",
        "model",
        "onnx",
        "sentence",
        "sentencetransformer",
        "test",
        "transformers"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "# Test OpenVINO backend (if installed)   model = SentenceTransformer('all-MiniLM-L6-v2', backend='openvino')",
    "metadata": {
      "chunk_id": "26df4c2ab670-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "filename": "Test_encoding.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Test OpenVINO backend (if installed)"
      ],
      "heading_text": "Test OpenVINO backend (if installed)",
      "token_count": 31,
      "char_count": 108,
      "start_char": 0,
      "end_char": 108,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:23.285748",
      "document_id": "26df4c2ab670",
      "document_name": "Test_encoding",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "source_filename": "Test_encoding.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "hierarchy_path": "Test OpenVINO backend (if installed)",
      "chunk_hash": "38e036ae6a9c36a2",
      "content_digest": "38e036ae6a9c36a2",
      "chunk_length": 108,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "openvino",
          "backend",
          "test",
          "installed",
          "model",
          "sentencetransformer",
          "all",
          "minilm"
        ],
        "term_weights": [
          {
            "term": "openvino",
            "tf": 2,
            "weight": 0.2
          },
          {
            "term": "backend",
            "tf": 2,
            "weight": 0.2
          },
          {
            "term": "test",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "installed",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "sentencetransformer",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.1
          },
          {
            "term": "minilm",
            "tf": 1,
            "weight": 0.1
          }
        ],
        "unique_terms": 8,
        "total_terms": 10
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Test OpenVINO backend (if installed)",
        "all",
        "backend",
        "installed",
        "minilm",
        "model",
        "openvino",
        "sentencetransformer",
        "test"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Backend-Specific Verification  Test different backends if installed: ```python",
    "metadata": {
      "chunk_id": "26df4c2ab670-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "filename": "Test_encoding.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Backend-Specific Verification"
      ],
      "heading_text": "Backend-Specific Verification",
      "token_count": 15,
      "char_count": 82,
      "start_char": 0,
      "end_char": 82,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.39,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:23.285269",
      "document_id": "26df4c2ab670",
      "document_name": "Test_encoding",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "source_filename": "Test_encoding.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "hierarchy_path": "Backend-Specific Verification",
      "chunk_hash": "95c7af5be42f3f44",
      "content_digest": "95c7af5be42f3f44",
      "chunk_length": 82,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "backend",
          "specific",
          "verification",
          "test",
          "different",
          "backends",
          "installed",
          "python"
        ],
        "term_weights": [
          {
            "term": "backend",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "specific",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "verification",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "test",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "backends",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "installed",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.125
          }
        ],
        "unique_terms": 8,
        "total_terms": 8
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Backend-Specific Verification",
        "backend",
        "backends",
        "different",
        "installed",
        "python",
        "specific",
        "test",
        "verification"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.39,
      "overall": 0.6966666666666667
    }
  },
  {
    "text": "# Check GPU availability import torch print(f\"CUDA available: {torch.cuda.is_available()}\") print(f\"GPU count: {torch.cuda.device_count()}\") ``` **Sources:** [docs/installation.md:1-177]()",
    "metadata": {
      "chunk_id": "26df4c2ab670-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "filename": "Test_encoding.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Check GPU availability"
      ],
      "heading_text": "Check GPU availability",
      "token_count": 46,
      "char_count": 188,
      "start_char": 0,
      "end_char": 188,
      "semantic_score": 0.2989906966686249,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.39,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:23.286039",
      "document_id": "26df4c2ab670",
      "document_name": "Test_encoding",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "source_filename": "Test_encoding.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "hierarchy_path": "Check GPU availability",
      "chunk_hash": "cdaca89393986047",
      "content_digest": "cdaca89393986047",
      "chunk_length": 188,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "torch",
          "cuda",
          "gpu",
          "print",
          "available",
          "count",
          "check",
          "availability",
          "import",
          "device",
          "sources",
          "docs",
          "installation",
          "177"
        ],
        "term_weights": [
          {
            "term": "torch",
            "tf": 3,
            "weight": 0.136364
          },
          {
            "term": "cuda",
            "tf": 3,
            "weight": 0.136364
          },
          {
            "term": "gpu",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "print",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "available",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "count",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "check",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "availability",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "import",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "device",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "docs",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "installation",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "177",
            "tf": 1,
            "weight": 0.045455
          }
        ],
        "unique_terms": 14,
        "total_terms": 22
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Check GPU availability",
        "availability",
        "available",
        "check",
        "count",
        "cuda",
        "device",
        "gpu",
        "import",
        "print",
        "torch"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.2989906966686249,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.39,
      "overall": 0.5296635655562083
    }
  }
]
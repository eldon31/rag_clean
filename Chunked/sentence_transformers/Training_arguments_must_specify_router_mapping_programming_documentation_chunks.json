[
  {
    "text": "#### Sparse Module Pipeline ```mermaid graph LR     Text[\"Input Text\"] --> MLMTrans[\"MLMTransformer<br/>auto_model + MLM head\"]     MLMTrans --> TokenLogits[\"Token Logits<br/>[batch, seq_len, vocab_size]\"]     TokenLogits --> SpladePool[\"SpladePooling<br/>pooling_strategy + activation\"]     SpladePool --> SparseEmb[\"Sparse Embedding<br/>[batch, vocab_size]\"]          subgraph SparseModules[\"Sparse Module Types\"]         MLMTrans         SpladePool     end ```",
    "metadata": {
      "chunk_id": "9eeaa096c300-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "filename": "Training_arguments_must_specify_router_mapping.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Sparse Module Pipeline"
      ],
      "heading_text": "Sparse Module Pipeline",
      "token_count": 113,
      "char_count": 463,
      "start_char": 0,
      "end_char": 463,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5268421052631579,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:27.789522",
      "document_id": "9eeaa096c300",
      "document_name": "Training_arguments_must_specify_router_mapping",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "source_filename": "Training_arguments_must_specify_router_mapping.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "hierarchy_path": "Sparse Module Pipeline",
      "chunk_hash": "5727d14804a83cd7",
      "content_digest": "5727d14804a83cd7",
      "chunk_length": 463,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparse",
          "mlmtrans",
          "spladepool",
          "module",
          "text",
          "tokenlogits",
          "batch",
          "vocab",
          "size",
          "pipeline",
          "mermaid",
          "graph",
          "input",
          "mlmtransformer",
          "auto",
          "model",
          "mlm",
          "head",
          "token",
          "logits"
        ],
        "term_weights": [
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "mlmtrans",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "spladepool",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "module",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "tokenlogits",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "batch",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "vocab",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "size",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "pipeline",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "mermaid",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "graph",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "input",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "mlmtransformer",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "auto",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "mlm",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "head",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "token",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "logits",
            "tf": 1,
            "weight": 0.022727
          }
        ],
        "unique_terms": 32,
        "total_terms": 44
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Sparse Module Pipeline",
        "batch",
        "mlmtrans",
        "module",
        "pipeline",
        "size",
        "sparse",
        "spladepool",
        "text",
        "tokenlogits",
        "vocab"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5268421052631579,
      "overall": 0.7422807017543859
    }
  },
  {
    "text": "### Installation Options Overview  The library provides five main installation configurations that correspond to different usage patterns: ```mermaid graph TB     subgraph \"Installation Options\"         Default[\"Default<br/>Basic inference\"]         ONNX[\"ONNX<br/>Optimized inference\"]         OpenVINO[\"OpenVINO<br/>Intel optimization\"]         Training[\"Default + Training<br/>Model training\"]         Development[\"Development<br/>Contributing\"]     end          subgraph \"Core Capabilities\"         Default --> LoadSave[\"Model loading/saving\"]         Default --> Inference[\"Embedding generation\"]                  ONNX --> ONNXOpt[\"ONNX optimization\"]         ONNX --> Quantization[\"Model quantization\"]                  OpenVINO --> IntelOpt[\"Intel hardware optimization\"]                  Training --> TrainLoop[\"Training loops\"]         Training --> Evaluation[\"Model evaluation\"]                  Development --> Testing[\"Unit testing\"]         Development --> Linting[\"Code formatting\"]     end          subgraph \"Backend Support\"         LoadSave --> PyTorchBackend[\"PyTorch backend\"]         ONNXOpt --> ONNXBackend[\"ONNX Runtime backend\"]         IntelOpt --> OpenVINOBackend[\"OpenVINO backend\"]     end          subgraph \"Model Types\"         PyTorchBackend --> SentenceTransformer[\"SentenceTransformer\"]         PyTorchBackend --> SparseEncoder[\"SparseEncoder\"]         PyTorchBackend --> CrossEncoder[\"CrossEncoder\"]                  ONNXBackend --> OptimizedModels[\"Optimized models\"]         OpenVINOBackend --> IntelModels[\"Intel-optimized models\"]     end ``` **Sources:** [docs/installation.md:3-8]()",
    "metadata": {
      "chunk_id": "9eeaa096c300-0012",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "filename": "Training_arguments_must_specify_router_mapping.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Installation Options Overview"
      ],
      "heading_text": "Installation Options Overview",
      "token_count": 325,
      "char_count": 1621,
      "start_char": 0,
      "end_char": 1621,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5077564102564103,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:27.793384",
      "document_id": "9eeaa096c300",
      "document_name": "Training_arguments_must_specify_router_mapping",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "source_filename": "Training_arguments_must_specify_router_mapping.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "hierarchy_path": "Installation Options Overview",
      "chunk_hash": "dafb604cda38c82b",
      "content_digest": "dafb604cda38c82b",
      "chunk_length": 1621,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "onnx",
          "training",
          "default",
          "model",
          "installation",
          "subgraph",
          "openvino",
          "development",
          "end",
          "backend",
          "pytorchbackend",
          "inference",
          "optimized",
          "intel",
          "optimization",
          "options",
          "loadsave",
          "onnxopt",
          "quantization",
          "intelopt"
        ],
        "term_weights": [
          {
            "term": "onnx",
            "tf": 6,
            "weight": 0.048
          },
          {
            "term": "training",
            "tf": 6,
            "weight": 0.048
          },
          {
            "term": "default",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "model",
            "tf": 5,
            "weight": 0.04
          },
          {
            "term": "installation",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "openvino",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "development",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "backend",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "pytorchbackend",
            "tf": 4,
            "weight": 0.032
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "optimized",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "intel",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "optimization",
            "tf": 3,
            "weight": 0.024
          },
          {
            "term": "options",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "loadsave",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "onnxopt",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "quantization",
            "tf": 2,
            "weight": 0.016
          },
          {
            "term": "intelopt",
            "tf": 2,
            "weight": 0.016
          }
        ],
        "unique_terms": 65,
        "total_terms": 125
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Installation Options Overview",
        "backend",
        "default",
        "development",
        "end",
        "installation",
        "model",
        "onnx",
        "openvino",
        "subgraph",
        "training"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5077564102564103,
      "overall": 0.7359188034188033
    }
  },
  {
    "text": "### pip Installation  The recommended installation method uses pip with specific extras for different use cases:  | Installation Type | Command | Use Case | |------------------|---------|----------| | Default | `pip install -U sentence-transformers` | Basic inference only | | ONNX (GPU+CPU) | `pip install -U \"sentence-transformers[onnx-gpu]\"` | Optimized inference with GPU support | | ONNX (CPU only) | `pip install -U \"sentence-transformers[onnx]\"` | CPU-only optimized inference | | OpenVINO | `pip install -U \"sentence-transformers[openvino]\"` | Intel hardware optimization | | Training | `pip install -U \"sentence-transformers[train]\"` | Model training capabilities | | Development | `pip install -U \"sentence-transformers[dev]\"` | Full development environment |",
    "metadata": {
      "chunk_id": "9eeaa096c300-0014",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "filename": "Training_arguments_must_specify_router_mapping.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "pip Installation"
      ],
      "heading_text": "pip Installation",
      "token_count": 180,
      "char_count": 769,
      "start_char": 0,
      "end_char": 769,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.435631067961165,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:27.793972",
      "document_id": "9eeaa096c300",
      "document_name": "Training_arguments_must_specify_router_mapping",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "source_filename": "Training_arguments_must_specify_router_mapping.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "hierarchy_path": "pip Installation",
      "chunk_hash": "f8a118b1c79e4f54",
      "content_digest": "f8a118b1c79e4f54",
      "chunk_length": 769,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "pip",
          "install",
          "sentence",
          "transformers",
          "onnx",
          "installation",
          "inference",
          "only",
          "gpu",
          "cpu",
          "with",
          "use",
          "optimized",
          "openvino",
          "training",
          "development",
          "the",
          "recommended",
          "method",
          "uses"
        ],
        "term_weights": [
          {
            "term": "pip",
            "tf": 8,
            "weight": 0.098765
          },
          {
            "term": "install",
            "tf": 6,
            "weight": 0.074074
          },
          {
            "term": "sentence",
            "tf": 6,
            "weight": 0.074074
          },
          {
            "term": "transformers",
            "tf": 6,
            "weight": 0.074074
          },
          {
            "term": "onnx",
            "tf": 4,
            "weight": 0.049383
          },
          {
            "term": "installation",
            "tf": 3,
            "weight": 0.037037
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.037037
          },
          {
            "term": "only",
            "tf": 3,
            "weight": 0.037037
          },
          {
            "term": "gpu",
            "tf": 3,
            "weight": 0.037037
          },
          {
            "term": "cpu",
            "tf": 3,
            "weight": 0.037037
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.024691
          },
          {
            "term": "use",
            "tf": 2,
            "weight": 0.024691
          },
          {
            "term": "optimized",
            "tf": 2,
            "weight": 0.024691
          },
          {
            "term": "openvino",
            "tf": 2,
            "weight": 0.024691
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.024691
          },
          {
            "term": "development",
            "tf": 2,
            "weight": 0.024691
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.012346
          },
          {
            "term": "recommended",
            "tf": 1,
            "weight": 0.012346
          },
          {
            "term": "method",
            "tf": 1,
            "weight": 0.012346
          },
          {
            "term": "uses",
            "tf": 1,
            "weight": 0.012346
          }
        ],
        "unique_terms": 40,
        "total_terms": 81
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "cpu",
        "gpu",
        "inference",
        "install",
        "installation",
        "only",
        "onnx",
        "pip",
        "pip Installation",
        "sentence",
        "transformers"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.435631067961165,
      "overall": 0.7118770226537215
    }
  },
  {
    "text": "#### Sparse Module Types  | Module | Purpose | Output Shape | |--------|---------|--------------| | `MLMTransformer` | Contextual token predictions | `[batch, seq_len, vocab_size]` | | `SpladePooling` | Aggregate tokens to sparse vector | `[batch, vocab_size]` | | `SparseStaticEmbedding` | Pre-computed static weights | `[batch, vocab_size]` | | `SparseAutoEncoder` | Learned sparse representations | `[batch, latent_dim]` |  Key configuration: - `pooling_strategy`: `\"max\"`, `\"mean\"`, `\"sum\"`   - `activation_function`: `\"relu\"`, `\"log1p_relu\"`, `\"identity\"` - `k`: Number of top-k active dimensions (for `SparseAutoEncoder`)  Sources: [sentence_transformers/sparse_encoder/models/MLMTransformer.py](), [sentence_transformers/sparse_encoder/models/SpladePooling.py](), [sentence_transformers/sparse_encoder/models/SparseStaticEmbedding.py](), [sentence_transformers/sparse_encoder/models/SparseAutoEncoder.py]()",
    "metadata": {
      "chunk_id": "9eeaa096c300-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "filename": "Training_arguments_must_specify_router_mapping.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Sparse Module Types"
      ],
      "heading_text": "Sparse Module Types",
      "token_count": 226,
      "char_count": 913,
      "start_char": 0,
      "end_char": 913,
      "semantic_score": 0.7159983515739441,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.48390243902439023,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:27.790015",
      "document_id": "9eeaa096c300",
      "document_name": "Training_arguments_must_specify_router_mapping",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "source_filename": "Training_arguments_must_specify_router_mapping.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "hierarchy_path": "Sparse Module Types",
      "chunk_hash": "74fd22d8f983412d",
      "content_digest": "74fd22d8f983412d",
      "chunk_length": 913,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparse",
          "batch",
          "sentence",
          "transformers",
          "encoder",
          "models",
          "vocab",
          "size",
          "sparseautoencoder",
          "module",
          "mlmtransformer",
          "spladepooling",
          "sparsestaticembedding",
          "relu",
          "types",
          "purpose",
          "output",
          "shape",
          "contextual",
          "token"
        ],
        "term_weights": [
          {
            "term": "sparse",
            "tf": 7,
            "weight": 0.084337
          },
          {
            "term": "batch",
            "tf": 4,
            "weight": 0.048193
          },
          {
            "term": "sentence",
            "tf": 4,
            "weight": 0.048193
          },
          {
            "term": "transformers",
            "tf": 4,
            "weight": 0.048193
          },
          {
            "term": "encoder",
            "tf": 4,
            "weight": 0.048193
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.048193
          },
          {
            "term": "vocab",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "size",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "sparseautoencoder",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "module",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "mlmtransformer",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "spladepooling",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "sparsestaticembedding",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "relu",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "types",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "purpose",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "output",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "shape",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "contextual",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "token",
            "tf": 1,
            "weight": 0.012048
          }
        ],
        "unique_terms": 51,
        "total_terms": 83
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Sparse Module Types",
        "batch",
        "encoder",
        "models",
        "module",
        "sentence",
        "size",
        "sparse",
        "sparseautoencoder",
        "transformers",
        "vocab"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.7159983515739441,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.48390243902439023,
      "overall": 0.6999669301994448
    }
  },
  {
    "text": "## Advanced Module Types",
    "metadata": {
      "chunk_id": "9eeaa096c300-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "filename": "Training_arguments_must_specify_router_mapping.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Advanced Module Types"
      ],
      "heading_text": "Advanced Module Types",
      "token_count": 4,
      "char_count": 24,
      "start_char": 0,
      "end_char": 24,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.39,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:27.789109",
      "document_id": "9eeaa096c300",
      "document_name": "Training_arguments_must_specify_router_mapping",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "source_filename": "Training_arguments_must_specify_router_mapping.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_must_specify_router_mapping.md",
      "hierarchy_path": "Advanced Module Types",
      "chunk_hash": "b8d0ae29c81b6e2a",
      "content_digest": "b8d0ae29c81b6e2a",
      "chunk_length": 24,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "advanced",
          "module",
          "types"
        ],
        "term_weights": [
          {
            "term": "advanced",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "module",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "types",
            "tf": 1,
            "weight": 0.333333
          }
        ],
        "unique_terms": 3,
        "total_terms": 3
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Advanced Module Types",
        "advanced",
        "module",
        "types"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.39,
      "overall": 0.6966666666666667
    }
  }
]
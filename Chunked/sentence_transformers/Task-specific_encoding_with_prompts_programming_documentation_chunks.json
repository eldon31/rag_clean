[
  {
    "text": "### Sparse Architecture Components ```mermaid graph TB     subgraph \"SparseEncoder Components\"         MLMTransformer[\"MLMTransformer<br/>Token-level predictions\"]         SpladePooling[\"SpladePooling<br/>Sparsification\"]         SparseAutoEncoder[\"SparseAutoEncoder<br/>k-sparse activation\"]         Router[\"Router<br/>Query/Document paths\"]     end          subgraph \"Output Processing\"         ActiveDims[\"max_active_dims<br/>Sparsity control\"]         SparseOutput[\"Sparse COO Tensor<br/>[batch_size, vocab_size]\"]     end          Input[\"Text\"] --> Router     Router --> MLMTransformer     MLMTransformer --> SpladePooling     SpladePooling --> ActiveDims     ActiveDims --> SparseOutput ```",
    "metadata": {
      "chunk_id": "90bd1bbb08f8-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "filename": "Task-specific_encoding_with_prompts.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Sparse Architecture Components"
      ],
      "heading_text": "Sparse Architecture Components",
      "token_count": 145,
      "char_count": 696,
      "start_char": 0,
      "end_char": 696,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5218181818181818,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:22.783449",
      "document_id": "90bd1bbb08f8",
      "document_name": "Task-specific_encoding_with_prompts",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "source_filename": "Task-specific_encoding_with_prompts.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "hierarchy_path": "Sparse Architecture Components",
      "chunk_hash": "d0820e962cec905d",
      "content_digest": "d0820e962cec905d",
      "chunk_length": 696,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "mlmtransformer",
          "spladepooling",
          "router",
          "sparse",
          "activedims",
          "components",
          "subgraph",
          "sparseautoencoder",
          "end",
          "sparseoutput",
          "size",
          "architecture",
          "mermaid",
          "graph",
          "sparseencoder",
          "token",
          "level",
          "predictions",
          "sparsification",
          "activation"
        ],
        "term_weights": [
          {
            "term": "mlmtransformer",
            "tf": 4,
            "weight": 0.072727
          },
          {
            "term": "spladepooling",
            "tf": 4,
            "weight": 0.072727
          },
          {
            "term": "router",
            "tf": 4,
            "weight": 0.072727
          },
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.054545
          },
          {
            "term": "activedims",
            "tf": 3,
            "weight": 0.054545
          },
          {
            "term": "components",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "subgraph",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "sparseautoencoder",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "sparseoutput",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "size",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "architecture",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "mermaid",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "graph",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "sparseencoder",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "token",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "level",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "predictions",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "sparsification",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "activation",
            "tf": 1,
            "weight": 0.018182
          }
        ],
        "unique_terms": 36,
        "total_terms": 55
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Sparse Architecture Components",
        "activedims",
        "components",
        "end",
        "mlmtransformer",
        "router",
        "sparse",
        "sparseautoencoder",
        "sparseoutput",
        "spladepooling",
        "subgraph"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5218181818181818,
      "overall": 0.7406060606060606
    }
  },
  {
    "text": "### Key Differences from SentenceTransformer  - **Vocabulary-Sized Output**: Embeddings have dimensions equal to tokenizer vocabulary size - **Sparsity Control**: `max_active_dims` parameter limits non-zero dimensions - **Sparse Tensor Format**: Outputs can be sparse COO tensors for memory efficiency - **Term Importance**: Non-zero values represent importance of vocabulary terms",
    "metadata": {
      "chunk_id": "90bd1bbb08f8-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "filename": "Task-specific_encoding_with_prompts.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Key Differences from SentenceTransformer"
      ],
      "heading_text": "Key Differences from SentenceTransformer",
      "token_count": 69,
      "char_count": 381,
      "start_char": 0,
      "end_char": 381,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.3517021276595744,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:22.784015",
      "document_id": "90bd1bbb08f8",
      "document_name": "Task-specific_encoding_with_prompts",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "source_filename": "Task-specific_encoding_with_prompts.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "hierarchy_path": "Key Differences from SentenceTransformer",
      "chunk_hash": "bc94360b3260c1d3",
      "content_digest": "bc94360b3260c1d3",
      "chunk_length": 381,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "vocabulary",
          "dimensions",
          "non",
          "zero",
          "sparse",
          "importance",
          "key",
          "differences",
          "from",
          "sentencetransformer",
          "sized",
          "output",
          "embeddings",
          "have",
          "equal",
          "tokenizer",
          "size",
          "sparsity",
          "control",
          "max"
        ],
        "term_weights": [
          {
            "term": "vocabulary",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "dimensions",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "non",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "zero",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "importance",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "differences",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "sentencetransformer",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "sized",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "output",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "have",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "equal",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "tokenizer",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "size",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "sparsity",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "control",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "max",
            "tf": 1,
            "weight": 0.022727
          }
        ],
        "unique_terms": 37,
        "total_terms": 44
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Key Differences from SentenceTransformer",
        "differences",
        "dimensions",
        "from",
        "importance",
        "key",
        "non",
        "sentencetransformer",
        "sparse",
        "vocabulary",
        "zero"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.3517021276595744,
      "overall": 0.683900709219858
    }
  },
  {
    "text": "### Decoding and Interpretation  The `SparseEncoder` provides a `decode()` method to interpret sparse embeddings as weighted vocabulary terms: ```python model = SparseEncoder(\"naver/splade-cocondenser-ensembledistil\") embeddings = model.encode(\"machine learning\") tokens_weights = model.decode(embeddings, top_k=10)",
    "metadata": {
      "chunk_id": "90bd1bbb08f8-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "filename": "Task-specific_encoding_with_prompts.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Decoding and Interpretation"
      ],
      "heading_text": "Decoding and Interpretation",
      "token_count": 70,
      "char_count": 315,
      "start_char": 0,
      "end_char": 315,
      "semantic_score": 0.3156752586364746,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.56,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:22.784434",
      "document_id": "90bd1bbb08f8",
      "document_name": "Task-specific_encoding_with_prompts",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "source_filename": "Task-specific_encoding_with_prompts.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "hierarchy_path": "Decoding and Interpretation",
      "chunk_hash": "d3104ba95b2a64ff",
      "content_digest": "d3104ba95b2a64ff",
      "chunk_length": 315,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "embeddings",
          "model",
          "sparseencoder",
          "decode",
          "decoding",
          "and",
          "interpretation",
          "the",
          "provides",
          "method",
          "interpret",
          "sparse",
          "weighted",
          "vocabulary",
          "terms",
          "python",
          "naver",
          "splade",
          "cocondenser",
          "ensembledistil"
        ],
        "term_weights": [
          {
            "term": "embeddings",
            "tf": 3,
            "weight": 0.09375
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.09375
          },
          {
            "term": "sparseencoder",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "decode",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "decoding",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "interpretation",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "method",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "interpret",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "sparse",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "weighted",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "vocabulary",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "terms",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "naver",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "splade",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "cocondenser",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "ensembledistil",
            "tf": 1,
            "weight": 0.03125
          }
        ],
        "unique_terms": 26,
        "total_terms": 32
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Decoding and Interpretation",
        "and",
        "decode",
        "decoding",
        "embeddings",
        "interpretation",
        "method",
        "model",
        "provides",
        "sparseencoder",
        "the"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.3156752586364746,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.56,
      "overall": 0.5918917528788249
    }
  },
  {
    "text": "## SparseEncoder  The `SparseEncoder` class extends `SentenceTransformer` to produce sparse vector representations where most dimensions are zero. This architecture is particularly effective for lexical matching and hybrid retrieval scenarios.",
    "metadata": {
      "chunk_id": "90bd1bbb08f8-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "filename": "Task-specific_encoding_with_prompts.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "SparseEncoder"
      ],
      "heading_text": "SparseEncoder",
      "token_count": 39,
      "char_count": 243,
      "start_char": 0,
      "end_char": 243,
      "semantic_score": 0.17946463823318481,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.39,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:54:22.782705",
      "document_id": "90bd1bbb08f8",
      "document_name": "Task-specific_encoding_with_prompts",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "source_filename": "Task-specific_encoding_with_prompts.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "hierarchy_path": "SparseEncoder",
      "chunk_hash": "1f2db940b5482381",
      "content_digest": "1f2db940b5482381",
      "chunk_length": 243,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparseencoder",
          "the",
          "class",
          "extends",
          "sentencetransformer",
          "produce",
          "sparse",
          "vector",
          "representations",
          "where",
          "most",
          "dimensions",
          "are",
          "zero",
          "this",
          "architecture",
          "particularly",
          "effective",
          "for",
          "lexical"
        ],
        "term_weights": [
          {
            "term": "sparseencoder",
            "tf": 2,
            "weight": 0.076923
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "extends",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "sentencetransformer",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "produce",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "sparse",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "representations",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "most",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "dimensions",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "zero",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "architecture",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "particularly",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "effective",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.038462
          },
          {
            "term": "lexical",
            "tf": 1,
            "weight": 0.038462
          }
        ],
        "unique_terms": 25,
        "total_terms": 26
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "SparseEncoder",
        "class",
        "extends",
        "produce",
        "representations",
        "sentencetransformer",
        "sparse",
        "sparseencoder",
        "the",
        "vector",
        "where"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.17946463823318481,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.39,
      "overall": 0.48982154607772826
    }
  }
]
[
  {
    "text": "### Sparse Architecture Components\n\n```mermaid\ngraph TB\n    subgraph \"SparseEncoder Components\"\n        MLMTransformer[\"MLMTransformer<br/>Token-level predictions\"]\n        SpladePooling[\"SpladePooling<br/>Sparsification\"]\n        SparseAutoEncoder[\"SparseAutoEncoder<br/>k-sparse activation\"]\n        Router[\"Router<br/>Query/Document paths\"]\n    end\n    \n    subgraph \"Output Processing\"\n        ActiveDims[\"max_active_dims<br/>Sparsity control\"]\n        SparseOutput[\"Sparse COO Tensor<br/>[batch_size, vocab_size]\"]\n    end\n    \n    Input[\"Text\"] --> Router\n    Router --> MLMTransformer\n    MLMTransformer --> SpladePooling\n    SpladePooling --> ActiveDims\n    ActiveDims --> SparseOutput\n```",
    "metadata": {
      "chunk_id": "90bd1bbb08f8-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "filename": "Task-specific_encoding_with_prompts.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Sparse Architecture Components"
      ],
      "heading_text": "Sparse Architecture Components",
      "token_count": 155,
      "char_count": 697,
      "start_char": 599,
      "end_char": 1296,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.5218181818181818,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:18.713845",
      "document_id": "90bd1bbb08f8",
      "document_name": "Task-specific_encoding_with_prompts",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "source_filename": "Task-specific_encoding_with_prompts.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "hierarchy_path": "Sparse Architecture Components",
      "chunk_hash": "a9f0bbd7c8fc4bbf",
      "content_digest": "a9f0bbd7c8fc4bbf",
      "chunk_length": 697,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "mlmtransformer",
          "spladepooling",
          "router",
          "sparse",
          "activedims",
          "components",
          "subgraph",
          "sparseautoencoder",
          "end",
          "sparseoutput",
          "size",
          "architecture",
          "mermaid",
          "graph",
          "sparseencoder",
          "token",
          "level",
          "predictions",
          "sparsification",
          "activation"
        ],
        "term_weights": [
          {
            "term": "mlmtransformer",
            "tf": 4,
            "weight": 0.072727
          },
          {
            "term": "spladepooling",
            "tf": 4,
            "weight": 0.072727
          },
          {
            "term": "router",
            "tf": 4,
            "weight": 0.072727
          },
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.054545
          },
          {
            "term": "activedims",
            "tf": 3,
            "weight": 0.054545
          },
          {
            "term": "components",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "subgraph",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "sparseautoencoder",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "sparseoutput",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "size",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "architecture",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "mermaid",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "graph",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "sparseencoder",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "token",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "level",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "predictions",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "sparsification",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "activation",
            "tf": 1,
            "weight": 0.018182
          }
        ],
        "unique_terms": 36,
        "total_terms": 55
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Sparse Architecture Components",
        "activedims",
        "components",
        "end",
        "mlmtransformer",
        "router",
        "sparse",
        "sparseautoencoder",
        "sparseoutput",
        "spladepooling",
        "subgraph"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.5218181818181818,
      "overall": 0.673939393939394
    }
  },
  {
    "text": "### Decoding and Interpretation\n\nThe `SparseEncoder` provides a `decode()` method to interpret sparse embeddings as weighted vocabulary terms:\n\n```python\nmodel = SparseEncoder(\"naver/splade-cocondenser-ensembledistil\")\nembeddings = model.encode(\"machine learning\")\ntokens_weights = model.decode(embeddings, top_k=10)",
    "metadata": {
      "chunk_id": "90bd1bbb08f8-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "filename": "Task-specific_encoding_with_prompts.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Decoding and Interpretation"
      ],
      "heading_text": "Decoding and Interpretation",
      "token_count": 72,
      "char_count": 316,
      "start_char": 1681,
      "end_char": 1997,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.56,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:18.714224",
      "document_id": "90bd1bbb08f8",
      "document_name": "Task-specific_encoding_with_prompts",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "source_filename": "Task-specific_encoding_with_prompts.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Task-specific_encoding_with_prompts.md",
      "hierarchy_path": "Decoding and Interpretation",
      "chunk_hash": "9225d071f75b9daf",
      "content_digest": "9225d071f75b9daf",
      "chunk_length": 316,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "embeddings",
          "model",
          "sparseencoder",
          "decode",
          "decoding",
          "and",
          "interpretation",
          "the",
          "provides",
          "method",
          "interpret",
          "sparse",
          "weighted",
          "vocabulary",
          "terms",
          "python",
          "naver",
          "splade",
          "cocondenser",
          "ensembledistil"
        ],
        "term_weights": [
          {
            "term": "embeddings",
            "tf": 3,
            "weight": 0.09375
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.09375
          },
          {
            "term": "sparseencoder",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "decode",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "decoding",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "interpretation",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "method",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "interpret",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "sparse",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "weighted",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "vocabulary",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "terms",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "naver",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "splade",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "cocondenser",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "ensembledistil",
            "tf": 1,
            "weight": 0.03125
          }
        ],
        "unique_terms": 26,
        "total_terms": 32
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Decoding and Interpretation",
        "and",
        "decode",
        "decoding",
        "embeddings",
        "interpretation",
        "method",
        "model",
        "provides",
        "sparseencoder",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.56,
      "overall": 0.6533333333333333
    }
  }
]
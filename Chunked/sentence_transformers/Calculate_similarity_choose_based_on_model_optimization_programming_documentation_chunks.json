[
  {
    "text": "### Cross-Encoder Model Usage\n\n```python\nfrom sentence_transformers import CrossEncoder\nimport torch",
    "metadata": {
      "chunk_id": "d6a5625c9b34-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Cross-Encoder Model Usage"
      ],
      "heading_text": "Cross-Encoder Model Usage",
      "token_count": 20,
      "char_count": 100,
      "start_char": 198,
      "end_char": 298,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.5627272727272727,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.257839",
      "document_id": "d6a5625c9b34",
      "document_name": "Calculate_similarity_choose_based_on_model_optimization",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "source_filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "hierarchy_path": "Cross-Encoder Model Usage",
      "chunk_hash": "0b511185ff6dec33",
      "content_digest": "0b511185ff6dec33",
      "chunk_length": 100,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "import",
          "cross",
          "encoder",
          "model",
          "usage",
          "python",
          "from",
          "sentence",
          "transformers",
          "crossencoder",
          "torch"
        ],
        "term_weights": [
          {
            "term": "import",
            "tf": 2,
            "weight": 0.166667
          },
          {
            "term": "cross",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "encoder",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "usage",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "torch",
            "tf": 1,
            "weight": 0.083333
          }
        ],
        "unique_terms": 11,
        "total_terms": 12
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Cross-Encoder Model Usage",
        "cross",
        "crossencoder",
        "encoder",
        "from",
        "import",
        "model",
        "python",
        "sentence",
        "transformers",
        "usage"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.5627272727272727,
      "overall": 0.6875757575757575
    }
  },
  {
    "text": "# Load cross-encoder with sigmoid activation for 0-1 scores\nmodel = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L6-v2\", activation_fn=torch.nn.Sigmoid())",
    "metadata": {
      "chunk_id": "d6a5625c9b34-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Load cross-encoder with sigmoid activation for 0-1 scores"
      ],
      "heading_text": "Load cross-encoder with sigmoid activation for 0-1 scores",
      "token_count": 41,
      "char_count": 153,
      "start_char": 300,
      "end_char": 453,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.258006",
      "document_id": "d6a5625c9b34",
      "document_name": "Calculate_similarity_choose_based_on_model_optimization",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "source_filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "hierarchy_path": "Load cross-encoder with sigmoid activation for 0-1 scores",
      "chunk_hash": "6f9fe9368e7693d8",
      "content_digest": "6f9fe9368e7693d8",
      "chunk_length": 153,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cross",
          "encoder",
          "sigmoid",
          "activation",
          "load",
          "with",
          "for",
          "scores",
          "model",
          "crossencoder",
          "marco",
          "minilm",
          "torch"
        ],
        "term_weights": [
          {
            "term": "cross",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "sigmoid",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "activation",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "load",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "scores",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "marco",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "minilm",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "torch",
            "tf": 1,
            "weight": 0.058824
          }
        ],
        "unique_terms": 13,
        "total_terms": 17
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Load cross-encoder with sigmoid activation for 0-1 scores",
        "activation",
        "cross",
        "crossencoder",
        "encoder",
        "for",
        "load",
        "model",
        "scores",
        "sigmoid",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.59,
      "overall": 0.6966666666666667
    }
  },
  {
    "text": "# Score query-passage pairs\nscores = model.predict([\n    (\"How big is London\", \"London has 9,787,426 inhabitants at the 2011 census\"),\n    (\"How big is London\", \"London is well known for its museums\")\n])",
    "metadata": {
      "chunk_id": "d6a5625c9b34-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Score query-passage pairs"
      ],
      "heading_text": "Score query-passage pairs",
      "token_count": 53,
      "char_count": 203,
      "start_char": 455,
      "end_char": 658,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5319354838709677,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.258158",
      "document_id": "d6a5625c9b34",
      "document_name": "Calculate_similarity_choose_based_on_model_optimization",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "source_filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "hierarchy_path": "Score query-passage pairs",
      "chunk_hash": "765e5bdb8855932a",
      "content_digest": "765e5bdb8855932a",
      "chunk_length": 203,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "london",
          "how",
          "big",
          "score",
          "query",
          "passage",
          "pairs",
          "scores",
          "model",
          "predict",
          "has",
          "787",
          "426",
          "inhabitants",
          "the",
          "2011",
          "census",
          "well",
          "known",
          "for"
        ],
        "term_weights": [
          {
            "term": "london",
            "tf": 4,
            "weight": 0.148148
          },
          {
            "term": "how",
            "tf": 2,
            "weight": 0.074074
          },
          {
            "term": "big",
            "tf": 2,
            "weight": 0.074074
          },
          {
            "term": "score",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "query",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "passage",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "pairs",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "scores",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "predict",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "has",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "787",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "426",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "inhabitants",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "2011",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "census",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "well",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "known",
            "tf": 1,
            "weight": 0.037037
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.037037
          }
        ],
        "unique_terms": 22,
        "total_terms": 27
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Score query-passage pairs",
        "big",
        "how",
        "london",
        "model",
        "pairs",
        "passage",
        "predict",
        "query",
        "score",
        "scores"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5319354838709677,
      "overall": 0.6439784946236559
    }
  },
  {
    "text": "### Batch Processing for Production\n\n```python",
    "metadata": {
      "chunk_id": "d6a5625c9b34-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Batch Processing for Production"
      ],
      "heading_text": "Batch Processing for Production",
      "token_count": 8,
      "char_count": 46,
      "start_char": 720,
      "end_char": 766,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.258313",
      "document_id": "d6a5625c9b34",
      "document_name": "Calculate_similarity_choose_based_on_model_optimization",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "source_filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "hierarchy_path": "Batch Processing for Production",
      "chunk_hash": "1b6e5a721f8174ab",
      "content_digest": "1b6e5a721f8174ab",
      "chunk_length": 46,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "batch",
          "processing",
          "for",
          "production",
          "python"
        ],
        "term_weights": [
          {
            "term": "batch",
            "tf": 1,
            "weight": 0.2
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.2
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.2
          },
          {
            "term": "production",
            "tf": 1,
            "weight": 0.2
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.2
          }
        ],
        "unique_terms": 5,
        "total_terms": 5
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Batch Processing for Production",
        "batch",
        "for",
        "processing",
        "production",
        "python"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.59,
      "overall": 0.6966666666666667
    }
  }
]
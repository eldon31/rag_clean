[
  {
    "text": "## Backend Optimization  Sentence-transformers supports multiple inference backends beyond PyTorch, enabling significant performance improvements for production deployments.",
    "metadata": {
      "chunk_id": "25f14ea5cc09-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "filename": "Multi-Processing_and_Optimization.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Backend Optimization"
      ],
      "heading_text": "Backend Optimization",
      "token_count": 25,
      "char_count": 173,
      "start_char": 0,
      "end_char": 173,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:51:49.231719",
      "document_id": "25f14ea5cc09",
      "document_name": "Multi-Processing_and_Optimization",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "source_filename": "Multi-Processing_and_Optimization.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "hierarchy_path": "Backend Optimization",
      "chunk_hash": "f357304227d1ce1f",
      "content_digest": "f357304227d1ce1f",
      "chunk_length": 173,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "backend",
          "optimization",
          "sentence",
          "transformers",
          "supports",
          "multiple",
          "inference",
          "backends",
          "beyond",
          "pytorch",
          "enabling",
          "significant",
          "performance",
          "improvements",
          "for",
          "production",
          "deployments"
        ],
        "term_weights": [
          {
            "term": "backend",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "optimization",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "backends",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "beyond",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "pytorch",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "enabling",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "significant",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "improvements",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "production",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "deployments",
            "tf": 1,
            "weight": 0.058824
          }
        ],
        "unique_terms": 17,
        "total_terms": 17
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Backend Optimization",
        "backend",
        "backends",
        "beyond",
        "inference",
        "multiple",
        "optimization",
        "pytorch",
        "sentence",
        "supports",
        "transformers"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Backend-Specific Parameters  Additional configuration options are available through `model_kwargs`: ```python",
    "metadata": {
      "chunk_id": "25f14ea5cc09-0006",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "filename": "Multi-Processing_and_Optimization.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Backend-Specific Parameters"
      ],
      "heading_text": "Backend-Specific Parameters",
      "token_count": 18,
      "char_count": 113,
      "start_char": 0,
      "end_char": 113,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:51:49.233046",
      "document_id": "25f14ea5cc09",
      "document_name": "Multi-Processing_and_Optimization",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "source_filename": "Multi-Processing_and_Optimization.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "hierarchy_path": "Backend-Specific Parameters",
      "chunk_hash": "351fa4603f772453",
      "content_digest": "351fa4603f772453",
      "chunk_length": 113,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "backend",
          "specific",
          "parameters",
          "additional",
          "configuration",
          "options",
          "are",
          "available",
          "through",
          "model",
          "kwargs",
          "python"
        ],
        "term_weights": [
          {
            "term": "backend",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "specific",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "parameters",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "additional",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "configuration",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "options",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "available",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "kwargs",
            "tf": 1,
            "weight": 0.083333
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.083333
          }
        ],
        "unique_terms": 12,
        "total_terms": 12
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Backend-Specific Parameters",
        "additional",
        "are",
        "available",
        "backend",
        "configuration",
        "model",
        "options",
        "parameters",
        "specific",
        "through"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "# ONNX provider selection model = SentenceTransformer(     \"model-name\",      backend=\"onnx\",     model_kwargs={\"provider\": \"CUDAExecutionProvider\"} )",
    "metadata": {
      "chunk_id": "25f14ea5cc09-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "filename": "Multi-Processing_and_Optimization.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ONNX provider selection"
      ],
      "heading_text": "ONNX provider selection",
      "token_count": 33,
      "char_count": 150,
      "start_char": 0,
      "end_char": 150,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:51:49.233455",
      "document_id": "25f14ea5cc09",
      "document_name": "Multi-Processing_and_Optimization",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "source_filename": "Multi-Processing_and_Optimization.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "hierarchy_path": "ONNX provider selection",
      "chunk_hash": "e432fdf903972522",
      "content_digest": "e432fdf903972522",
      "chunk_length": 150,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "onnx",
          "provider",
          "selection",
          "sentencetransformer",
          "name",
          "backend",
          "kwargs",
          "cudaexecutionprovider"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 3,
            "weight": 0.230769
          },
          {
            "term": "onnx",
            "tf": 2,
            "weight": 0.153846
          },
          {
            "term": "provider",
            "tf": 2,
            "weight": 0.153846
          },
          {
            "term": "selection",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "sentencetransformer",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "name",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "backend",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "kwargs",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "cudaexecutionprovider",
            "tf": 1,
            "weight": 0.076923
          }
        ],
        "unique_terms": 9,
        "total_terms": 13
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ONNX provider selection",
        "backend",
        "cudaexecutionprovider",
        "kwargs",
        "model",
        "name",
        "onnx",
        "provider",
        "selection",
        "sentencetransformer"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "## Memory Optimization Strategies",
    "metadata": {
      "chunk_id": "25f14ea5cc09-0016",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "filename": "Multi-Processing_and_Optimization.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Memory Optimization Strategies"
      ],
      "heading_text": "Memory Optimization Strategies",
      "token_count": 4,
      "char_count": 33,
      "start_char": 0,
      "end_char": 33,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:51:49.237932",
      "document_id": "25f14ea5cc09",
      "document_name": "Multi-Processing_and_Optimization",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "source_filename": "Multi-Processing_and_Optimization.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "hierarchy_path": "Memory Optimization Strategies",
      "chunk_hash": "1b155fce135f52c9",
      "content_digest": "1b155fce135f52c9",
      "chunk_length": 33,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "memory",
          "optimization",
          "strategies"
        ],
        "term_weights": [
          {
            "term": "memory",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "optimization",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "strategies",
            "tf": 1,
            "weight": 0.333333
          }
        ],
        "unique_terms": 3,
        "total_terms": 3
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Memory Optimization Strategies",
        "memory",
        "optimization",
        "strategies"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "# Optimized model file selection model = SentenceTransformer(     \"model-name\",     backend=\"openvino\",      model_kwargs={\"file_name\": \"model_optimized.xml\"} )",
    "metadata": {
      "chunk_id": "25f14ea5cc09-0008",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "filename": "Multi-Processing_and_Optimization.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Optimized model file selection"
      ],
      "heading_text": "Optimized model file selection",
      "token_count": 37,
      "char_count": 160,
      "start_char": 0,
      "end_char": 160,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.566923076923077,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:51:49.233727",
      "document_id": "25f14ea5cc09",
      "document_name": "Multi-Processing_and_Optimization",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "source_filename": "Multi-Processing_and_Optimization.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-Processing_and_Optimization.md",
      "hierarchy_path": "Optimized model file selection",
      "chunk_hash": "bdf54a5ac538515c",
      "content_digest": "bdf54a5ac538515c",
      "chunk_length": 160,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "optimized",
          "file",
          "name",
          "selection",
          "sentencetransformer",
          "backend",
          "openvino",
          "kwargs",
          "xml"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 5,
            "weight": 0.294118
          },
          {
            "term": "optimized",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "file",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "name",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "selection",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "sentencetransformer",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "backend",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "openvino",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "kwargs",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "xml",
            "tf": 1,
            "weight": 0.058824
          }
        ],
        "unique_terms": 10,
        "total_terms": 17
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Optimized model file selection",
        "backend",
        "file",
        "kwargs",
        "model",
        "name",
        "openvino",
        "optimized",
        "selection",
        "sentencetransformer",
        "xml"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.566923076923077,
      "overall": 0.7556410256410256
    }
  }
]
[
  {
    "text": "# Prepare queries, corpus, and relevance judgments\nqueries = {\"q1\": \"machine learning definition\"}\ncorpus = {\"d1\": \"ML is AI subset\", \"d2\": \"Weather is sunny\"}  \nrelevant_docs = {\"q1\": {\"d1\"}}\n\nevaluator = InformationRetrievalEvaluator(\n    queries=queries,\n    corpus=corpus, \n    relevant_docs=relevant_docs,\n    name=\"ir_test\"\n)\nresults = evaluator(model)\nprint(f\"MAP@100: {results['ir_test_cosine_map@100']}\")\n```\n\nSources: [sentence_transformers/evaluation/BinaryClassificationEvaluator.py:49-83](), [sentence_transformers/evaluation/RerankingEvaluator.py:48-87](), [sentence_transformers/evaluation/InformationRetrievalEvaluator.py:54-123](), [tests/test_pretrained_stsb.py:74-79]()",
    "metadata": {
      "chunk_id": "38b11176fc1e-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Prepare_samples_with_queries_positives_and_negatives.md",
      "filename": "Prepare_samples_with_queries_positives_and_negatives.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Prepare queries, corpus, and relevance judgments"
      ],
      "heading_text": "Prepare queries, corpus, and relevance judgments",
      "token_count": 185,
      "char_count": 688,
      "start_char": 479,
      "end_char": 1167,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7,
      "retrieval_quality": 0.5517021276595745,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.591888",
      "document_id": "38b11176fc1e",
      "document_name": "Prepare_samples_with_queries_positives_and_negatives",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Prepare_samples_with_queries_positives_and_negatives.md",
      "source_filename": "Prepare_samples_with_queries_positives_and_negatives.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Prepare_samples_with_queries_positives_and_negatives.md",
      "hierarchy_path": "Prepare queries, corpus, and relevance judgments",
      "chunk_hash": "b25adcf835d74740",
      "content_digest": "b25adcf835d74740",
      "chunk_length": 688,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "queries",
          "corpus",
          "relevant",
          "docs",
          "test",
          "sentence",
          "transformers",
          "evaluation",
          "evaluator",
          "informationretrievalevaluator",
          "results",
          "map",
          "100",
          "prepare",
          "and",
          "relevance",
          "judgments",
          "machine",
          "learning",
          "definition"
        ],
        "term_weights": [
          {
            "term": "queries",
            "tf": 4,
            "weight": 0.070175
          },
          {
            "term": "corpus",
            "tf": 4,
            "weight": 0.070175
          },
          {
            "term": "relevant",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "docs",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "test",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "evaluation",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "evaluator",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "informationretrievalevaluator",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "results",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "map",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "100",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "prepare",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "relevance",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "judgments",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "machine",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "learning",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "definition",
            "tf": 1,
            "weight": 0.017544
          }
        ],
        "unique_terms": 34,
        "total_terms": 57
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Prepare queries, corpus, and relevance judgments",
        "corpus",
        "docs",
        "evaluation",
        "evaluator",
        "informationretrievalevaluator",
        "queries",
        "relevant",
        "sentence",
        "test",
        "transformers"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7,
      "retrieval_quality": 0.5517021276595745,
      "overall": 0.6839007092198582
    }
  },
  {
    "text": "# Called automatically during training\nresults = evaluator(model, output_path=\"./results\", epoch=1, steps=100)",
    "metadata": {
      "chunk_id": "38b11176fc1e-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Prepare_samples_with_queries_positives_and_negatives.md",
      "filename": "Prepare_samples_with_queries_positives_and_negatives.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Called automatically during training"
      ],
      "heading_text": "Called automatically during training",
      "token_count": 24,
      "char_count": 110,
      "start_char": 2248,
      "end_char": 2358,
      "semantic_score": 0.6,
      "structural_score": 0.7,
      "retrieval_quality": 0.7899999999999999,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.592582",
      "document_id": "38b11176fc1e",
      "document_name": "Prepare_samples_with_queries_positives_and_negatives",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Prepare_samples_with_queries_positives_and_negatives.md",
      "source_filename": "Prepare_samples_with_queries_positives_and_negatives.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Prepare_samples_with_queries_positives_and_negatives.md",
      "hierarchy_path": "Called automatically during training",
      "chunk_hash": "2a1dacd4ffa077e6",
      "content_digest": "2a1dacd4ffa077e6",
      "chunk_length": 110,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "results",
          "called",
          "automatically",
          "during",
          "training",
          "evaluator",
          "model",
          "output",
          "path",
          "epoch",
          "steps",
          "100"
        ],
        "term_weights": [
          {
            "term": "results",
            "tf": 2,
            "weight": 0.153846
          },
          {
            "term": "called",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "automatically",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "during",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "training",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "evaluator",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "output",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "path",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "epoch",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "steps",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "100",
            "tf": 1,
            "weight": 0.076923
          }
        ],
        "unique_terms": 12,
        "total_terms": 13
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Called automatically during training",
        "automatically",
        "called",
        "during",
        "epoch",
        "evaluator",
        "model",
        "output",
        "path",
        "results",
        "training"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7,
      "retrieval_quality": 0.7899999999999999,
      "overall": 0.6966666666666667
    }
  },
  {
    "text": "### Model Card Integration\n\nEvaluation results are automatically stored in the model's metadata via the `store_metrics_in_model_card_data()` method, which updates `model.model_card_data` with performance metrics.\n\nSources: [sentence_transformers/evaluation/BinaryClassificationEvaluator.py:151-221](), [sentence_transformers/evaluation/RerankingEvaluator.py:137-198](), [sentence_transformers/evaluation/InformationRetrievalEvaluator.py:211-290]()",
    "metadata": {
      "chunk_id": "38b11176fc1e-0009",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Prepare_samples_with_queries_positives_and_negatives.md",
      "filename": "Prepare_samples_with_queries_positives_and_negatives.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Card Integration"
      ],
      "heading_text": "Model Card Integration",
      "token_count": 93,
      "char_count": 447,
      "start_char": 2545,
      "end_char": 2992,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5788888888888889,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.593110",
      "document_id": "38b11176fc1e",
      "document_name": "Prepare_samples_with_queries_positives_and_negatives",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Prepare_samples_with_queries_positives_and_negatives.md",
      "source_filename": "Prepare_samples_with_queries_positives_and_negatives.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Prepare_samples_with_queries_positives_and_negatives.md",
      "hierarchy_path": "Model Card Integration",
      "chunk_hash": "10a96e8e3dbafe12",
      "content_digest": "10a96e8e3dbafe12",
      "chunk_length": 447,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "evaluation",
          "card",
          "sentence",
          "transformers",
          "the",
          "metrics",
          "data",
          "integration",
          "results",
          "are",
          "automatically",
          "stored",
          "metadata",
          "via",
          "store",
          "method",
          "which",
          "updates",
          "with"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 5,
            "weight": 0.106383
          },
          {
            "term": "evaluation",
            "tf": 4,
            "weight": 0.085106
          },
          {
            "term": "card",
            "tf": 3,
            "weight": 0.06383
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.06383
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.06383
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.042553
          },
          {
            "term": "metrics",
            "tf": 2,
            "weight": 0.042553
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.042553
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "results",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "automatically",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "stored",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "metadata",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "via",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "store",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "method",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "which",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "updates",
            "tf": 1,
            "weight": 0.021277
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.021277
          }
        ],
        "unique_terms": 31,
        "total_terms": 47
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Card Integration",
        "card",
        "data",
        "evaluation",
        "integration",
        "metrics",
        "model",
        "results",
        "sentence",
        "the",
        "transformers"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5788888888888889,
      "overall": 0.6596296296296296
    }
  },
  {
    "text": "## 8. Performance Considerations  When evaluating large datasets, consider:  - Batch processing: Evaluate models in batches to avoid memory issues - Caching: Cache model outputs to avoid redundant computation - Metrics selection: Choose metrics appropriate for your task and dataset size  Efficient evaluation is especially important when working with resource-intensive models or large test sets.",
    "metadata": {
      "chunk_id": "38b11176fc1e-0012",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Prepare_samples_with_queries_positives_and_negatives.md",
      "filename": "Prepare_samples_with_queries_positives_and_negatives.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "8. Performance Considerations"
      ],
      "heading_text": "8. Performance Considerations",
      "token_count": 69,
      "char_count": 397,
      "start_char": 4018,
      "end_char": 4415,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5463636363636364,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.593875",
      "document_id": "38b11176fc1e",
      "document_name": "Prepare_samples_with_queries_positives_and_negatives",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Prepare_samples_with_queries_positives_and_negatives.md",
      "source_filename": "Prepare_samples_with_queries_positives_and_negatives.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Prepare_samples_with_queries_positives_and_negatives.md",
      "hierarchy_path": "8. Performance Considerations",
      "chunk_hash": "1808e6d4382da50d",
      "content_digest": "1808e6d4382da50d",
      "chunk_length": 397,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "when",
          "large",
          "models",
          "avoid",
          "metrics",
          "performance",
          "considerations",
          "evaluating",
          "datasets",
          "consider",
          "batch",
          "processing",
          "evaluate",
          "batches",
          "memory",
          "issues",
          "caching",
          "cache",
          "model",
          "outputs"
        ],
        "term_weights": [
          {
            "term": "when",
            "tf": 2,
            "weight": 0.043478
          },
          {
            "term": "large",
            "tf": 2,
            "weight": 0.043478
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.043478
          },
          {
            "term": "avoid",
            "tf": 2,
            "weight": 0.043478
          },
          {
            "term": "metrics",
            "tf": 2,
            "weight": 0.043478
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "considerations",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "evaluating",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "datasets",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "consider",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "batch",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "evaluate",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "batches",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "memory",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "issues",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "caching",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "cache",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.021739
          },
          {
            "term": "outputs",
            "tf": 1,
            "weight": 0.021739
          }
        ],
        "unique_terms": 41,
        "total_terms": 46
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "8. Performance Considerations",
        "avoid",
        "consider",
        "considerations",
        "datasets",
        "evaluating",
        "large",
        "metrics",
        "models",
        "performance",
        "when"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5463636363636364,
      "overall": 0.7487878787878787
    }
  }
]
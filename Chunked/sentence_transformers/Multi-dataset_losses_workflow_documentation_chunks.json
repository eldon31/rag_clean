[
  {
    "text": "### Router Configuration ```python",
    "metadata": {
      "chunk_id": "9f9486e3c392-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-dataset_losses.md",
      "filename": "Multi-dataset_losses.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Router Configuration"
      ],
      "heading_text": "Router Configuration",
      "token_count": 5,
      "char_count": 34,
      "start_char": 0,
      "end_char": 34,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:51:46.888664",
      "document_id": "9f9486e3c392",
      "document_name": "Multi-dataset_losses",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-dataset_losses.md",
      "source_filename": "Multi-dataset_losses.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-dataset_losses.md",
      "hierarchy_path": "Router Configuration",
      "chunk_hash": "13c04902746d194d",
      "content_digest": "13c04902746d194d",
      "chunk_length": 34,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "router",
          "configuration",
          "python"
        ],
        "term_weights": [
          {
            "term": "router",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "configuration",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.333333
          }
        ],
        "unique_terms": 3,
        "total_terms": 3
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Router Configuration",
        "configuration",
        "python",
        "router"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "## Router Support for Asymmetric Training  The training system integrates with the `Router` module to enable asymmetric architectures where different paths are used for queries vs documents:",
    "metadata": {
      "chunk_id": "9f9486e3c392-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-dataset_losses.md",
      "filename": "Multi-dataset_losses.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Router Support for Asymmetric Training"
      ],
      "heading_text": "Router Support for Asymmetric Training",
      "token_count": 32,
      "char_count": 190,
      "start_char": 0,
      "end_char": 190,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5455555555555556,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:51:46.888579",
      "document_id": "9f9486e3c392",
      "document_name": "Multi-dataset_losses",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-dataset_losses.md",
      "source_filename": "Multi-dataset_losses.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-dataset_losses.md",
      "hierarchy_path": "Router Support for Asymmetric Training",
      "chunk_hash": "df3e02efe760ee85",
      "content_digest": "df3e02efe760ee85",
      "chunk_length": 190,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "router",
          "for",
          "asymmetric",
          "training",
          "the",
          "support",
          "system",
          "integrates",
          "with",
          "module",
          "enable",
          "architectures",
          "where",
          "different",
          "paths",
          "are",
          "used",
          "queries",
          "documents"
        ],
        "term_weights": [
          {
            "term": "router",
            "tf": 2,
            "weight": 0.083333
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.083333
          },
          {
            "term": "asymmetric",
            "tf": 2,
            "weight": 0.083333
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.083333
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.083333
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "integrates",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "module",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "enable",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "architectures",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "paths",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "used",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "queries",
            "tf": 1,
            "weight": 0.041667
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.041667
          }
        ],
        "unique_terms": 19,
        "total_terms": 24
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Router Support for Asymmetric Training",
        "asymmetric",
        "for",
        "integrates",
        "module",
        "router",
        "support",
        "system",
        "the",
        "training",
        "with"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5455555555555556,
      "overall": 0.7485185185185186
    }
  },
  {
    "text": "## Multi-Dataset Training  The training system supports training on multiple datasets simultaneously using `DatasetDict`: ```mermaid graph TB     subgraph \"Multi-Dataset Input\"         DD[\"DatasetDict\"]         DS1[\"Dataset 'nli'\"]         DS2[\"Dataset 'sts'\"]          DS3[\"Dataset 'quora'\"]     end          subgraph \"Loss Mapping\"         LossDict[\"Loss Dictionary\"]         L1[\"nli: CoSENTLoss\"]         L2[\"sts: CosineSimilarityLoss\"]         L3[\"quora: MNRL\"]     end          subgraph \"Batch Sampling\"         BatchSampler[\"MultiDatasetBatchSampler\"]         RoundRobin[\"RoundRobinBatchSampler\"]         Proportional[\"ProportionalBatchSampler\"]     end          subgraph \"Training Process\"         DataCollator[\"add_dataset_name_column()\"]         ComputeLoss[\"compute_loss()\"]         LossSelect[\"Select loss by dataset_name\"]     end          DD --> DS1     DD --> DS2     DD --> DS3          LossDict --> L1     LossDict --> L2       LossDict --> L3          DS1 --> BatchSampler     DS2 --> BatchSampler     DS3 --> BatchSampler          BatchSampler --> RoundRobin     BatchSampler --> Proportional          BatchSampler --> DataCollator     DataCollator --> ComputeLoss     LossDict --> LossSelect     ComputeLoss --> LossSelect ``` **Multi-Dataset Training Architecture**  Sources: [sentence_transformers/trainer.py:295-310](), [sentence_transformers/trainer.py:416-422](), [sentence_transformers/trainer.py:785-800]()",
    "metadata": {
      "chunk_id": "9f9486e3c392-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-dataset_losses.md",
      "filename": "Multi-dataset_losses.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Multi-Dataset Training"
      ],
      "heading_text": "Multi-Dataset Training",
      "token_count": 335,
      "char_count": 1432,
      "start_char": 0,
      "end_char": 1432,
      "semantic_score": 0.4342729151248932,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.49413636363636365,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:51:46.888152",
      "document_id": "9f9486e3c392",
      "document_name": "Multi-dataset_losses",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-dataset_losses.md",
      "source_filename": "Multi-dataset_losses.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Multi-dataset_losses.md",
      "hierarchy_path": "Multi-Dataset Training",
      "chunk_hash": "53e86df1e5006df3",
      "content_digest": "53e86df1e5006df3",
      "chunk_length": 1432,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "dataset",
          "batchsampler",
          "training",
          "lossdict",
          "subgraph",
          "end",
          "loss",
          "multi",
          "ds1",
          "ds2",
          "ds3",
          "datacollator",
          "computeloss",
          "lossselect",
          "sentence",
          "transformers",
          "trainer",
          "datasetdict",
          "nli",
          "sts"
        ],
        "term_weights": [
          {
            "term": "dataset",
            "tf": 8,
            "weight": 0.070175
          },
          {
            "term": "batchsampler",
            "tf": 7,
            "weight": 0.061404
          },
          {
            "term": "training",
            "tf": 5,
            "weight": 0.04386
          },
          {
            "term": "lossdict",
            "tf": 5,
            "weight": 0.04386
          },
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.035088
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.035088
          },
          {
            "term": "loss",
            "tf": 4,
            "weight": 0.035088
          },
          {
            "term": "multi",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "ds1",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "ds2",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "ds3",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "datacollator",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "computeloss",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "lossselect",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "trainer",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "datasetdict",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "nli",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "sts",
            "tf": 2,
            "weight": 0.017544
          }
        ],
        "unique_terms": 57,
        "total_terms": 114
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Multi-Dataset Training",
        "batchsampler",
        "dataset",
        "ds1",
        "ds2",
        "end",
        "loss",
        "lossdict",
        "multi",
        "subgraph",
        "training"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.4342729151248932,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.49413636363636365,
      "overall": 0.6094697595870856
    }
  }
]
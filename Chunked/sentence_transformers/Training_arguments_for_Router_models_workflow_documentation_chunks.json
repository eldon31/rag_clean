[
  {
    "text": "### Multi-Dataset Training\n\nThe system supports training on multiple datasets simultaneously with different batch sampling strategies:\n\n```python\nargs = SparseEncoderTrainingArguments(\n    multi_dataset_batch_sampler=BatchSamplers.PROPORTIONAL,\n    batch_sampler=BatchSamplers.NO_DUPLICATES,\n)\n```\n\n**Sources:** [docs/sparse_encoder/training_overview.md:419-425]()",
    "metadata": {
      "chunk_id": "9c1904d331aa-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_for_Router_models.md",
      "filename": "Training_arguments_for_Router_models.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Multi-Dataset Training"
      ],
      "heading_text": "Multi-Dataset Training",
      "token_count": 77,
      "char_count": 364,
      "start_char": 312,
      "end_char": 676,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5784615384615385,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.825637",
      "document_id": "9c1904d331aa",
      "document_name": "Training_arguments_for_Router_models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_for_Router_models.md",
      "source_filename": "Training_arguments_for_Router_models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_for_Router_models.md",
      "hierarchy_path": "Multi-Dataset Training",
      "chunk_hash": "f041d574957ede92",
      "content_digest": "f041d574957ede92",
      "chunk_length": 364,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "training",
          "batch",
          "multi",
          "dataset",
          "sampler",
          "batchsamplers",
          "the",
          "system",
          "supports",
          "multiple",
          "datasets",
          "simultaneously",
          "with",
          "different",
          "sampling",
          "strategies",
          "python",
          "args",
          "sparseencodertrainingarguments",
          "proportional"
        ],
        "term_weights": [
          {
            "term": "training",
            "tf": 3,
            "weight": 0.083333
          },
          {
            "term": "batch",
            "tf": 3,
            "weight": 0.083333
          },
          {
            "term": "multi",
            "tf": 2,
            "weight": 0.055556
          },
          {
            "term": "dataset",
            "tf": 2,
            "weight": 0.055556
          },
          {
            "term": "sampler",
            "tf": 2,
            "weight": 0.055556
          },
          {
            "term": "batchsamplers",
            "tf": 2,
            "weight": 0.055556
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "datasets",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "simultaneously",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "sampling",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "strategies",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "args",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "sparseencodertrainingarguments",
            "tf": 1,
            "weight": 0.027778
          },
          {
            "term": "proportional",
            "tf": 1,
            "weight": 0.027778
          }
        ],
        "unique_terms": 28,
        "total_terms": 36
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Multi-Dataset Training",
        "batch",
        "batchsamplers",
        "dataset",
        "multi",
        "multiple",
        "sampler",
        "supports",
        "system",
        "the",
        "training"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5784615384615385,
      "overall": 0.6928205128205128
    }
  },
  {
    "text": "### Memory Optimization  For large models, several memory optimization techniques are available:  - **Gradient Checkpointing**: `gradient_checkpointing=True` - **Mixed Precision**: `fp16=True` or `bf16=True` - **Chunked Processing**: Configure `chunk_size` in `SpladePooling` - **Gradient Accumulation**: `gradient_accumulation_steps=N`  **Sources:** [docs/sparse_encoder/training_overview.md:400-425](), [sentence_transformers/sparse_encoder/models/SpladePooling.py:92-128]()",
    "metadata": {
      "chunk_id": "9c1904d331aa-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_for_Router_models.md",
      "filename": "Training_arguments_for_Router_models.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Memory Optimization"
      ],
      "heading_text": "Memory Optimization",
      "token_count": 113,
      "char_count": 476,
      "start_char": 678,
      "end_char": 1154,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.74,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.825892",
      "document_id": "9c1904d331aa",
      "document_name": "Training_arguments_for_Router_models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_for_Router_models.md",
      "source_filename": "Training_arguments_for_Router_models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Training_arguments_for_Router_models.md",
      "hierarchy_path": "Memory Optimization",
      "chunk_hash": "85a1fccbb654f997",
      "content_digest": "85a1fccbb654f997",
      "chunk_length": 476,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "gradient",
          "true",
          "memory",
          "optimization",
          "models",
          "checkpointing",
          "spladepooling",
          "accumulation",
          "sparse",
          "encoder",
          "for",
          "large",
          "several",
          "techniques",
          "are",
          "available",
          "mixed",
          "precision",
          "fp16",
          "bf16"
        ],
        "term_weights": [
          {
            "term": "gradient",
            "tf": 4,
            "weight": 0.083333
          },
          {
            "term": "true",
            "tf": 3,
            "weight": 0.0625
          },
          {
            "term": "memory",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "optimization",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "checkpointing",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "spladepooling",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "accumulation",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "large",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "several",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "techniques",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "available",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "mixed",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "precision",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "fp16",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "bf16",
            "tf": 1,
            "weight": 0.020833
          }
        ],
        "unique_terms": 35,
        "total_terms": 48
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Memory Optimization",
        "accumulation",
        "checkpointing",
        "encoder",
        "gradient",
        "memory",
        "models",
        "optimization",
        "sparse",
        "spladepooling",
        "true"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.74,
      "overall": 0.8133333333333331
    }
  }
]
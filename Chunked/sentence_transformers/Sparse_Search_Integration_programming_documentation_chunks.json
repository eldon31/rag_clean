[
  {
    "text": "## Overview\n\nSparse search integration allows `SparseEncoder` models to work with external search systems that can efficiently handle sparse vector data. The integration supports both manual in-memory search and production-ready vector database solutions.\n\n```mermaid\ngraph TD\n    SparseEncoder[\"SparseEncoder\"]\n    EncodeDoc[\"encode_document()\"]\n    EncodeQuery[\"encode_query()\"]\n    SparseEmbeddings[\"Sparse Embeddings<br/>(COO Tensors)\"]\n    \n    SparseEncoder --> EncodeDoc\n    SparseEncoder --> EncodeQuery\n    EncodeDoc --> SparseEmbeddings\n    EncodeQuery --> SparseEmbeddings\n    \n    SparseEmbeddings --> ManualSearch[\"Manual Search<br/>util.semantic_search()\"]\n    SparseEmbeddings --> VectorDBs[\"Vector Databases\"]\n    \n    VectorDBs --> Qdrant[\"semantic_search_qdrant()\"]\n    VectorDBs --> Elasticsearch[\"semantic_search_elasticsearch()\"] \n    VectorDBs --> OpenSearch[\"semantic_search_opensearch()\"]\n    VectorDBs --> Seismic[\"semantic_search_seismic()\"]\n    VectorDBs --> SpladeIndex[\"SPLADE-index\"]\n```\n\n**Architecture Components for Sparse Search Integration**\n\nSources: [sentence_transformers/sparse_encoder/search_engines.py:1-556](), [examples/sparse_encoder/applications/semantic_search/README.md:1-529]()",
    "metadata": {
      "chunk_id": "088f0de81daa-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Overview"
      ],
      "heading_text": "Overview",
      "token_count": 270,
      "char_count": 1225,
      "start_char": 482,
      "end_char": 1707,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.696896551724138,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.524365",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Overview",
      "chunk_hash": "b17e7ebc333cb3fe",
      "content_digest": "b17e7ebc333cb3fe",
      "chunk_length": 1225,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "sparse",
          "semantic",
          "vectordbs",
          "sparseencoder",
          "sparseembeddings",
          "integration",
          "vector",
          "encodedoc",
          "encodequery",
          "manual",
          "encode",
          "qdrant",
          "elasticsearch",
          "opensearch",
          "seismic",
          "encoder",
          "overview",
          "allows",
          "models"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 12,
            "weight": 0.107143
          },
          {
            "term": "sparse",
            "tf": 6,
            "weight": 0.053571
          },
          {
            "term": "semantic",
            "tf": 6,
            "weight": 0.053571
          },
          {
            "term": "vectordbs",
            "tf": 6,
            "weight": 0.053571
          },
          {
            "term": "sparseencoder",
            "tf": 5,
            "weight": 0.044643
          },
          {
            "term": "sparseembeddings",
            "tf": 5,
            "weight": 0.044643
          },
          {
            "term": "integration",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "vector",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "encodedoc",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "encodequery",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "manual",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "encode",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "elasticsearch",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "opensearch",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "seismic",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "overview",
            "tf": 1,
            "weight": 0.008929
          },
          {
            "term": "allows",
            "tf": 1,
            "weight": 0.008929
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.008929
          }
        ],
        "unique_terms": 63,
        "total_terms": 112
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Overview",
        "encodedoc",
        "encodequery",
        "integration",
        "search",
        "semantic",
        "sparse",
        "sparseembeddings",
        "sparseencoder",
        "vector",
        "vectordbs"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.696896551724138,
      "overall": 0.7656321839080459
    }
  },
  {
    "text": "### Vector Database Search Approach  Vector database search leverages specialized systems optimized for sparse vector operations, providing better scalability and performance for large corpora. | Search Engine | Function | Index Type | Key Features | |---------------|----------|------------|--------------| | Qdrant | `semantic_search_qdrant()` | Sparse vectors | Native sparse vector support | | Elasticsearch | `semantic_search_elasticsearch()` | rank_features | Elastic stack integration | | OpenSearch | `semantic_search_opensearch()` | neural_sparse | Amazon OpenSearch compatibility | | Seismic | `semantic_search_seismic()` | SeismicIndex | High-performance in-memory search | | SPLADE-index | External library | SciPy sparse matrices | BM25s-based implementation |  Sources: [examples/sparse_encoder/applications/semantic_search/README.md:11-132]()",
    "metadata": {
      "chunk_id": "088f0de81daa-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Vector Database Search Approach"
      ],
      "heading_text": "Vector Database Search Approach",
      "token_count": 169,
      "char_count": 857,
      "start_char": 2432,
      "end_char": 3289,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6644897959183673,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.525380",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Vector Database Search Approach",
      "chunk_hash": "ae9b4cf042c1a20b",
      "content_digest": "ae9b4cf042c1a20b",
      "chunk_length": 857,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "sparse",
          "semantic",
          "vector",
          "opensearch",
          "database",
          "for",
          "performance",
          "index",
          "features",
          "qdrant",
          "elasticsearch",
          "seismic",
          "approach",
          "leverages",
          "specialized",
          "systems",
          "optimized",
          "operations",
          "providing"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 9,
            "weight": 0.104651
          },
          {
            "term": "sparse",
            "tf": 6,
            "weight": 0.069767
          },
          {
            "term": "semantic",
            "tf": 5,
            "weight": 0.05814
          },
          {
            "term": "vector",
            "tf": 4,
            "weight": 0.046512
          },
          {
            "term": "opensearch",
            "tf": 3,
            "weight": 0.034884
          },
          {
            "term": "database",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "performance",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "index",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "features",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "elasticsearch",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "seismic",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "approach",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "leverages",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "specialized",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "systems",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "optimized",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "operations",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "providing",
            "tf": 1,
            "weight": 0.011628
          }
        ],
        "unique_terms": 56,
        "total_terms": 86
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Vector Database Search Approach",
        "database",
        "features",
        "for",
        "index",
        "opensearch",
        "performance",
        "search",
        "semantic",
        "sparse",
        "vector"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6644897959183673,
      "overall": 0.7881632653061224
    }
  },
  {
    "text": "## Search Engine Integration Functions",
    "metadata": {
      "chunk_id": "088f0de81daa-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Search Engine Integration Functions"
      ],
      "heading_text": "Search Engine Integration Functions",
      "token_count": 5,
      "char_count": 38,
      "start_char": 3292,
      "end_char": 3330,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.525380",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Search Engine Integration Functions",
      "chunk_hash": "67823a326051df34",
      "content_digest": "67823a326051df34",
      "chunk_length": 38,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "engine",
          "integration",
          "functions"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 1,
            "weight": 0.25
          },
          {
            "term": "engine",
            "tf": 1,
            "weight": 0.25
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.25
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.25
          }
        ],
        "unique_terms": 4,
        "total_terms": 4
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Search Engine Integration Functions",
        "engine",
        "functions",
        "integration",
        "search"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Qdrant Integration\n\nThe `semantic_search_qdrant()` function provides native integration with Qdrant's sparse vector capabilities.\n\n```mermaid\ngraph LR\n    QueryEmb[\"query_embeddings<br/>(COO Tensor)\"]\n    CorpusEmb[\"corpus_embeddings<br/>(COO Tensor)\"]\n    \n    QueryEmb --> QdrantFunc[\"semantic_search_qdrant()\"]\n    CorpusEmb --> QdrantFunc\n    \n    QdrantFunc --> QdrantClient[\"QdrantClient\"]\n    QdrantFunc --> Collection[\"Sparse Collection\"]\n    QdrantFunc --> SparseVector[\"SparseVector Models\"]\n    \n    QdrantClient --> Results[\"Search Results<br/>[{'corpus_id': int, 'score': float}]\"]\n```\n\n**Qdrant Integration Data Flow**\n\nThe integration handles COO sparse tensors directly and creates collections with `SparseVectorParams` configuration.\n\n**Key Parameters:**\n- Input: PyTorch COO sparse tensors\n- Collection: Auto-generated with timestamp\n- Indexing: Batch processing with configurable `batch_size`\n- Search: Native sparse vector queries using `models.SparseVector`\n\nSources: [sentence_transformers/sparse_encoder/search_engines.py:32-158](), [examples/sparse_encoder/applications/semantic_search/semantic_search_qdrant.py:1-64]()",
    "metadata": {
      "chunk_id": "088f0de81daa-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Qdrant Integration"
      ],
      "heading_text": "Qdrant Integration",
      "token_count": 276,
      "char_count": 1147,
      "start_char": 3332,
      "end_char": 4479,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7070212765957448,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.526375",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Qdrant Integration",
      "chunk_hash": "d8e9c1f39513b57b",
      "content_digest": "d8e9c1f39513b57b",
      "chunk_length": 1147,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "sparse",
          "qdrant",
          "qdrantfunc",
          "integration",
          "semantic",
          "with",
          "coo",
          "qdrantclient",
          "collection",
          "sparsevector",
          "the",
          "native",
          "vector",
          "queryemb",
          "embeddings",
          "tensor",
          "corpusemb",
          "corpus",
          "models"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 7,
            "weight": 0.061404
          },
          {
            "term": "sparse",
            "tf": 7,
            "weight": 0.061404
          },
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.052632
          },
          {
            "term": "qdrantfunc",
            "tf": 5,
            "weight": 0.04386
          },
          {
            "term": "integration",
            "tf": 4,
            "weight": 0.035088
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.035088
          },
          {
            "term": "with",
            "tf": 4,
            "weight": 0.035088
          },
          {
            "term": "coo",
            "tf": 4,
            "weight": 0.035088
          },
          {
            "term": "qdrantclient",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "collection",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "sparsevector",
            "tf": 3,
            "weight": 0.026316
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "native",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "queryemb",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "tensor",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "corpusemb",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "corpus",
            "tf": 2,
            "weight": 0.017544
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.017544
          }
        ],
        "unique_terms": 62,
        "total_terms": 114
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Qdrant Integration",
        "collection",
        "coo",
        "integration",
        "qdrant",
        "qdrantclient",
        "qdrantfunc",
        "search",
        "semantic",
        "sparse",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7070212765957448,
      "overall": 0.7690070921985814
    }
  },
  {
    "text": "### Elasticsearch Integration  \n\nThe `semantic_search_elasticsearch()` function uses Elasticsearch's `rank_features` field type for sparse vector storage and search.\n\n```mermaid\ngraph LR\n    DecodedEmb[\"query_embeddings_decoded<br/>[[('token', value)]]\"]\n    CorpusDecoded[\"corpus_embeddings_decoded<br/>[[('token', value)]]\"]\n    \n    DecodedEmb --> ESFunc[\"semantic_search_elasticsearch()\"]\n    CorpusDecoded --> ESFunc\n    \n    ESFunc --> ESClient[\"Elasticsearch Client\"]\n    ESFunc --> RankFeatures[\"rank_features Mapping\"]\n    ESFunc --> RankFeatureQuery[\"rank_feature Queries\"]\n    \n    ESClient --> ESResults[\"Search Results<br/>[{'corpus_id': int, '_score': float}]\"]\n```\n\n**Elasticsearch Integration Data Flow**\n\n**Key Features:**\n- Input: Decoded embeddings in `[('token', value)]` format\n- Mapping: Uses `rank_features` field type for sparse vectors\n- Indexing: Bulk operations with configurable batch size\n- Search: `rank_feature` queries with `saturation` and `boost` parameters\n\nSources: [sentence_transformers/sparse_encoder/search_engines.py:160-297](), [examples/sparse_encoder/applications/semantic_search/semantic_search_elasticsearch.py:1-68]()",
    "metadata": {
      "chunk_id": "088f0de81daa-0006",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Elasticsearch Integration"
      ],
      "heading_text": "Elasticsearch Integration",
      "token_count": 273,
      "char_count": 1164,
      "start_char": 4481,
      "end_char": 5645,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7222580645161291,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.526375",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Elasticsearch Integration",
      "chunk_hash": "bfeb144ea147995b",
      "content_digest": "bfeb144ea147995b",
      "chunk_length": 1164,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "elasticsearch",
          "rank",
          "esfunc",
          "semantic",
          "features",
          "sparse",
          "embeddings",
          "decoded",
          "token",
          "value",
          "integration",
          "uses",
          "field",
          "type",
          "for",
          "and",
          "decodedemb",
          "corpusdecoded",
          "corpus"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 8,
            "weight": 0.068376
          },
          {
            "term": "elasticsearch",
            "tf": 7,
            "weight": 0.059829
          },
          {
            "term": "rank",
            "tf": 5,
            "weight": 0.042735
          },
          {
            "term": "esfunc",
            "tf": 5,
            "weight": 0.042735
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.034188
          },
          {
            "term": "features",
            "tf": 4,
            "weight": 0.034188
          },
          {
            "term": "sparse",
            "tf": 4,
            "weight": 0.034188
          },
          {
            "term": "embeddings",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "decoded",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "token",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "value",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "integration",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "uses",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "field",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "type",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "decodedemb",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "corpusdecoded",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "corpus",
            "tf": 2,
            "weight": 0.017094
          }
        ],
        "unique_terms": 64,
        "total_terms": 117
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Elasticsearch Integration",
        "decoded",
        "elasticsearch",
        "embeddings",
        "esfunc",
        "features",
        "rank",
        "search",
        "semantic",
        "sparse",
        "token"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7222580645161291,
      "overall": 0.7740860215053762
    }
  },
  {
    "text": "### OpenSearch Integration\n\nThe `semantic_search_opensearch()` function leverages OpenSearch's `neural_sparse` query capabilities.\n\n**Key Differences from Elasticsearch:**\n- Uses `neural_sparse` query type instead of `rank_feature`\n- Compatible with Amazon OpenSearch Service\n- Supports asymmetric sparse encoder architectures\n\nSources: [sentence_transformers/sparse_encoder/search_engines.py:428-556](), [examples/sparse_encoder/applications/semantic_search/semantic_search_opensearch.py:1-87]()",
    "metadata": {
      "chunk_id": "088f0de81daa-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "OpenSearch Integration"
      ],
      "heading_text": "OpenSearch Integration",
      "token_count": 105,
      "char_count": 496,
      "start_char": 5647,
      "end_char": 6143,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7505263157894736,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.527378",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "OpenSearch Integration",
      "chunk_hash": "d0a8b144eeaa8e4e",
      "content_digest": "d0a8b144eeaa8e4e",
      "chunk_length": 496,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "opensearch",
          "sparse",
          "search",
          "semantic",
          "encoder",
          "neural",
          "query",
          "integration",
          "the",
          "function",
          "leverages",
          "capabilities",
          "key",
          "differences",
          "from",
          "elasticsearch",
          "uses",
          "type",
          "instead",
          "rank"
        ],
        "term_weights": [
          {
            "term": "opensearch",
            "tf": 5,
            "weight": 0.09434
          },
          {
            "term": "sparse",
            "tf": 5,
            "weight": 0.09434
          },
          {
            "term": "search",
            "tf": 4,
            "weight": 0.075472
          },
          {
            "term": "semantic",
            "tf": 3,
            "weight": 0.056604
          },
          {
            "term": "encoder",
            "tf": 3,
            "weight": 0.056604
          },
          {
            "term": "neural",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.037736
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "function",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "leverages",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "capabilities",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "differences",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "elasticsearch",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "uses",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "type",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "instead",
            "tf": 1,
            "weight": 0.018868
          },
          {
            "term": "rank",
            "tf": 1,
            "weight": 0.018868
          }
        ],
        "unique_terms": 36,
        "total_terms": 53
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "OpenSearch Integration",
        "encoder",
        "function",
        "integration",
        "neural",
        "opensearch",
        "query",
        "search",
        "semantic",
        "sparse",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7505263157894736,
      "overall": 0.7835087719298244
    }
  },
  {
    "text": "### Seismic Integration\n\nThe `semantic_search_seismic()` function provides integration with the high-performance Seismic library for in-memory sparse vector search.\n\n```mermaid\ngraph LR\n    DecodedQuery[\"query_embeddings_decoded\"]\n    DecodedCorpus[\"corpus_embeddings_decoded\"]\n    \n    DecodedQuery --> SeismicFunc[\"semantic_search_seismic()\"]\n    DecodedCorpus --> SeismicFunc\n    \n    SeismicFunc --> SeismicDataset[\"SeismicDataset.add_document()\"]\n    SeismicFunc --> SeismicIndex[\"SeismicIndex.build_from_dataset()\"]\n    SeismicFunc --> BatchSearch[\"SeismicIndex.batch_search()\"]\n    \n    BatchSearch --> SeismicResults[\"Sorted Results<br/>[{'corpus_id': int, 'score': float}]\"]\n```\n\n**Seismic Integration Architecture**\n\n**Performance Features:**\n- `SeismicDataset` for document management\n- `SeismicIndex.build_from_dataset()` with configurable index parameters\n- `batch_search()` with `query_cut` and `heap_factor` optimizations\n- Order-of-magnitude performance improvements over IVF approaches\n\nSources: [sentence_transformers/sparse_encoder/search_engines.py:299-426](), [examples/sparse_encoder/applications/semantic_search/semantic_search_seismic.py:1-66]()",
    "metadata": {
      "chunk_id": "088f0de81daa-0008",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Seismic Integration"
      ],
      "heading_text": "Seismic Integration",
      "token_count": 265,
      "char_count": 1169,
      "start_char": 6145,
      "end_char": 7314,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7216455696202532,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.528029",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Seismic Integration",
      "chunk_hash": "424d076f94622a8b",
      "content_digest": "424d076f94622a8b",
      "chunk_length": 1169,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "seismic",
          "seismicfunc",
          "semantic",
          "seismicindex",
          "integration",
          "with",
          "performance",
          "sparse",
          "seismicdataset",
          "the",
          "for",
          "decodedquery",
          "query",
          "embeddings",
          "decoded",
          "decodedcorpus",
          "corpus",
          "document",
          "build"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 8,
            "weight": 0.071429
          },
          {
            "term": "seismic",
            "tf": 6,
            "weight": 0.053571
          },
          {
            "term": "seismicfunc",
            "tf": 5,
            "weight": 0.044643
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.035714
          },
          {
            "term": "seismicindex",
            "tf": 4,
            "weight": 0.035714
          },
          {
            "term": "integration",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "performance",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "seismicdataset",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "decodedquery",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "decoded",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "decodedcorpus",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "corpus",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "document",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "build",
            "tf": 2,
            "weight": 0.017857
          }
        ],
        "unique_terms": 65,
        "total_terms": 112
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Seismic Integration",
        "integration",
        "performance",
        "search",
        "seismic",
        "seismicdataset",
        "seismicfunc",
        "seismicindex",
        "semantic",
        "sparse",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7216455696202532,
      "overall": 0.7738818565400843
    }
  },
  {
    "text": "### Encoding Workflow\n\n```mermaid\ngraph TD\n    TextInput[\"Text Input<br/>['query text', 'document text']\"]\n    \n    TextInput --> EncodeQuery[\"model.encode_query()\"]\n    TextInput --> EncodeDoc[\"model.encode_document()\"]\n    \n    EncodeQuery --> SparseQuery[\"Sparse Query Embeddings\"]\n    EncodeDoc --> SparseDoc[\"Sparse Document Embeddings\"]\n    \n    SparseQuery --> QdrantFormat[\"COO Tensor<br/>(for Qdrant)\"]\n    SparseQuery --> DecodedFormat[\"Decoded Format<br/>(for ES/OpenSearch/Seismic)\"]\n    \n    SparseDoc --> QdrantFormat\n    SparseDoc --> DecodedFormat\n    \n    QdrantFormat --> QdrantSearch[\"semantic_search_qdrant()\"]\n    DecodedFormat --> OtherSearches[\"Other search_* functions\"]\n```\n\n**Data Format Conversion Pipeline**",
    "metadata": {
      "chunk_id": "088f0de81daa-0011",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Encoding Workflow"
      ],
      "heading_text": "Encoding Workflow",
      "token_count": 178,
      "char_count": 735,
      "start_char": 7771,
      "end_char": 8506,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5096428571428571,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.529448",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Encoding Workflow",
      "chunk_hash": "6707c8b5f1964b19",
      "content_digest": "6707c8b5f1964b19",
      "chunk_length": 735,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "textinput",
          "text",
          "query",
          "document",
          "sparsequery",
          "sparsedoc",
          "qdrantformat",
          "decodedformat",
          "encodequery",
          "model",
          "encode",
          "encodedoc",
          "sparse",
          "embeddings",
          "for",
          "qdrant",
          "format",
          "search",
          "encoding",
          "workflow"
        ],
        "term_weights": [
          {
            "term": "textinput",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "text",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "query",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "document",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "sparsequery",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "sparsedoc",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "qdrantformat",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "decodedformat",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "encodequery",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "encode",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "encodedoc",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "format",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "encoding",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "workflow",
            "tf": 1,
            "weight": 0.016129
          }
        ],
        "unique_terms": 36,
        "total_terms": 62
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Encoding Workflow",
        "decodedformat",
        "document",
        "encodequery",
        "model",
        "qdrantformat",
        "query",
        "sparsedoc",
        "sparsequery",
        "text",
        "textinput"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5096428571428571,
      "overall": 0.7032142857142856
    }
  },
  {
    "text": "### Sparse Tensor Formats  **COO Sparse Tensor (Qdrant):** - Format: PyTorch coordinate format sparse tensor - Indices: `[row_indices, col_indices]` - Values: Sparse embedding values - Advantages: Direct tensor operations, GPU compatibility  **Decoded Format (Others):** - Format: `List[List[Tuple[str, float]]]` - Structure: `[[('token1', 0.5), ('token2', 0.3)], ...]` - Advantages: Human-readable, search engine compatible  Sources: [sentence_transformers/sparse_encoder/search_engines.py:67-76](), [examples/sparse_encoder/applications/semantic_search/README.md:53-83]()",
    "metadata": {
      "chunk_id": "088f0de81daa-0012",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Sparse Tensor Formats"
      ],
      "heading_text": "Sparse Tensor Formats",
      "token_count": 150,
      "char_count": 573,
      "start_char": 8508,
      "end_char": 9081,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5066666666666666,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.529686",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Sparse Tensor Formats",
      "chunk_hash": "a8250a15647d9bb4",
      "content_digest": "a8250a15647d9bb4",
      "chunk_length": 573,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparse",
          "tensor",
          "format",
          "indices",
          "search",
          "values",
          "advantages",
          "list",
          "encoder",
          "formats",
          "coo",
          "qdrant",
          "pytorch",
          "coordinate",
          "row",
          "col",
          "embedding",
          "direct",
          "operations",
          "gpu"
        ],
        "term_weights": [
          {
            "term": "sparse",
            "tf": 6,
            "weight": 0.1
          },
          {
            "term": "tensor",
            "tf": 4,
            "weight": 0.066667
          },
          {
            "term": "format",
            "tf": 4,
            "weight": 0.066667
          },
          {
            "term": "indices",
            "tf": 3,
            "weight": 0.05
          },
          {
            "term": "search",
            "tf": 3,
            "weight": 0.05
          },
          {
            "term": "values",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "advantages",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "list",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "formats",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "coo",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "pytorch",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "coordinate",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "row",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "col",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "direct",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "operations",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "gpu",
            "tf": 1,
            "weight": 0.016667
          }
        ],
        "unique_terms": 41,
        "total_terms": 60
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Sparse Tensor Formats",
        "advantages",
        "encoder",
        "format",
        "formats",
        "indices",
        "list",
        "search",
        "sparse",
        "tensor",
        "values"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5066666666666666,
      "overall": 0.7022222222222222
    }
  },
  {
    "text": "### Reusable Index Pattern\n\nAll search engine integrations support index reuse through the `output_index` parameter:\n\n```mermaid\ngraph TD\n    FirstCall[\"First Function Call\"]\n    CreateIndex[\"Create Index<br/>(corpus_embeddings required)\"]\n    SearchResults1[\"Search Results + Index\"]\n    \n    SecondCall[\"Subsequent Calls\"]\n    ReuseIndex[\"Reuse Existing Index<br/>(corpus_index provided)\"]\n    SearchResults2[\"Search Results Only\"]\n    \n    FirstCall --> CreateIndex\n    CreateIndex --> SearchResults1\n    \n    SecondCall --> ReuseIndex\n    ReuseIndex --> SearchResults2\n    \n    SearchResults1 --> IndexStorage[\"Store Index Reference\"]\n    IndexStorage --> SecondCall\n```\n\n**Index Reuse Pattern for Production Workflows**",
    "metadata": {
      "chunk_id": "088f0de81daa-0014",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Reusable Index Pattern"
      ],
      "heading_text": "Reusable Index Pattern",
      "token_count": 161,
      "char_count": 724,
      "start_char": 9108,
      "end_char": 9832,
      "semantic_score": 0.8,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.524375,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.529945",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Reusable Index Pattern",
      "chunk_hash": "dd667dd0982e0427",
      "content_digest": "dd667dd0982e0427",
      "chunk_length": 724,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "index",
          "search",
          "reuse",
          "createindex",
          "searchresults1",
          "secondcall",
          "reuseindex",
          "pattern",
          "firstcall",
          "corpus",
          "results",
          "searchresults2",
          "indexstorage",
          "reusable",
          "all",
          "engine",
          "integrations",
          "support",
          "through",
          "the"
        ],
        "term_weights": [
          {
            "term": "index",
            "tf": 9,
            "weight": 0.136364
          },
          {
            "term": "search",
            "tf": 3,
            "weight": 0.045455
          },
          {
            "term": "reuse",
            "tf": 3,
            "weight": 0.045455
          },
          {
            "term": "createindex",
            "tf": 3,
            "weight": 0.045455
          },
          {
            "term": "searchresults1",
            "tf": 3,
            "weight": 0.045455
          },
          {
            "term": "secondcall",
            "tf": 3,
            "weight": 0.045455
          },
          {
            "term": "reuseindex",
            "tf": 3,
            "weight": 0.045455
          },
          {
            "term": "pattern",
            "tf": 2,
            "weight": 0.030303
          },
          {
            "term": "firstcall",
            "tf": 2,
            "weight": 0.030303
          },
          {
            "term": "corpus",
            "tf": 2,
            "weight": 0.030303
          },
          {
            "term": "results",
            "tf": 2,
            "weight": 0.030303
          },
          {
            "term": "searchresults2",
            "tf": 2,
            "weight": 0.030303
          },
          {
            "term": "indexstorage",
            "tf": 2,
            "weight": 0.030303
          },
          {
            "term": "reusable",
            "tf": 1,
            "weight": 0.015152
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.015152
          },
          {
            "term": "engine",
            "tf": 1,
            "weight": 0.015152
          },
          {
            "term": "integrations",
            "tf": 1,
            "weight": 0.015152
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.015152
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.015152
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.015152
          }
        ],
        "unique_terms": 40,
        "total_terms": 66
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Reusable Index Pattern",
        "corpus",
        "createindex",
        "firstcall",
        "index",
        "pattern",
        "reuse",
        "reuseindex",
        "search",
        "searchresults1",
        "secondcall"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.524375,
      "overall": 0.7081249999999999
    }
  },
  {
    "text": "### Error Handling and Validation  All integration functions include comprehensive input validation:  - Sparse tensor format validation for Qdrant - Decoded embedding format validation for other engines   - Client availability checks with helpful error messages - Required dependency import validation  Sources: [sentence_transformers/sparse_encoder/search_engines.py:67-76](), [sentence_transformers/sparse_encoder/search_engines.py:204-218]()",
    "metadata": {
      "chunk_id": "088f0de81daa-0015",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Error Handling and Validation"
      ],
      "heading_text": "Error Handling and Validation",
      "token_count": 83,
      "char_count": 444,
      "start_char": 9834,
      "end_char": 10278,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5272093023255814,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.529945",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Error Handling and Validation",
      "chunk_hash": "fcf98e46aca900e3",
      "content_digest": "fcf98e46aca900e3",
      "chunk_length": 444,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "validation",
          "sparse",
          "engines",
          "error",
          "format",
          "for",
          "sentence",
          "transformers",
          "encoder",
          "search",
          "handling",
          "and",
          "all",
          "integration",
          "functions",
          "include",
          "comprehensive",
          "input",
          "tensor",
          "qdrant"
        ],
        "term_weights": [
          {
            "term": "validation",
            "tf": 5,
            "weight": 0.1
          },
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.06
          },
          {
            "term": "engines",
            "tf": 3,
            "weight": 0.06
          },
          {
            "term": "error",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "format",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.04
          },
          {
            "term": "handling",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "include",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "comprehensive",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "input",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "tensor",
            "tf": 1,
            "weight": 0.02
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.02
          }
        ],
        "unique_terms": 35,
        "total_terms": 50
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Error Handling and Validation",
        "encoder",
        "engines",
        "error",
        "for",
        "format",
        "search",
        "sentence",
        "sparse",
        "transformers",
        "validation"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5272093023255814,
      "overall": 0.7424031007751938
    }
  },
  {
    "text": "## Performance Considerations",
    "metadata": {
      "chunk_id": "088f0de81daa-0016",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Considerations"
      ],
      "heading_text": "Performance Considerations",
      "token_count": 4,
      "char_count": 29,
      "start_char": 10280,
      "end_char": 10309,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.530955",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Performance Considerations",
      "chunk_hash": "f0c6f691b1d6938e",
      "content_digest": "f0c6f691b1d6938e",
      "chunk_length": 29,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "performance",
          "considerations"
        ],
        "term_weights": [
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "considerations",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Considerations",
        "considerations",
        "performance"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Scalability Recommendations  - **Small Corpora (< 10K docs):** Manual search with `util.semantic_search()` - **Medium Corpora (10K-1M docs):** Qdrant or Seismic for performance - **Large Corpora (> 1M docs):** Elasticsearch/OpenSearch with distributed setup - **Real-time Applications:** Seismic for lowest latency in-memory search  Sources: [examples/sparse_encoder/applications/semantic_search/README.md:127-132](), [examples/sparse_encoder/applications/semantic_search/README.md:388-396]()",
    "metadata": {
      "chunk_id": "088f0de81daa-0018",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "filename": "Sparse_Search_Integration.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Scalability Recommendations"
      ],
      "heading_text": "Scalability Recommendations",
      "token_count": 119,
      "char_count": 496,
      "start_char": 10803,
      "end_char": 11299,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7166666666666667,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.530955",
      "document_id": "088f0de81daa",
      "document_name": "Sparse_Search_Integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "source_filename": "Sparse_Search_Integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Sparse_Search_Integration.md",
      "hierarchy_path": "Scalability Recommendations",
      "chunk_hash": "e75a73d785958868",
      "content_digest": "e75a73d785958868",
      "chunk_length": 496,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "corpora",
          "docs",
          "semantic",
          "applications",
          "10k",
          "with",
          "seismic",
          "for",
          "examples",
          "sparse",
          "encoder",
          "readme",
          "scalability",
          "recommendations",
          "small",
          "manual",
          "util",
          "medium",
          "qdrant"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 5,
            "weight": 0.089286
          },
          {
            "term": "corpora",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "docs",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "semantic",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "applications",
            "tf": 3,
            "weight": 0.053571
          },
          {
            "term": "10k",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "seismic",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "readme",
            "tf": 2,
            "weight": 0.035714
          },
          {
            "term": "scalability",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "recommendations",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "small",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "manual",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "util",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "medium",
            "tf": 1,
            "weight": 0.017857
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.017857
          }
        ],
        "unique_terms": 36,
        "total_terms": 56
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "10k",
        "Scalability Recommendations",
        "applications",
        "corpora",
        "docs",
        "examples",
        "for",
        "search",
        "seismic",
        "semantic",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7166666666666667,
      "overall": 0.8055555555555555
    }
  }
]
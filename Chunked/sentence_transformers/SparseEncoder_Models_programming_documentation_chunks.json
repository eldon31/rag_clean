[
  {
    "text": "## Model Architecture Types\n\nSparseEncoder models in the sentence-transformers ecosystem fall into two primary architectural categories, each optimized for different use cases and performance requirements.\n\n```mermaid\ngraph TB\n    subgraph \"SparseEncoder Model Types\"\n        CoreSPLADE[\"Core SPLADE Models<br/>Full Neural Inference\"]\n        InferenceFree[\"Inference-Free SPLADE Models<br/>Hybrid Architecture\"]\n    end\n    \n    subgraph \"Core SPLADE Architecture\"\n        CoreQuery[\"Query: MLMTransformer + SpladePooling\"]\n        CoreDoc[\"Document: MLMTransformer + SpladePooling\"]\n        CoreSPLADE --> CoreQuery\n        CoreSPLADE --> CoreDoc\n    end\n    \n    subgraph \"Inference-Free Architecture\"\n        IFQuery[\"Query: SparseStaticEmbedding<br/>(Pre-computed scores)\"]\n        IFDoc[\"Document: MLMTransformer + SpladePooling\"]\n        InferenceFree --> IFQuery\n        InferenceFree --> IFDoc\n    end\n    \n    subgraph \"Common Interface\"\n        EncodeQuery[\"encode_query()\"]\n        EncodeDoc[\"encode_document()\"]\n        Similarity[\"similarity()\"]\n    end\n    \n    CoreQuery --> EncodeQuery\n    CoreDoc --> EncodeDoc\n    IFQuery --> EncodeQuery\n    IFDoc --> EncodeDoc\n    EncodeQuery --> Similarity\n    EncodeDoc --> Similarity\n    \n    subgraph \"Output Characteristics\"\n        CoreOutput[\"Sparse Vectors<br/>Query Expansion: Yes<br/>Latency: Higher\"]\n        IFOutput[\"Sparse Vectors<br/>Query Expansion: No<br/>Latency: Near-instant\"]\n    end\n    \n    CoreSPLADE --> CoreOutput\n    InferenceFree --> IFOutput\n```\n\n**SparseEncoder Model Architecture Types**\n\nSources: [docs/sparse_encoder/pretrained_models.md:62-76]()",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Architecture Types"
      ],
      "heading_text": "Model Architecture Types",
      "token_count": 370,
      "char_count": 1633,
      "start_char": 506,
      "end_char": 2139,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5048461538461538,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.735619",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Model Architecture Types",
      "chunk_hash": "86b3f8a339120f69",
      "content_digest": "86b3f8a339120f69",
      "chunk_length": 1633,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "architecture",
          "subgraph",
          "end",
          "query",
          "models",
          "coresplade",
          "inferencefree",
          "encodequery",
          "encodedoc",
          "similarity",
          "model",
          "types",
          "sparseencoder",
          "splade",
          "inference",
          "corequery",
          "mlmtransformer",
          "spladepooling",
          "coredoc",
          "document"
        ],
        "term_weights": [
          {
            "term": "architecture",
            "tf": 5,
            "weight": 0.035971
          },
          {
            "term": "subgraph",
            "tf": 5,
            "weight": 0.035971
          },
          {
            "term": "end",
            "tf": 5,
            "weight": 0.035971
          },
          {
            "term": "query",
            "tf": 5,
            "weight": 0.035971
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.028777
          },
          {
            "term": "coresplade",
            "tf": 4,
            "weight": 0.028777
          },
          {
            "term": "inferencefree",
            "tf": 4,
            "weight": 0.028777
          },
          {
            "term": "encodequery",
            "tf": 4,
            "weight": 0.028777
          },
          {
            "term": "encodedoc",
            "tf": 4,
            "weight": 0.028777
          },
          {
            "term": "similarity",
            "tf": 4,
            "weight": 0.028777
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.021583
          },
          {
            "term": "types",
            "tf": 3,
            "weight": 0.021583
          },
          {
            "term": "sparseencoder",
            "tf": 3,
            "weight": 0.021583
          },
          {
            "term": "splade",
            "tf": 3,
            "weight": 0.021583
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.021583
          },
          {
            "term": "corequery",
            "tf": 3,
            "weight": 0.021583
          },
          {
            "term": "mlmtransformer",
            "tf": 3,
            "weight": 0.021583
          },
          {
            "term": "spladepooling",
            "tf": 3,
            "weight": 0.021583
          },
          {
            "term": "coredoc",
            "tf": 3,
            "weight": 0.021583
          },
          {
            "term": "document",
            "tf": 3,
            "weight": 0.021583
          }
        ],
        "unique_terms": 71,
        "total_terms": 139
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Architecture Types",
        "architecture",
        "coresplade",
        "encodedoc",
        "encodequery",
        "end",
        "inferencefree",
        "models",
        "query",
        "similarity",
        "subgraph"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5048461538461538,
      "overall": 0.7016153846153844
    }
  },
  {
    "text": "## Core SPLADE Models  Core SPLADE models use neural inference for both queries and documents, providing query expansion capabilities and optimal retrieval performance. These models are trained on datasets like MS MARCO Passage Retrieval and evaluated on BEIR benchmarks. | Model Name | MS MARCO MRR@10 | BEIR-13 avg nDCG@10 | Parameters | Architecture | |------------|:---------------:|:-------------------:|-----------:|-------------| | [opensearch-project/opensearch-neural-sparse-encoding-v2-distill](https://huggingface.co/opensearch-project/opensearch-neural-sparse-encoding-v2-distill) | NA | **52.8** | 67M | DistilBERT | | [opensearch-project/opensearch-neural-sparse-encoding-v1](https://huggingface.co/opensearch-project/opensearch-neural-sparse-encoding-v1) | NA | 52.4 | 133M | BERT | | [naver/splade-v3](https://huggingface.co/naver/splade-v3) | **40.2** | 51.7 | 109M | BERT | | [ibm-granite/granite-embedding-30m-sparse](https://huggingface.co/ibm-granite/granite-embedding-30m-sparse) | NA | 50.8 | 30M | Custom | | [naver/splade-cocondenser-selfdistil](https://huggingface.co/naver/splade-cocondenser-selfdistil) | 37.6 | 50.7 | 109M | BERT | | [naver/splade_v2_distil](https://huggingface.co/naver/splade_v2_distil) | 36.8 | 50.6 | 67M | DistilBERT | | [naver/splade-v3-distilbert](https://huggingface.co/naver/splade-v3-distilbert) | 38.7 | 50.0 | 67M | DistilBERT | | [naver/splade-v3-lexical](https://huggingface.co/naver/splade-v3-lexical) | 40.0 | 49.1 | 109M | BERT | | [rasyosef/splade-mini](https://huggingface.co/rasyosef/splade-mini) | 33.2 | 42.5 | 11M | Mini | | [rasyosef/splade-tiny](https://huggingface.co/rasyosef/splade-tiny) | 30.9 | 40.6 | 4M | Tiny |  **Note:** BM25 baseline achieves 18.4 MS MARCO MRR@10 and 45.6 BEIR-13 avg nDCG@10. Sources: [docs/sparse_encoder/pretrained_models.md:36-60]()",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Core SPLADE Models"
      ],
      "heading_text": "Core SPLADE Models",
      "token_count": 637,
      "char_count": 1834,
      "start_char": 2141,
      "end_char": 3975,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6475138121546962,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.737571",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Core SPLADE Models",
      "chunk_hash": "9ebb41dae4f35e2d",
      "content_digest": "9ebb41dae4f35e2d",
      "chunk_length": 1834,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "splade",
          "https",
          "huggingface",
          "naver",
          "opensearch",
          "sparse",
          "neural",
          "distilbert",
          "models",
          "and",
          "project",
          "encoding",
          "bert",
          "granite",
          "rasyosef",
          "marco",
          "beir",
          "67m",
          "109m",
          "30m"
        ],
        "term_weights": [
          {
            "term": "splade",
            "tf": 16,
            "weight": 0.089385
          },
          {
            "term": "https",
            "tf": 10,
            "weight": 0.055866
          },
          {
            "term": "huggingface",
            "tf": 10,
            "weight": 0.055866
          },
          {
            "term": "naver",
            "tf": 10,
            "weight": 0.055866
          },
          {
            "term": "opensearch",
            "tf": 8,
            "weight": 0.044693
          },
          {
            "term": "sparse",
            "tf": 7,
            "weight": 0.039106
          },
          {
            "term": "neural",
            "tf": 5,
            "weight": 0.027933
          },
          {
            "term": "distilbert",
            "tf": 5,
            "weight": 0.027933
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "project",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "encoding",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "bert",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "granite",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "rasyosef",
            "tf": 4,
            "weight": 0.022346
          },
          {
            "term": "marco",
            "tf": 3,
            "weight": 0.01676
          },
          {
            "term": "beir",
            "tf": 3,
            "weight": 0.01676
          },
          {
            "term": "67m",
            "tf": 3,
            "weight": 0.01676
          },
          {
            "term": "109m",
            "tf": 3,
            "weight": 0.01676
          },
          {
            "term": "30m",
            "tf": 3,
            "weight": 0.01676
          }
        ],
        "unique_terms": 69,
        "total_terms": 179
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Core SPLADE Models",
        "and",
        "distilbert",
        "https",
        "huggingface",
        "models",
        "naver",
        "neural",
        "opensearch",
        "sparse",
        "splade"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6475138121546962,
      "overall": 0.749171270718232
    }
  },
  {
    "text": "## Basic Usage Pattern\n\nAll SparseEncoder models follow a consistent interface for encoding queries and documents:\n\n```python\nfrom sentence_transformers import SparseEncoder",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Basic Usage Pattern"
      ],
      "heading_text": "Basic Usage Pattern",
      "token_count": 29,
      "char_count": 173,
      "start_char": 5464,
      "end_char": 5637,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.5757142857142857,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.738983",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Basic Usage Pattern",
      "chunk_hash": "a0fea33adbfa463d",
      "content_digest": "a0fea33adbfa463d",
      "chunk_length": 173,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparseencoder",
          "basic",
          "usage",
          "pattern",
          "all",
          "models",
          "follow",
          "consistent",
          "interface",
          "for",
          "encoding",
          "queries",
          "and",
          "documents",
          "python",
          "from",
          "sentence",
          "transformers",
          "import"
        ],
        "term_weights": [
          {
            "term": "sparseencoder",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "basic",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "usage",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "pattern",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "follow",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "consistent",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "interface",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "encoding",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "queries",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "import",
            "tf": 1,
            "weight": 0.05
          }
        ],
        "unique_terms": 19,
        "total_terms": 20
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Basic Usage Pattern",
        "all",
        "basic",
        "consistent",
        "follow",
        "for",
        "interface",
        "models",
        "pattern",
        "sparseencoder",
        "usage"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.5757142857142857,
      "overall": 0.6919047619047619
    }
  },
  {
    "text": "# Load any SparseEncoder model\nmodel = SparseEncoder(\"naver/splade-v3\")",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Load any SparseEncoder model"
      ],
      "heading_text": "Load any SparseEncoder model",
      "token_count": 20,
      "char_count": 71,
      "start_char": 5639,
      "end_char": 5710,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.5525,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.739089",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Load any SparseEncoder model",
      "chunk_hash": "0d5551f40f78c405",
      "content_digest": "0d5551f40f78c405",
      "chunk_length": 71,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparseencoder",
          "model",
          "load",
          "any",
          "naver",
          "splade"
        ],
        "term_weights": [
          {
            "term": "sparseencoder",
            "tf": 2,
            "weight": 0.25
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.25
          },
          {
            "term": "load",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "any",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "naver",
            "tf": 1,
            "weight": 0.125
          },
          {
            "term": "splade",
            "tf": 1,
            "weight": 0.125
          }
        ],
        "unique_terms": 6,
        "total_terms": 8
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Load any SparseEncoder model",
        "any",
        "load",
        "model",
        "naver",
        "sparseencoder",
        "splade"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.5525,
      "overall": 0.6841666666666667
    }
  },
  {
    "text": "# Encode queries and documents\nqueries = [\"what causes aging fast\"]\ndocuments = [\"UV-A light causes skin aging...\", \"Alzheimer's disease...\"]\n\nquery_embeddings = model.encode_query(queries)\ndocument_embeddings = model.encode_document(documents)",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Encode queries and documents"
      ],
      "heading_text": "Encode queries and documents",
      "token_count": 49,
      "char_count": 244,
      "start_char": 5712,
      "end_char": 5956,
      "semantic_score": 0.6,
      "structural_score": 0.7,
      "retrieval_quality": 0.5207692307692308,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.739256",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Encode queries and documents",
      "chunk_hash": "940a4de6397bcd06",
      "content_digest": "940a4de6397bcd06",
      "chunk_length": 244,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "encode",
          "queries",
          "documents",
          "causes",
          "aging",
          "query",
          "embeddings",
          "model",
          "document",
          "and",
          "what",
          "fast",
          "light",
          "skin",
          "alzheimer",
          "disease"
        ],
        "term_weights": [
          {
            "term": "encode",
            "tf": 3,
            "weight": 0.107143
          },
          {
            "term": "queries",
            "tf": 3,
            "weight": 0.107143
          },
          {
            "term": "documents",
            "tf": 3,
            "weight": 0.107143
          },
          {
            "term": "causes",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "aging",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "document",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "what",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "fast",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "light",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "skin",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "alzheimer",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "disease",
            "tf": 1,
            "weight": 0.035714
          }
        ],
        "unique_terms": 16,
        "total_terms": 28
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Encode queries and documents",
        "aging",
        "and",
        "causes",
        "document",
        "documents",
        "embeddings",
        "encode",
        "model",
        "queries",
        "query"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7,
      "retrieval_quality": 0.5207692307692308,
      "overall": 0.6069230769230769
    }
  },
  {
    "text": "# Compute similarities\nsimilarities = model.similarity(query_embeddings, document_embeddings)\n```\n\nThe `encode_query()` and `encode_document()` methods return sparse tensors with shape `[batch_size, vocab_size]`, where non-zero values indicate token activations.\n\nSources: [docs/sparse_encoder/pretrained_models.md:12-33]()",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0006",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Compute similarities"
      ],
      "heading_text": "Compute similarities",
      "token_count": 66,
      "char_count": 323,
      "start_char": 5958,
      "end_char": 6281,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5792857142857143,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.739449",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Compute similarities",
      "chunk_hash": "64eb3336eabae6bf",
      "content_digest": "64eb3336eabae6bf",
      "chunk_length": 323,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "similarities",
          "query",
          "embeddings",
          "document",
          "encode",
          "sparse",
          "size",
          "compute",
          "model",
          "similarity",
          "the",
          "and",
          "methods",
          "return",
          "tensors",
          "with",
          "shape",
          "batch",
          "vocab",
          "where"
        ],
        "term_weights": [
          {
            "term": "similarities",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "document",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "encode",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "size",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "compute",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "similarity",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "methods",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "return",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "tensors",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "shape",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "batch",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "vocab",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.026316
          }
        ],
        "unique_terms": 31,
        "total_terms": 38
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Compute similarities",
        "compute",
        "document",
        "embeddings",
        "encode",
        "model",
        "query",
        "similarities",
        "similarity",
        "size",
        "sparse"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5792857142857143,
      "overall": 0.6597619047619047
    }
  },
  {
    "text": "## Integration with Search Systems\n\nSparseEncoder models integrate seamlessly with various search infrastructures, leveraging their sparse vector representations for efficient retrieval.\n\n```mermaid\ngraph TD\n    subgraph \"SparseEncoder Integration Architecture\"\n        QueryInput[\"Query Input<br/>encode_query()\"]\n        DocInput[\"Document Corpus<br/>encode_document()\"]\n        \n        SparseModel[\"SparseEncoder<br/>(naver/splade-v3)\"]\n        \n        QueryInput --> SparseModel\n        DocInput --> SparseModel\n    end\n    \n    subgraph \"Sparse Vector Processing\"\n        QuerySparse[\"Query Sparse Vector<br/>[1, 30522]\"]\n        DocSparse[\"Document Sparse Vectors<br/>[N, 30522]\"]\n        \n        SparseModel --> QuerySparse\n        SparseModel --> DocSparse\n    end\n    \n    subgraph \"Search Engine Integration\"\n        Elasticsearch[\"Elasticsearch<br/>sparse_vector field\"]\n        OpenSearch[\"OpenSearch<br/>neural-sparse plugin\"]\n        Qdrant[\"Qdrant<br/>sparse vectors\"]\n        SpladeIndex[\"splade-index<br/>specialized library\"]\n    end\n    \n    subgraph \"Application Layer\"\n        SemanticSearch[\"Semantic Search<br/>semantic_search_splade_index.py\"]\n        HybridRetrieval[\"Hybrid Retrieval<br/>Dense + Sparse\"]\n        NeuralLexical[\"Neural Lexical Search<br/>Token-level matching\"]\n    end\n    \n    QuerySparse --> Elasticsearch\n    DocSparse --> Elasticsearch\n    QuerySparse --> OpenSearch\n    DocSparse --> OpenSearch\n    QuerySparse --> Qdrant\n    DocSparse --> Qdrant\n    QuerySparse --> SpladeIndex\n    DocSparse --> SpladeIndex\n    \n    Elasticsearch --> SemanticSearch\n    OpenSearch --> SemanticSearch\n    SpladeIndex --> SemanticSearch\n    \n    SemanticSearch --> HybridRetrieval\n    SemanticSearch --> NeuralLexical\n```\n\n**SparseEncoder Integration with Search Systems**\n\nSources: [examples/sparse_encoder/applications/semantic_search/semantic_search_splade_index.py:1-52](), [docs/sparse_encoder/pretrained_models.md:1-83]()",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration with Search Systems"
      ],
      "heading_text": "Integration with Search Systems",
      "token_count": 433,
      "char_count": 1960,
      "start_char": 6283,
      "end_char": 8243,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7090044776119403,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.740496",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Integration with Search Systems",
      "chunk_hash": "02788eeda3205af1",
      "content_digest": "02788eeda3205af1",
      "chunk_length": 1960,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparse",
          "search",
          "querysparse",
          "docsparse",
          "semanticsearch",
          "sparsemodel",
          "elasticsearch",
          "opensearch",
          "integration",
          "sparseencoder",
          "vector",
          "subgraph",
          "splade",
          "end",
          "qdrant",
          "spladeindex",
          "semantic",
          "with",
          "query",
          "document"
        ],
        "term_weights": [
          {
            "term": "sparse",
            "tf": 10,
            "weight": 0.063291
          },
          {
            "term": "search",
            "tf": 9,
            "weight": 0.056962
          },
          {
            "term": "querysparse",
            "tf": 6,
            "weight": 0.037975
          },
          {
            "term": "docsparse",
            "tf": 6,
            "weight": 0.037975
          },
          {
            "term": "semanticsearch",
            "tf": 6,
            "weight": 0.037975
          },
          {
            "term": "sparsemodel",
            "tf": 5,
            "weight": 0.031646
          },
          {
            "term": "elasticsearch",
            "tf": 5,
            "weight": 0.031646
          },
          {
            "term": "opensearch",
            "tf": 5,
            "weight": 0.031646
          },
          {
            "term": "integration",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "sparseencoder",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "vector",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "splade",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "spladeindex",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.025316
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.018987
          },
          {
            "term": "query",
            "tf": 3,
            "weight": 0.018987
          },
          {
            "term": "document",
            "tf": 3,
            "weight": 0.018987
          }
        ],
        "unique_terms": 67,
        "total_terms": 158
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration with Search Systems",
        "docsparse",
        "elasticsearch",
        "integration",
        "opensearch",
        "querysparse",
        "search",
        "semanticsearch",
        "sparse",
        "sparseencoder",
        "sparsemodel"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7090044776119403,
      "overall": 0.76966815920398
    }
  },
  {
    "text": "## Model Selection Guidelines",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0008",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Selection Guidelines"
      ],
      "heading_text": "Model Selection Guidelines",
      "token_count": 4,
      "char_count": 29,
      "start_char": 8245,
      "end_char": 8274,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7899999999999999,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.740571",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Model Selection Guidelines",
      "chunk_hash": "01d249a713ad3e0f",
      "content_digest": "01d249a713ad3e0f",
      "chunk_length": 29,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "selection",
          "guidelines"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "selection",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "guidelines",
            "tf": 1,
            "weight": 0.333333
          }
        ],
        "unique_terms": 3,
        "total_terms": 3
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Selection Guidelines",
        "guidelines",
        "model",
        "selection"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7899999999999999,
      "overall": 0.83
    }
  },
  {
    "text": "### Performance Considerations  - **Highest BEIR Performance**: `opensearch-project/opensearch-neural-sparse-encoding-v2-distill` (52.8 nDCG@10) - **Highest MS MARCO Performance**: `naver/splade-v3` (40.2 MRR@10) - **Best Efficiency Trade-off**: `rasyosef/splade-tiny` (4M parameters, 40.6 BEIR nDCG@10) - **Fastest Query Processing**: Inference-free models with `SparseStaticEmbedding`",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0009",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Considerations"
      ],
      "heading_text": "Performance Considerations",
      "token_count": 120,
      "char_count": 386,
      "start_char": 8276,
      "end_char": 8662,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5316666666666666,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.740782",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Performance Considerations",
      "chunk_hash": "9a71c19fd560102d",
      "content_digest": "9a71c19fd560102d",
      "chunk_length": 386,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "performance",
          "highest",
          "beir",
          "opensearch",
          "ndcg",
          "splade",
          "considerations",
          "project",
          "neural",
          "sparse",
          "encoding",
          "distill",
          "marco",
          "naver",
          "mrr",
          "best",
          "efficiency",
          "trade",
          "off",
          "rasyosef"
        ],
        "term_weights": [
          {
            "term": "performance",
            "tf": 3,
            "weight": 0.081081
          },
          {
            "term": "highest",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "beir",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "opensearch",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "ndcg",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "splade",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "considerations",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "project",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "neural",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "sparse",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "encoding",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "distill",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "marco",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "naver",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "mrr",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "best",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "efficiency",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "trade",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "off",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "rasyosef",
            "tf": 1,
            "weight": 0.027027
          }
        ],
        "unique_terms": 30,
        "total_terms": 37
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Considerations",
        "beir",
        "considerations",
        "highest",
        "ndcg",
        "neural",
        "opensearch",
        "performance",
        "project",
        "sparse",
        "splade"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5316666666666666,
      "overall": 0.7105555555555555
    }
  },
  {
    "text": "## Model Collections  Pre-organized collections of SparseEncoder models are available on the Hugging Face Hub:  - **[SPLADE Models](https://huggingface.co/collections/sparse-encoder/splade-models-6862be100374b320d826eeaa)**: Complete collection of core SPLADE models - **[Inference-Free SPLADE Models](https://huggingface.co/collections/sparse-encoder/inference-free-splade-models-6862be3a1d72eab38920bc6a)**: Models optimized for query speed  These collections provide curated access to models with consistent naming conventions and documented performance characteristics. Sources: [docs/sparse_encoder/pretrained_models.md:77-83]()",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0011",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Collections"
      ],
      "heading_text": "Model Collections",
      "token_count": 154,
      "char_count": 633,
      "start_char": 9281,
      "end_char": 9914,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.542,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.741498",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Model Collections",
      "chunk_hash": "3de40dab6f5c1070",
      "content_digest": "3de40dab6f5c1070",
      "chunk_length": 633,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "models",
          "collections",
          "splade",
          "sparse",
          "encoder",
          "https",
          "huggingface",
          "inference",
          "free",
          "model",
          "pre",
          "organized",
          "sparseencoder",
          "are",
          "available",
          "the",
          "hugging",
          "face",
          "hub",
          "6862be100374b320d826eeaa"
        ],
        "term_weights": [
          {
            "term": "models",
            "tf": 9,
            "weight": 0.134328
          },
          {
            "term": "collections",
            "tf": 5,
            "weight": 0.074627
          },
          {
            "term": "splade",
            "tf": 5,
            "weight": 0.074627
          },
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "encoder",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "huggingface",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "free",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "pre",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "organized",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "sparseencoder",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "available",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "hugging",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "face",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "hub",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "6862be100374b320d826eeaa",
            "tf": 1,
            "weight": 0.014925
          }
        ],
        "unique_terms": 43,
        "total_terms": 67
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Collections",
        "collections",
        "encoder",
        "free",
        "https",
        "huggingface",
        "inference",
        "model",
        "models",
        "sparse",
        "splade"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.542,
      "overall": 0.7473333333333333
    }
  },
  {
    "text": "# CrossEncoder Models\n\n\n\n\nThis document covers the pretrained CrossEncoder models available in the sentence-transformers library, their characteristics, performance metrics, and usage patterns. CrossEncoder models are designed for pairwise text scoring and classification tasks, making them particularly effective for reranking, semantic similarity measurement, and natural language inference.\n\nFor information about training CrossEncoder models, see [CrossEncoder Training](#3.3). For details about CrossEncoder evaluation methods, see [CrossEncoder Evaluators](#4.3).",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0012",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "CrossEncoder Models"
      ],
      "heading_text": "CrossEncoder Models",
      "token_count": 100,
      "char_count": 569,
      "start_char": 9917,
      "end_char": 10486,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5196875,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.741847",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "CrossEncoder Models",
      "chunk_hash": "b87cf858fb3e6b65",
      "content_digest": "b87cf858fb3e6b65",
      "chunk_length": 569,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "crossencoder",
          "models",
          "for",
          "and",
          "the",
          "about",
          "training",
          "see",
          "this",
          "document",
          "covers",
          "pretrained",
          "available",
          "sentence",
          "transformers",
          "library",
          "their",
          "characteristics",
          "performance",
          "metrics"
        ],
        "term_weights": [
          {
            "term": "crossencoder",
            "tf": 7,
            "weight": 0.111111
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.063492
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.063492
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.047619
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "about",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "see",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "covers",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "pretrained",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "available",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "their",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "characteristics",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "metrics",
            "tf": 1,
            "weight": 0.015873
          }
        ],
        "unique_terms": 45,
        "total_terms": 63
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "CrossEncoder Models",
        "about",
        "and",
        "crossencoder",
        "document",
        "for",
        "models",
        "see",
        "the",
        "this",
        "training"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5196875,
      "overall": 0.7398958333333332
    }
  },
  {
    "text": "## Model Architecture and Purpose\n\nCrossEncoder models process pairs of texts jointly through a single transformer model, producing similarity scores or classification outputs. Unlike bi-encoder architectures that encode texts independently, CrossEncoders perform cross-attention between the input texts, enabling more precise but computationally expensive comparisons.\n\n```mermaid\ngraph TD\n    subgraph \"CrossEncoder Architecture\"\n        TextPair[\"Text Pair Input<br/>(query, passage)\"] --> Tokenizer[\"Tokenizer\"]\n        Tokenizer --> CrossAttention[\"Cross-Attention<br/>Transformer\"]\n        CrossAttention --> Classifier[\"Classification Head\"]\n        Classifier --> ActivationFn[\"Activation Function<br/>(Sigmoid/Identity)\"]\n        ActivationFn --> Score[\"Relevance Score<br/>(0-1 or logit)\"]\n    end\n    \n    subgraph \"Use Cases\"\n        Score --> Reranking[\"Reranking Pipeline\"]\n        Score --> STS[\"Semantic Similarity\"]\n        Score --> NLI[\"Natural Language Inference\"]\n        Score --> QA[\"Question Answering\"]\n    end\n```\n\n**Sources:** [docs/cross_encoder/pretrained_models.md:1-33](), [docs/pretrained-models/ce-msmarco.md:1-63]()",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0013",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Architecture and Purpose"
      ],
      "heading_text": "Model Architecture and Purpose",
      "token_count": 246,
      "char_count": 1149,
      "start_char": 10488,
      "end_char": 11637,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5445454545454546,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.742340",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Model Architecture and Purpose",
      "chunk_hash": "89839632377e245a",
      "content_digest": "89839632377e245a",
      "chunk_length": 1149,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "score",
          "models",
          "texts",
          "cross",
          "tokenizer",
          "model",
          "architecture",
          "crossencoder",
          "transformer",
          "similarity",
          "classification",
          "encoder",
          "attention",
          "input",
          "subgraph",
          "crossattention",
          "classifier",
          "activationfn",
          "end",
          "reranking"
        ],
        "term_weights": [
          {
            "term": "score",
            "tf": 6,
            "weight": 0.057143
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "texts",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "cross",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "tokenizer",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "architecture",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "crossencoder",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "transformer",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "similarity",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "classification",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "attention",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "input",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "subgraph",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "crossattention",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "classifier",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "activationfn",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "reranking",
            "tf": 2,
            "weight": 0.019048
          }
        ],
        "unique_terms": 75,
        "total_terms": 105
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Architecture and Purpose",
        "architecture",
        "cross",
        "crossencoder",
        "model",
        "models",
        "score",
        "similarity",
        "texts",
        "tokenizer",
        "transformer"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5445454545454546,
      "overall": 0.7148484848484847
    }
  },
  {
    "text": "### MS MARCO Models\n\nMS MARCO CrossEncoder models are specifically trained for information retrieval and reranking tasks using real user queries from Bing search engine.\n\n```mermaid\ngraph LR\n    subgraph \"MS MARCO Model Hierarchy\"\n        TinyBERT[\"cross-encoder/ms-marco-TinyBERT-L2-v2<br/>NDCG@10: 69.84<br/>9000 docs/sec\"]\n        MiniLM2[\"cross-encoder/ms-marco-MiniLM-L2-v2<br/>NDCG@10: 71.01<br/>4100 docs/sec\"]\n        MiniLM4[\"cross-encoder/ms-marco-MiniLM-L4-v2<br/>NDCG@10: 73.04<br/>2500 docs/sec\"]\n        MiniLM6[\"cross-encoder/ms-marco-MiniLM-L6-v2<br/>NDCG@10: 74.30<br/>1800 docs/sec\"]\n        MiniLM12[\"cross-encoder/ms-marco-MiniLM-L12-v2<br/>NDCG@10: 74.31<br/>960 docs/sec\"]\n    end\n    \n    TinyBERT --> |\"Higher Performance\"| MiniLM2\n    MiniLM2 --> MiniLM4\n    MiniLM4 --> MiniLM6\n    MiniLM6 --> MiniLM12\n    \n    TinyBERT --> |\"Higher Speed\"| MiniLM2\n```\n\n**Sources:** [docs/cross_encoder/pretrained_models.md:35-42](), [docs/pretrained-models/ce-msmarco.md:41-48]()",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0015",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "MS MARCO Models"
      ],
      "heading_text": "MS MARCO Models",
      "token_count": 325,
      "char_count": 991,
      "start_char": 12445,
      "end_char": 13436,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5225,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.743544",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "MS MARCO Models",
      "chunk_hash": "619cc1486969f8f1",
      "content_digest": "619cc1486969f8f1",
      "chunk_length": 991,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "marco",
          "docs",
          "cross",
          "encoder",
          "ndcg",
          "sec",
          "models",
          "tinybert",
          "minilm2",
          "minilm",
          "minilm4",
          "minilm6",
          "minilm12",
          "higher",
          "pretrained",
          "crossencoder",
          "are",
          "specifically",
          "trained",
          "for"
        ],
        "term_weights": [
          {
            "term": "marco",
            "tf": 8,
            "weight": 0.080808
          },
          {
            "term": "docs",
            "tf": 7,
            "weight": 0.070707
          },
          {
            "term": "cross",
            "tf": 6,
            "weight": 0.060606
          },
          {
            "term": "encoder",
            "tf": 6,
            "weight": 0.060606
          },
          {
            "term": "ndcg",
            "tf": 5,
            "weight": 0.050505
          },
          {
            "term": "sec",
            "tf": 5,
            "weight": 0.050505
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.040404
          },
          {
            "term": "tinybert",
            "tf": 4,
            "weight": 0.040404
          },
          {
            "term": "minilm2",
            "tf": 4,
            "weight": 0.040404
          },
          {
            "term": "minilm",
            "tf": 4,
            "weight": 0.040404
          },
          {
            "term": "minilm4",
            "tf": 3,
            "weight": 0.030303
          },
          {
            "term": "minilm6",
            "tf": 3,
            "weight": 0.030303
          },
          {
            "term": "minilm12",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "higher",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "pretrained",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.010101
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.010101
          },
          {
            "term": "specifically",
            "tf": 1,
            "weight": 0.010101
          },
          {
            "term": "trained",
            "tf": 1,
            "weight": 0.010101
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.010101
          }
        ],
        "unique_terms": 49,
        "total_terms": 99
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "MS MARCO Models",
        "cross",
        "docs",
        "encoder",
        "marco",
        "minilm",
        "minilm2",
        "models",
        "ndcg",
        "sec",
        "tinybert"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5225,
      "overall": 0.6741666666666667
    }
  },
  {
    "text": "### Community Models  The ecosystem includes high-quality community-contributed models for specialized domains:  - **BAAI BGE Rerankers**: `BAAI/bge-reranker-base`, `BAAI/bge-reranker-large`, `BAAI/bge-reranker-v2-m3` - **Jina AI Models**: `jinaai/jina-reranker-v1-tiny-en`, `jinaai/jina-reranker-v1-turbo-en` - **Mixedbread AI**: `mixedbread-ai/mxbai-rerank-base-v1`, `mixedbread-ai/mxbai-rerank-large-v1` - **Alibaba GTE**: `Alibaba-NLP/gte-reranker-modernbert-base`, `Alibaba-NLP/gte-multilingual-reranker-base`  **Sources:** [docs/cross_encoder/pretrained_models.md:114-130]()",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0016",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Community Models"
      ],
      "heading_text": "Community Models",
      "token_count": 194,
      "char_count": 580,
      "start_char": 13438,
      "end_char": 14018,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5575675675675675,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.743861",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Community Models",
      "chunk_hash": "2cb9b879c1803310",
      "content_digest": "2cb9b879c1803310",
      "chunk_length": 580,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "reranker",
          "models",
          "baai",
          "bge",
          "base",
          "jina",
          "mixedbread",
          "alibaba",
          "gte",
          "community",
          "large",
          "jinaai",
          "mxbai",
          "rerank",
          "nlp",
          "the",
          "ecosystem",
          "includes",
          "high",
          "quality"
        ],
        "term_weights": [
          {
            "term": "reranker",
            "tf": 7,
            "weight": 0.102941
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.058824
          },
          {
            "term": "baai",
            "tf": 4,
            "weight": 0.058824
          },
          {
            "term": "bge",
            "tf": 4,
            "weight": 0.058824
          },
          {
            "term": "base",
            "tf": 4,
            "weight": 0.058824
          },
          {
            "term": "jina",
            "tf": 3,
            "weight": 0.044118
          },
          {
            "term": "mixedbread",
            "tf": 3,
            "weight": 0.044118
          },
          {
            "term": "alibaba",
            "tf": 3,
            "weight": 0.044118
          },
          {
            "term": "gte",
            "tf": 3,
            "weight": 0.044118
          },
          {
            "term": "community",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "large",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "jinaai",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "mxbai",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "rerank",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "nlp",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "ecosystem",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "includes",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "high",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "quality",
            "tf": 1,
            "weight": 0.014706
          }
        ],
        "unique_terms": 36,
        "total_terms": 68
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Community Models",
        "alibaba",
        "baai",
        "base",
        "bge",
        "community",
        "gte",
        "jina",
        "mixedbread",
        "models",
        "reranker"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5575675675675675,
      "overall": 0.7525225225225224
    }
  },
  {
    "text": "# Load with sigmoid activation for 0-1 scores\nmodel = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L6-v2\", activation_fn=torch.nn.Sigmoid())\nscores = model.predict([\n    (\"How many people live in Berlin?\", \"Berlin had a population of 3,520,031 registered inhabitants.\"),\n    (\"How many people live in Berlin?\", \"Berlin is well known for its museums.\"),\n])",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0019",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Load with sigmoid activation for 0-1 scores"
      ],
      "heading_text": "Load with sigmoid activation for 0-1 scores",
      "token_count": 86,
      "char_count": 354,
      "start_char": 14153,
      "end_char": 14507,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5202325581395348,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.744450",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Load with sigmoid activation for 0-1 scores",
      "chunk_hash": "3ef9b445aa0850c2",
      "content_digest": "3ef9b445aa0850c2",
      "chunk_length": 354,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "berlin",
          "sigmoid",
          "activation",
          "for",
          "scores",
          "model",
          "how",
          "many",
          "people",
          "live",
          "load",
          "with",
          "crossencoder",
          "cross",
          "encoder",
          "marco",
          "minilm",
          "torch",
          "predict",
          "had"
        ],
        "term_weights": [
          {
            "term": "berlin",
            "tf": 4,
            "weight": 0.097561
          },
          {
            "term": "sigmoid",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "activation",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "scores",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "how",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "many",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "people",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "live",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "load",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "cross",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "encoder",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "marco",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "minilm",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "torch",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "predict",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "had",
            "tf": 1,
            "weight": 0.02439
          }
        ],
        "unique_terms": 29,
        "total_terms": 41
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Load with sigmoid activation for 0-1 scores",
        "activation",
        "berlin",
        "for",
        "how",
        "live",
        "many",
        "model",
        "people",
        "scores",
        "sigmoid"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5202325581395348,
      "overall": 0.6400775193798449
    }
  },
  {
    "text": "### Integration with Transformers Library\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L6-v2\")\ntokenizer = AutoTokenizer.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L6-v2\")\n\nfeatures = tokenizer([\"Query\", \"Query\"], [\"Paragraph1\", \"Paragraph2\"], \n                    padding=True, truncation=True, return_tensors=\"pt\")\n\nwith torch.no_grad():\n    scores = model(**features).logits\n```\n\n**Sources:** [docs/cross_encoder/pretrained_models.md:12-33](), [docs/pretrained-models/ce-msmarco.md:19-33]()",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0021",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration with Transformers Library"
      ],
      "heading_text": "Integration with Transformers Library",
      "token_count": 154,
      "char_count": 642,
      "start_char": 14565,
      "end_char": 15207,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5413513513513514,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.744930",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Integration with Transformers Library",
      "chunk_hash": "c6d169bd26ff4e21",
      "content_digest": "c6d169bd26ff4e21",
      "chunk_length": 642,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "pretrained",
          "from",
          "cross",
          "encoder",
          "with",
          "transformers",
          "import",
          "autotokenizer",
          "automodelforsequenceclassification",
          "torch",
          "model",
          "marco",
          "minilm",
          "tokenizer",
          "features",
          "query",
          "true",
          "docs",
          "models",
          "integration"
        ],
        "term_weights": [
          {
            "term": "pretrained",
            "tf": 4,
            "weight": 0.070175
          },
          {
            "term": "from",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "cross",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "encoder",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "import",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "autotokenizer",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "automodelforsequenceclassification",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "torch",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "marco",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "minilm",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "tokenizer",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "features",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "true",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.017544
          }
        ],
        "unique_terms": 33,
        "total_terms": 57
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration with Transformers Library",
        "automodelforsequenceclassification",
        "autotokenizer",
        "cross",
        "encoder",
        "from",
        "import",
        "pretrained",
        "torch",
        "transformers",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5413513513513514,
      "overall": 0.6804504504504504
    }
  },
  {
    "text": "## Performance Characteristics",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0022",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Characteristics"
      ],
      "heading_text": "Performance Characteristics",
      "token_count": 3,
      "char_count": 30,
      "start_char": 15209,
      "end_char": 15239,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.745001",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Performance Characteristics",
      "chunk_hash": "f2053113b0f9431f",
      "content_digest": "f2053113b0f9431f",
      "chunk_length": 30,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "performance",
          "characteristics"
        ],
        "term_weights": [
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "characteristics",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Characteristics",
        "characteristics",
        "performance"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Speed vs Accuracy Trade-offs\n\n```mermaid\ngraph TD\n    subgraph \"Performance Matrix\"\n        FastLow[\"Fast & Lower Accuracy<br/>TinyBERT-L2: 9000 docs/sec<br/>NDCG@10: 69.84\"]\n        MediumMed[\"Medium Speed & Accuracy<br/>MiniLM-L6: 1800 docs/sec<br/>NDCG@10: 74.30\"]\n        SlowHigh[\"Slower & Higher Accuracy<br/>MiniLM-L12: 960 docs/sec<br/>NDCG@10: 74.31\"]\n    end\n    \n    FastLow --> |\"Diminishing Returns\"| MediumMed\n    MediumMed --> SlowHigh\n    \n    subgraph \"Use Case Mapping\"\n        RealTime[\"Real-time Applications\"] --> FastLow\n        BatchProcessing[\"Batch Processing\"] --> MediumMed\n        HighPrecision[\"High Precision Tasks\"] --> SlowHigh\n    end\n```",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0023",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 23,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Speed vs Accuracy Trade-offs"
      ],
      "heading_text": "Speed vs Accuracy Trade-offs",
      "token_count": 191,
      "char_count": 675,
      "start_char": 15241,
      "end_char": 15916,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7,
      "retrieval_quality": 0.515,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.745401",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Speed vs Accuracy Trade-offs",
      "chunk_hash": "f32ea5c7c6d85cd3",
      "content_digest": "f32ea5c7c6d85cd3",
      "chunk_length": 675,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "accuracy",
          "mediummed",
          "fastlow",
          "docs",
          "sec",
          "ndcg",
          "slowhigh",
          "speed",
          "subgraph",
          "minilm",
          "end",
          "trade",
          "offs",
          "mermaid",
          "graph",
          "performance",
          "matrix",
          "fast",
          "lower",
          "tinybert"
        ],
        "term_weights": [
          {
            "term": "accuracy",
            "tf": 4,
            "weight": 0.063492
          },
          {
            "term": "mediummed",
            "tf": 4,
            "weight": 0.063492
          },
          {
            "term": "fastlow",
            "tf": 3,
            "weight": 0.047619
          },
          {
            "term": "docs",
            "tf": 3,
            "weight": 0.047619
          },
          {
            "term": "sec",
            "tf": 3,
            "weight": 0.047619
          },
          {
            "term": "ndcg",
            "tf": 3,
            "weight": 0.047619
          },
          {
            "term": "slowhigh",
            "tf": 3,
            "weight": 0.047619
          },
          {
            "term": "speed",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "subgraph",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "minilm",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.031746
          },
          {
            "term": "trade",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "offs",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "mermaid",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "graph",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "matrix",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "fast",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "lower",
            "tf": 1,
            "weight": 0.015873
          },
          {
            "term": "tinybert",
            "tf": 1,
            "weight": 0.015873
          }
        ],
        "unique_terms": 43,
        "total_terms": 63
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Speed vs Accuracy Trade-offs",
        "accuracy",
        "docs",
        "fastlow",
        "mediummed",
        "minilm",
        "ndcg",
        "sec",
        "slowhigh",
        "speed",
        "subgraph"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7,
      "retrieval_quality": 0.515,
      "overall": 0.6716666666666667
    }
  },
  {
    "text": "## Integration with Retrieval Systems\n\nCrossEncoder models are typically used in the reranking stage of two-stage retrieval systems, where they refine results from faster bi-encoder models.\n\n```mermaid\ngraph LR\n    subgraph \"Retrieve & Rerank Pipeline\"\n        Query[\"User Query\"] --> BiEncoder[\"Bi-Encoder<br/>SentenceTransformer\"]\n        Corpus[\"Document Corpus<br/>8.8M passages\"] --> BiEncoder\n        BiEncoder --> CandidateSet[\"Top-k Candidates<br/>(e.g., 100-1000)\"]\n        CandidateSet --> CrossEncoder[\"CrossEncoder<br/>cross-encoder/ms-marco-MiniLM-L6-v2\"]\n        CrossEncoder --> RankedResults[\"Final Ranked Results<br/>(e.g., top 10)\"]\n    end\n    \n    subgraph \"Performance Benefits\"\n        BiEncoder --> |\"Fast Retrieval<br/>Dense Search\"| Speed[\"Speed: ~10k docs/sec\"]\n        CrossEncoder --> |\"Precise Reranking<br/>Cross-Attention\"| Accuracy[\"Accuracy: NDCG@10 74.30\"]\n    end\n```",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0025",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 25,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration with Retrieval Systems"
      ],
      "heading_text": "Integration with Retrieval Systems",
      "token_count": 227,
      "char_count": 902,
      "start_char": 16282,
      "end_char": 17184,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7,
      "retrieval_quality": 0.5406329113924051,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.746198",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Integration with Retrieval Systems",
      "chunk_hash": "2c40cb97636e4a12",
      "content_digest": "2c40cb97636e4a12",
      "chunk_length": 902,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "crossencoder",
          "biencoder",
          "retrieval",
          "encoder",
          "systems",
          "models",
          "reranking",
          "stage",
          "results",
          "subgraph",
          "query",
          "corpus",
          "candidateset",
          "top",
          "cross",
          "end",
          "speed",
          "accuracy",
          "integration",
          "with"
        ],
        "term_weights": [
          {
            "term": "crossencoder",
            "tf": 5,
            "weight": 0.060241
          },
          {
            "term": "biencoder",
            "tf": 4,
            "weight": 0.048193
          },
          {
            "term": "retrieval",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "encoder",
            "tf": 3,
            "weight": 0.036145
          },
          {
            "term": "systems",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "reranking",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "stage",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "results",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "subgraph",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "corpus",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "candidateset",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "top",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "cross",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "speed",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "accuracy",
            "tf": 2,
            "weight": 0.024096
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.012048
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.012048
          }
        ],
        "unique_terms": 58,
        "total_terms": 83
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration with Retrieval Systems",
        "biencoder",
        "crossencoder",
        "encoder",
        "models",
        "reranking",
        "results",
        "retrieval",
        "stage",
        "subgraph",
        "systems"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7,
      "retrieval_quality": 0.5406329113924051,
      "overall": 0.680210970464135
    }
  },
  {
    "text": "### Hard Negatives Mining\n\nCrossEncoder models are used to generate hard negatives for training bi-encoder models, creating a feedback loop for model improvement.\n\n```mermaid\ngraph TD\n    subgraph \"Hard Negatives Pipeline\"\n        BiEncoderV2[\"Bi-Encoder v2<br/>msmarco-distilbert-base-v2\"] --> SimilarPassages[\"Retrieved Similar Passages\"]\n        SimilarPassages --> CrossEncoderElectra[\"CrossEncoder<br/>electra-base-msmarco\"]\n        CrossEncoderElectra --> LowScores[\"Low Cross-Encoder Scores<br/>(Hard Negatives)\"]\n        LowScores --> TrainingData[\"Enhanced Training Data\"]\n        TrainingData --> BiEncoderV3[\"Bi-Encoder v3<br/>msmarco-distilbert-base-v3\"]\n    end\n```\n\n**Sources:** [docs/pretrained-models/msmarco-v3.md:53-58](), [docs/cross_encoder/pretrained_models.md:44]()",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0026",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 26,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Hard Negatives Mining"
      ],
      "heading_text": "Hard Negatives Mining",
      "token_count": 199,
      "char_count": 787,
      "start_char": 17186,
      "end_char": 17973,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5442372881355932,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.746689",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Hard Negatives Mining",
      "chunk_hash": "8b75ec1501f84abc",
      "content_digest": "8b75ec1501f84abc",
      "chunk_length": 787,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "encoder",
          "hard",
          "negatives",
          "models",
          "msmarco",
          "base",
          "crossencoder",
          "for",
          "training",
          "distilbert",
          "similarpassages",
          "crossencoderelectra",
          "lowscores",
          "cross",
          "trainingdata",
          "docs",
          "pretrained",
          "mining",
          "are",
          "used"
        ],
        "term_weights": [
          {
            "term": "encoder",
            "tf": 5,
            "weight": 0.070423
          },
          {
            "term": "hard",
            "tf": 4,
            "weight": 0.056338
          },
          {
            "term": "negatives",
            "tf": 4,
            "weight": 0.056338
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.056338
          },
          {
            "term": "msmarco",
            "tf": 4,
            "weight": 0.056338
          },
          {
            "term": "base",
            "tf": 3,
            "weight": 0.042254
          },
          {
            "term": "crossencoder",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "distilbert",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "similarpassages",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "crossencoderelectra",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "lowscores",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "cross",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "trainingdata",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "pretrained",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "mining",
            "tf": 1,
            "weight": 0.014085
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.014085
          },
          {
            "term": "used",
            "tf": 1,
            "weight": 0.014085
          }
        ],
        "unique_terms": 42,
        "total_terms": 71
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Hard Negatives Mining",
        "base",
        "crossencoder",
        "distilbert",
        "encoder",
        "for",
        "hard",
        "models",
        "msmarco",
        "negatives",
        "training"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5442372881355932,
      "overall": 0.7147457627118644
    }
  },
  {
    "text": "## Model Selection Guidelines  | Task Type | Recommended Model | Key Considerations | |-----------|------------------|-------------------| | Information Retrieval | `cross-encoder/ms-marco-MiniLM-L6-v2` | Best balance of speed/accuracy | | Semantic Similarity | `cross-encoder/stsb-roberta-large` | Optimized for similarity scoring | | Question Answering | `cross-encoder/qnli-electra-base` | Passage-question relevance | | Duplicate Detection | `cross-encoder/quora-roberta-base` | Text pair classification | | Multilingual Tasks | `Alibaba-NLP/gte-multilingual-reranker-base` | Cross-lingual support |  **Sources:** [docs/cross_encoder/pretrained_models.md:1-130](), [docs/pretrained-models/ce-msmarco.md:1-63]()",
    "metadata": {
      "chunk_id": "94c47cacd3ca-0027",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "filename": "SparseEncoder_Models.md",
      "file_extension": ".md",
      "chunk_index": 27,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Selection Guidelines"
      ],
      "heading_text": "Model Selection Guidelines",
      "token_count": 179,
      "char_count": 714,
      "start_char": 17975,
      "end_char": 18689,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6797058823529412,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.747034",
      "document_id": "94c47cacd3ca",
      "document_name": "SparseEncoder_Models",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "source_filename": "SparseEncoder_Models.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\SparseEncoder_Models.md",
      "hierarchy_path": "Model Selection Guidelines",
      "chunk_hash": "dc08d0d482d0c4c6",
      "content_digest": "dc08d0d482d0c4c6",
      "chunk_length": 714,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cross",
          "encoder",
          "base",
          "model",
          "similarity",
          "roberta",
          "question",
          "multilingual",
          "docs",
          "pretrained",
          "models",
          "selection",
          "guidelines",
          "task",
          "type",
          "recommended",
          "key",
          "considerations",
          "information",
          "retrieval"
        ],
        "term_weights": [
          {
            "term": "cross",
            "tf": 6,
            "weight": 0.083333
          },
          {
            "term": "encoder",
            "tf": 5,
            "weight": 0.069444
          },
          {
            "term": "base",
            "tf": 3,
            "weight": 0.041667
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "similarity",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "roberta",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "question",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "multilingual",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "pretrained",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "selection",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "guidelines",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "task",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "type",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "recommended",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "considerations",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "information",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "retrieval",
            "tf": 1,
            "weight": 0.013889
          }
        ],
        "unique_terms": 53,
        "total_terms": 72
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Selection Guidelines",
        "base",
        "cross",
        "docs",
        "encoder",
        "model",
        "multilingual",
        "pretrained",
        "question",
        "roberta",
        "similarity"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6797058823529412,
      "overall": 0.7932352941176469
    }
  }
]
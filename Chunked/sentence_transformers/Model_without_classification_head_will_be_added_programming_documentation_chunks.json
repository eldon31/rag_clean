[
  {
    "text": "### Dataset Format Requirements\n\nCrossEncoder training datasets must match the chosen loss function requirements. The validation involves three steps:\n\n1. **Input Columns**: All columns except \"label\", \"labels\", \"score\", or \"scores\" are treated as inputs\n2. **Label Columns**: If the loss function requires labels, the dataset must have a column named \"label\", \"labels\", \"score\", or \"scores\"\n3. **Model Output Compatibility**: The number of model output labels must match the loss function requirements\n\n**Dataset Format Validation Flow**\n```mermaid\ngraph TD\n    InputDataset[Input Dataset]\n    \n    InputDataset --> CheckColumns{Check Column Names}\n    CheckColumns --> LabelCols[Extract Label Columns]\n    CheckColumns --> InputCols[Extract Input Columns]\n    \n    LabelCols --> ValidateLabels{Validate Labels}\n    InputCols --> ValidateInputs{Validate Input Count}\n    \n    ValidateLabels --> CheckModelOutput{Check Model Output}\n    ValidateInputs --> CheckModelOutput\n    \n    CheckModelOutput --> Compatible[Compatible Format]\n    CheckModelOutput --> Error[Format Error]\n    \n    Compatible --> Training[Begin Training]\n    Error --> FixDataset[Fix Dataset Format]\n    FixDataset --> CheckColumns\n```\n\nSources: [docs/cross_encoder/training_overview.md:171-189]()",
    "metadata": {
      "chunk_id": "40662e14640d-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Dataset Format Requirements"
      ],
      "heading_text": "Dataset Format Requirements",
      "token_count": 265,
      "char_count": 1269,
      "start_char": 119,
      "end_char": 1388,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.6922222222222222,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.469132",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Dataset Format Requirements",
      "chunk_hash": "7ac595d5c135d2d8",
      "content_digest": "7ac595d5c135d2d8",
      "chunk_length": 1269,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "dataset",
          "format",
          "columns",
          "labels",
          "training",
          "input",
          "label",
          "checkcolumns",
          "checkmodeloutput",
          "requirements",
          "must",
          "loss",
          "function",
          "model",
          "output",
          "compatible",
          "error",
          "match",
          "validation"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 6,
            "weight": 0.046875
          },
          {
            "term": "dataset",
            "tf": 5,
            "weight": 0.039062
          },
          {
            "term": "format",
            "tf": 5,
            "weight": 0.039062
          },
          {
            "term": "columns",
            "tf": 5,
            "weight": 0.039062
          },
          {
            "term": "labels",
            "tf": 5,
            "weight": 0.039062
          },
          {
            "term": "training",
            "tf": 4,
            "weight": 0.03125
          },
          {
            "term": "input",
            "tf": 4,
            "weight": 0.03125
          },
          {
            "term": "label",
            "tf": 4,
            "weight": 0.03125
          },
          {
            "term": "checkcolumns",
            "tf": 4,
            "weight": 0.03125
          },
          {
            "term": "checkmodeloutput",
            "tf": 4,
            "weight": 0.03125
          },
          {
            "term": "requirements",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "must",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "loss",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "function",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "output",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "compatible",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "error",
            "tf": 3,
            "weight": 0.023438
          },
          {
            "term": "match",
            "tf": 2,
            "weight": 0.015625
          },
          {
            "term": "validation",
            "tf": 2,
            "weight": 0.015625
          }
        ],
        "unique_terms": 62,
        "total_terms": 128
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Dataset Format Requirements",
        "checkcolumns",
        "checkmodeloutput",
        "columns",
        "dataset",
        "format",
        "input",
        "label",
        "labels",
        "the",
        "training"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.6922222222222222,
      "overall": 0.7640740740740739
    }
  },
  {
    "text": "### Hard Negatives Mining\n\nCrossEncoder performance often depends on the quality of negative examples. The `mine_hard_negatives` function helps generate challenging negatives:\n\n```python\nfrom sentence_transformers.util import mine_hard_negatives\n\nhard_train_dataset = mine_hard_negatives(\n    train_dataset,\n    embedding_model,\n    num_negatives=5,\n    range_min=10,\n    range_max=100,\n    max_score=0.8,\n    output_format=\"labeled-pair\"\n)\n```\n\nSources: [docs/cross_encoder/training_overview.md:204-242]()",
    "metadata": {
      "chunk_id": "40662e14640d-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Hard Negatives Mining"
      ],
      "heading_text": "Hard Negatives Mining",
      "token_count": 118,
      "char_count": 506,
      "start_char": 2071,
      "end_char": 2577,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7825,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.469945",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Hard Negatives Mining",
      "chunk_hash": "8ee7ee11a0a31b0b",
      "content_digest": "8ee7ee11a0a31b0b",
      "chunk_length": 506,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "negatives",
          "hard",
          "mine",
          "the",
          "train",
          "dataset",
          "range",
          "max",
          "mining",
          "crossencoder",
          "performance",
          "often",
          "depends",
          "quality",
          "negative",
          "examples",
          "function",
          "helps",
          "generate",
          "challenging"
        ],
        "term_weights": [
          {
            "term": "negatives",
            "tf": 6,
            "weight": 0.1
          },
          {
            "term": "hard",
            "tf": 5,
            "weight": 0.083333
          },
          {
            "term": "mine",
            "tf": 3,
            "weight": 0.05
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "train",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "dataset",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "range",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "max",
            "tf": 2,
            "weight": 0.033333
          },
          {
            "term": "mining",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "often",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "depends",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "quality",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "negative",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "examples",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "function",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "helps",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "generate",
            "tf": 1,
            "weight": 0.016667
          },
          {
            "term": "challenging",
            "tf": 1,
            "weight": 0.016667
          }
        ],
        "unique_terms": 44,
        "total_terms": 60
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Hard Negatives Mining",
        "crossencoder",
        "dataset",
        "hard",
        "max",
        "mine",
        "mining",
        "negatives",
        "range",
        "the",
        "train"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7825,
      "overall": 0.7275
    }
  },
  {
    "text": "## Training Process Integration\n\nCrossEncoder training integrates with the broader sentence-transformers training infrastructure while maintaining its specialized functionality.\n\n**CrossEncoder Training Infrastructure**\n```mermaid\ngraph TB\n    subgraph \"CrossEncoder Specific\"\n        CEModel[CrossEncoder]\n        CETrainer[CrossEncoderTrainer]\n        CEArgs[CrossEncoderTrainingArguments]\n        CELoss[CrossEncoder Losses]\n        CEEval[CrossEncoder Evaluators]\n    end\n    \n    subgraph \"Shared Infrastructure\"\n        HFTrainer[transformers.Trainer]\n        DataCollator[SentenceTransformerDataCollator]\n        ModelCard[Model Card Callbacks]\n        Optimizers[Optimizers & Schedulers]\n    end\n    \n    subgraph \"External Integration\"\n        HFHub[Hugging Face Hub]\n        WandB[Weights & Biases]\n        TensorBoard[TensorBoard]\n    end\n    \n    CETrainer --> HFTrainer\n    CEArgs --> HFTrainer\n    DataCollator --> CETrainer\n    ModelCard --> CETrainer\n    Optimizers --> CETrainer\n    \n    CEModel --> CELoss\n    CELoss --> CETrainer\n    CEEval --> CETrainer\n    \n    CETrainer --> HFHub\n    CETrainer --> WandB\n    CETrainer --> TensorBoard\n```\n\nSources: [sentence_transformers/trainer.py:59-128](), [docs/cross_encoder/training_overview.md:314-400]()",
    "metadata": {
      "chunk_id": "40662e14640d-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Training Process Integration"
      ],
      "heading_text": "Training Process Integration",
      "token_count": 299,
      "char_count": 1267,
      "start_char": 2579,
      "end_char": 3846,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.501578947368421,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.470691",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Training Process Integration",
      "chunk_hash": "699721a979a22e71",
      "content_digest": "699721a979a22e71",
      "chunk_length": 1267,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cetrainer",
          "crossencoder",
          "training",
          "transformers",
          "infrastructure",
          "subgraph",
          "celoss",
          "end",
          "hftrainer",
          "optimizers",
          "tensorboard",
          "integration",
          "sentence",
          "cemodel",
          "ceargs",
          "ceeval",
          "trainer",
          "datacollator",
          "modelcard",
          "hfhub"
        ],
        "term_weights": [
          {
            "term": "cetrainer",
            "tf": 10,
            "weight": 0.098039
          },
          {
            "term": "crossencoder",
            "tf": 6,
            "weight": 0.058824
          },
          {
            "term": "training",
            "tf": 5,
            "weight": 0.04902
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.029412
          },
          {
            "term": "infrastructure",
            "tf": 3,
            "weight": 0.029412
          },
          {
            "term": "subgraph",
            "tf": 3,
            "weight": 0.029412
          },
          {
            "term": "celoss",
            "tf": 3,
            "weight": 0.029412
          },
          {
            "term": "end",
            "tf": 3,
            "weight": 0.029412
          },
          {
            "term": "hftrainer",
            "tf": 3,
            "weight": 0.029412
          },
          {
            "term": "optimizers",
            "tf": 3,
            "weight": 0.029412
          },
          {
            "term": "tensorboard",
            "tf": 3,
            "weight": 0.029412
          },
          {
            "term": "integration",
            "tf": 2,
            "weight": 0.019608
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.019608
          },
          {
            "term": "cemodel",
            "tf": 2,
            "weight": 0.019608
          },
          {
            "term": "ceargs",
            "tf": 2,
            "weight": 0.019608
          },
          {
            "term": "ceeval",
            "tf": 2,
            "weight": 0.019608
          },
          {
            "term": "trainer",
            "tf": 2,
            "weight": 0.019608
          },
          {
            "term": "datacollator",
            "tf": 2,
            "weight": 0.019608
          },
          {
            "term": "modelcard",
            "tf": 2,
            "weight": 0.019608
          },
          {
            "term": "hfhub",
            "tf": 2,
            "weight": 0.019608
          }
        ],
        "unique_terms": 58,
        "total_terms": 102
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Training Process Integration",
        "celoss",
        "cetrainer",
        "crossencoder",
        "end",
        "hftrainer",
        "infrastructure",
        "optimizers",
        "subgraph",
        "training",
        "transformers"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.501578947368421,
      "overall": 0.7005263157894736
    }
  },
  {
    "text": "### Training Arguments  `CrossEncoderTrainingArguments` extends the standard transformers training arguments with CrossEncoder-specific parameters:  **Key Training Arguments:** - **Performance**: `learning_rate`, `per_device_train_batch_size`, `num_train_epochs`, `gradient_accumulation_steps` - **Optimization**: `fp16`, `bf16`, `optim`, `lr_scheduler_type`, `warmup_ratio` - **Evaluation**: `eval_strategy`, `eval_steps`, `load_best_model_at_end`, `metric_for_best_model` - **Tracking**: `report_to`, `run_name`, `logging_steps`, `push_to_hub`  Sources: [docs/cross_encoder/training_overview.md:320-344]()",
    "metadata": {
      "chunk_id": "40662e14640d-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Training Arguments"
      ],
      "heading_text": "Training Arguments",
      "token_count": 144,
      "char_count": 607,
      "start_char": 3848,
      "end_char": 4455,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7481395348837209,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.470973",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Training Arguments",
      "chunk_hash": "fc46a09635257338",
      "content_digest": "fc46a09635257338",
      "chunk_length": 607,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "training",
          "arguments",
          "steps",
          "train",
          "eval",
          "best",
          "model",
          "crossencodertrainingarguments",
          "extends",
          "the",
          "standard",
          "transformers",
          "with",
          "crossencoder",
          "specific",
          "parameters",
          "key",
          "performance",
          "learning",
          "rate"
        ],
        "term_weights": [
          {
            "term": "training",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "arguments",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "steps",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "train",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "eval",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "best",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "crossencodertrainingarguments",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "extends",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "standard",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "specific",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "parameters",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "learning",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "rate",
            "tf": 1,
            "weight": 0.014925
          }
        ],
        "unique_terms": 56,
        "total_terms": 67
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Training Arguments",
        "arguments",
        "best",
        "crossencodertrainingarguments",
        "eval",
        "extends",
        "model",
        "steps",
        "the",
        "train",
        "training"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7481395348837209,
      "overall": 0.8160465116279069
    }
  },
  {
    "text": "### Evaluation System  CrossEncoder evaluators assess model performance during training with task-specific metrics:  - `BinaryClassificationEvaluator`: For binary classification tasks - `CrossEncoderReranking`: For ranking performance evaluation   - `EmbeddingSimilarityEvaluator`: For similarity scoring tasks - `InformationRetrievalEvaluator`: For retrieval performance  Sources: [docs/cross_encoder/training_overview.md:365-400]()",
    "metadata": {
      "chunk_id": "40662e14640d-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Evaluation System"
      ],
      "heading_text": "Evaluation System",
      "token_count": 83,
      "char_count": 433,
      "start_char": 4457,
      "end_char": 4890,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5110526315789473,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.471275",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Evaluation System",
      "chunk_hash": "75db68d2860bcc16",
      "content_digest": "75db68d2860bcc16",
      "chunk_length": 433,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "for",
          "performance",
          "evaluation",
          "training",
          "tasks",
          "system",
          "crossencoder",
          "evaluators",
          "assess",
          "model",
          "during",
          "with",
          "task",
          "specific",
          "metrics",
          "binaryclassificationevaluator",
          "binary",
          "classification",
          "crossencoderreranking",
          "ranking"
        ],
        "term_weights": [
          {
            "term": "for",
            "tf": 4,
            "weight": 0.1
          },
          {
            "term": "performance",
            "tf": 3,
            "weight": 0.075
          },
          {
            "term": "evaluation",
            "tf": 2,
            "weight": 0.05
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.05
          },
          {
            "term": "tasks",
            "tf": 2,
            "weight": 0.05
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "evaluators",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "assess",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "during",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "task",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "specific",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "metrics",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "binaryclassificationevaluator",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "binary",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "classification",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "crossencoderreranking",
            "tf": 1,
            "weight": 0.025
          },
          {
            "term": "ranking",
            "tf": 1,
            "weight": 0.025
          }
        ],
        "unique_terms": 32,
        "total_terms": 40
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Evaluation System",
        "assess",
        "crossencoder",
        "evaluation",
        "evaluators",
        "for",
        "model",
        "performance",
        "system",
        "tasks",
        "training"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5110526315789473,
      "overall": 0.737017543859649
    }
  },
  {
    "text": "## Relationship to Other Training Systems\n\nCrossEncoder training shares infrastructure with other sentence-transformers training systems while maintaining its distinct characteristics.\n\n**Training System Relationships**\n```mermaid\ngraph TB\n    subgraph \"Base Training Infrastructure\"\n        BaseTrainer[SentenceTransformerTrainer]\n        BaseArgs[SentenceTransformerTrainingArguments]\n        BaseCollator[SentenceTransformerDataCollator]\n        BaseCard[SentenceTransformerModelCardCallback]\n    end\n    \n    subgraph \"CrossEncoder Training\"\n        CETrainer[CrossEncoderTrainer]\n        CEArgs[CrossEncoderTrainingArguments]\n        CEModel[CrossEncoder]\n        CELosses[CrossEncoder Losses]\n        CEEvals[CrossEncoder Evaluators]\n    end\n    \n    subgraph \"SparseEncoder Training\"\n        SETrainer[SparseEncoderTrainer]\n        SEArgs[SparseEncoderTrainingArguments]\n        SEModel[SparseEncoder]\n        SELosses[SparseEncoder Losses]\n    end\n    \n    subgraph \"SentenceTransformer Training\"  \n        STModel[SentenceTransformer]\n        STLosses[SentenceTransformer Losses]\n        STEvals[SentenceTransformer Evaluators]\n    end\n    \n    BaseTrainer --> CETrainer\n    BaseTrainer --> SETrainer\n    BaseArgs --> CEArgs\n    BaseArgs --> SEArgs\n    BaseCollator --> CETrainer\n    BaseCollator --> SETrainer\n    BaseCard --> CETrainer\n    \n    STModel --> BaseTrainer\n    CEModel --> CETrainer\n    SEModel --> SETrainer\n    \n    STLosses --> BaseTrainer\n    CELosses --> CETrainer\n    SELosses --> SETrainer\n    \n    STEvals --> BaseTrainer\n    CEEvals --> CETrainer\n```\n\nSources: [sentence_transformers/trainer.py:59-128](), [sentence_transformers/sparse_encoder/trainer.py:31-98]()\n\nThe CrossEncoder training system leverages the shared infrastructure while providing specialized components for joint text encoding and ranking tasks, making it suitable for reranking applications and text pair classification scenarios.",
    "metadata": {
      "chunk_id": "40662e14640d-0006",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Relationship to Other Training Systems"
      ],
      "heading_text": "Relationship to Other Training Systems",
      "token_count": 424,
      "char_count": 1933,
      "start_char": 4892,
      "end_char": 6825,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.9999999999999999,
      "retrieval_quality": 0.5160111888111888,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.472316",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Relationship to Other Training Systems",
      "chunk_hash": "d56b583605b16d83",
      "content_digest": "d56b583605b16d83",
      "chunk_length": 1933,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "training",
          "cetrainer",
          "crossencoder",
          "basetrainer",
          "setrainer",
          "subgraph",
          "end",
          "sentencetransformer",
          "infrastructure",
          "sentence",
          "transformers",
          "baseargs",
          "basecollator",
          "losses",
          "sparseencoder",
          "other",
          "systems",
          "while",
          "system",
          "basecard"
        ],
        "term_weights": [
          {
            "term": "training",
            "tf": 9,
            "weight": 0.061224
          },
          {
            "term": "cetrainer",
            "tf": 7,
            "weight": 0.047619
          },
          {
            "term": "crossencoder",
            "tf": 6,
            "weight": 0.040816
          },
          {
            "term": "basetrainer",
            "tf": 6,
            "weight": 0.040816
          },
          {
            "term": "setrainer",
            "tf": 5,
            "weight": 0.034014
          },
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.027211
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.027211
          },
          {
            "term": "sentencetransformer",
            "tf": 4,
            "weight": 0.027211
          },
          {
            "term": "infrastructure",
            "tf": 3,
            "weight": 0.020408
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.020408
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.020408
          },
          {
            "term": "baseargs",
            "tf": 3,
            "weight": 0.020408
          },
          {
            "term": "basecollator",
            "tf": 3,
            "weight": 0.020408
          },
          {
            "term": "losses",
            "tf": 3,
            "weight": 0.020408
          },
          {
            "term": "sparseencoder",
            "tf": 3,
            "weight": 0.020408
          },
          {
            "term": "other",
            "tf": 2,
            "weight": 0.013605
          },
          {
            "term": "systems",
            "tf": 2,
            "weight": 0.013605
          },
          {
            "term": "while",
            "tf": 2,
            "weight": 0.013605
          },
          {
            "term": "system",
            "tf": 2,
            "weight": 0.013605
          },
          {
            "term": "basecard",
            "tf": 2,
            "weight": 0.013605
          }
        ],
        "unique_terms": 75,
        "total_terms": 147
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Relationship to Other Training Systems",
        "basetrainer",
        "cetrainer",
        "crossencoder",
        "end",
        "infrastructure",
        "sentence",
        "sentencetransformer",
        "setrainer",
        "subgraph",
        "training"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.9999999999999999,
      "retrieval_quality": 0.5160111888111888,
      "overall": 0.7720037296037295
    }
  },
  {
    "text": "# Loss Functions for SentenceTransformer",
    "metadata": {
      "chunk_id": "40662e14640d-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Loss Functions for SentenceTransformer"
      ],
      "heading_text": "Loss Functions for SentenceTransformer",
      "token_count": 6,
      "char_count": 40,
      "start_char": 6827,
      "end_char": 6867,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.472402",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Loss Functions for SentenceTransformer",
      "chunk_hash": "85d4901ab926634f",
      "content_digest": "85d4901ab926634f",
      "chunk_length": 40,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "loss",
          "functions",
          "for",
          "sentencetransformer"
        ],
        "term_weights": [
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.25
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.25
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.25
          },
          {
            "term": "sentencetransformer",
            "tf": 1,
            "weight": 0.25
          }
        ],
        "unique_terms": 4,
        "total_terms": 4
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Loss Functions for SentenceTransformer",
        "for",
        "functions",
        "loss",
        "sentencetransformer"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "## Introduction\n\nThis page documents the loss functions available for training SentenceTransformer models. Loss functions are a critical component that defines the training objective and directly influences the quality and properties of the resulting sentence embeddings. \n\nFor information about how to use these loss functions in training, see [SentenceTransformer Training](#3.1) and [CrossEncoder Training](#3.2).\n\nThe SentenceTransformer library offers a diverse set of loss functions, each designed for specific use cases and data formats:\n\n```mermaid\ngraph TD\n    subgraph \"Overview of Loss Functions\"\n        ST[SentenceTransformer]\n        Loss[Loss Functions]\n        Training[Training Process]\n        \n        ST --> Loss\n        Loss --> Training\n        Training --> ST\n    end\n```\n\nSources: \n- [sentence_transformers/losses/__init__.py:1-67]()",
    "metadata": {
      "chunk_id": "40662e14640d-0008",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Introduction"
      ],
      "heading_text": "Introduction",
      "token_count": 172,
      "char_count": 857,
      "start_char": 6872,
      "end_char": 7729,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7051515151515152,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.472799",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Introduction",
      "chunk_hash": "256f0d08ae954ef6",
      "content_digest": "256f0d08ae954ef6",
      "chunk_length": 857,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "loss",
          "training",
          "functions",
          "the",
          "sentencetransformer",
          "and",
          "for",
          "sentence",
          "use",
          "introduction",
          "this",
          "page",
          "documents",
          "available",
          "models",
          "are",
          "critical",
          "component",
          "that",
          "defines"
        ],
        "term_weights": [
          {
            "term": "loss",
            "tf": 9,
            "weight": 0.102273
          },
          {
            "term": "training",
            "tf": 9,
            "weight": 0.102273
          },
          {
            "term": "functions",
            "tf": 6,
            "weight": 0.068182
          },
          {
            "term": "the",
            "tf": 5,
            "weight": 0.056818
          },
          {
            "term": "sentencetransformer",
            "tf": 4,
            "weight": 0.045455
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.045455
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "use",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "introduction",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "page",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "available",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "critical",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "component",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "defines",
            "tf": 1,
            "weight": 0.011364
          }
        ],
        "unique_terms": 53,
        "total_terms": 88
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Introduction",
        "and",
        "for",
        "functions",
        "introduction",
        "loss",
        "sentence",
        "sentencetransformer",
        "the",
        "training",
        "use"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7051515151515152,
      "overall": 0.7683838383838383
    }
  },
  {
    "text": "## Loss Function Taxonomy\n\nSentenceTransformer provides several categories of loss functions, each with different approaches to learning sentence embeddings:\n\nLoss Function Taxonomy\n\n```mermaid\ngraph TD\n    subgraph \"Complete Loss Function Taxonomy\"\n        LF[\"Loss Functions\"]\n        \n        Ranking[\"Ranking-based Losses\"]\n        Contrastive[\"Contrastive Losses\"]\n        Triplet[\"Triplet Losses\"]\n        MSE[\"MSE-based Losses\"]\n        Special[\"Specialized Losses\"]\n        \n        LF --> Ranking\n        LF --> Contrastive\n        LF --> Triplet\n        LF --> MSE\n        LF --> Special\n        \n        Ranking --> MNRL[\"MultipleNegativesRankingLoss\"]\n        Ranking --> CMNRL[\"CachedMultipleNegativesRankingLoss\"]\n        Ranking --> MNRSL[\"MultipleNegativesSymmetricRankingLoss\"]\n        Ranking --> CMNRSL[\"CachedMultipleNegativesSymmetricRankingLoss\"]\n        Ranking --> GISTL[\"GISTEmbedLoss\"]\n        Ranking --> CGISTL[\"CachedGISTEmbedLoss\"]\n        Ranking --> MBML[\"MegaBatchMarginLoss\"]\n        \n        Contrastive --> CL[\"ContrastiveLoss\"]\n        Contrastive --> OCL[\"OnlineContrastiveLoss\"]\n        Contrastive --> CTL[\"ContrastiveTensionLoss\"]\n        Contrastive --> CTLBN[\"ContrastiveTensionLossInBatchNegatives\"]\n        Contrastive --> COSENT[\"CoSENTLoss\"]\n        Contrastive --> AnglE[\"AnglELoss\"]\n        \n        Triplet --> TL[\"TripletLoss\"]\n        Triplet --> BHTL[\"BatchHardTripletLoss\"]\n        Triplet --> BHSM[\"BatchHardSoftMarginTripletLoss\"]\n        Triplet --> BSHT[\"BatchSemiHardTripletLoss\"]\n        Triplet --> BATL[\"BatchAllTripletLoss\"]\n        \n        MSE --> MSEL[\"MSELoss\"]\n        MSE --> MMSE[\"MarginMSELoss\"]\n        MSE --> CSL[\"CosineSimilarityLoss\"]\n        MSE --> DKL[\"DistillKLDivLoss\"]\n        \n        Special --> ML[\"MatryoshkaLoss\"]\n        Special --> M2D[\"Matryoshka2dLoss\"]\n        Special --> ALL[\"AdaptiveLayerLoss\"]\n        Special --> DAEL[\"DenoisingAutoEncoderLoss\"]\n        Special --> SL[\"SoftmaxLoss\"]\n    end\n```\n\nSources:\n- [sentence_transformers/losses/__init__.py:1-67]()",
    "metadata": {
      "chunk_id": "40662e14640d-0009",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Loss Function Taxonomy"
      ],
      "heading_text": "Loss Function Taxonomy",
      "token_count": 501,
      "char_count": 2054,
      "start_char": 7731,
      "end_char": 9785,
      "semantic_score": 0.8,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.6489510489510489,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.473983",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Loss Function Taxonomy",
      "chunk_hash": "8602c889910015b7",
      "content_digest": "8602c889910015b7",
      "chunk_length": 2054,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "ranking",
          "contrastive",
          "triplet",
          "mse",
          "special",
          "losses",
          "loss",
          "function",
          "taxonomy",
          "functions",
          "sentence",
          "based",
          "sentencetransformer",
          "provides",
          "several",
          "categories",
          "each",
          "with",
          "different",
          "approaches"
        ],
        "term_weights": [
          {
            "term": "ranking",
            "tf": 10,
            "weight": 0.075188
          },
          {
            "term": "contrastive",
            "tf": 9,
            "weight": 0.067669
          },
          {
            "term": "triplet",
            "tf": 8,
            "weight": 0.06015
          },
          {
            "term": "mse",
            "tf": 7,
            "weight": 0.052632
          },
          {
            "term": "special",
            "tf": 7,
            "weight": 0.052632
          },
          {
            "term": "losses",
            "tf": 6,
            "weight": 0.045113
          },
          {
            "term": "loss",
            "tf": 5,
            "weight": 0.037594
          },
          {
            "term": "function",
            "tf": 3,
            "weight": 0.022556
          },
          {
            "term": "taxonomy",
            "tf": 3,
            "weight": 0.022556
          },
          {
            "term": "functions",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "based",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "sentencetransformer",
            "tf": 1,
            "weight": 0.007519
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.007519
          },
          {
            "term": "several",
            "tf": 1,
            "weight": 0.007519
          },
          {
            "term": "categories",
            "tf": 1,
            "weight": 0.007519
          },
          {
            "term": "each",
            "tf": 1,
            "weight": 0.007519
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.007519
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.007519
          },
          {
            "term": "approaches",
            "tf": 1,
            "weight": 0.007519
          }
        ],
        "unique_terms": 81,
        "total_terms": 133
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Loss Function Taxonomy",
        "contrastive",
        "function",
        "functions",
        "loss",
        "losses",
        "mse",
        "ranking",
        "special",
        "taxonomy",
        "triplet"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.6489510489510489,
      "overall": 0.7496503496503496
    }
  },
  {
    "text": "## Ranking-Based Loss Functions\n\nRanking-based loss functions are commonly used for training retrieval models. They focus on learning representations where relevant pairs have higher similarity than irrelevant pairs.",
    "metadata": {
      "chunk_id": "40662e14640d-0010",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Ranking-Based Loss Functions"
      ],
      "heading_text": "Ranking-Based Loss Functions",
      "token_count": 34,
      "char_count": 216,
      "start_char": 9787,
      "end_char": 10003,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5578571428571428,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.474116",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Ranking-Based Loss Functions",
      "chunk_hash": "51702c8a2c43ee77",
      "content_digest": "51702c8a2c43ee77",
      "chunk_length": 216,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "ranking",
          "based",
          "loss",
          "functions",
          "pairs",
          "are",
          "commonly",
          "used",
          "for",
          "training",
          "retrieval",
          "models",
          "they",
          "focus",
          "learning",
          "representations",
          "where",
          "relevant",
          "have",
          "higher"
        ],
        "term_weights": [
          {
            "term": "ranking",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "based",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "loss",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "functions",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "pairs",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "commonly",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "used",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "training",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "retrieval",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "they",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "focus",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "learning",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "representations",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "relevant",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "have",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "higher",
            "tf": 1,
            "weight": 0.035714
          }
        ],
        "unique_terms": 23,
        "total_terms": 28
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Ranking-Based Loss Functions",
        "are",
        "based",
        "commonly",
        "for",
        "functions",
        "loss",
        "pairs",
        "ranking",
        "training",
        "used"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5578571428571428,
      "overall": 0.7192857142857143
    }
  },
  {
    "text": "### MultipleNegativesRankingLoss\n\nThis is one of the most widely used loss functions for training sentence embeddings. It treats other samples in the batch as negatives, creating an effective training signal that improves with larger batch sizes.\n\n```mermaid\nflowchart TD\n    subgraph \"MultipleNegativesRankingLoss Flow\"\n        A[\"Anchor Embeddings\"] \n        P[\"Positive Embeddings\"]\n        S[\"Similarity Matrix\"]\n        L[\"Loss Computation\"]\n        \n        A --> S\n        P --> S\n        S --> L\n        \n        L -->|\"Cross Entropy\"| RL[\"Ranking Loss\"]\n    end\n```\n\n**Key Properties**:\n- Also known as InfoNCE loss, SimCSE loss, or in-batch negatives loss\n- Performance generally improves with increasing batch size\n- Requires (anchor, positive) pairs or (anchor, positive, negative) triplets\n- Each anchor should be most similar to its corresponding positive from all candidates in the batch\n\nSources:\n- [sentence_transformers/losses/MultipleNegativesRankingLoss.py:13-132]()",
    "metadata": {
      "chunk_id": "40662e14640d-0011",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "MultipleNegativesRankingLoss"
      ],
      "heading_text": "MultipleNegativesRankingLoss",
      "token_count": 224,
      "char_count": 986,
      "start_char": 10005,
      "end_char": 10991,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5264406779661017,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.474543",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "MultipleNegativesRankingLoss",
      "chunk_hash": "c78532d7c92cc459",
      "content_digest": "c78532d7c92cc459",
      "chunk_length": 986,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "loss",
          "batch",
          "anchor",
          "positive",
          "multiplenegativesrankingloss",
          "the",
          "embeddings",
          "most",
          "training",
          "sentence",
          "negatives",
          "improves",
          "with",
          "this",
          "one",
          "widely",
          "used",
          "functions",
          "for",
          "treats"
        ],
        "term_weights": [
          {
            "term": "loss",
            "tf": 6,
            "weight": 0.065217
          },
          {
            "term": "batch",
            "tf": 5,
            "weight": 0.054348
          },
          {
            "term": "anchor",
            "tf": 4,
            "weight": 0.043478
          },
          {
            "term": "positive",
            "tf": 4,
            "weight": 0.043478
          },
          {
            "term": "multiplenegativesrankingloss",
            "tf": 3,
            "weight": 0.032609
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.032609
          },
          {
            "term": "embeddings",
            "tf": 3,
            "weight": 0.032609
          },
          {
            "term": "most",
            "tf": 2,
            "weight": 0.021739
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.021739
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.021739
          },
          {
            "term": "negatives",
            "tf": 2,
            "weight": 0.021739
          },
          {
            "term": "improves",
            "tf": 2,
            "weight": 0.021739
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.021739
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.01087
          },
          {
            "term": "one",
            "tf": 1,
            "weight": 0.01087
          },
          {
            "term": "widely",
            "tf": 1,
            "weight": 0.01087
          },
          {
            "term": "used",
            "tf": 1,
            "weight": 0.01087
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.01087
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.01087
          },
          {
            "term": "treats",
            "tf": 1,
            "weight": 0.01087
          }
        ],
        "unique_terms": 65,
        "total_terms": 92
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "MultipleNegativesRankingLoss",
        "anchor",
        "batch",
        "embeddings",
        "loss",
        "most",
        "multiplenegativesrankingloss",
        "positive",
        "sentence",
        "the",
        "training"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5264406779661017,
      "overall": 0.7088135593220338
    }
  },
  {
    "text": "### GISTEmbedLoss  An improved ranking loss that uses a guide model to guide the in-batch negative sample selection, providing a stronger training signal. **Key Properties**: - Uses a teacher/guide model to identify and suppress false negatives - Supports different margin strategies for negative filtering - Better training signal than MultipleNegativesRankingLoss  Sources: - [sentence_transformers/losses/GISTEmbedLoss.py:13-221]() - [sentence_transformers/losses/CachedGISTEmbedLoss.py:63-382]()",
    "metadata": {
      "chunk_id": "40662e14640d-0013",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "GISTEmbedLoss"
      ],
      "heading_text": "GISTEmbedLoss",
      "token_count": 108,
      "char_count": 499,
      "start_char": 11881,
      "end_char": 12380,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7245454545454545,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.475140",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "GISTEmbedLoss",
      "chunk_hash": "47ccb112169f0bcc",
      "content_digest": "47ccb112169f0bcc",
      "chunk_length": 499,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "guide",
          "gistembedloss",
          "uses",
          "model",
          "negative",
          "training",
          "signal",
          "sentence",
          "transformers",
          "losses",
          "improved",
          "ranking",
          "loss",
          "that",
          "the",
          "batch",
          "sample",
          "selection",
          "providing",
          "stronger"
        ],
        "term_weights": [
          {
            "term": "guide",
            "tf": 3,
            "weight": 0.057692
          },
          {
            "term": "gistembedloss",
            "tf": 2,
            "weight": 0.038462
          },
          {
            "term": "uses",
            "tf": 2,
            "weight": 0.038462
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.038462
          },
          {
            "term": "negative",
            "tf": 2,
            "weight": 0.038462
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.038462
          },
          {
            "term": "signal",
            "tf": 2,
            "weight": 0.038462
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.038462
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.038462
          },
          {
            "term": "losses",
            "tf": 2,
            "weight": 0.038462
          },
          {
            "term": "improved",
            "tf": 1,
            "weight": 0.019231
          },
          {
            "term": "ranking",
            "tf": 1,
            "weight": 0.019231
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.019231
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.019231
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.019231
          },
          {
            "term": "batch",
            "tf": 1,
            "weight": 0.019231
          },
          {
            "term": "sample",
            "tf": 1,
            "weight": 0.019231
          },
          {
            "term": "selection",
            "tf": 1,
            "weight": 0.019231
          },
          {
            "term": "providing",
            "tf": 1,
            "weight": 0.019231
          },
          {
            "term": "stronger",
            "tf": 1,
            "weight": 0.019231
          }
        ],
        "unique_terms": 41,
        "total_terms": 52
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "GISTEmbedLoss",
        "gistembedloss",
        "guide",
        "losses",
        "model",
        "negative",
        "sentence",
        "signal",
        "training",
        "transformers",
        "uses"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7245454545454545,
      "overall": 0.8081818181818181
    }
  },
  {
    "text": "## Contrastive Loss Functions\n\nContrastive losses optimize embeddings so that similar items are closer together and dissimilar items are farther apart in the embedding space.",
    "metadata": {
      "chunk_id": "40662e14640d-0014",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Contrastive Loss Functions"
      ],
      "heading_text": "Contrastive Loss Functions",
      "token_count": 31,
      "char_count": 174,
      "start_char": 12383,
      "end_char": 12557,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.554,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.475335",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Contrastive Loss Functions",
      "chunk_hash": "5154d7599c14e1fa",
      "content_digest": "5154d7599c14e1fa",
      "chunk_length": 174,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "contrastive",
          "items",
          "are",
          "loss",
          "functions",
          "losses",
          "optimize",
          "embeddings",
          "that",
          "similar",
          "closer",
          "together",
          "and",
          "dissimilar",
          "farther",
          "apart",
          "the",
          "embedding",
          "space"
        ],
        "term_weights": [
          {
            "term": "contrastive",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "items",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "losses",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "optimize",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "similar",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "closer",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "together",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "dissimilar",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "farther",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "apart",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "space",
            "tf": 1,
            "weight": 0.045455
          }
        ],
        "unique_terms": 19,
        "total_terms": 22
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Contrastive Loss Functions",
        "are",
        "contrastive",
        "embeddings",
        "functions",
        "items",
        "loss",
        "losses",
        "optimize",
        "similar",
        "that"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.554,
      "overall": 0.7513333333333333
    }
  },
  {
    "text": "### ContrastiveLoss\n\nThe standard contrastive loss function that minimizes distance between positive pairs and maximizes distance between negative pairs.\n\n**Key Properties**:\n- Expects pairs of texts with binary labels (1 for similar, 0 for dissimilar)\n- Uses a specified distance metric (cosine, euclidean, manhattan)\n- Includes a margin hyperparameter\n\n```mermaid\nflowchart TD\n    subgraph \"ContrastiveLoss Flow\"\n        Input1[\"Text A\"] --> Embedding1[\"Embedding A\"]\n        Input2[\"Text B\"] --> Embedding2[\"Embedding B\"]\n        \n        Embedding1 --> Distance[\"Distance Calculation\"]\n        Embedding2 --> Distance\n        \n        Distance --> Contrastive[\"Contrastive Loss\"]\n        Label[\"Label (0 or 1)\"] --> Contrastive\n    end\n```\n\nSources:\n- [sentence_transformers/losses/ContrastiveLoss.py:13-120]()",
    "metadata": {
      "chunk_id": "40662e14640d-0015",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ContrastiveLoss"
      ],
      "heading_text": "ContrastiveLoss",
      "token_count": 194,
      "char_count": 814,
      "start_char": 12559,
      "end_char": 13373,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5244827586206896,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.475732",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "ContrastiveLoss",
      "chunk_hash": "469da29c06ff010f",
      "content_digest": "469da29c06ff010f",
      "chunk_length": 814,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "distance",
          "contrastive",
          "contrastiveloss",
          "pairs",
          "loss",
          "between",
          "for",
          "text",
          "embedding1",
          "embedding",
          "embedding2",
          "label",
          "the",
          "standard",
          "function",
          "that",
          "minimizes",
          "positive",
          "and",
          "maximizes"
        ],
        "term_weights": [
          {
            "term": "distance",
            "tf": 7,
            "weight": 0.09589
          },
          {
            "term": "contrastive",
            "tf": 4,
            "weight": 0.054795
          },
          {
            "term": "contrastiveloss",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "pairs",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "loss",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "between",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "embedding1",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "embedding2",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "label",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "standard",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "function",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "minimizes",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "positive",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "maximizes",
            "tf": 1,
            "weight": 0.013699
          }
        ],
        "unique_terms": 52,
        "total_terms": 73
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ContrastiveLoss",
        "between",
        "contrastive",
        "contrastiveloss",
        "distance",
        "embedding",
        "embedding1",
        "for",
        "loss",
        "pairs",
        "text"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5244827586206896,
      "overall": 0.7081609195402297
    }
  },
  {
    "text": "### CoSENTLoss  An improved contrastive loss that provides a stronger training signal than standard CosineSimilarityLoss. **Key Properties**: - Uses a logsum formulation comparing multiple pairs in the batch - Faster convergence and better performance than CosineSimilarityLoss - Requires sentence pairs with similarity scores  Sources: - [sentence_transformers/losses/CoSENTLoss.py:13-115]()",
    "metadata": {
      "chunk_id": "40662e14640d-0016",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "CoSENTLoss"
      ],
      "heading_text": "CoSENTLoss",
      "token_count": 80,
      "char_count": 392,
      "start_char": 13375,
      "end_char": 13767,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5508695652173913,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.475903",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "CoSENTLoss",
      "chunk_hash": "4de75796607c7a9a",
      "content_digest": "4de75796607c7a9a",
      "chunk_length": 392,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cosentloss",
          "than",
          "cosinesimilarityloss",
          "pairs",
          "sentence",
          "improved",
          "contrastive",
          "loss",
          "that",
          "provides",
          "stronger",
          "training",
          "signal",
          "standard",
          "key",
          "properties",
          "uses",
          "logsum",
          "formulation",
          "comparing"
        ],
        "term_weights": [
          {
            "term": "cosentloss",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "than",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "cosinesimilarityloss",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "pairs",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "improved",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "contrastive",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "stronger",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "training",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "signal",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "standard",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "properties",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "uses",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "logsum",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "formulation",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "comparing",
            "tf": 1,
            "weight": 0.02439
          }
        ],
        "unique_terms": 36,
        "total_terms": 41
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "CoSENTLoss",
        "contrastive",
        "cosentloss",
        "cosinesimilarityloss",
        "improved",
        "loss",
        "pairs",
        "provides",
        "sentence",
        "than",
        "that"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5508695652173913,
      "overall": 0.7502898550724636
    }
  },
  {
    "text": "### ContrastiveTensionLoss  Designed for unsupervised learning, this loss creates positive and negative pairs automatically. **Key Properties**: - Works without explicit labels - Creates a copy of the encoder model to produce embeddings for the first sentence in each pair - Requires using `ContrastiveTensionDataLoader` for proper pair generation  Sources: - [sentence_transformers/losses/ContrastiveTensionLoss.py:17-204]()",
    "metadata": {
      "chunk_id": "40662e14640d-0017",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ContrastiveTensionLoss"
      ],
      "heading_text": "ContrastiveTensionLoss",
      "token_count": 90,
      "char_count": 425,
      "start_char": 13770,
      "end_char": 14195,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.542,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.476138",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "ContrastiveTensionLoss",
      "chunk_hash": "e6da9ca3a58889eb",
      "content_digest": "e6da9ca3a58889eb",
      "chunk_length": 425,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "for",
          "contrastivetensionloss",
          "creates",
          "the",
          "sentence",
          "pair",
          "designed",
          "unsupervised",
          "learning",
          "this",
          "loss",
          "positive",
          "and",
          "negative",
          "pairs",
          "automatically",
          "key",
          "properties",
          "works",
          "without"
        ],
        "term_weights": [
          {
            "term": "for",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "contrastivetensionloss",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "creates",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "pair",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "designed",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "unsupervised",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "learning",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "positive",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "negative",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "pairs",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "automatically",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "properties",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "works",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "without",
            "tf": 1,
            "weight": 0.022222
          }
        ],
        "unique_terms": 38,
        "total_terms": 45
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ContrastiveTensionLoss",
        "contrastivetensionloss",
        "creates",
        "designed",
        "for",
        "learning",
        "pair",
        "sentence",
        "the",
        "this",
        "unsupervised"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.542,
      "overall": 0.7473333333333333
    }
  },
  {
    "text": "## Triplet Loss Functions\n\nTriplet losses use triplets of (anchor, positive, negative) to learn embeddings where the anchor is closer to the positive than to the negative by a certain margin.",
    "metadata": {
      "chunk_id": "40662e14640d-0018",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Triplet Loss Functions"
      ],
      "heading_text": "Triplet Loss Functions",
      "token_count": 40,
      "char_count": 191,
      "start_char": 14198,
      "end_char": 14389,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5416129032258065,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.476325",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Triplet Loss Functions",
      "chunk_hash": "5737dc9c72c3776d",
      "content_digest": "5737dc9c72c3776d",
      "chunk_length": 191,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "triplet",
          "anchor",
          "positive",
          "negative",
          "loss",
          "functions",
          "losses",
          "use",
          "triplets",
          "learn",
          "embeddings",
          "where",
          "closer",
          "than",
          "certain",
          "margin"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 3,
            "weight": 0.130435
          },
          {
            "term": "triplet",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "anchor",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "positive",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "negative",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "losses",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "triplets",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "learn",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "closer",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "than",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "certain",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "margin",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 17,
        "total_terms": 23
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Triplet Loss Functions",
        "anchor",
        "functions",
        "loss",
        "losses",
        "negative",
        "positive",
        "the",
        "triplet",
        "triplets",
        "use"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5416129032258065,
      "overall": 0.7472043010752688
    }
  },
  {
    "text": "### TripletLoss\n\nThe basic triplet loss function minimizes the distance between anchor and positive while maximizing the distance between anchor and negative.\n\n**Key Properties**:\n- Requires (anchor, positive, negative) triplets\n- Uses a specified distance metric and margin\n- Optimizes: max(||anchor - positive|| - ||anchor - negative|| + margin, 0)\n\n```mermaid\nflowchart TD\n    subgraph \"TripletLoss Structure\"\n        A[\"Anchor\"] --> E_A[\"Anchor Embedding\"]\n        P[\"Positive\"] --> E_P[\"Positive Embedding\"]\n        N[\"Negative\"] --> E_N[\"Negative Embedding\"]\n        \n        E_A --> D_AP[\"Distance(Anchor, Positive)\"]\n        E_P --> D_AP\n        \n        E_A --> D_AN[\"Distance(Anchor, Negative)\"]\n        E_N --> D_AN\n        \n        D_AP --> TL[\"Triplet Loss\"]\n        D_AN --> TL\n        \n        M[\"Margin\"] --> TL\n    end\n```\n\nSources:\n- [sentence_transformers/losses/TripletLoss.py:13-112]()",
    "metadata": {
      "chunk_id": "40662e14640d-0019",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "TripletLoss"
      ],
      "heading_text": "TripletLoss",
      "token_count": 223,
      "char_count": 906,
      "start_char": 14391,
      "end_char": 15297,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5003092783505154,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.476761",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "TripletLoss",
      "chunk_hash": "1ec4754b25b55209",
      "content_digest": "1ec4754b25b55209",
      "chunk_length": 906,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "anchor",
          "positive",
          "negative",
          "distance",
          "tripletloss",
          "the",
          "and",
          "margin",
          "embedding",
          "triplet",
          "loss",
          "between",
          "basic",
          "function",
          "minimizes",
          "while",
          "maximizing",
          "key",
          "properties",
          "requires"
        ],
        "term_weights": [
          {
            "term": "anchor",
            "tf": 9,
            "weight": 0.126761
          },
          {
            "term": "positive",
            "tf": 6,
            "weight": 0.084507
          },
          {
            "term": "negative",
            "tf": 6,
            "weight": 0.084507
          },
          {
            "term": "distance",
            "tf": 5,
            "weight": 0.070423
          },
          {
            "term": "tripletloss",
            "tf": 3,
            "weight": 0.042254
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.042254
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.042254
          },
          {
            "term": "margin",
            "tf": 3,
            "weight": 0.042254
          },
          {
            "term": "embedding",
            "tf": 3,
            "weight": 0.042254
          },
          {
            "term": "triplet",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "loss",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "between",
            "tf": 2,
            "weight": 0.028169
          },
          {
            "term": "basic",
            "tf": 1,
            "weight": 0.014085
          },
          {
            "term": "function",
            "tf": 1,
            "weight": 0.014085
          },
          {
            "term": "minimizes",
            "tf": 1,
            "weight": 0.014085
          },
          {
            "term": "while",
            "tf": 1,
            "weight": 0.014085
          },
          {
            "term": "maximizing",
            "tf": 1,
            "weight": 0.014085
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.014085
          },
          {
            "term": "properties",
            "tf": 1,
            "weight": 0.014085
          },
          {
            "term": "requires",
            "tf": 1,
            "weight": 0.014085
          }
        ],
        "unique_terms": 36,
        "total_terms": 71
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "TripletLoss",
        "anchor",
        "and",
        "distance",
        "embedding",
        "margin",
        "negative",
        "positive",
        "the",
        "triplet",
        "tripletloss"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5003092783505154,
      "overall": 0.7001030927835051
    }
  },
  {
    "text": "### Batch Triplet Losses\n\nThese are more advanced variants of triplet loss that use different strategies for mining triplets within a batch:\n\n1. **BatchHardTripletLoss**: Selects hardest positive and negative samples for each anchor.\n2. **BatchSemiHardTripletLoss**: Focuses on semi-hard triplets (not too easy, not too hard).\n3. **BatchAllTripletLoss**: Uses all valid triplets in the batch.\n4. **BatchHardSoftMarginTripletLoss**: Similar to BatchHardTripletLoss but with a soft margin.\n\n**Key Properties**:\n- Require single sentences with class labels\n- Create triplets on-the-fly from the batch\n- Recommend using batches with multiple examples per class\n- Different mining strategies for different training dynamics\n\nSources:\n- [sentence_transformers/losses/BatchHardTripletLoss.py:12-267]()\n- [sentence_transformers/losses/BatchSemiHardTripletLoss.py:13-188]()\n- [sentence_transformers/losses/BatchAllTripletLoss.py:13-151]()\n- [sentence_transformers/losses/BatchHardSoftMarginTripletLoss.py:13-153]()",
    "metadata": {
      "chunk_id": "40662e14640d-0020",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Batch Triplet Losses"
      ],
      "heading_text": "Batch Triplet Losses",
      "token_count": 245,
      "char_count": 1005,
      "start_char": 15299,
      "end_char": 16304,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5220754716981132,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.477188",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Batch Triplet Losses",
      "chunk_hash": "890b3d421e83f685",
      "content_digest": "890b3d421e83f685",
      "chunk_length": 1005,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "losses",
          "batch",
          "triplets",
          "sentence",
          "transformers",
          "different",
          "for",
          "batchhardtripletloss",
          "the",
          "with",
          "triplet",
          "strategies",
          "mining",
          "batchsemihardtripletloss",
          "hard",
          "not",
          "too",
          "batchalltripletloss",
          "batchhardsoftmargintripletloss",
          "class"
        ],
        "term_weights": [
          {
            "term": "losses",
            "tf": 5,
            "weight": 0.047619
          },
          {
            "term": "batch",
            "tf": 4,
            "weight": 0.038095
          },
          {
            "term": "triplets",
            "tf": 4,
            "weight": 0.038095
          },
          {
            "term": "sentence",
            "tf": 4,
            "weight": 0.038095
          },
          {
            "term": "transformers",
            "tf": 4,
            "weight": 0.038095
          },
          {
            "term": "different",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "batchhardtripletloss",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "triplet",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "strategies",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "mining",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "batchsemihardtripletloss",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "hard",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "not",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "too",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "batchalltripletloss",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "batchhardsoftmargintripletloss",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "class",
            "tf": 2,
            "weight": 0.019048
          }
        ],
        "unique_terms": 69,
        "total_terms": 105
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Batch Triplet Losses",
        "batch",
        "batchhardtripletloss",
        "different",
        "for",
        "losses",
        "sentence",
        "the",
        "transformers",
        "triplets",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5220754716981132,
      "overall": 0.6740251572327044
    }
  },
  {
    "text": "## MSE-Based Loss Functions\n\nThese loss functions use Mean Squared Error (MSE) to optimize embeddings against a target.",
    "metadata": {
      "chunk_id": "40662e14640d-0021",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "MSE-Based Loss Functions"
      ],
      "heading_text": "MSE-Based Loss Functions",
      "token_count": 25,
      "char_count": 119,
      "start_char": 16306,
      "end_char": 16425,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.477293",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "MSE-Based Loss Functions",
      "chunk_hash": "add57076a64e6b2b",
      "content_digest": "add57076a64e6b2b",
      "chunk_length": 119,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "mse",
          "loss",
          "functions",
          "based",
          "these",
          "use",
          "mean",
          "squared",
          "error",
          "optimize",
          "embeddings",
          "against",
          "target"
        ],
        "term_weights": [
          {
            "term": "mse",
            "tf": 2,
            "weight": 0.125
          },
          {
            "term": "loss",
            "tf": 2,
            "weight": 0.125
          },
          {
            "term": "functions",
            "tf": 2,
            "weight": 0.125
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "these",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "mean",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "squared",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "error",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "optimize",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "against",
            "tf": 1,
            "weight": 0.0625
          },
          {
            "term": "target",
            "tf": 1,
            "weight": 0.0625
          }
        ],
        "unique_terms": 13,
        "total_terms": 16
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "MSE-Based Loss Functions",
        "based",
        "error",
        "functions",
        "loss",
        "mean",
        "mse",
        "optimize",
        "squared",
        "these",
        "use"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5566666666666666,
      "overall": 0.7522222222222222
    }
  },
  {
    "text": "### MSELoss\n\nMSE Loss computes the squared error between computed sentence embeddings and target embeddings.\n\n**Key Properties**:\n- Often used for knowledge distillation and multilingual model extension\n- Requires sentences with corresponding target embeddings\n- Simple and effective for teacher-student learning\n\n```mermaid\nflowchart TD\n    subgraph \"MSELoss Flow\"\n        Input[\"Input Text\"] --> StudentModel[\"Student Model\"]\n        StudentModel --> Embedding[\"Student Embedding\"]\n        \n        TargetEmb[\"Target Embedding\"] --> MSE[\"MSE Loss\"]\n        Embedding --> MSE\n    end\n```\n\nSources:\n- [sentence_transformers/losses/MSELoss.py:11-98]()",
    "metadata": {
      "chunk_id": "40662e14640d-0022",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "MSELoss"
      ],
      "heading_text": "MSELoss",
      "token_count": 143,
      "char_count": 650,
      "start_char": 16427,
      "end_char": 17077,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5334782608695652,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.477594",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "MSELoss",
      "chunk_hash": "a59be9f6214965fb",
      "content_digest": "a59be9f6214965fb",
      "chunk_length": 650,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "mse",
          "embedding",
          "mseloss",
          "embeddings",
          "and",
          "target",
          "student",
          "loss",
          "sentence",
          "for",
          "model",
          "input",
          "studentmodel",
          "computes",
          "the",
          "squared",
          "error",
          "between",
          "computed",
          "key"
        ],
        "term_weights": [
          {
            "term": "mse",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "embedding",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "mseloss",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "embeddings",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "target",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "student",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "loss",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "input",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "studentmodel",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "computes",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "squared",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "error",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "between",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "computed",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.014925
          }
        ],
        "unique_terms": 45,
        "total_terms": 67
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "MSELoss",
        "and",
        "embedding",
        "embeddings",
        "for",
        "loss",
        "mse",
        "mseloss",
        "sentence",
        "student",
        "target"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5334782608695652,
      "overall": 0.7111594202898549
    }
  },
  {
    "text": "### MarginMSELoss  An extension of MSE loss that focuses on the margin between pairs of passages for a query. **Key Properties**: - Computes MSE between predicted margins and gold margins - More suitable for ranking tasks - Does not require strict positive/negative distinction - Often used with a teacher model in knowledge distillation  Sources: - [sentence_transformers/losses/MarginMSELoss.py:10-143]()",
    "metadata": {
      "chunk_id": "40662e14640d-0023",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 23,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "MarginMSELoss"
      ],
      "heading_text": "MarginMSELoss",
      "token_count": 85,
      "char_count": 406,
      "start_char": 17079,
      "end_char": 17485,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5364285714285714,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.477768",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "MarginMSELoss",
      "chunk_hash": "d23e70c5ba6bde76",
      "content_digest": "d23e70c5ba6bde76",
      "chunk_length": 406,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "marginmseloss",
          "mse",
          "between",
          "for",
          "margins",
          "extension",
          "loss",
          "that",
          "focuses",
          "the",
          "margin",
          "pairs",
          "passages",
          "query",
          "key",
          "properties",
          "computes",
          "predicted",
          "and",
          "gold"
        ],
        "term_weights": [
          {
            "term": "marginmseloss",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "mse",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "between",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "margins",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "extension",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "focuses",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "margin",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "pairs",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "passages",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "query",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "properties",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "computes",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "predicted",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "gold",
            "tf": 1,
            "weight": 0.020833
          }
        ],
        "unique_terms": 43,
        "total_terms": 48
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "MarginMSELoss",
        "between",
        "extension",
        "focuses",
        "for",
        "loss",
        "marginmseloss",
        "margins",
        "mse",
        "that",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5364285714285714,
      "overall": 0.7454761904761904
    }
  },
  {
    "text": "## Specialized Loss Functions",
    "metadata": {
      "chunk_id": "40662e14640d-0025",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 25,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Specialized Loss Functions"
      ],
      "heading_text": "Specialized Loss Functions",
      "token_count": 5,
      "char_count": 29,
      "start_char": 17866,
      "end_char": 17895,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.478124",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Specialized Loss Functions",
      "chunk_hash": "d61f9d78abba3bae",
      "content_digest": "d61f9d78abba3bae",
      "chunk_length": 29,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "specialized",
          "loss",
          "functions"
        ],
        "term_weights": [
          {
            "term": "specialized",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.333333
          }
        ],
        "unique_terms": 3,
        "total_terms": 3
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Specialized Loss Functions",
        "functions",
        "loss",
        "specialized"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### MatryoshkaLoss\n\nA loss function modifier that enables training models to produce effective embeddings at multiple dimensions. This allows users to reduce the embedding dimension at inference time without retraining.\n\n**Key Properties**:\n- Trains on multiple embedding dimensions simultaneously\n- Allows flexible trade-off between quality and dimensionality at inference time\n- Compatible with other base losses (wraps another loss function)\n\n```mermaid\nflowchart TD\n    subgraph \"MatryoshkaLoss Architecture\"\n        BaseL[\"Base Loss Function\"]\n        ML[\"MatryoshkaLoss\"]\n        \n        Dims[\"Multiple Dimensions\"] --> ML\n        Weights[\"Dimension Weights\"] --> ML\n        BaseL --> ML\n        \n        ML --> MDim1[\"Train at Dim 768\"]\n        ML --> MDim2[\"Train at Dim 384\"]\n        ML --> MDim3[\"Train at Dim 128\"]\n        \n        MDim1 --> CombLoss[\"Combined Loss\"]\n        MDim2 --> CombLoss\n        MDim3 --> CombLoss\n    end\n```\n\nSources:\n- [sentence_transformers/losses/MatryoshkaLoss.py:113-253]()",
    "metadata": {
      "chunk_id": "40662e14640d-0026",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 26,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "MatryoshkaLoss"
      ],
      "heading_text": "MatryoshkaLoss",
      "token_count": 237,
      "char_count": 1016,
      "start_char": 17897,
      "end_char": 18913,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5057894736842106,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.478551",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "MatryoshkaLoss",
      "chunk_hash": "b69eef3ac7dc6ef3",
      "content_digest": "b69eef3ac7dc6ef3",
      "chunk_length": 1016,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "matryoshkaloss",
          "loss",
          "function",
          "multiple",
          "dimensions",
          "train",
          "dim",
          "combloss",
          "allows",
          "embedding",
          "dimension",
          "inference",
          "time",
          "base",
          "losses",
          "basel",
          "weights",
          "mdim1",
          "mdim2",
          "mdim3"
        ],
        "term_weights": [
          {
            "term": "matryoshkaloss",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "loss",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "function",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "multiple",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "dimensions",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "train",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "dim",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "combloss",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "allows",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "dimension",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "time",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "base",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "losses",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "basel",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "weights",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "mdim1",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "mdim2",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "mdim3",
            "tf": 2,
            "weight": 0.021053
          }
        ],
        "unique_terms": 65,
        "total_terms": 95
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "MatryoshkaLoss",
        "allows",
        "combloss",
        "dim",
        "dimensions",
        "embedding",
        "function",
        "loss",
        "matryoshkaloss",
        "multiple",
        "train"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5057894736842106,
      "overall": 0.7019298245614034
    }
  },
  {
    "text": "### AdaptiveLayerLoss  Trains model to produce good embeddings with fewer transformer layers, enabling faster inference. **Key Properties**: - Applies loss to intermediate transformer layers - Allows layer reduction at inference time - KL divergence regularization between layer outputs  Sources: - [sentence_transformers/losses/AdaptiveLayerLoss.py:106-274]()",
    "metadata": {
      "chunk_id": "40662e14640d-0027",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 27,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "AdaptiveLayerLoss"
      ],
      "heading_text": "AdaptiveLayerLoss",
      "token_count": 68,
      "char_count": 360,
      "start_char": 18915,
      "end_char": 19275,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5460975609756098,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.478708",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "AdaptiveLayerLoss",
      "chunk_hash": "d7e466c6ae640b41",
      "content_digest": "d7e466c6ae640b41",
      "chunk_length": 360,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "adaptivelayerloss",
          "transformer",
          "layers",
          "inference",
          "layer",
          "trains",
          "model",
          "produce",
          "good",
          "embeddings",
          "with",
          "fewer",
          "enabling",
          "faster",
          "key",
          "properties",
          "applies",
          "loss",
          "intermediate",
          "allows"
        ],
        "term_weights": [
          {
            "term": "adaptivelayerloss",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "transformer",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "layers",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "layer",
            "tf": 2,
            "weight": 0.054054
          },
          {
            "term": "trains",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "produce",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "good",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "fewer",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "enabling",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "faster",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "properties",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "applies",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "intermediate",
            "tf": 1,
            "weight": 0.027027
          },
          {
            "term": "allows",
            "tf": 1,
            "weight": 0.027027
          }
        ],
        "unique_terms": 32,
        "total_terms": 37
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "AdaptiveLayerLoss",
        "adaptivelayerloss",
        "embeddings",
        "good",
        "inference",
        "layer",
        "layers",
        "model",
        "produce",
        "trains",
        "transformer"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5460975609756098,
      "overall": 0.7153658536585366
    }
  },
  {
    "text": "### Matryoshka2dLoss  Combines MatryoshkaLoss and AdaptiveLayerLoss to enable both dimension and layer reduction. **Key Properties**: - 2D flexibility in both dimensions and layers - Allows for different performance vs. efficiency trade-offs  Sources: - [sentence_transformers/losses/Matryoshka2dLoss.py:13-152]()",
    "metadata": {
      "chunk_id": "40662e14640d-0028",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 28,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Matryoshka2dLoss"
      ],
      "heading_text": "Matryoshka2dLoss",
      "token_count": 77,
      "char_count": 313,
      "start_char": 19278,
      "end_char": 19591,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5458823529411765,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.478912",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Matryoshka2dLoss",
      "chunk_hash": "42d52817e0b2bb4a",
      "content_digest": "42d52817e0b2bb4a",
      "chunk_length": 313,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "and",
          "matryoshka2dloss",
          "both",
          "combines",
          "matryoshkaloss",
          "adaptivelayerloss",
          "enable",
          "dimension",
          "layer",
          "reduction",
          "key",
          "properties",
          "flexibility",
          "dimensions",
          "layers",
          "allows",
          "for",
          "different",
          "performance",
          "efficiency"
        ],
        "term_weights": [
          {
            "term": "and",
            "tf": 3,
            "weight": 0.096774
          },
          {
            "term": "matryoshka2dloss",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "both",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "combines",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "matryoshkaloss",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "adaptivelayerloss",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "enable",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "dimension",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "layer",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "reduction",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "properties",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "flexibility",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "dimensions",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "layers",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "allows",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "efficiency",
            "tf": 1,
            "weight": 0.032258
          }
        ],
        "unique_terms": 27,
        "total_terms": 31
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Matryoshka2dLoss",
        "adaptivelayerloss",
        "and",
        "both",
        "combines",
        "dimension",
        "enable",
        "layer",
        "matryoshka2dloss",
        "matryoshkaloss",
        "reduction"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5458823529411765,
      "overall": 0.7152941176470587
    }
  },
  {
    "text": "### DenoisingAutoEncoderLoss  Trains a model to reconstruct original sentences from damaged versions, useful for unsupervised learning. **Key Properties**: - Requires pairs of damaged and original sentences - Creates a decoder component to reconstruct from embeddings - Used in TSDAE (Transformer-based Sequential Denoising Auto-Encoder)  Sources: - [sentence_transformers/losses/DenoisingAutoEncoderLoss.py:15-203]()",
    "metadata": {
      "chunk_id": "40662e14640d-0029",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 29,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "DenoisingAutoEncoderLoss"
      ],
      "heading_text": "DenoisingAutoEncoderLoss",
      "token_count": 88,
      "char_count": 417,
      "start_char": 19594,
      "end_char": 20011,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5247826086956522,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.479136",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "DenoisingAutoEncoderLoss",
      "chunk_hash": "778d5dbd23568403",
      "content_digest": "778d5dbd23568403",
      "chunk_length": 417,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "denoisingautoencoderloss",
          "reconstruct",
          "original",
          "sentences",
          "from",
          "damaged",
          "trains",
          "model",
          "versions",
          "useful",
          "for",
          "unsupervised",
          "learning",
          "key",
          "properties",
          "requires",
          "pairs",
          "and",
          "creates",
          "decoder"
        ],
        "term_weights": [
          {
            "term": "denoisingautoencoderloss",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "reconstruct",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "original",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "sentences",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "from",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "damaged",
            "tf": 2,
            "weight": 0.04878
          },
          {
            "term": "trains",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "versions",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "useful",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "unsupervised",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "learning",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "key",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "properties",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "requires",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "pairs",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "creates",
            "tf": 1,
            "weight": 0.02439
          },
          {
            "term": "decoder",
            "tf": 1,
            "weight": 0.02439
          }
        ],
        "unique_terms": 35,
        "total_terms": 41
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "DenoisingAutoEncoderLoss",
        "damaged",
        "denoisingautoencoderloss",
        "from",
        "model",
        "original",
        "reconstruct",
        "sentences",
        "trains",
        "useful",
        "versions"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5247826086956522,
      "overall": 0.7415942028985506
    }
  },
  {
    "text": "## Loss Function Selection Guide  The table below provides guidance on which loss function to use based on your data and task:  | Loss Function | Best For | Input Format | Special Requirements | |---------------|----------|--------------|---------------------| | MultipleNegativesRankingLoss | Retrieval, general purpose | (anchor, positive) pairs | Large batch size beneficial | | CoSENTLoss | Semantic similarity | Text pairs with scores | - | | TripletLoss | Clustering, similarity | (anchor, positive, negative) triplets | - | | BatchHardTripletLoss | Classification | Single texts with labels | Multiple examples per class | | MSELoss | Distillation, transfer | Texts with target embeddings | Teacher model | | MatryoshkaLoss | Size-efficient models | Depends on base loss | - | | AdaptiveLayerLoss | Speed-efficient models | Depends on base loss | - | | ContrastiveTensionLoss | Unsupervised learning | Single sentences | Special dataloader | | GISTEmbedLoss | Better negative sampling | Same as MNRL | Guide model |",
    "metadata": {
      "chunk_id": "40662e14640d-0031",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 31,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Loss Function Selection Guide"
      ],
      "heading_text": "Loss Function Selection Guide",
      "token_count": 221,
      "char_count": 1022,
      "start_char": 20379,
      "end_char": 21401,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.650377358490566,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.479752",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Loss Function Selection Guide",
      "chunk_hash": "a79cb57bb5f335ab",
      "content_digest": "a79cb57bb5f335ab",
      "chunk_length": 1022,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "loss",
          "function",
          "with",
          "guide",
          "special",
          "anchor",
          "positive",
          "pairs",
          "size",
          "similarity",
          "negative",
          "single",
          "texts",
          "model",
          "efficient",
          "models",
          "depends",
          "base",
          "selection",
          "the"
        ],
        "term_weights": [
          {
            "term": "loss",
            "tf": 5,
            "weight": 0.050505
          },
          {
            "term": "function",
            "tf": 3,
            "weight": 0.030303
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.030303
          },
          {
            "term": "guide",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "special",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "anchor",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "positive",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "pairs",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "size",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "similarity",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "negative",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "single",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "texts",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "efficient",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "depends",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "base",
            "tf": 2,
            "weight": 0.020202
          },
          {
            "term": "selection",
            "tf": 1,
            "weight": 0.010101
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.010101
          }
        ],
        "unique_terms": 76,
        "total_terms": 99
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Loss Function Selection Guide",
        "anchor",
        "function",
        "guide",
        "loss",
        "pairs",
        "positive",
        "similarity",
        "size",
        "special",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.650377358490566,
      "overall": 0.7834591194968553
    }
  },
  {
    "text": "## Implementation Details\n\nAll loss functions in SentenceTransformer follow a common pattern:\n\n1. They are subclasses of `torch.nn.Module`\n2. They implement a `forward` method that:\n   - Takes sentence features and optional labels as input\n   - Computes sentence embeddings using the model\n   - Calculates and returns the loss value\n\nMany loss functions also provide:\n- `get_config_dict` method for configuration serialization\n- `citation` property for academic references\n- Documentation about input requirements and recommendations\n\nThe loss function is typically passed to a `SentenceTransformerTrainer` along with the model and dataset, as shown in this example pattern:\n\n```python\nfrom sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, losses\nfrom datasets import Dataset\n\nmodel = SentenceTransformer(\"model_name\")\ntrain_dataset = Dataset.from_dict({\n    \"anchor\": [\"Text A\", \"Text B\"],  \n    \"positive\": [\"Similar to A\", \"Similar to B\"],\n})\nloss = losses.MultipleNegativesRankingLoss(model)\n\ntrainer = SentenceTransformerTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    loss=loss,\n)\ntrainer.train()\n```\n\nSources:\n- [sentence_transformers/losses/MultipleNegativesRankingLoss.py:13-132]()\n- [sentence_transformers/losses/__init__.py:1-67]()",
    "metadata": {
      "chunk_id": "40662e14640d-0033",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 33,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Implementation Details"
      ],
      "heading_text": "Implementation Details",
      "token_count": 274,
      "char_count": 1286,
      "start_char": 22605,
      "end_char": 23891,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7064285714285714,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.480980",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Implementation Details",
      "chunk_hash": "2124d21d25571a26",
      "content_digest": "2124d21d25571a26",
      "chunk_length": 1286,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "loss",
          "model",
          "dataset",
          "sentence",
          "and",
          "the",
          "losses",
          "train",
          "sentencetransformer",
          "sentencetransformertrainer",
          "from",
          "transformers",
          "functions",
          "pattern",
          "they",
          "method",
          "input",
          "dict",
          "for",
          "import"
        ],
        "term_weights": [
          {
            "term": "loss",
            "tf": 7,
            "weight": 0.053846
          },
          {
            "term": "model",
            "tf": 7,
            "weight": 0.053846
          },
          {
            "term": "dataset",
            "tf": 6,
            "weight": 0.046154
          },
          {
            "term": "sentence",
            "tf": 5,
            "weight": 0.038462
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.030769
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.030769
          },
          {
            "term": "losses",
            "tf": 4,
            "weight": 0.030769
          },
          {
            "term": "train",
            "tf": 4,
            "weight": 0.030769
          },
          {
            "term": "sentencetransformer",
            "tf": 3,
            "weight": 0.023077
          },
          {
            "term": "sentencetransformertrainer",
            "tf": 3,
            "weight": 0.023077
          },
          {
            "term": "from",
            "tf": 3,
            "weight": 0.023077
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.023077
          },
          {
            "term": "functions",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "pattern",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "they",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "method",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "input",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "dict",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.015385
          },
          {
            "term": "import",
            "tf": 2,
            "weight": 0.015385
          }
        ],
        "unique_terms": 77,
        "total_terms": 130
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Implementation Details",
        "and",
        "dataset",
        "loss",
        "losses",
        "model",
        "sentence",
        "sentencetransformer",
        "sentencetransformertrainer",
        "the",
        "train"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7064285714285714,
      "overall": 0.7688095238095237
    }
  },
  {
    "text": "# Loss Functions for SparseEncoder\n\n\n\n\nThis document covers the specialized loss functions designed for training `SparseEncoder` models. These losses are specifically tailored for sparse neural information retrieval models like SPLADE and CSR architectures that require both effectiveness and efficiency through sparsity regularization.\n\nFor dense embedding loss functions, see [Loss Functions for SentenceTransformer](#3.4). For reranking model loss functions, see [Loss Functions for CrossEncoder](#3.6).",
    "metadata": {
      "chunk_id": "40662e14640d-0034",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 34,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Loss Functions for SparseEncoder"
      ],
      "heading_text": "Loss Functions for SparseEncoder",
      "token_count": 90,
      "char_count": 506,
      "start_char": 23893,
      "end_char": 24399,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5125806451612903,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.481198",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Loss Functions for SparseEncoder",
      "chunk_hash": "0eb0751b883e714b",
      "content_digest": "0eb0751b883e714b",
      "chunk_length": 506,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "for",
          "loss",
          "functions",
          "sparseencoder",
          "models",
          "and",
          "see",
          "this",
          "document",
          "covers",
          "the",
          "specialized",
          "designed",
          "training",
          "these",
          "losses",
          "are",
          "specifically",
          "tailored",
          "sparse"
        ],
        "term_weights": [
          {
            "term": "for",
            "tf": 7,
            "weight": 0.114754
          },
          {
            "term": "loss",
            "tf": 6,
            "weight": 0.098361
          },
          {
            "term": "functions",
            "tf": 6,
            "weight": 0.098361
          },
          {
            "term": "sparseencoder",
            "tf": 2,
            "weight": 0.032787
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.032787
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.032787
          },
          {
            "term": "see",
            "tf": 2,
            "weight": 0.032787
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "covers",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "specialized",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "designed",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "training",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "these",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "losses",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "specifically",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "tailored",
            "tf": 1,
            "weight": 0.016393
          },
          {
            "term": "sparse",
            "tf": 1,
            "weight": 0.016393
          }
        ],
        "unique_terms": 41,
        "total_terms": 61
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Loss Functions for SparseEncoder",
        "and",
        "covers",
        "document",
        "for",
        "functions",
        "loss",
        "models",
        "see",
        "sparseencoder",
        "this"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5125806451612903,
      "overall": 0.73752688172043
    }
  },
  {
    "text": "## Overview  SparseEncoder loss functions follow a hierarchical architecture where wrapper losses combine base contrastive/similarity losses with regularization terms to control sparsity. The two main wrapper losses are:  - **`SpladeLoss`**: For SPLADE-style models that use MLM heads with pooling - **`CSRLoss`**: For CSR (Contrastive Sparse Representation) models with autoencoder components  These wrapper losses are required for training `SparseEncoder` models, as they provide the necessary sparsity regularization on top of standard contrastive learning objectives.",
    "metadata": {
      "chunk_id": "40662e14640d-0035",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 35,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Overview"
      ],
      "heading_text": "Overview",
      "token_count": 110,
      "char_count": 571,
      "start_char": 24401,
      "end_char": 24972,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5365753424657534,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.481410",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Overview",
      "chunk_hash": "0ef4a91ed1ed23e0",
      "content_digest": "0ef4a91ed1ed23e0",
      "chunk_length": 571,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "losses",
          "wrapper",
          "contrastive",
          "with",
          "for",
          "models",
          "sparseencoder",
          "regularization",
          "sparsity",
          "the",
          "are",
          "overview",
          "loss",
          "functions",
          "follow",
          "hierarchical",
          "architecture",
          "where",
          "combine",
          "base"
        ],
        "term_weights": [
          {
            "term": "losses",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "wrapper",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "contrastive",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "sparseencoder",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "regularization",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "sparsity",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "overview",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "follow",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "hierarchical",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "architecture",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "combine",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "base",
            "tf": 1,
            "weight": 0.014925
          }
        ],
        "unique_terms": 49,
        "total_terms": 67
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Overview",
        "contrastive",
        "for",
        "losses",
        "models",
        "regularization",
        "sparseencoder",
        "sparsity",
        "the",
        "with",
        "wrapper"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5365753424657534,
      "overall": 0.7455251141552511
    }
  },
  {
    "text": "### CSRLoss\n\n`CSRLoss` is designed for CSR (Contrastive Sparse Representation) models that use autoencoder components for reconstruction-based training.\n\n**Key Components:**\n- **Base Loss**: Typically `SparseMultipleNegativesRankingLoss` for contrastive learning\n- **Reconstruction Loss**: `CSRReconstructionLoss` with three components:\n  - L_k: Reconstruction loss using top-k sparse components\n  - L_4k: Reconstruction loss using top-4k sparse components  \n  - L_aux: Auxiliary loss for residual information\n\n**Configuration Parameters:**\n- `beta`: Weight for L_aux component in reconstruction loss\n- `gamma`: Weight for the main contrastive loss component\n\n```mermaid\ngraph TD\n    subgraph \"CSRLoss Components\"\n        CSRMain[\"CSRLoss\"]\n        MainLoss[\"base_loss<br/>(e.g., SparseMultipleNegativesRankingLoss)\"]\n        ReconLoss[\"CSRReconstructionLoss\"]\n        \n        subgraph \"Reconstruction Components\"\n            LossK[\"L_k: MSE(x, recons_k)\"]\n            Loss4K[\"L_4k: MSE(x, recons_4k)\"]\n            LossAux[\"L_aux: NMSE(recons_aux, residual)\"]\n        end\n        \n        CSRMain --> MainLoss\n        CSRMain --> ReconLoss\n        ReconLoss --> LossK\n        ReconLoss --> Loss4K  \n        ReconLoss --> LossAux\n    end\n```\n\nSources: [sentence_transformers/sparse_encoder/losses/CSRLoss.py:129-215](), [sentence_transformers/sparse_encoder/losses/CSRLoss.py:28-127]()",
    "metadata": {
      "chunk_id": "40662e14640d-0039",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 39,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "CSRLoss"
      ],
      "heading_text": "CSRLoss",
      "token_count": 346,
      "char_count": 1385,
      "start_char": 28153,
      "end_char": 29538,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5095851239669421,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.483731",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "CSRLoss",
      "chunk_hash": "36cf4ce51a7a81f5",
      "content_digest": "36cf4ce51a7a81f5",
      "chunk_length": 1385,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "loss",
          "components",
          "csrloss",
          "for",
          "reconstruction",
          "sparse",
          "reconloss",
          "aux",
          "contrastive",
          "csrmain",
          "recons",
          "base",
          "sparsemultiplenegativesrankingloss",
          "csrreconstructionloss",
          "using",
          "top",
          "residual",
          "weight",
          "component",
          "subgraph"
        ],
        "term_weights": [
          {
            "term": "loss",
            "tf": 8,
            "weight": 0.065041
          },
          {
            "term": "components",
            "tf": 7,
            "weight": 0.056911
          },
          {
            "term": "csrloss",
            "tf": 6,
            "weight": 0.04878
          },
          {
            "term": "for",
            "tf": 6,
            "weight": 0.04878
          },
          {
            "term": "reconstruction",
            "tf": 6,
            "weight": 0.04878
          },
          {
            "term": "sparse",
            "tf": 5,
            "weight": 0.04065
          },
          {
            "term": "reconloss",
            "tf": 5,
            "weight": 0.04065
          },
          {
            "term": "aux",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "contrastive",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "csrmain",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "recons",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "base",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "sparsemultiplenegativesrankingloss",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "csrreconstructionloss",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "using",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "top",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "residual",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "weight",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "component",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "subgraph",
            "tf": 2,
            "weight": 0.01626
          }
        ],
        "unique_terms": 59,
        "total_terms": 123
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "CSRLoss",
        "aux",
        "components",
        "contrastive",
        "csrloss",
        "csrmain",
        "for",
        "loss",
        "reconloss",
        "reconstruction",
        "sparse"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5095851239669421,
      "overall": 0.7031950413223139
    }
  },
  {
    "text": "# Typical SPLADE training setup\nstudent_model = SparseEncoder(\"distilbert/distilbert-base-uncased\")\nteacher_model = SparseEncoder(\"naver/splade-cocondenser-ensembledistil\")\n\nloss = SpladeLoss(\n    model=student_model,\n    loss=SparseMarginMSELoss(student_model),\n    document_regularizer_weight=3e-5,\n    query_regularizer_weight=5e-5,\n)\n```",
    "metadata": {
      "chunk_id": "40662e14640d-0045",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "filename": "Model_without_classification_head_will_be_added.md",
      "file_extension": ".md",
      "chunk_index": 45,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Typical SPLADE training setup"
      ],
      "heading_text": "Typical SPLADE training setup",
      "token_count": 90,
      "char_count": 341,
      "start_char": 31979,
      "end_char": 32320,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.56,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:29.485284",
      "document_id": "40662e14640d",
      "document_name": "Model_without_classification_head_will_be_added",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "source_filename": "Model_without_classification_head_will_be_added.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Model_without_classification_head_will_be_added.md",
      "hierarchy_path": "Typical SPLADE training setup",
      "chunk_hash": "23b09e012356d702",
      "content_digest": "23b09e012356d702",
      "chunk_length": 341,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "student",
          "splade",
          "sparseencoder",
          "distilbert",
          "loss",
          "regularizer",
          "weight",
          "typical",
          "training",
          "setup",
          "base",
          "uncased",
          "teacher",
          "naver",
          "cocondenser",
          "ensembledistil",
          "spladeloss",
          "sparsemarginmseloss",
          "document"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 5,
            "weight": 0.151515
          },
          {
            "term": "student",
            "tf": 3,
            "weight": 0.090909
          },
          {
            "term": "splade",
            "tf": 2,
            "weight": 0.060606
          },
          {
            "term": "sparseencoder",
            "tf": 2,
            "weight": 0.060606
          },
          {
            "term": "distilbert",
            "tf": 2,
            "weight": 0.060606
          },
          {
            "term": "loss",
            "tf": 2,
            "weight": 0.060606
          },
          {
            "term": "regularizer",
            "tf": 2,
            "weight": 0.060606
          },
          {
            "term": "weight",
            "tf": 2,
            "weight": 0.060606
          },
          {
            "term": "typical",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "training",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "setup",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "base",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "uncased",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "teacher",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "naver",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "cocondenser",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "ensembledistil",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "spladeloss",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "sparsemarginmseloss",
            "tf": 1,
            "weight": 0.030303
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.030303
          }
        ],
        "unique_terms": 21,
        "total_terms": 33
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Typical SPLADE training setup",
        "distilbert",
        "loss",
        "model",
        "regularizer",
        "sparseencoder",
        "splade",
        "student",
        "training",
        "typical",
        "weight"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.56,
      "overall": 0.6866666666666666
    }
  }
]
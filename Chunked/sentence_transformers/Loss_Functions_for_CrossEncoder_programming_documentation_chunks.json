[
  {
    "text": "### ListNet Loss  The `ListNetLoss` implements the ListNet ranking algorithm using cross-entropy between predicted and ground truth ranking distributions: ```python",
    "metadata": {
      "chunk_id": "a51716c2d709-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "filename": "Loss_Functions_for_CrossEncoder.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ListNet Loss"
      ],
      "heading_text": "ListNet Loss",
      "token_count": 31,
      "char_count": 164,
      "start_char": 0,
      "end_char": 164,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.545,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:50:57.222385",
      "document_id": "a51716c2d709",
      "document_name": "Loss_Functions_for_CrossEncoder",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "source_filename": "Loss_Functions_for_CrossEncoder.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "hierarchy_path": "ListNet Loss",
      "chunk_hash": "8e9316a8e4338aa1",
      "content_digest": "8e9316a8e4338aa1",
      "chunk_length": 164,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "listnet",
          "the",
          "ranking",
          "loss",
          "listnetloss",
          "implements",
          "algorithm",
          "using",
          "cross",
          "entropy",
          "between",
          "predicted",
          "and",
          "ground",
          "truth",
          "distributions",
          "python"
        ],
        "term_weights": [
          {
            "term": "listnet",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "ranking",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "listnetloss",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "implements",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "algorithm",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "cross",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "entropy",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "between",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "predicted",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "ground",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "truth",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "distributions",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.05
          }
        ],
        "unique_terms": 17,
        "total_terms": 20
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ListNet Loss",
        "algorithm",
        "cross",
        "entropy",
        "implements",
        "listnet",
        "listnetloss",
        "loss",
        "ranking",
        "the",
        "using"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.545,
      "overall": 0.7483333333333334
    }
  },
  {
    "text": "## Loss Function Hierarchy  The following diagram shows the inheritance and relationship structure of CrossEncoder loss functions: ```mermaid graph TD     Module[\"nn.Module\"]          subgraph \"Learning-to-Rank Losses\"         LambdaLoss[\"LambdaLoss\"]         ListNetLoss[\"ListNetLoss\"]          PListMLELoss[\"PListMLELoss\"]         ListMLELoss[\"ListMLELoss\"]         RankNetLoss[\"RankNetLoss\"]     end          subgraph \"Classification Losses\"         BinaryCrossEntropyLoss[\"BinaryCrossEntropyLoss\"]         CrossEntropyLoss[\"CrossEntropyLoss\"]         MultipleNegativesRankingLoss[\"MultipleNegativesRankingLoss\"]         CachedMultipleNegativesRankingLoss[\"CachedMultipleNegativesRankingLoss\"]     end          subgraph \"Regression Losses\"         MSELoss[\"MSELoss\"]         MarginMSELoss[\"MarginMSELoss\"]     end          subgraph \"Weighting Schemes\"         BaseWeightingScheme[\"BaseWeightingScheme\"]         NoWeightingScheme[\"NoWeightingScheme\"]         NDCGLoss1Scheme[\"NDCGLoss1Scheme\"]         NDCGLoss2Scheme[\"NDCGLoss2Scheme\"]         LambdaRankScheme[\"LambdaRankScheme\"]         NDCGLoss2PPScheme[\"NDCGLoss2PPScheme\"]         PListMLELambdaWeight[\"PListMLELambdaWeight\"]     end          Module --> LambdaLoss     Module --> ListNetLoss     Module --> PListMLELoss     Module --> BinaryCrossEntropyLoss     Module --> CrossEntropyLoss     Module --> MultipleNegativesRankingLoss     Module --> CachedMultipleNegativesRankingLoss     Module --> MSELoss     Module --> MarginMSELoss     Module --> BaseWeightingScheme          ListMLELoss --> PListMLELoss     LambdaLoss --> RankNetLoss     BaseWeightingScheme --> NoWeightingScheme     BaseWeightingScheme --> NDCGLoss1Scheme     BaseWeightingScheme --> NDCGLoss2Scheme     BaseWeightingScheme --> LambdaRankScheme     BaseWeightingScheme --> NDCGLoss2PPScheme     Module --> PListMLELambdaWeight          LambdaLoss -.-> BaseWeightingScheme     PListMLELoss -.-> PListMLELambdaWeight ``` Sources: [sentence_transformers/cross_encoder/losses/LambdaLoss.py:103-361](), [sentence_transformers/cross_encoder/losses/ListNetLoss.py:10-198](), [sentence_transformers/cross_encoder/losses/PListMLELoss.py:45-295](), [sentence_transformers/cross_encoder/losses/ListMLELoss.py:9-127](), [sentence_transformers/cross_encoder/losses/RankNetLoss.py:11-124](), [docs/package_reference/cross_encoder/losses.md:1-68]()",
    "metadata": {
      "chunk_id": "a51716c2d709-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "filename": "Loss_Functions_for_CrossEncoder.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Loss Function Hierarchy"
      ],
      "heading_text": "Loss Function Hierarchy",
      "token_count": 576,
      "char_count": 2365,
      "start_char": 0,
      "end_char": 2365,
      "semantic_score": 0.402871698141098,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6804878048780487,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:50:57.220495",
      "document_id": "a51716c2d709",
      "document_name": "Loss_Functions_for_CrossEncoder",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "source_filename": "Loss_Functions_for_CrossEncoder.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "hierarchy_path": "Loss Function Hierarchy",
      "chunk_hash": "cb5bc93b6beb249a",
      "content_digest": "cb5bc93b6beb249a",
      "chunk_length": 2365,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "module",
          "losses",
          "baseweightingscheme",
          "lambdaloss",
          "plistmleloss",
          "cross",
          "encoder",
          "sentence",
          "transformers",
          "subgraph",
          "listnetloss",
          "listmleloss",
          "ranknetloss",
          "end",
          "plistmlelambdaweight",
          "binarycrossentropyloss",
          "crossentropyloss",
          "multiplenegativesrankingloss",
          "cachedmultiplenegativesrankingloss",
          "mseloss"
        ],
        "term_weights": [
          {
            "term": "module",
            "tf": 13,
            "weight": 0.083871
          },
          {
            "term": "losses",
            "tf": 9,
            "weight": 0.058065
          },
          {
            "term": "baseweightingscheme",
            "tf": 9,
            "weight": 0.058065
          },
          {
            "term": "lambdaloss",
            "tf": 6,
            "weight": 0.03871
          },
          {
            "term": "plistmleloss",
            "tf": 6,
            "weight": 0.03871
          },
          {
            "term": "cross",
            "tf": 6,
            "weight": 0.03871
          },
          {
            "term": "encoder",
            "tf": 6,
            "weight": 0.03871
          },
          {
            "term": "sentence",
            "tf": 5,
            "weight": 0.032258
          },
          {
            "term": "transformers",
            "tf": 5,
            "weight": 0.032258
          },
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.025806
          },
          {
            "term": "listnetloss",
            "tf": 4,
            "weight": 0.025806
          },
          {
            "term": "listmleloss",
            "tf": 4,
            "weight": 0.025806
          },
          {
            "term": "ranknetloss",
            "tf": 4,
            "weight": 0.025806
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.025806
          },
          {
            "term": "plistmlelambdaweight",
            "tf": 4,
            "weight": 0.025806
          },
          {
            "term": "binarycrossentropyloss",
            "tf": 3,
            "weight": 0.019355
          },
          {
            "term": "crossentropyloss",
            "tf": 3,
            "weight": 0.019355
          },
          {
            "term": "multiplenegativesrankingloss",
            "tf": 3,
            "weight": 0.019355
          },
          {
            "term": "cachedmultiplenegativesrankingloss",
            "tf": 3,
            "weight": 0.019355
          },
          {
            "term": "mseloss",
            "tf": 3,
            "weight": 0.019355
          }
        ],
        "unique_terms": 57,
        "total_terms": 155
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Loss Function Hierarchy",
        "baseweightingscheme",
        "cross",
        "encoder",
        "lambdaloss",
        "losses",
        "module",
        "plistmleloss",
        "sentence",
        "subgraph",
        "transformers"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.402871698141098,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6804878048780487,
      "overall": 0.6611198343397156
    }
  },
  {
    "text": "## Overview  CrossEncoder loss functions are designed to train models that process text pairs jointly through a single transformer encoder. These loss functions fall into three main categories:  - **Learning-to-Rank Losses**: Optimize ranking metrics like NDCG for information retrieval tasks - **Classification Losses**: Handle binary or multi-class classification scenarios   - **Regression Losses**: Predict continuous similarity scores between text pairs",
    "metadata": {
      "chunk_id": "a51716c2d709-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "filename": "Loss_Functions_for_CrossEncoder.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Overview"
      ],
      "heading_text": "Overview",
      "token_count": 81,
      "char_count": 458,
      "start_char": 0,
      "end_char": 458,
      "semantic_score": 0.5127255320549011,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5493220338983051,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:50:57.219433",
      "document_id": "a51716c2d709",
      "document_name": "Loss_Functions_for_CrossEncoder",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "source_filename": "Loss_Functions_for_CrossEncoder.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "hierarchy_path": "Overview",
      "chunk_hash": "8fc81849b0ea35eb",
      "content_digest": "8fc81849b0ea35eb",
      "chunk_length": 458,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "losses",
          "loss",
          "functions",
          "text",
          "pairs",
          "classification",
          "overview",
          "crossencoder",
          "are",
          "designed",
          "train",
          "models",
          "that",
          "process",
          "jointly",
          "through",
          "single",
          "transformer",
          "encoder",
          "these"
        ],
        "term_weights": [
          {
            "term": "losses",
            "tf": 3,
            "weight": 0.055556
          },
          {
            "term": "loss",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "functions",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "pairs",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "classification",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "overview",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "designed",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "train",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "jointly",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "single",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "transformer",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "encoder",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "these",
            "tf": 1,
            "weight": 0.018519
          }
        ],
        "unique_terms": 47,
        "total_terms": 54
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Overview",
        "are",
        "classification",
        "crossencoder",
        "designed",
        "functions",
        "loss",
        "losses",
        "overview",
        "pairs",
        "text"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.5127255320549011,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5493220338983051,
      "overall": 0.6540158553177354
    }
  },
  {
    "text": "### Data Format Requirements  All learning-to-rank losses expect the following input format:  | Component | Format | Description | |-----------|--------|-------------| | Inputs | `(queries, documents_list)` | List of query strings and list of document lists | | Labels | `[score1, score2, ..., scoreN]` | List of relevance scores per query | | Model Output | 1 label | Single relevance score per query-document pair |",
    "metadata": {
      "chunk_id": "a51716c2d709-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "filename": "Loss_Functions_for_CrossEncoder.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Data Format Requirements"
      ],
      "heading_text": "Data Format Requirements",
      "token_count": 91,
      "char_count": 417,
      "start_char": 0,
      "end_char": 417,
      "semantic_score": 0.43633872270584106,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.4838461538461538,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:50:57.221222",
      "document_id": "a51716c2d709",
      "document_name": "Loss_Functions_for_CrossEncoder",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "source_filename": "Loss_Functions_for_CrossEncoder.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "hierarchy_path": "Data Format Requirements",
      "chunk_hash": "17ef27e696bce499",
      "content_digest": "17ef27e696bce499",
      "chunk_length": 417,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "list",
          "format",
          "query",
          "document",
          "relevance",
          "per",
          "data",
          "requirements",
          "all",
          "learning",
          "rank",
          "losses",
          "expect",
          "the",
          "following",
          "input",
          "component",
          "description",
          "inputs",
          "queries"
        ],
        "term_weights": [
          {
            "term": "list",
            "tf": 4,
            "weight": 0.088889
          },
          {
            "term": "format",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "query",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "document",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "relevance",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "per",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "data",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "requirements",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "learning",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "rank",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "losses",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "expect",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "following",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "input",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "component",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "description",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "inputs",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "queries",
            "tf": 1,
            "weight": 0.022222
          }
        ],
        "unique_terms": 35,
        "total_terms": 45
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Data Format Requirements",
        "all",
        "data",
        "document",
        "format",
        "learning",
        "list",
        "per",
        "query",
        "relevance",
        "requirements"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.43633872270584106,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.4838461538461538,
      "overall": 0.6067282921839983
    }
  },
  {
    "text": "### LambdaLoss Framework  The `LambdaLoss` class implements a comprehensive framework for ranking metric optimization with multiple weighting schemes: ```mermaid graph LR     subgraph \"Input Processing\"         QueryDocs[\"queries + docs_list\"] --> Pairs[\"query-document pairs\"]         Labels[\"labels list\"] --> LabelMatrix[\"labels_matrix\"]     end          subgraph \"Model Processing\"         Pairs --> CrossEncoder[\"model.forward()\"]         CrossEncoder --> Logits[\"logits\"]         Logits --> ActivationFn[\"activation_fn\"]         ActivationFn --> LogitsMatrix[\"logits_matrix\"]     end          subgraph \"LambdaLoss Computation\"         LogitsMatrix --> Sorting[\"sort by logits\"]         LabelMatrix --> Sorting         Sorting --> TrueDiffs[\"true_diffs\"]         Sorting --> Gains[\"gain calculation\"]         Sorting --> Discounts[\"discount calculation\"]                  Gains --> WeightingScheme[\"weighting_scheme.forward()\"]         Discounts --> WeightingScheme         WeightingScheme --> Weights[\"weights\"]                  TrueDiffs --> ScoreDiffs[\"score differences\"]         ScoreDiffs --> WeightedProbas[\"weighted probabilities\"]         Weights --> WeightedProbas         WeightedProbas --> Loss[\"final loss\"]     end ``` The `LambdaLoss` supports five weighting schemes:  | Scheme | Class | Purpose | |--------|-------|---------| | No Weighting | `NoWeightingScheme` | Uniform weights (RankNet equivalent) | | NDCG Loss1 | `NDCGLoss1Scheme` | Basic NDCG optimization | | NDCG Loss2 | `NDCGLoss2Scheme` | Improved NDCG with tighter bounds | | LambdaRank | `LambdaRankScheme` | Coarse upper bound optimization | | NDCG Loss2++ | `NDCGLoss2PPScheme` | Hybrid scheme (recommended) |  Sources: [sentence_transformers/cross_encoder/losses/LambdaLoss.py:103-361](), [sentence_transformers/cross_encoder/losses/LambdaLoss.py:12-101]()",
    "metadata": {
      "chunk_id": "a51716c2d709-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "filename": "Loss_Functions_for_CrossEncoder.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "LambdaLoss Framework"
      ],
      "heading_text": "LambdaLoss Framework",
      "token_count": 423,
      "char_count": 1843,
      "start_char": 0,
      "end_char": 1843,
      "semantic_score": 0.4055454134941101,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5079650887573964,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:50:57.222005",
      "document_id": "a51716c2d709",
      "document_name": "Loss_Functions_for_CrossEncoder",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "source_filename": "Loss_Functions_for_CrossEncoder.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "hierarchy_path": "LambdaLoss Framework",
      "chunk_hash": "b598dbb5c5205784",
      "content_digest": "b598dbb5c5205784",
      "chunk_length": 1843,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "lambdaloss",
          "logits",
          "sorting",
          "ndcg",
          "weighting",
          "weights",
          "optimization",
          "subgraph",
          "pairs",
          "labels",
          "end",
          "weightingscheme",
          "scheme",
          "weightedprobas",
          "framework",
          "the",
          "class",
          "with",
          "schemes",
          "processing"
        ],
        "term_weights": [
          {
            "term": "lambdaloss",
            "tf": 6,
            "weight": 0.038217
          },
          {
            "term": "logits",
            "tf": 5,
            "weight": 0.031847
          },
          {
            "term": "sorting",
            "tf": 5,
            "weight": 0.031847
          },
          {
            "term": "ndcg",
            "tf": 5,
            "weight": 0.031847
          },
          {
            "term": "weighting",
            "tf": 4,
            "weight": 0.025478
          },
          {
            "term": "weights",
            "tf": 4,
            "weight": 0.025478
          },
          {
            "term": "optimization",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "subgraph",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "pairs",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "labels",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "end",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "weightingscheme",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "scheme",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "weightedprobas",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "framework",
            "tf": 2,
            "weight": 0.012739
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.012739
          },
          {
            "term": "class",
            "tf": 2,
            "weight": 0.012739
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.012739
          },
          {
            "term": "schemes",
            "tf": 2,
            "weight": 0.012739
          },
          {
            "term": "processing",
            "tf": 2,
            "weight": 0.012739
          }
        ],
        "unique_terms": 92,
        "total_terms": 157
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "LambdaLoss Framework",
        "labels",
        "lambdaloss",
        "logits",
        "ndcg",
        "optimization",
        "pairs",
        "sorting",
        "subgraph",
        "weighting",
        "weights"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.4055454134941101,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5079650887573964,
      "overall": 0.6045035007505022
    }
  }
]
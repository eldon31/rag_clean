[
  {
    "text": "## Overview\n\nCrossEncoder loss functions are designed to train models that process text pairs jointly through a single transformer encoder. These loss functions fall into three main categories:\n\n- **Learning-to-Rank Losses**: Optimize ranking metrics like NDCG for information retrieval tasks\n- **Classification Losses**: Handle binary or multi-class classification scenarios  \n- **Regression Losses**: Predict continuous similarity scores between text pairs",
    "metadata": {
      "chunk_id": "a51716c2d709-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "filename": "Loss_Functions_for_CrossEncoder.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Overview"
      ],
      "heading_text": "Overview",
      "token_count": 81,
      "char_count": 458,
      "start_char": 480,
      "end_char": 938,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5493220338983051,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.187068",
      "document_id": "a51716c2d709",
      "document_name": "Loss_Functions_for_CrossEncoder",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "source_filename": "Loss_Functions_for_CrossEncoder.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "hierarchy_path": "Overview",
      "chunk_hash": "5192e9588d50cde9",
      "content_digest": "5192e9588d50cde9",
      "chunk_length": 458,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "losses",
          "loss",
          "functions",
          "text",
          "pairs",
          "classification",
          "overview",
          "crossencoder",
          "are",
          "designed",
          "train",
          "models",
          "that",
          "process",
          "jointly",
          "through",
          "single",
          "transformer",
          "encoder",
          "these"
        ],
        "term_weights": [
          {
            "term": "losses",
            "tf": 3,
            "weight": 0.055556
          },
          {
            "term": "loss",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "functions",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "pairs",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "classification",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "overview",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "crossencoder",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "designed",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "train",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "jointly",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "single",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "transformer",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "encoder",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "these",
            "tf": 1,
            "weight": 0.018519
          }
        ],
        "unique_terms": 47,
        "total_terms": 54
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Overview",
        "are",
        "classification",
        "crossencoder",
        "designed",
        "functions",
        "loss",
        "losses",
        "overview",
        "pairs",
        "text"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5493220338983051,
      "overall": 0.7164406779661016
    }
  },
  {
    "text": "## Loss Function Hierarchy\n\nThe following diagram shows the inheritance and relationship structure of CrossEncoder loss functions:\n\n```mermaid\ngraph TD\n    Module[\"nn.Module\"]\n    \n    subgraph \"Learning-to-Rank Losses\"\n        LambdaLoss[\"LambdaLoss\"]\n        ListNetLoss[\"ListNetLoss\"] \n        PListMLELoss[\"PListMLELoss\"]\n        ListMLELoss[\"ListMLELoss\"]\n        RankNetLoss[\"RankNetLoss\"]\n    end\n    \n    subgraph \"Classification Losses\"\n        BinaryCrossEntropyLoss[\"BinaryCrossEntropyLoss\"]\n        CrossEntropyLoss[\"CrossEntropyLoss\"]\n        MultipleNegativesRankingLoss[\"MultipleNegativesRankingLoss\"]\n        CachedMultipleNegativesRankingLoss[\"CachedMultipleNegativesRankingLoss\"]\n    end\n    \n    subgraph \"Regression Losses\"\n        MSELoss[\"MSELoss\"]\n        MarginMSELoss[\"MarginMSELoss\"]\n    end\n    \n    subgraph \"Weighting Schemes\"\n        BaseWeightingScheme[\"BaseWeightingScheme\"]\n        NoWeightingScheme[\"NoWeightingScheme\"]\n        NDCGLoss1Scheme[\"NDCGLoss1Scheme\"]\n        NDCGLoss2Scheme[\"NDCGLoss2Scheme\"]\n        LambdaRankScheme[\"LambdaRankScheme\"]\n        NDCGLoss2PPScheme[\"NDCGLoss2PPScheme\"]\n        PListMLELambdaWeight[\"PListMLELambdaWeight\"]\n    end\n    \n    Module --> LambdaLoss\n    Module --> ListNetLoss\n    Module --> PListMLELoss\n    Module --> BinaryCrossEntropyLoss\n    Module --> CrossEntropyLoss\n    Module --> MultipleNegativesRankingLoss\n    Module --> CachedMultipleNegativesRankingLoss\n    Module --> MSELoss\n    Module --> MarginMSELoss\n    Module --> BaseWeightingScheme\n    \n    ListMLELoss --> PListMLELoss\n    LambdaLoss --> RankNetLoss\n    BaseWeightingScheme --> NoWeightingScheme\n    BaseWeightingScheme --> NDCGLoss1Scheme\n    BaseWeightingScheme --> NDCGLoss2Scheme\n    BaseWeightingScheme --> LambdaRankScheme\n    BaseWeightingScheme --> NDCGLoss2PPScheme\n    Module --> PListMLELambdaWeight\n    \n    LambdaLoss -.-> BaseWeightingScheme\n    PListMLELoss -.-> PListMLELambdaWeight\n```\n\nSources: [sentence_transformers/cross_encoder/losses/LambdaLoss.py:103-361](), [sentence_transformers/cross_encoder/losses/ListNetLoss.py:10-198](), [sentence_transformers/cross_encoder/losses/PListMLELoss.py:45-295](), [sentence_transformers/cross_encoder/losses/ListMLELoss.py:9-127](), [sentence_transformers/cross_encoder/losses/RankNetLoss.py:11-124](), [docs/package_reference/cross_encoder/losses.md:1-68]()",
    "metadata": {
      "chunk_id": "a51716c2d709-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "filename": "Loss_Functions_for_CrossEncoder.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Loss Function Hierarchy"
      ],
      "heading_text": "Loss Function Hierarchy",
      "token_count": 605,
      "char_count": 2367,
      "start_char": 940,
      "end_char": 3307,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7,
      "retrieval_quality": 0.6804878048780487,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.189235",
      "document_id": "a51716c2d709",
      "document_name": "Loss_Functions_for_CrossEncoder",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "source_filename": "Loss_Functions_for_CrossEncoder.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "hierarchy_path": "Loss Function Hierarchy",
      "chunk_hash": "d9c970c14e22f6ab",
      "content_digest": "d9c970c14e22f6ab",
      "chunk_length": 2367,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "module",
          "losses",
          "baseweightingscheme",
          "lambdaloss",
          "plistmleloss",
          "cross",
          "encoder",
          "sentence",
          "transformers",
          "subgraph",
          "listnetloss",
          "listmleloss",
          "ranknetloss",
          "end",
          "plistmlelambdaweight",
          "binarycrossentropyloss",
          "crossentropyloss",
          "multiplenegativesrankingloss",
          "cachedmultiplenegativesrankingloss",
          "mseloss"
        ],
        "term_weights": [
          {
            "term": "module",
            "tf": 13,
            "weight": 0.083871
          },
          {
            "term": "losses",
            "tf": 9,
            "weight": 0.058065
          },
          {
            "term": "baseweightingscheme",
            "tf": 9,
            "weight": 0.058065
          },
          {
            "term": "lambdaloss",
            "tf": 6,
            "weight": 0.03871
          },
          {
            "term": "plistmleloss",
            "tf": 6,
            "weight": 0.03871
          },
          {
            "term": "cross",
            "tf": 6,
            "weight": 0.03871
          },
          {
            "term": "encoder",
            "tf": 6,
            "weight": 0.03871
          },
          {
            "term": "sentence",
            "tf": 5,
            "weight": 0.032258
          },
          {
            "term": "transformers",
            "tf": 5,
            "weight": 0.032258
          },
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.025806
          },
          {
            "term": "listnetloss",
            "tf": 4,
            "weight": 0.025806
          },
          {
            "term": "listmleloss",
            "tf": 4,
            "weight": 0.025806
          },
          {
            "term": "ranknetloss",
            "tf": 4,
            "weight": 0.025806
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.025806
          },
          {
            "term": "plistmlelambdaweight",
            "tf": 4,
            "weight": 0.025806
          },
          {
            "term": "binarycrossentropyloss",
            "tf": 3,
            "weight": 0.019355
          },
          {
            "term": "crossentropyloss",
            "tf": 3,
            "weight": 0.019355
          },
          {
            "term": "multiplenegativesrankingloss",
            "tf": 3,
            "weight": 0.019355
          },
          {
            "term": "cachedmultiplenegativesrankingloss",
            "tf": 3,
            "weight": 0.019355
          },
          {
            "term": "mseloss",
            "tf": 3,
            "weight": 0.019355
          }
        ],
        "unique_terms": 57,
        "total_terms": 155
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Loss Function Hierarchy",
        "baseweightingscheme",
        "cross",
        "encoder",
        "lambdaloss",
        "losses",
        "module",
        "plistmleloss",
        "sentence",
        "subgraph",
        "transformers"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7,
      "retrieval_quality": 0.6804878048780487,
      "overall": 0.726829268292683
    }
  },
  {
    "text": "## Learning-to-Rank Loss Functions\n\nLearning-to-rank losses are designed for information retrieval tasks where the goal is to rank documents by relevance for a given query. These losses work with listwise data formats.",
    "metadata": {
      "chunk_id": "a51716c2d709-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "filename": "Loss_Functions_for_CrossEncoder.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Learning-to-Rank Loss Functions"
      ],
      "heading_text": "Learning-to-Rank Loss Functions",
      "token_count": 42,
      "char_count": 218,
      "start_char": 3309,
      "end_char": 3527,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.561875,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.189235",
      "document_id": "a51716c2d709",
      "document_name": "Loss_Functions_for_CrossEncoder",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "source_filename": "Loss_Functions_for_CrossEncoder.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "hierarchy_path": "Learning-to-Rank Loss Functions",
      "chunk_hash": "c93e7276f42d2890",
      "content_digest": "c93e7276f42d2890",
      "chunk_length": 218,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "rank",
          "learning",
          "losses",
          "for",
          "loss",
          "functions",
          "are",
          "designed",
          "information",
          "retrieval",
          "tasks",
          "where",
          "the",
          "goal",
          "documents",
          "relevance",
          "given",
          "query",
          "these",
          "work"
        ],
        "term_weights": [
          {
            "term": "rank",
            "tf": 3,
            "weight": 0.103448
          },
          {
            "term": "learning",
            "tf": 2,
            "weight": 0.068966
          },
          {
            "term": "losses",
            "tf": 2,
            "weight": 0.068966
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.068966
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "functions",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "designed",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "information",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "retrieval",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "tasks",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "goal",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "relevance",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "given",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "query",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "these",
            "tf": 1,
            "weight": 0.034483
          },
          {
            "term": "work",
            "tf": 1,
            "weight": 0.034483
          }
        ],
        "unique_terms": 24,
        "total_terms": 29
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Learning-to-Rank Loss Functions",
        "are",
        "designed",
        "for",
        "functions",
        "information",
        "learning",
        "loss",
        "losses",
        "rank",
        "retrieval"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.561875,
      "overall": 0.720625
    }
  },
  {
    "text": "### LambdaLoss Framework  The `LambdaLoss` class implements a comprehensive framework for ranking metric optimization with multiple weighting schemes: ```mermaid graph LR     subgraph \"Input Processing\"         QueryDocs[\"queries + docs_list\"] --> Pairs[\"query-document pairs\"]         Labels[\"labels list\"] --> LabelMatrix[\"labels_matrix\"]     end          subgraph \"Model Processing\"         Pairs --> CrossEncoder[\"model.forward()\"]         CrossEncoder --> Logits[\"logits\"]         Logits --> ActivationFn[\"activation_fn\"]         ActivationFn --> LogitsMatrix[\"logits_matrix\"]     end          subgraph \"LambdaLoss Computation\"         LogitsMatrix --> Sorting[\"sort by logits\"]         LabelMatrix --> Sorting         Sorting --> TrueDiffs[\"true_diffs\"]         Sorting --> Gains[\"gain calculation\"]         Sorting --> Discounts[\"discount calculation\"]                  Gains --> WeightingScheme[\"weighting_scheme.forward()\"]         Discounts --> WeightingScheme         WeightingScheme --> Weights[\"weights\"]                  TrueDiffs --> ScoreDiffs[\"score differences\"]         ScoreDiffs --> WeightedProbas[\"weighted probabilities\"]         Weights --> WeightedProbas         WeightedProbas --> Loss[\"final loss\"]     end ``` The `LambdaLoss` supports five weighting schemes:  | Scheme | Class | Purpose | |--------|-------|---------| | No Weighting | `NoWeightingScheme` | Uniform weights (RankNet equivalent) | | NDCG Loss1 | `NDCGLoss1Scheme` | Basic NDCG optimization | | NDCG Loss2 | `NDCGLoss2Scheme` | Improved NDCG with tighter bounds | | LambdaRank | `LambdaRankScheme` | Coarse upper bound optimization | | NDCG Loss2++ | `NDCGLoss2PPScheme` | Hybrid scheme (recommended) |  Sources: [sentence_transformers/cross_encoder/losses/LambdaLoss.py:103-361](), [sentence_transformers/cross_encoder/losses/LambdaLoss.py:12-101]()",
    "metadata": {
      "chunk_id": "a51716c2d709-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "filename": "Loss_Functions_for_CrossEncoder.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "LambdaLoss Framework"
      ],
      "heading_text": "LambdaLoss Framework",
      "token_count": 423,
      "char_count": 1843,
      "start_char": 3948,
      "end_char": 5791,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5079650887573964,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.190312",
      "document_id": "a51716c2d709",
      "document_name": "Loss_Functions_for_CrossEncoder",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "source_filename": "Loss_Functions_for_CrossEncoder.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "hierarchy_path": "LambdaLoss Framework",
      "chunk_hash": "b598dbb5c5205784",
      "content_digest": "b598dbb5c5205784",
      "chunk_length": 1843,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "lambdaloss",
          "logits",
          "sorting",
          "ndcg",
          "weighting",
          "weights",
          "optimization",
          "subgraph",
          "pairs",
          "labels",
          "end",
          "weightingscheme",
          "scheme",
          "weightedprobas",
          "framework",
          "the",
          "class",
          "with",
          "schemes",
          "processing"
        ],
        "term_weights": [
          {
            "term": "lambdaloss",
            "tf": 6,
            "weight": 0.038217
          },
          {
            "term": "logits",
            "tf": 5,
            "weight": 0.031847
          },
          {
            "term": "sorting",
            "tf": 5,
            "weight": 0.031847
          },
          {
            "term": "ndcg",
            "tf": 5,
            "weight": 0.031847
          },
          {
            "term": "weighting",
            "tf": 4,
            "weight": 0.025478
          },
          {
            "term": "weights",
            "tf": 4,
            "weight": 0.025478
          },
          {
            "term": "optimization",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "subgraph",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "pairs",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "labels",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "end",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "weightingscheme",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "scheme",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "weightedprobas",
            "tf": 3,
            "weight": 0.019108
          },
          {
            "term": "framework",
            "tf": 2,
            "weight": 0.012739
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.012739
          },
          {
            "term": "class",
            "tf": 2,
            "weight": 0.012739
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.012739
          },
          {
            "term": "schemes",
            "tf": 2,
            "weight": 0.012739
          },
          {
            "term": "processing",
            "tf": 2,
            "weight": 0.012739
          }
        ],
        "unique_terms": 92,
        "total_terms": 157
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "LambdaLoss Framework",
        "labels",
        "lambdaloss",
        "logits",
        "ndcg",
        "optimization",
        "pairs",
        "sorting",
        "subgraph",
        "weighting",
        "weights"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5079650887573964,
      "overall": 0.735988362919132
    }
  },
  {
    "text": "### ListNet Loss\n\nThe `ListNetLoss` implements the ListNet ranking algorithm using cross-entropy between predicted and ground truth ranking distributions:\n\n```python",
    "metadata": {
      "chunk_id": "a51716c2d709-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "filename": "Loss_Functions_for_CrossEncoder.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ListNet Loss"
      ],
      "heading_text": "ListNet Loss",
      "token_count": 31,
      "char_count": 165,
      "start_char": 5795,
      "end_char": 5960,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.545,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.190897",
      "document_id": "a51716c2d709",
      "document_name": "Loss_Functions_for_CrossEncoder",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "source_filename": "Loss_Functions_for_CrossEncoder.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Loss_Functions_for_CrossEncoder.md",
      "hierarchy_path": "ListNet Loss",
      "chunk_hash": "df3e4980dd0f2dc4",
      "content_digest": "df3e4980dd0f2dc4",
      "chunk_length": 165,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "listnet",
          "the",
          "ranking",
          "loss",
          "listnetloss",
          "implements",
          "algorithm",
          "using",
          "cross",
          "entropy",
          "between",
          "predicted",
          "and",
          "ground",
          "truth",
          "distributions",
          "python"
        ],
        "term_weights": [
          {
            "term": "listnet",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "ranking",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "loss",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "listnetloss",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "implements",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "algorithm",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "cross",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "entropy",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "between",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "predicted",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "ground",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "truth",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "distributions",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.05
          }
        ],
        "unique_terms": 17,
        "total_terms": 20
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ListNet Loss",
        "algorithm",
        "cross",
        "entropy",
        "implements",
        "listnet",
        "listnetloss",
        "loss",
        "ranking",
        "the",
        "using"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.545,
      "overall": 0.6816666666666666
    }
  }
]
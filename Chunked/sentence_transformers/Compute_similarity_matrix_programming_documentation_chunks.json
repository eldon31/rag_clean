[
  {
    "text": "## Model Training Evolution\n\nThe MS MARCO models have evolved through multiple versions with different training methodologies:",
    "metadata": {
      "chunk_id": "a90936d62a1c-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Training Evolution"
      ],
      "heading_text": "Model Training Evolution",
      "token_count": 20,
      "char_count": 126,
      "start_char": 187,
      "end_char": 313,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.5723529411764706,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.983330",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "Model Training Evolution",
      "chunk_hash": "012f05022e27267c",
      "content_digest": "012f05022e27267c",
      "chunk_length": 126,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "training",
          "model",
          "evolution",
          "the",
          "marco",
          "models",
          "have",
          "evolved",
          "through",
          "multiple",
          "versions",
          "with",
          "different",
          "methodologies"
        ],
        "term_weights": [
          {
            "term": "training",
            "tf": 2,
            "weight": 0.133333
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "evolution",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "marco",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "have",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "evolved",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "versions",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "methodologies",
            "tf": 1,
            "weight": 0.066667
          }
        ],
        "unique_terms": 14,
        "total_terms": 15
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Training Evolution",
        "evolution",
        "evolved",
        "have",
        "marco",
        "model",
        "models",
        "multiple",
        "the",
        "through",
        "training"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.5723529411764706,
      "overall": 0.6907843137254902
    }
  },
  {
    "text": "### Version 3 Hard Negative Mining Process\n\nThe v3 models used an automated hard negative mining pipeline implemented with sentence-transformers utilities:\n\n1. **Initial Retrieval**: v2 `SentenceTransformer` models encoded queries and retrieved similar passages\n2. **Cross-Encoder Scoring**: `CrossEncoder(\"cross-encoder/ms-marco-electra-base\")` scored query-passage pairs\n3. **Hard Negative Mining**: `util.mine_hard_negatives()` identified passages with high bi-encoder similarity but low cross-encoder relevance scores\n4. **Retraining**: Models trained with `MultipleNegativesRankingLoss` using the mined hard negatives",
    "metadata": {
      "chunk_id": "a90936d62a1c-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Version 3 Hard Negative Mining Process"
      ],
      "heading_text": "Version 3 Hard Negative Mining Process",
      "token_count": 132,
      "char_count": 622,
      "start_char": 1350,
      "end_char": 1972,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5407462686567164,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.985090",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "Version 3 Hard Negative Mining Process",
      "chunk_hash": "582d09120a95186c",
      "content_digest": "582d09120a95186c",
      "chunk_length": 622,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "hard",
          "encoder",
          "negative",
          "mining",
          "models",
          "with",
          "cross",
          "the",
          "passages",
          "negatives",
          "version",
          "process",
          "used",
          "automated",
          "pipeline",
          "implemented",
          "sentence",
          "transformers",
          "utilities",
          "initial"
        ],
        "term_weights": [
          {
            "term": "hard",
            "tf": 5,
            "weight": 0.071429
          },
          {
            "term": "encoder",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "negative",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "mining",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "cross",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "passages",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "negatives",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "version",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "used",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "automated",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "pipeline",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "implemented",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "utilities",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "initial",
            "tf": 1,
            "weight": 0.014286
          }
        ],
        "unique_terms": 50,
        "total_terms": 70
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Version 3 Hard Negative Mining Process",
        "cross",
        "encoder",
        "hard",
        "mining",
        "models",
        "negative",
        "negatives",
        "passages",
        "the",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5407462686567164,
      "overall": 0.6469154228855721
    }
  },
  {
    "text": "## Model Selection Guidelines",
    "metadata": {
      "chunk_id": "a90936d62a1c-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Selection Guidelines"
      ],
      "heading_text": "Model Selection Guidelines",
      "token_count": 4,
      "char_count": 29,
      "start_char": 2536,
      "end_char": 2565,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7899999999999999,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.985599",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "Model Selection Guidelines",
      "chunk_hash": "01d249a713ad3e0f",
      "content_digest": "01d249a713ad3e0f",
      "chunk_length": 29,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "selection",
          "guidelines"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "selection",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "guidelines",
            "tf": 1,
            "weight": 0.333333
          }
        ],
        "unique_terms": 3,
        "total_terms": 3
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Selection Guidelines",
        "guidelines",
        "model",
        "selection"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7899999999999999,
      "overall": 0.83
    }
  },
  {
    "text": "### Choose Based on Similarity Method  - **Cosine Similarity Models**: Use when you need normalized similarity scores and prefer shorter, focused passages - **Dot Product Models**: Use when longer, comprehensive passages are preferred and unnormalized scores are acceptable",
    "metadata": {
      "chunk_id": "a90936d62a1c-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Choose Based on Similarity Method"
      ],
      "heading_text": "Choose Based on Similarity Method",
      "token_count": 49,
      "char_count": 273,
      "start_char": 2567,
      "end_char": 2840,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5110526315789473,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.985681",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "Choose Based on Similarity Method",
      "chunk_hash": "9d420b0a179e99d0",
      "content_digest": "9d420b0a179e99d0",
      "chunk_length": 273,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "similarity",
          "models",
          "use",
          "when",
          "scores",
          "and",
          "passages",
          "are",
          "choose",
          "based",
          "method",
          "cosine",
          "you",
          "need",
          "normalized",
          "prefer",
          "shorter",
          "focused",
          "dot",
          "product"
        ],
        "term_weights": [
          {
            "term": "similarity",
            "tf": 3,
            "weight": 0.088235
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "use",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "when",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "scores",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "passages",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "choose",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "method",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "cosine",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "need",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "normalized",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "prefer",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "shorter",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "focused",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "dot",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "product",
            "tf": 1,
            "weight": 0.029412
          }
        ],
        "unique_terms": 25,
        "total_terms": 34
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Choose Based on Similarity Method",
        "and",
        "are",
        "based",
        "choose",
        "models",
        "passages",
        "scores",
        "similarity",
        "use",
        "when"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5110526315789473,
      "overall": 0.7370175438596491
    }
  },
  {
    "text": "### Choose Based on Architecture\n\n```mermaid\ngraph TD\n    RETRIEVAL_TASK[\"Retrieval Task\"]\n    \n    RETRIEVAL_TASK --> FIRST_STAGE[\"First Stage Retrieval<br/>encode() + similarity search\"]\n    RETRIEVAL_TASK --> SECOND_STAGE[\"Second Stage Reranking<br/>predict() on pairs\"]\n    \n    FIRST_STAGE --> ST_CLASS[\"SentenceTransformer class\"]\n    SECOND_STAGE --> CE_CLASS[\"CrossEncoder class\"]\n    \n    ST_CLASS --> ST_FAST[\"Fast: msmarco-MiniLM-L6-v3<br/>18k queries/sec GPU\"]\n    ST_CLASS --> ST_BALANCED[\"Balanced: msmarco-distilbert-base-v4<br/>7k queries/sec, 70.24 NDCG@10\"]\n    ST_CLASS --> ST_ACCURATE[\"Accurate: msmarco-distilbert-base-tas-b<br/>71.04 NDCG@10, 34.43 MRR@10\"]\n    \n    CE_CLASS --> CE_FAST[\"Fast: cross-encoder/ms-marco-TinyBERT-L2-v2<br/>9k docs/sec\"]\n    CE_CLASS --> CE_ACCURATE[\"Accurate: cross-encoder/ms-marco-MiniLM-L6-v2<br/>74.30 NDCG@10, 39.01 MRR@10\"]\n    \n    subgraph \"Integration Methods\"\n        UTIL_COS[\"util.cos_sim()\"]\n        UTIL_DOT[\"util.dot_score()\"] \n        PREDICT_METHOD[\"predict() method\"]\n    end\n    \n    ST_FAST --> UTIL_COS\n    ST_BALANCED --> UTIL_COS\n    ST_ACCURATE --> UTIL_DOT\n    CE_FAST --> PREDICT_METHOD\n    CE_ACCURATE --> PREDICT_METHOD\n```",
    "metadata": {
      "chunk_id": "a90936d62a1c-0006",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Choose Based on Architecture"
      ],
      "heading_text": "Choose Based on Architecture",
      "token_count": 363,
      "char_count": 1204,
      "start_char": 2842,
      "end_char": 4046,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7,
      "retrieval_quality": 0.5280011235955057,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.986869",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "Choose Based on Architecture",
      "chunk_hash": "056b874f3a0a6bd1",
      "content_digest": "056b874f3a0a6bd1",
      "chunk_length": 1204,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "class",
          "util",
          "stage",
          "fast",
          "accurate",
          "retrieval",
          "predict",
          "task",
          "cos",
          "method",
          "first",
          "second",
          "msmarco",
          "sec",
          "balanced",
          "ndcg",
          "dot",
          "minilm",
          "queries",
          "distilbert"
        ],
        "term_weights": [
          {
            "term": "class",
            "tf": 9,
            "weight": 0.077586
          },
          {
            "term": "util",
            "tf": 7,
            "weight": 0.060345
          },
          {
            "term": "stage",
            "tf": 6,
            "weight": 0.051724
          },
          {
            "term": "fast",
            "tf": 6,
            "weight": 0.051724
          },
          {
            "term": "accurate",
            "tf": 6,
            "weight": 0.051724
          },
          {
            "term": "retrieval",
            "tf": 5,
            "weight": 0.043103
          },
          {
            "term": "predict",
            "tf": 5,
            "weight": 0.043103
          },
          {
            "term": "task",
            "tf": 4,
            "weight": 0.034483
          },
          {
            "term": "cos",
            "tf": 4,
            "weight": 0.034483
          },
          {
            "term": "method",
            "tf": 4,
            "weight": 0.034483
          },
          {
            "term": "first",
            "tf": 3,
            "weight": 0.025862
          },
          {
            "term": "second",
            "tf": 3,
            "weight": 0.025862
          },
          {
            "term": "msmarco",
            "tf": 3,
            "weight": 0.025862
          },
          {
            "term": "sec",
            "tf": 3,
            "weight": 0.025862
          },
          {
            "term": "balanced",
            "tf": 3,
            "weight": 0.025862
          },
          {
            "term": "ndcg",
            "tf": 3,
            "weight": 0.025862
          },
          {
            "term": "dot",
            "tf": 3,
            "weight": 0.025862
          },
          {
            "term": "minilm",
            "tf": 2,
            "weight": 0.017241
          },
          {
            "term": "queries",
            "tf": 2,
            "weight": 0.017241
          },
          {
            "term": "distilbert",
            "tf": 2,
            "weight": 0.017241
          }
        ],
        "unique_terms": 48,
        "total_terms": 116
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Choose Based on Architecture",
        "accurate",
        "class",
        "cos",
        "fast",
        "method",
        "predict",
        "retrieval",
        "stage",
        "task",
        "util"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7,
      "retrieval_quality": 0.5280011235955057,
      "overall": 0.6760003745318351
    }
  },
  {
    "text": "### Performance vs Speed Trade-offs  - **Fastest**: `msmarco-MiniLM-L6-v3` (18,000 queries/sec GPU) - **Best Balance**: `msmarco-distilbert-base-v4` (7,000 queries/sec GPU, highest accuracy) - **Highest Quality**: `msmarco-distilbert-base-tas-b` (34.43 MRR@10)  **Sources:** [docs/pretrained-models/msmarco-v3.md:45-50]()",
    "metadata": {
      "chunk_id": "a90936d62a1c-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance vs Speed Trade-offs"
      ],
      "heading_text": "Performance vs Speed Trade-offs",
      "token_count": 106,
      "char_count": 321,
      "start_char": 4048,
      "end_char": 4369,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5578571428571428,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.987379",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "Performance vs Speed Trade-offs",
      "chunk_hash": "2a5150b8d8b66ac6",
      "content_digest": "2a5150b8d8b66ac6",
      "chunk_length": 321,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "msmarco",
          "000",
          "queries",
          "sec",
          "gpu",
          "distilbert",
          "base",
          "highest",
          "performance",
          "speed",
          "trade",
          "offs",
          "fastest",
          "minilm",
          "best",
          "balance",
          "accuracy",
          "quality",
          "tas",
          "mrr"
        ],
        "term_weights": [
          {
            "term": "msmarco",
            "tf": 4,
            "weight": 0.117647
          },
          {
            "term": "000",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "queries",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "sec",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "gpu",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "distilbert",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "base",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "highest",
            "tf": 2,
            "weight": 0.058824
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "speed",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "trade",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "offs",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "fastest",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "minilm",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "best",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "balance",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "accuracy",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "quality",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "tas",
            "tf": 1,
            "weight": 0.029412
          },
          {
            "term": "mrr",
            "tf": 1,
            "weight": 0.029412
          }
        ],
        "unique_terms": 24,
        "total_terms": 34
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "000",
        "Performance vs Speed Trade-offs",
        "base",
        "distilbert",
        "gpu",
        "highest",
        "msmarco",
        "performance",
        "queries",
        "sec",
        "speed"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5578571428571428,
      "overall": 0.7192857142857143
    }
  },
  {
    "text": "## Integration with Search Systems\n\nMS MARCO models integrate with various search architectures for production deployment. For detailed integration patterns, see [Retrieve & Rerank Architecture](#6.3) and [Semantic Search](#6.1).\n\n**Sources:** [docs/pretrained-models/msmarco-v3.md:19](), [docs/cross_encoder/pretrained_models.md:44]()",
    "metadata": {
      "chunk_id": "a90936d62a1c-0008",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration with Search Systems"
      ],
      "heading_text": "Integration with Search Systems",
      "token_count": 79,
      "char_count": 335,
      "start_char": 4371,
      "end_char": 4706,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5512903225806451,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.987467",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "Integration with Search Systems",
      "chunk_hash": "f2007a217dcbc387",
      "content_digest": "f2007a217dcbc387",
      "chunk_length": 335,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "models",
          "integration",
          "with",
          "for",
          "docs",
          "pretrained",
          "systems",
          "marco",
          "integrate",
          "various",
          "architectures",
          "production",
          "deployment",
          "detailed",
          "patterns",
          "see",
          "retrieve",
          "rerank",
          "architecture"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 3,
            "weight": 0.085714
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.085714
          },
          {
            "term": "integration",
            "tf": 2,
            "weight": 0.057143
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.057143
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.057143
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.057143
          },
          {
            "term": "pretrained",
            "tf": 2,
            "weight": 0.057143
          },
          {
            "term": "systems",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "marco",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "integrate",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "various",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "architectures",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "production",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "deployment",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "detailed",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "patterns",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "see",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "retrieve",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "rerank",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "architecture",
            "tf": 1,
            "weight": 0.028571
          }
        ],
        "unique_terms": 26,
        "total_terms": 35
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration with Search Systems",
        "docs",
        "for",
        "integrate",
        "integration",
        "marco",
        "models",
        "pretrained",
        "search",
        "systems",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5512903225806451,
      "overall": 0.6837634408602149
    }
  },
  {
    "text": "# Applications\n\n\n\n\nThis page provides an overview of real-world applications and integration patterns using sentence-transformers models. It covers how the three core model types (`SentenceTransformer`, `SparseEncoder`, and `CrossEncoder`) are deployed in production systems for semantic search, retrieval, reranking, and other natural language processing tasks.\n\nFor specific implementation details of individual applications, see [Semantic Search](#6.1), [Sparse Search Integration](#6.2), [Retrieve & Rerank Architecture](#6.3), [Semantic Textual Similarity](#6.4), and [Multimodal Applications](#6.5). For information about available pretrained models optimized for specific applications, see [Pretrained Models](#5).",
    "metadata": {
      "chunk_id": "a90936d62a1c-0009",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Applications"
      ],
      "heading_text": "Applications",
      "token_count": 148,
      "char_count": 721,
      "start_char": 4708,
      "end_char": 5429,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.545,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.988065",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "Applications",
      "chunk_hash": "aab5346126af7bc5",
      "content_digest": "aab5346126af7bc5",
      "chunk_length": 721,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "applications",
          "and",
          "for",
          "models",
          "semantic",
          "search",
          "integration",
          "specific",
          "see",
          "pretrained",
          "this",
          "page",
          "provides",
          "overview",
          "real",
          "world",
          "patterns",
          "using",
          "sentence",
          "transformers"
        ],
        "term_weights": [
          {
            "term": "applications",
            "tf": 5,
            "weight": 0.066667
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.053333
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.053333
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.04
          },
          {
            "term": "semantic",
            "tf": 3,
            "weight": 0.04
          },
          {
            "term": "search",
            "tf": 3,
            "weight": 0.04
          },
          {
            "term": "integration",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "specific",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "see",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "pretrained",
            "tf": 2,
            "weight": 0.026667
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "page",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "overview",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "real",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "world",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "patterns",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.013333
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.013333
          }
        ],
        "unique_terms": 55,
        "total_terms": 75
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Applications",
        "and",
        "applications",
        "for",
        "integration",
        "models",
        "pretrained",
        "search",
        "see",
        "semantic",
        "specific"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.545,
      "overall": 0.715
    }
  },
  {
    "text": "## Core Application Categories\n\nThe sentence-transformers library enables three primary categories of applications, each leveraging different model architectures optimized for specific use cases:",
    "metadata": {
      "chunk_id": "a90936d62a1c-0010",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Core Application Categories"
      ],
      "heading_text": "Core Application Categories",
      "token_count": 28,
      "char_count": 195,
      "start_char": 5431,
      "end_char": 5626,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.5769565217391305,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.988065",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "Core Application Categories",
      "chunk_hash": "4cc40b377b3b3a9b",
      "content_digest": "4cc40b377b3b3a9b",
      "chunk_length": 195,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "categories",
          "core",
          "application",
          "the",
          "sentence",
          "transformers",
          "library",
          "enables",
          "three",
          "primary",
          "applications",
          "each",
          "leveraging",
          "different",
          "model",
          "architectures",
          "optimized",
          "for",
          "specific",
          "use"
        ],
        "term_weights": [
          {
            "term": "categories",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "core",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "application",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "enables",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "three",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "primary",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "applications",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "each",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "leveraging",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "architectures",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "optimized",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "specific",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.045455
          }
        ],
        "unique_terms": 21,
        "total_terms": 22
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Core Application Categories",
        "application",
        "categories",
        "core",
        "enables",
        "library",
        "primary",
        "sentence",
        "the",
        "three",
        "transformers"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.5769565217391305,
      "overall": 0.6923188405797102
    }
  },
  {
    "text": "### Application Architecture Overview\n\n```mermaid\ngraph TB\n    subgraph \"Dense Embedding Applications\"\n        ST[\"SentenceTransformer\"]\n        ST --> SemanticSearch[\"Semantic Search\"]\n        ST --> Clustering[\"Document Clustering\"]\n        ST --> STS[\"Semantic Textual Similarity\"]\n        ST --> Recommendation[\"Content Recommendation\"]\n    end\n    \n    subgraph \"Sparse Embedding Applications\" \n        SE[\"SparseEncoder\"]\n        SE --> NeuralLexical[\"Neural Lexical Search\"]\n        SE --> HybridRetrieval[\"Hybrid Dense-Sparse Retrieval\"]\n        SE --> KeywordSearch[\"Enhanced Keyword Search\"]\n    end\n    \n    subgraph \"Cross-Attention Applications\"\n        CE[\"CrossEncoder\"]\n        CE --> Reranking[\"Search Result Reranking\"]\n        CE --> Classification[\"Text Pair Classification\"]\n        CE --> ScoreRegression[\"Similarity Score Regression\"]\n    end\n    \n    subgraph \"Output Formats\"\n        SemanticSearch --> DenseVectors[\"Dense Vectors (384-1024 dim)\"]\n        NeuralLexical --> SparseVectors[\"Sparse Vectors (30k+ dim)\"]\n        Reranking --> SimilarityScores[\"Similarity Scores (0-1)\"]\n    end\n```\n\n**Dense embedding applications** use `SentenceTransformer` models to convert text into fixed-size dense vectors that capture semantic meaning. These applications excel at finding semantically similar content even when lexical overlap is minimal.\n\n**Sparse embedding applications** use `SparseEncoder` models to generate high-dimensional sparse vectors that preserve lexical information while adding semantic understanding. These applications bridge the gap between traditional keyword search and semantic search.\n\n**Cross-attention applications** use `CrossEncoder` models that jointly process text pairs to produce precise similarity scores. These applications provide the highest accuracy for ranking and classification tasks but with higher computational cost.\n\nSources: [docs/pretrained-models/msmarco-v2.md:1-39]()",
    "metadata": {
      "chunk_id": "a90936d62a1c-0011",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Application Architecture Overview"
      ],
      "heading_text": "Application Architecture Overview",
      "token_count": 386,
      "char_count": 1940,
      "start_char": 5628,
      "end_char": 7568,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5232468085106383,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.989408",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "Application Architecture Overview",
      "chunk_hash": "db3a79d43cb147c2",
      "content_digest": "db3a79d43cb147c2",
      "chunk_length": 1940,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "applications",
          "search",
          "dense",
          "semantic",
          "sparse",
          "subgraph",
          "embedding",
          "similarity",
          "end",
          "vectors",
          "models",
          "lexical",
          "reranking",
          "classification",
          "text",
          "use",
          "that",
          "these",
          "sentencetransformer",
          "semanticsearch"
        ],
        "term_weights": [
          {
            "term": "applications",
            "tf": 9,
            "weight": 0.050562
          },
          {
            "term": "search",
            "tf": 6,
            "weight": 0.033708
          },
          {
            "term": "dense",
            "tf": 5,
            "weight": 0.02809
          },
          {
            "term": "semantic",
            "tf": 5,
            "weight": 0.02809
          },
          {
            "term": "sparse",
            "tf": 5,
            "weight": 0.02809
          },
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.022472
          },
          {
            "term": "embedding",
            "tf": 4,
            "weight": 0.022472
          },
          {
            "term": "similarity",
            "tf": 4,
            "weight": 0.022472
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.022472
          },
          {
            "term": "vectors",
            "tf": 4,
            "weight": 0.022472
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.022472
          },
          {
            "term": "lexical",
            "tf": 3,
            "weight": 0.016854
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.016854
          },
          {
            "term": "classification",
            "tf": 3,
            "weight": 0.016854
          },
          {
            "term": "text",
            "tf": 3,
            "weight": 0.016854
          },
          {
            "term": "use",
            "tf": 3,
            "weight": 0.016854
          },
          {
            "term": "that",
            "tf": 3,
            "weight": 0.016854
          },
          {
            "term": "these",
            "tf": 3,
            "weight": 0.016854
          },
          {
            "term": "sentencetransformer",
            "tf": 2,
            "weight": 0.011236
          },
          {
            "term": "semanticsearch",
            "tf": 2,
            "weight": 0.011236
          }
        ],
        "unique_terms": 106,
        "total_terms": 178
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Application Architecture Overview",
        "applications",
        "dense",
        "embedding",
        "end",
        "search",
        "semantic",
        "similarity",
        "sparse",
        "subgraph",
        "vectors"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5232468085106383,
      "overall": 0.7077489361702126
    }
  },
  {
    "text": "## Integration Patterns\n\nProduction systems typically integrate sentence-transformers models through several common patterns, each optimized for different scalability and accuracy requirements:",
    "metadata": {
      "chunk_id": "a90936d62a1c-0012",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration Patterns"
      ],
      "heading_text": "Integration Patterns",
      "token_count": 26,
      "char_count": 193,
      "start_char": 7570,
      "end_char": 7763,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.989408",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "Integration Patterns",
      "chunk_hash": "e2457b600a7b82a0",
      "content_digest": "e2457b600a7b82a0",
      "chunk_length": 193,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "patterns",
          "integration",
          "production",
          "systems",
          "typically",
          "integrate",
          "sentence",
          "transformers",
          "models",
          "through",
          "several",
          "common",
          "each",
          "optimized",
          "for",
          "different",
          "scalability",
          "and",
          "accuracy",
          "requirements"
        ],
        "term_weights": [
          {
            "term": "patterns",
            "tf": 2,
            "weight": 0.095238
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "production",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "systems",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "typically",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "integrate",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "sentence",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "transformers",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "several",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "common",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "each",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "optimized",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "scalability",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "accuracy",
            "tf": 1,
            "weight": 0.047619
          },
          {
            "term": "requirements",
            "tf": 1,
            "weight": 0.047619
          }
        ],
        "unique_terms": 20,
        "total_terms": 21
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration Patterns",
        "integrate",
        "integration",
        "models",
        "patterns",
        "production",
        "sentence",
        "systems",
        "through",
        "transformers",
        "typically"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.59,
      "overall": 0.6966666666666667
    }
  },
  {
    "text": "### System Integration Architecture\n\n```mermaid\ngraph LR\n    subgraph \"Data Sources\"\n        Documents[\"Document Corpus\"]\n        Queries[\"User Queries\"]\n        TextPairs[\"Text Pairs\"]\n    end\n    \n    subgraph \"sentence_transformers\"\n        STModel[\"SentenceTransformer.encode()\"]\n        SEModel[\"SparseEncoder.encode_query()\"]\n        CEModel[\"CrossEncoder.predict()\"]\n    end\n    \n    subgraph \"Storage Systems\"\n        VectorDB[\"Vector Databases<br/>Pinecone, Weaviate, Qdrant\"]\n        SearchEngines[\"Search Engines<br/>Elasticsearch, OpenSearch\"]\n        Cache[\"Embedding Cache<br/>Redis, Memcached\"]\n    end\n    \n    subgraph \"Application Layer\"\n        SearchAPI[\"Search API\"]\n        RerankAPI[\"Reranking API\"]\n        SimilarityAPI[\"Similarity API\"]\n    end\n    \n    Documents --> STModel\n    Documents --> SEModel\n    STModel --> VectorDB\n    SEModel --> SearchEngines\n    \n    Queries --> STModel\n    Queries --> SEModel\n    Queries --> CEModel\n    \n    VectorDB --> SearchAPI\n    SearchEngines --> SearchAPI\n    Cache --> SearchAPI\n    \n    TextPairs --> CEModel\n    CEModel --> RerankAPI\n    CEModel --> SimilarityAPI\n    \n    SearchAPI --> RerankAPI\n```\n\n**Vector database integration** stores dense embeddings from `SentenceTransformer.encode()` in specialized vector databases optimized for similarity search. Common databases include Pinecone, Weaviate, and Qdrant, which provide approximate nearest neighbor search capabilities.\n\n**Search engine integration** indexes sparse embeddings from `SparseEncoder.encode_query()` and `SparseEncoder.encode_document()` in traditional search engines like Elasticsearch or OpenSearch, enabling hybrid lexical-semantic search.\n\n**API-based reranking** uses `CrossEncoder.predict()` to refine initial retrieval results, typically processing the top-k candidates from a faster first-stage retrieval system.\n\nSources: [docs/pretrained-models/msmarco-v2.md:7-16]()",
    "metadata": {
      "chunk_id": "a90936d62a1c-0013",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "System Integration Architecture"
      ],
      "heading_text": "System Integration Architecture",
      "token_count": 415,
      "char_count": 1920,
      "start_char": 7765,
      "end_char": 9685,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5366951219512195,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.991210",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "System Integration Architecture",
      "chunk_hash": "801fc9ca07077f28",
      "content_digest": "801fc9ca07077f28",
      "chunk_length": 1920,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "search",
          "queries",
          "encode",
          "cemodel",
          "searchapi",
          "subgraph",
          "end",
          "stmodel",
          "semodel",
          "api",
          "integration",
          "documents",
          "sparseencoder",
          "vectordb",
          "vector",
          "databases",
          "searchengines",
          "cache",
          "rerankapi",
          "from"
        ],
        "term_weights": [
          {
            "term": "search",
            "tf": 7,
            "weight": 0.04023
          },
          {
            "term": "queries",
            "tf": 5,
            "weight": 0.028736
          },
          {
            "term": "encode",
            "tf": 5,
            "weight": 0.028736
          },
          {
            "term": "cemodel",
            "tf": 5,
            "weight": 0.028736
          },
          {
            "term": "searchapi",
            "tf": 5,
            "weight": 0.028736
          },
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.022989
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.022989
          },
          {
            "term": "stmodel",
            "tf": 4,
            "weight": 0.022989
          },
          {
            "term": "semodel",
            "tf": 4,
            "weight": 0.022989
          },
          {
            "term": "api",
            "tf": 4,
            "weight": 0.022989
          },
          {
            "term": "integration",
            "tf": 3,
            "weight": 0.017241
          },
          {
            "term": "documents",
            "tf": 3,
            "weight": 0.017241
          },
          {
            "term": "sparseencoder",
            "tf": 3,
            "weight": 0.017241
          },
          {
            "term": "vectordb",
            "tf": 3,
            "weight": 0.017241
          },
          {
            "term": "vector",
            "tf": 3,
            "weight": 0.017241
          },
          {
            "term": "databases",
            "tf": 3,
            "weight": 0.017241
          },
          {
            "term": "searchengines",
            "tf": 3,
            "weight": 0.017241
          },
          {
            "term": "cache",
            "tf": 3,
            "weight": 0.017241
          },
          {
            "term": "rerankapi",
            "tf": 3,
            "weight": 0.017241
          },
          {
            "term": "from",
            "tf": 3,
            "weight": 0.017241
          }
        ],
        "unique_terms": 97,
        "total_terms": 174
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "System Integration Architecture",
        "api",
        "cemodel",
        "encode",
        "end",
        "queries",
        "search",
        "searchapi",
        "semodel",
        "stmodel",
        "subgraph"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5366951219512195,
      "overall": 0.7122317073170731
    }
  },
  {
    "text": "### Two-Stage Retrieval Architecture\n\nThe most common production pattern combines fast retrieval with precise reranking:\n\n```mermaid\ngraph TD\n    UserQuery[\"User Query\"]\n    \n    subgraph \"Stage 1: Fast Retrieval\"\n        BiEncoder[\"SentenceTransformer<br/>or SparseEncoder\"]\n        CandidateRetrieval[\"Retrieve Top-100<br/>Candidates\"]\n    end\n    \n    subgraph \"Stage 2: Precise Reranking\"\n        CrossEncoder[\"CrossEncoder.predict()\"]\n        FinalRanking[\"Return Top-10<br/>Results\"]\n    end\n    \n    UserQuery --> BiEncoder\n    BiEncoder --> CandidateRetrieval\n    CandidateRetrieval --> CrossEncoder\n    CrossEncoder --> FinalRanking\n```\n\nThis architecture balances computational efficiency with accuracy by using fast bi-encoder models for initial retrieval and slower but more accurate cross-encoder models for final ranking.",
    "metadata": {
      "chunk_id": "a90936d62a1c-0015",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "filename": "Compute_similarity_matrix.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Two-Stage Retrieval Architecture"
      ],
      "heading_text": "Two-Stage Retrieval Architecture",
      "token_count": 181,
      "char_count": 835,
      "start_char": 9722,
      "end_char": 10557,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5198701298701298,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.991813",
      "document_id": "a90936d62a1c",
      "document_name": "Compute_similarity_matrix",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "source_filename": "Compute_similarity_matrix.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Compute_similarity_matrix.md",
      "hierarchy_path": "Two-Stage Retrieval Architecture",
      "chunk_hash": "a9f68b85ef92e6c4",
      "content_digest": "a9f68b85ef92e6c4",
      "chunk_length": 835,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "retrieval",
          "crossencoder",
          "stage",
          "fast",
          "biencoder",
          "candidateretrieval",
          "architecture",
          "with",
          "precise",
          "reranking",
          "userquery",
          "subgraph",
          "top",
          "end",
          "finalranking",
          "encoder",
          "models",
          "for",
          "two",
          "the"
        ],
        "term_weights": [
          {
            "term": "retrieval",
            "tf": 4,
            "weight": 0.051282
          },
          {
            "term": "crossencoder",
            "tf": 4,
            "weight": 0.051282
          },
          {
            "term": "stage",
            "tf": 3,
            "weight": 0.038462
          },
          {
            "term": "fast",
            "tf": 3,
            "weight": 0.038462
          },
          {
            "term": "biencoder",
            "tf": 3,
            "weight": 0.038462
          },
          {
            "term": "candidateretrieval",
            "tf": 3,
            "weight": 0.038462
          },
          {
            "term": "architecture",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "precise",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "reranking",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "userquery",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "subgraph",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "top",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "finalranking",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.025641
          },
          {
            "term": "two",
            "tf": 1,
            "weight": 0.012821
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.012821
          }
        ],
        "unique_terms": 52,
        "total_terms": 78
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Two-Stage Retrieval Architecture",
        "architecture",
        "biencoder",
        "candidateretrieval",
        "crossencoder",
        "fast",
        "precise",
        "reranking",
        "retrieval",
        "stage",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5198701298701298,
      "overall": 0.7399567099567098
    }
  }
]
[
  {
    "text": "## Template System",
    "metadata": {
      "chunk_id": "6d5ecad88747-0017",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Template System"
      ],
      "heading_text": "Template System",
      "token_count": 3,
      "char_count": 18,
      "start_char": 0,
      "end_char": 18,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:50:29.206564",
      "document_id": "6d5ecad88747",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Template System",
      "chunk_hash": "a6b717fcaa8ed430",
      "content_digest": "a6b717fcaa8ed430",
      "chunk_length": 18,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "template",
          "system"
        ],
        "term_weights": [
          {
            "term": "template",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Template System",
        "system",
        "template"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "## Backend Architecture and Optimization  The library supports multiple backend implementations for optimized inference across different deployment scenarios.",
    "metadata": {
      "chunk_id": "6d5ecad88747-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Backend Architecture and Optimization"
      ],
      "heading_text": "Backend Architecture and Optimization",
      "token_count": 20,
      "char_count": 158,
      "start_char": 0,
      "end_char": 158,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5733333333333334,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:50:29.200529",
      "document_id": "6d5ecad88747",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Backend Architecture and Optimization",
      "chunk_hash": "c83b4af4c05a1969",
      "content_digest": "c83b4af4c05a1969",
      "chunk_length": 158,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "backend",
          "architecture",
          "and",
          "optimization",
          "the",
          "library",
          "supports",
          "multiple",
          "implementations",
          "for",
          "optimized",
          "inference",
          "across",
          "different",
          "deployment",
          "scenarios"
        ],
        "term_weights": [
          {
            "term": "backend",
            "tf": 2,
            "weight": 0.117647
          },
          {
            "term": "architecture",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "optimization",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "multiple",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "implementations",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "optimized",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "across",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "deployment",
            "tf": 1,
            "weight": 0.058824
          },
          {
            "term": "scenarios",
            "tf": 1,
            "weight": 0.058824
          }
        ],
        "unique_terms": 16,
        "total_terms": 17
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Backend Architecture and Optimization",
        "and",
        "architecture",
        "backend",
        "for",
        "implementations",
        "library",
        "multiple",
        "optimization",
        "supports",
        "the"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5733333333333334,
      "overall": 0.7577777777777778
    }
  },
  {
    "text": "### Dataset Information Extraction  The system automatically infers dataset metadata from Hugging Face Hub information: ```python",
    "metadata": {
      "chunk_id": "6d5ecad88747-0014",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Dataset Information Extraction"
      ],
      "heading_text": "Dataset Information Extraction",
      "token_count": 21,
      "char_count": 129,
      "start_char": 0,
      "end_char": 129,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.57125,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:50:29.205865",
      "document_id": "6d5ecad88747",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Dataset Information Extraction",
      "chunk_hash": "0a08c846afdf040d",
      "content_digest": "0a08c846afdf040d",
      "chunk_length": 129,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "dataset",
          "information",
          "extraction",
          "the",
          "system",
          "automatically",
          "infers",
          "metadata",
          "from",
          "hugging",
          "face",
          "hub",
          "python"
        ],
        "term_weights": [
          {
            "term": "dataset",
            "tf": 2,
            "weight": 0.133333
          },
          {
            "term": "information",
            "tf": 2,
            "weight": 0.133333
          },
          {
            "term": "extraction",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "automatically",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "infers",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "metadata",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "hugging",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "face",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "hub",
            "tf": 1,
            "weight": 0.066667
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.066667
          }
        ],
        "unique_terms": 13,
        "total_terms": 15
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Dataset Information Extraction",
        "automatically",
        "dataset",
        "extraction",
        "from",
        "hugging",
        "infers",
        "information",
        "metadata",
        "system",
        "the"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.57125,
      "overall": 0.7570833333333334
    }
  },
  {
    "text": "### Model Type Detection  The system automatically detects model characteristics for specialized documentation: ```python",
    "metadata": {
      "chunk_id": "6d5ecad88747-0019",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Type Detection"
      ],
      "heading_text": "Model Type Detection",
      "token_count": 17,
      "char_count": 121,
      "start_char": 0,
      "end_char": 121,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5685714285714286,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:50:29.206967",
      "document_id": "6d5ecad88747",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Model Type Detection",
      "chunk_hash": "60af71c2bd3a08d7",
      "content_digest": "60af71c2bd3a08d7",
      "chunk_length": 121,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "type",
          "detection",
          "the",
          "system",
          "automatically",
          "detects",
          "characteristics",
          "for",
          "specialized",
          "documentation",
          "python"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 2,
            "weight": 0.153846
          },
          {
            "term": "type",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "detection",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "automatically",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "detects",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "characteristics",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "specialized",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "documentation",
            "tf": 1,
            "weight": 0.076923
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.076923
          }
        ],
        "unique_terms": 12,
        "total_terms": 13
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Type Detection",
        "automatically",
        "characteristics",
        "detection",
        "detects",
        "for",
        "model",
        "specialized",
        "system",
        "the",
        "type"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5685714285714286,
      "overall": 0.7561904761904762
    }
  },
  {
    "text": "### Performance Optimization Techniques  The library implements several optimization strategies for production deployment:  | Optimization | Implementation | Use Case | |-------------|----------------|----------| | **Multi-Processing** | Process pools for batch encoding | Large-scale text processing | | **ONNX Conversion** | Model quantization and optimization | CPU inference optimization | | **Backend Selection** | Runtime backend switching | Hardware-specific optimization | | **Memory Management** | Gradient caching, efficient batching | Memory-constrained training | | **Sparse Operations** | Optimized sparse tensor operations | Sparse encoder efficiency |",
    "metadata": {
      "chunk_id": "6d5ecad88747-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "filename": "Example_of_automatic_statistics_generation.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Optimization Techniques"
      ],
      "heading_text": "Performance Optimization Techniques",
      "token_count": 113,
      "char_count": 666,
      "start_char": 0,
      "end_char": 666,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.4828571428571429,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:50:29.201702",
      "document_id": "6d5ecad88747",
      "document_name": "Example_of_automatic_statistics_generation",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "source_filename": "Example_of_automatic_statistics_generation.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Example_of_automatic_statistics_generation.md",
      "hierarchy_path": "Performance Optimization Techniques",
      "chunk_hash": "24b308f0e8787747",
      "content_digest": "24b308f0e8787747",
      "chunk_length": 666,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "optimization",
          "sparse",
          "for",
          "processing",
          "backend",
          "memory",
          "operations",
          "performance",
          "techniques",
          "the",
          "library",
          "implements",
          "several",
          "strategies",
          "production",
          "deployment",
          "implementation",
          "use",
          "case",
          "multi"
        ],
        "term_weights": [
          {
            "term": "optimization",
            "tf": 6,
            "weight": 0.096774
          },
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.048387
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "processing",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "backend",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "memory",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "operations",
            "tf": 2,
            "weight": 0.032258
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "techniques",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "implements",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "several",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "strategies",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "production",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "deployment",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "case",
            "tf": 1,
            "weight": 0.016129
          },
          {
            "term": "multi",
            "tf": 1,
            "weight": 0.016129
          }
        ],
        "unique_terms": 50,
        "total_terms": 62
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Optimization Techniques",
        "backend",
        "for",
        "memory",
        "operations",
        "optimization",
        "performance",
        "processing",
        "sparse",
        "techniques",
        "the"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.4828571428571429,
      "overall": 0.7276190476190476
    }
  }
]
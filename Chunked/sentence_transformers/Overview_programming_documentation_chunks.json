[
  {
    "text": "## Purpose and Scope\n\nThe sentence-transformers library is a comprehensive Python framework for accessing, using, and training state-of-the-art embedding and reranker models. It provides three core model types that serve different purposes in natural language processing pipelines: `SentenceTransformer` for dense embeddings, `SparseEncoder` for sparse embeddings, and `CrossEncoder` for pairwise scoring and reranking.\n\nThis document covers the high-level architecture and core concepts of the sentence-transformers library. For specific usage instructions, see [Quickstart Guide](#2.1). For detailed training procedures, see [Training](#3). For performance optimization, see [Advanced Topics](#7).\n\nSources: [README.md:15-21](), [sentence_transformers/__init__.py:27-34]()",
    "metadata": {
      "chunk_id": "4a318e767b6a-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Purpose and Scope"
      ],
      "heading_text": "Purpose and Scope",
      "token_count": 157,
      "char_count": 774,
      "start_char": 0,
      "end_char": 774,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7244827586206896,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.372497",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "Purpose and Scope",
      "chunk_hash": "5c73b63d3c2771fa",
      "content_digest": "5c73b63d3c2771fa",
      "chunk_length": 774,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "for",
          "and",
          "the",
          "sentence",
          "transformers",
          "training",
          "see",
          "library",
          "core",
          "embeddings",
          "purpose",
          "scope",
          "comprehensive",
          "python",
          "framework",
          "accessing",
          "using",
          "state",
          "art",
          "embedding"
        ],
        "term_weights": [
          {
            "term": "for",
            "tf": 7,
            "weight": 0.079545
          },
          {
            "term": "and",
            "tf": 6,
            "weight": 0.068182
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.045455
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "training",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "see",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "library",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "core",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "purpose",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "scope",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "comprehensive",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "framework",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "accessing",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "state",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "art",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.011364
          }
        ],
        "unique_terms": 63,
        "total_terms": 88
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Purpose and Scope",
        "and",
        "core",
        "embeddings",
        "for",
        "library",
        "see",
        "sentence",
        "the",
        "training",
        "transformers"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7244827586206896,
      "overall": 0.7081609195402297
    }
  },
  {
    "text": "## Core Architecture\n\nThe sentence-transformers library is built around three fundamental model architectures that can be used independently or in combination for various NLP tasks:\n\n```mermaid\ngraph TB\n    subgraph \"sentence_transformers Library\"\n        ST[\"SentenceTransformer<br/>Dense Embeddings\"]\n        SE[\"SparseEncoder<br/>Sparse Embeddings\"]\n        CE[\"CrossEncoder<br/>Pairwise Scoring\"]\n    end\n    \n    subgraph \"Core Functionality\"\n        ST --> |\"encode()\"| DenseEmb[\"Dense Vector<br/>Embeddings\"]\n        SE --> |\"encode_query()<br/>encode_document()\"| SparseEmb[\"Sparse Vector<br/>Embeddings\"]\n        CE --> |\"predict()<br/>rank()\"| Scores[\"Relevance<br/>Scores\"]\n    end\n    \n    subgraph \"Primary Applications\"\n        DenseEmb --> SemanticSearch[\"Semantic Search\"]\n        DenseEmb --> Clustering[\"Clustering\"]\n        SparseEmb --> NeuralLexical[\"Neural Lexical<br/>Search\"]\n        SparseEmb --> HybridRetrieval[\"Hybrid Retrieval\"]\n        Scores --> Reranking[\"Reranking\"]\n        Scores --> Classification[\"Text Classification\"]\n    end\n    \n    subgraph \"Training Infrastructure\"\n        STTrainer[\"SentenceTransformerTrainer\"]\n        SETrainer[\"SparseEncoderTrainer\"]\n        CETrainer[\"CrossEncoderTrainer\"]\n        \n        STTrainer --> ST\n        SETrainer --> SE\n        CETrainer --> CE\n    end\n```\n\nEach model type has corresponding trainer classes and specialized loss functions optimized for their specific use cases. The library provides over 15,000 pretrained models available through Hugging Face Hub.\n\nSources: [sentence_transformers/__init__.py:15-36](), [README.md:19](), [index.rst:12-15]()",
    "metadata": {
      "chunk_id": "4a318e767b6a-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Core Architecture"
      ],
      "heading_text": "Core Architecture",
      "token_count": 368,
      "char_count": 1637,
      "start_char": 776,
      "end_char": 2413,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7,
      "retrieval_quality": 0.5444909090909091,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.374275",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "Core Architecture",
      "chunk_hash": "f4e3f8e982873a01",
      "content_digest": "f4e3f8e982873a01",
      "chunk_length": 1637,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "subgraph",
          "embeddings",
          "end",
          "scores",
          "sentence",
          "transformers",
          "library",
          "encode",
          "denseemb",
          "sparseemb",
          "core",
          "the",
          "model",
          "for",
          "dense",
          "sparse",
          "vector",
          "search",
          "clustering",
          "reranking"
        ],
        "term_weights": [
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.02963
          },
          {
            "term": "embeddings",
            "tf": 4,
            "weight": 0.02963
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.02963
          },
          {
            "term": "scores",
            "tf": 4,
            "weight": 0.02963
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.022222
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.022222
          },
          {
            "term": "library",
            "tf": 3,
            "weight": 0.022222
          },
          {
            "term": "encode",
            "tf": 3,
            "weight": 0.022222
          },
          {
            "term": "denseemb",
            "tf": 3,
            "weight": 0.022222
          },
          {
            "term": "sparseemb",
            "tf": 3,
            "weight": 0.022222
          },
          {
            "term": "core",
            "tf": 2,
            "weight": 0.014815
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.014815
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.014815
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.014815
          },
          {
            "term": "dense",
            "tf": 2,
            "weight": 0.014815
          },
          {
            "term": "sparse",
            "tf": 2,
            "weight": 0.014815
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.014815
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.014815
          },
          {
            "term": "clustering",
            "tf": 2,
            "weight": 0.014815
          },
          {
            "term": "reranking",
            "tf": 2,
            "weight": 0.014815
          }
        ],
        "unique_terms": 97,
        "total_terms": 135
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Core Architecture",
        "denseemb",
        "embeddings",
        "encode",
        "end",
        "library",
        "scores",
        "sentence",
        "sparseemb",
        "subgraph",
        "transformers"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7,
      "retrieval_quality": 0.5444909090909091,
      "overall": 0.6814969696969696
    }
  },
  {
    "text": "## Model Types",
    "metadata": {
      "chunk_id": "4a318e767b6a-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Types"
      ],
      "heading_text": "Model Types",
      "token_count": 3,
      "char_count": 14,
      "start_char": 2415,
      "end_char": 2429,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.374275",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "Model Types",
      "chunk_hash": "fa462c843eb3388e",
      "content_digest": "fa462c843eb3388e",
      "chunk_length": 14,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "types"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "types",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Types",
        "model",
        "types"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### SentenceTransformer\n\nThe `SentenceTransformer` class produces dense vector embeddings where semantically similar texts have similar vector representations. These models use bi-encoder architectures that independently encode each input text.\n\n**Key characteristics:**\n- Output: Dense vectors (typically 384-1024 dimensions)\n- Use case: Semantic similarity, clustering, dense retrieval\n- Similarity functions: Cosine similarity, dot product, Euclidean distance\n- Example models: `all-MiniLM-L6-v2`, `all-mpnet-base-v2`\n\n**Basic usage pattern:**\n```python\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer(\"all-MiniLM-L6-v2\")\nembeddings = model.encode(sentences)\nsimilarities = model.similarity(embeddings, embeddings)\n```\n\nSources: [README.md:56-87](), [sentence_transformers/__init__.py:27]()",
    "metadata": {
      "chunk_id": "4a318e767b6a-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "SentenceTransformer"
      ],
      "heading_text": "SentenceTransformer",
      "token_count": 182,
      "char_count": 827,
      "start_char": 2431,
      "end_char": 3258,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7418518518518519,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.374880",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "SentenceTransformer",
      "chunk_hash": "c31c2f8aabe0898d",
      "content_digest": "c31c2f8aabe0898d",
      "chunk_length": 827,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sentencetransformer",
          "embeddings",
          "similarity",
          "dense",
          "all",
          "model",
          "vector",
          "similar",
          "models",
          "use",
          "encode",
          "minilm",
          "sentence",
          "transformers",
          "the",
          "class",
          "produces",
          "where",
          "semantically",
          "texts"
        ],
        "term_weights": [
          {
            "term": "sentencetransformer",
            "tf": 4,
            "weight": 0.047059
          },
          {
            "term": "embeddings",
            "tf": 4,
            "weight": 0.047059
          },
          {
            "term": "similarity",
            "tf": 4,
            "weight": 0.047059
          },
          {
            "term": "dense",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "all",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "similar",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "use",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "encode",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "minilm",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "produces",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "semantically",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "texts",
            "tf": 1,
            "weight": 0.011765
          }
        ],
        "unique_terms": 62,
        "total_terms": 85
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "SentenceTransformer",
        "all",
        "dense",
        "embeddings",
        "model",
        "models",
        "sentencetransformer",
        "similar",
        "similarity",
        "use",
        "vector"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7418518518518519,
      "overall": 0.7806172839506171
    }
  },
  {
    "text": "### SparseEncoder\n\nThe `SparseEncoder` class generates sparse vector embeddings where most dimensions are zero, creating interpretable representations that combine neural and lexical matching signals.\n\n**Key characteristics:**\n- Output: Sparse vectors (vocabulary-size dimensions, ~99% zeros)\n- Use case: Neural lexical search, hybrid retrieval, interpretability\n- Similarity functions: Dot product on sparse representations\n- Example models: `naver/splade-cocondenser-ensembledistil`\n\n**Basic usage pattern:**\n```python\nfrom sentence_transformers import SparseEncoder\nmodel = SparseEncoder(\"naver/splade-cocondenser-ensembledistil\")\nembeddings = model.encode(sentences)\nstats = SparseEncoder.sparsity(embeddings)\n```\n\nSources: [README.md:133-167](), [sentence_transformers/__init__.py:29-34]()",
    "metadata": {
      "chunk_id": "4a318e767b6a-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "SparseEncoder"
      ],
      "heading_text": "SparseEncoder",
      "token_count": 178,
      "char_count": 794,
      "start_char": 3260,
      "end_char": 4054,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7426315789473684,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.375466",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "SparseEncoder",
      "chunk_hash": "4b04677afe88dc2e",
      "content_digest": "4b04677afe88dc2e",
      "chunk_length": 794,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparseencoder",
          "sparse",
          "embeddings",
          "dimensions",
          "representations",
          "neural",
          "lexical",
          "naver",
          "splade",
          "cocondenser",
          "ensembledistil",
          "sentence",
          "transformers",
          "model",
          "the",
          "class",
          "generates",
          "vector",
          "where",
          "most"
        ],
        "term_weights": [
          {
            "term": "sparseencoder",
            "tf": 5,
            "weight": 0.060976
          },
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.036585
          },
          {
            "term": "embeddings",
            "tf": 3,
            "weight": 0.036585
          },
          {
            "term": "dimensions",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "representations",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "neural",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "lexical",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "naver",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "splade",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "cocondenser",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "ensembledistil",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.012195
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.012195
          },
          {
            "term": "generates",
            "tf": 1,
            "weight": 0.012195
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.012195
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.012195
          },
          {
            "term": "most",
            "tf": 1,
            "weight": 0.012195
          }
        ],
        "unique_terms": 63,
        "total_terms": 82
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "SparseEncoder",
        "cocondenser",
        "dimensions",
        "embeddings",
        "lexical",
        "naver",
        "neural",
        "representations",
        "sparse",
        "sparseencoder",
        "splade"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7426315789473684,
      "overall": 0.7808771929824561
    }
  },
  {
    "text": "### CrossEncoder\n\nThe `CrossEncoder` class performs joint encoding of text pairs to produce similarity scores, making it ideal for reranking and classification tasks where high precision is required.\n\n**Key characteristics:**\n- Output: Scalar similarity scores\n- Use case: Reranking, text pair classification, high-precision ranking\n- Architecture: Joint encoding (both texts processed together)\n- Example models: `cross-encoder/ms-marco-MiniLM-L6-v2`\n\n**Basic usage pattern:**\n```python\nfrom sentence_transformers import CrossEncoder\nmodel = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L6-v2\")\nscores = model.predict([(query, passage) for passage in passages])\nranks = model.rank(query, passages, return_documents=True)\n```\n\nSources: [README.md:89-132](), [sentence_transformers/__init__.py:15-20]()",
    "metadata": {
      "chunk_id": "4a318e767b6a-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "CrossEncoder"
      ],
      "heading_text": "CrossEncoder",
      "token_count": 184,
      "char_count": 800,
      "start_char": 4056,
      "end_char": 4856,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7471428571428571,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.376024",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "CrossEncoder",
      "chunk_hash": "b818bfc17e549af5",
      "content_digest": "b818bfc17e549af5",
      "chunk_length": 800,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "crossencoder",
          "scores",
          "model",
          "joint",
          "encoding",
          "text",
          "similarity",
          "for",
          "reranking",
          "classification",
          "high",
          "precision",
          "cross",
          "encoder",
          "marco",
          "minilm",
          "sentence",
          "transformers",
          "query",
          "passage"
        ],
        "term_weights": [
          {
            "term": "crossencoder",
            "tf": 4,
            "weight": 0.045455
          },
          {
            "term": "scores",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "joint",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "encoding",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "similarity",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "reranking",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "classification",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "high",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "precision",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "cross",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "marco",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "minilm",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "passage",
            "tf": 2,
            "weight": 0.022727
          }
        ],
        "unique_terms": 63,
        "total_terms": 88
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "CrossEncoder",
        "classification",
        "crossencoder",
        "encoding",
        "for",
        "joint",
        "model",
        "reranking",
        "scores",
        "similarity",
        "text"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7471428571428571,
      "overall": 0.7823809523809523
    }
  },
  {
    "text": "## Training Infrastructure\n\nEach model type has specialized training infrastructure with corresponding trainer classes, loss functions, and evaluation metrics:\n\n```mermaid\ngraph LR\n    subgraph \"Model Classes\"\n        ST_Model[\"SentenceTransformer\"]\n        SE_Model[\"SparseEncoder\"] \n        CE_Model[\"CrossEncoder\"]\n    end\n    \n    subgraph \"Trainer Classes\"\n        ST_Trainer[\"SentenceTransformerTrainer\"]\n        SE_Trainer[\"SparseEncoderTrainer\"]\n        CE_Trainer[\"CrossEncoderTrainer\"]\n    end\n    \n    subgraph \"Training Arguments\"\n        ST_Args[\"SentenceTransformerTrainingArguments\"]\n        SE_Args[\"SparseEncoderTrainingArguments\"]\n        CE_Args[\"CrossEncoderTrainingArguments\"]\n    end\n    \n    subgraph \"Model Cards\"\n        ST_Card[\"SentenceTransformerModelCardData\"]\n        SE_Card[\"SparseEncoderModelCardData\"]\n        CE_Card[\"CrossEncoderModelCardData\"]\n    end\n    \n    ST_Model --> ST_Trainer\n    SE_Model --> SE_Trainer\n    CE_Model --> CE_Trainer\n    \n    ST_Args --> ST_Trainer\n    SE_Args --> SE_Trainer\n    CE_Args --> CE_Trainer\n    \n    ST_Trainer --> ST_Card\n    SE_Trainer --> SE_Card\n    CE_Trainer --> CE_Card\n```\n\nThe library provides 20+ loss functions for SentenceTransformer training, 10+ for SparseEncoder training, and 10+ for CrossEncoder training, enabling fine-tuning for specific tasks and domains.\n\nSources: [sentence_transformers/__init__.py:35-64](), [README.md:195]()",
    "metadata": {
      "chunk_id": "4a318e767b6a-0006",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Training Infrastructure"
      ],
      "heading_text": "Training Infrastructure",
      "token_count": 328,
      "char_count": 1421,
      "start_char": 4858,
      "end_char": 6279,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7,
      "retrieval_quality": 0.5050037735849056,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.377602",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "Training Infrastructure",
      "chunk_hash": "8cc82ad7b433bc75",
      "content_digest": "8cc82ad7b433bc75",
      "chunk_length": 1421,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "trainer",
          "model",
          "training",
          "args",
          "card",
          "subgraph",
          "end",
          "for",
          "classes",
          "and",
          "infrastructure",
          "loss",
          "functions",
          "sentencetransformer",
          "sparseencoder",
          "crossencoder",
          "each",
          "type",
          "has",
          "specialized"
        ],
        "term_weights": [
          {
            "term": "trainer",
            "tf": 14,
            "weight": 0.130841
          },
          {
            "term": "model",
            "tf": 9,
            "weight": 0.084112
          },
          {
            "term": "training",
            "tf": 6,
            "weight": 0.056075
          },
          {
            "term": "args",
            "tf": 6,
            "weight": 0.056075
          },
          {
            "term": "card",
            "tf": 6,
            "weight": 0.056075
          },
          {
            "term": "subgraph",
            "tf": 4,
            "weight": 0.037383
          },
          {
            "term": "end",
            "tf": 4,
            "weight": 0.037383
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.037383
          },
          {
            "term": "classes",
            "tf": 3,
            "weight": 0.028037
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.028037
          },
          {
            "term": "infrastructure",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "loss",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "functions",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "sentencetransformer",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "sparseencoder",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "crossencoder",
            "tf": 2,
            "weight": 0.018692
          },
          {
            "term": "each",
            "tf": 1,
            "weight": 0.009346
          },
          {
            "term": "type",
            "tf": 1,
            "weight": 0.009346
          },
          {
            "term": "has",
            "tf": 1,
            "weight": 0.009346
          },
          {
            "term": "specialized",
            "tf": 1,
            "weight": 0.009346
          }
        ],
        "unique_terms": 52,
        "total_terms": 107
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Training Infrastructure",
        "and",
        "args",
        "card",
        "classes",
        "end",
        "for",
        "model",
        "subgraph",
        "trainer",
        "training"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7,
      "retrieval_quality": 0.5050037735849056,
      "overall": 0.6683345911949686
    }
  },
  {
    "text": "## Integration Ecosystem  The sentence-transformers library integrates with a wide ecosystem of tools and platforms:  **Backend Support:** - PyTorch (default) - ONNX Runtime for optimized inference - Intel OpenVINO for CPU optimization  **Vector Databases:** - Pinecone, Weaviate, Qdrant, ChromaDB  **Search Engines:** - Elasticsearch, OpenSearch, Apache Solr  **ML Frameworks:** - Hugging Face ecosystem (transformers, datasets, hub) - LangChain, Haystack, LlamaIndex  **Specialized Libraries:** - BERTopic, KeyBERT, SetFit for domain-specific applications  Sources: [sentence_transformers/__init__.py:10-14](), [README.md:172-189]()",
    "metadata": {
      "chunk_id": "4a318e767b6a-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integration Ecosystem"
      ],
      "heading_text": "Integration Ecosystem",
      "token_count": 156,
      "char_count": 634,
      "start_char": 6281,
      "end_char": 6915,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5435211267605634,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.377602",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "Integration Ecosystem",
      "chunk_hash": "aed7bf1df5a2b0fd",
      "content_digest": "aed7bf1df5a2b0fd",
      "chunk_length": 634,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "ecosystem",
          "transformers",
          "for",
          "sentence",
          "integration",
          "the",
          "library",
          "integrates",
          "with",
          "wide",
          "tools",
          "and",
          "platforms",
          "backend",
          "support",
          "pytorch",
          "default",
          "onnx",
          "runtime",
          "optimized"
        ],
        "term_weights": [
          {
            "term": "ecosystem",
            "tf": 3,
            "weight": 0.046154
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.046154
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.046154
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "integration",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "integrates",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "wide",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "tools",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "platforms",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "backend",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "pytorch",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "default",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "onnx",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "runtime",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "optimized",
            "tf": 1,
            "weight": 0.015385
          }
        ],
        "unique_terms": 58,
        "total_terms": 65
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integration Ecosystem",
        "ecosystem",
        "for",
        "integrates",
        "integration",
        "library",
        "sentence",
        "the",
        "transformers",
        "wide",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5435211267605634,
      "overall": 0.7478403755868545
    }
  },
  {
    "text": "## Module Architecture\n\nThe library follows a modular design where models are composed of reusable components:\n\n```mermaid\ngraph TB\n    subgraph \"Core Modules\"\n        Transformer[\"Transformer<br/>Base encoding\"]\n        Pooling[\"Pooling<br/>Sequence aggregation\"]\n        Router[\"Router<br/>Asymmetric routing\"]\n    end\n    \n    subgraph \"Specialized Modules\"\n        MLMTransformer[\"MLMTransformer<br/>Masked language modeling\"]\n        SpladePooling[\"SpladePooling<br/>Sparse activation\"]\n        CLIPModel[\"CLIPModel<br/>Vision-text joint encoding\"]\n    end\n    \n    subgraph \"Backend Options\"\n        PyTorchBackend[\"PyTorch Backend\"]\n        ONNXBackend[\"ONNX Backend\"]\n        OpenVINOBackend[\"OpenVINO Backend\"]\n    end\n    \n    Transformer --> Pooling\n    MLMTransformer --> SpladePooling\n    \n    Router --> Transformer\n    Router --> MLMTransformer\n    Router --> CLIPModel\n    \n    PyTorchBackend --> Router\n    ONNXBackend --> Router\n    OpenVINOBackend --> Router\n```\n\nThis modular architecture enables flexible model composition and optimization for different use cases. For detailed information about the module system, see [Module Architecture](#1.2).\n\nSources: [sentence_transformers/__init__.py:10-14](), [pyproject.toml:52-54]()",
    "metadata": {
      "chunk_id": "4a318e767b6a-0008",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Module Architecture"
      ],
      "heading_text": "Module Architecture",
      "token_count": 273,
      "char_count": 1248,
      "start_char": 6917,
      "end_char": 8165,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7,
      "retrieval_quality": 0.5105882352941177,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:47.378795",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "Module Architecture",
      "chunk_hash": "423b527f87c07dca",
      "content_digest": "423b527f87c07dca",
      "chunk_length": 1248,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "router",
          "transformer",
          "mlmtransformer",
          "backend",
          "module",
          "architecture",
          "subgraph",
          "pooling",
          "end",
          "spladepooling",
          "clipmodel",
          "the",
          "modular",
          "modules",
          "encoding",
          "pytorchbackend",
          "onnxbackend",
          "openvinobackend",
          "for",
          "library"
        ],
        "term_weights": [
          {
            "term": "router",
            "tf": 8,
            "weight": 0.074074
          },
          {
            "term": "transformer",
            "tf": 4,
            "weight": 0.037037
          },
          {
            "term": "mlmtransformer",
            "tf": 4,
            "weight": 0.037037
          },
          {
            "term": "backend",
            "tf": 4,
            "weight": 0.037037
          },
          {
            "term": "module",
            "tf": 3,
            "weight": 0.027778
          },
          {
            "term": "architecture",
            "tf": 3,
            "weight": 0.027778
          },
          {
            "term": "subgraph",
            "tf": 3,
            "weight": 0.027778
          },
          {
            "term": "pooling",
            "tf": 3,
            "weight": 0.027778
          },
          {
            "term": "end",
            "tf": 3,
            "weight": 0.027778
          },
          {
            "term": "spladepooling",
            "tf": 3,
            "weight": 0.027778
          },
          {
            "term": "clipmodel",
            "tf": 3,
            "weight": 0.027778
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.018519
          },
          {
            "term": "modular",
            "tf": 2,
            "weight": 0.018519
          },
          {
            "term": "modules",
            "tf": 2,
            "weight": 0.018519
          },
          {
            "term": "encoding",
            "tf": 2,
            "weight": 0.018519
          },
          {
            "term": "pytorchbackend",
            "tf": 2,
            "weight": 0.018519
          },
          {
            "term": "onnxbackend",
            "tf": 2,
            "weight": 0.018519
          },
          {
            "term": "openvinobackend",
            "tf": 2,
            "weight": 0.018519
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.018519
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.009259
          }
        ],
        "unique_terms": 70,
        "total_terms": 108
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Module Architecture",
        "architecture",
        "backend",
        "end",
        "mlmtransformer",
        "module",
        "pooling",
        "router",
        "spladepooling",
        "subgraph",
        "transformer"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7,
      "retrieval_quality": 0.5105882352941177,
      "overall": 0.6701960784313726
    }
  }
]
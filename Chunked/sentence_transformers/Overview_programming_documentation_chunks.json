[
  {
    "text": "## Model Types",
    "metadata": {
      "chunk_id": "4a318e767b6a-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Types"
      ],
      "heading_text": "Model Types",
      "token_count": 3,
      "char_count": 14,
      "start_char": 0,
      "end_char": 14,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:52:27.965882",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "Model Types",
      "chunk_hash": "fa462c843eb3388e",
      "content_digest": "fa462c843eb3388e",
      "chunk_length": 14,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "types"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "types",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Types",
        "model",
        "types"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### SparseEncoder  The `SparseEncoder` class generates sparse vector embeddings where most dimensions are zero, creating interpretable representations that combine neural and lexical matching signals. **Key characteristics:** - Output: Sparse vectors (vocabulary-size dimensions, ~99% zeros) - Use case: Neural lexical search, hybrid retrieval, interpretability - Similarity functions: Dot product on sparse representations - Example models: `naver/splade-cocondenser-ensembledistil`  **Basic usage pattern:** ```python from sentence_transformers import SparseEncoder model = SparseEncoder(\"naver/splade-cocondenser-ensembledistil\") embeddings = model.encode(sentences) stats = SparseEncoder.sparsity(embeddings) ``` Sources: [README.md:133-167](), [sentence_transformers/__init__.py:29-34]()",
    "metadata": {
      "chunk_id": "4a318e767b6a-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "SparseEncoder"
      ],
      "heading_text": "SparseEncoder",
      "token_count": 171,
      "char_count": 792,
      "start_char": 0,
      "end_char": 792,
      "semantic_score": 0.4185401499271393,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7426315789473684,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:52:27.966684",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "SparseEncoder",
      "chunk_hash": "d094e8b928f6902e",
      "content_digest": "d094e8b928f6902e",
      "chunk_length": 792,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sparseencoder",
          "sparse",
          "embeddings",
          "dimensions",
          "representations",
          "neural",
          "lexical",
          "naver",
          "splade",
          "cocondenser",
          "ensembledistil",
          "sentence",
          "transformers",
          "model",
          "the",
          "class",
          "generates",
          "vector",
          "where",
          "most"
        ],
        "term_weights": [
          {
            "term": "sparseencoder",
            "tf": 5,
            "weight": 0.060976
          },
          {
            "term": "sparse",
            "tf": 3,
            "weight": 0.036585
          },
          {
            "term": "embeddings",
            "tf": 3,
            "weight": 0.036585
          },
          {
            "term": "dimensions",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "representations",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "neural",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "lexical",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "naver",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "splade",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "cocondenser",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "ensembledistil",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.02439
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.012195
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.012195
          },
          {
            "term": "generates",
            "tf": 1,
            "weight": 0.012195
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.012195
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.012195
          },
          {
            "term": "most",
            "tf": 1,
            "weight": 0.012195
          }
        ],
        "unique_terms": 63,
        "total_terms": 82
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "SparseEncoder",
        "cocondenser",
        "dimensions",
        "embeddings",
        "lexical",
        "naver",
        "neural",
        "representations",
        "sparse",
        "sparseencoder",
        "splade"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.4185401499271393,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7426315789473684,
      "overall": 0.6870572429581693
    }
  },
  {
    "text": "### SentenceTransformer  The `SentenceTransformer` class produces dense vector embeddings where semantically similar texts have similar vector representations. These models use bi-encoder architectures that independently encode each input text. **Key characteristics:** - Output: Dense vectors (typically 384-1024 dimensions) - Use case: Semantic similarity, clustering, dense retrieval - Similarity functions: Cosine similarity, dot product, Euclidean distance - Example models: `all-MiniLM-L6-v2`, `all-mpnet-base-v2`  **Basic usage pattern:** ```python from sentence_transformers import SentenceTransformer model = SentenceTransformer(\"all-MiniLM-L6-v2\") embeddings = model.encode(sentences) similarities = model.similarity(embeddings, embeddings) ``` Sources: [README.md:56-87](), [sentence_transformers/__init__.py:27]()",
    "metadata": {
      "chunk_id": "4a318e767b6a-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "SentenceTransformer"
      ],
      "heading_text": "SentenceTransformer",
      "token_count": 174,
      "char_count": 825,
      "start_char": 0,
      "end_char": 825,
      "semantic_score": 0.3939207196235657,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7418518518518519,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:52:27.966233",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "SentenceTransformer",
      "chunk_hash": "3f9b3bb8ba6ef7aa",
      "content_digest": "3f9b3bb8ba6ef7aa",
      "chunk_length": 825,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "sentencetransformer",
          "embeddings",
          "similarity",
          "dense",
          "all",
          "model",
          "vector",
          "similar",
          "models",
          "use",
          "encode",
          "minilm",
          "sentence",
          "transformers",
          "the",
          "class",
          "produces",
          "where",
          "semantically",
          "texts"
        ],
        "term_weights": [
          {
            "term": "sentencetransformer",
            "tf": 4,
            "weight": 0.047059
          },
          {
            "term": "embeddings",
            "tf": 4,
            "weight": 0.047059
          },
          {
            "term": "similarity",
            "tf": 4,
            "weight": 0.047059
          },
          {
            "term": "dense",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "all",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "similar",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "use",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "encode",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "minilm",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "produces",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "where",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "semantically",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "texts",
            "tf": 1,
            "weight": 0.011765
          }
        ],
        "unique_terms": 62,
        "total_terms": 85
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "SentenceTransformer",
        "all",
        "dense",
        "embeddings",
        "model",
        "models",
        "sentencetransformer",
        "similar",
        "similarity",
        "use",
        "vector"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.3939207196235657,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7418518518518519,
      "overall": 0.6785908571584724
    }
  },
  {
    "text": "### CrossEncoder  The `CrossEncoder` class performs joint encoding of text pairs to produce similarity scores, making it ideal for reranking and classification tasks where high precision is required. **Key characteristics:** - Output: Scalar similarity scores - Use case: Reranking, text pair classification, high-precision ranking - Architecture: Joint encoding (both texts processed together) - Example models: `cross-encoder/ms-marco-MiniLM-L6-v2`  **Basic usage pattern:** ```python from sentence_transformers import CrossEncoder model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L6-v2\") scores = model.predict([(query, passage) for passage in passages]) ranks = model.rank(query, passages, return_documents=True) ``` Sources: [README.md:89-132](), [sentence_transformers/__init__.py:15-20]()",
    "metadata": {
      "chunk_id": "4a318e767b6a-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "CrossEncoder"
      ],
      "heading_text": "CrossEncoder",
      "token_count": 177,
      "char_count": 798,
      "start_char": 0,
      "end_char": 798,
      "semantic_score": 0.3211383819580078,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7471428571428571,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:52:27.967116",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "CrossEncoder",
      "chunk_hash": "2b2d21b6fd019102",
      "content_digest": "2b2d21b6fd019102",
      "chunk_length": 798,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "crossencoder",
          "scores",
          "model",
          "joint",
          "encoding",
          "text",
          "similarity",
          "for",
          "reranking",
          "classification",
          "high",
          "precision",
          "cross",
          "encoder",
          "marco",
          "minilm",
          "sentence",
          "transformers",
          "query",
          "passage"
        ],
        "term_weights": [
          {
            "term": "crossencoder",
            "tf": 4,
            "weight": 0.045455
          },
          {
            "term": "scores",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "joint",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "encoding",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "similarity",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "reranking",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "classification",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "high",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "precision",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "cross",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "marco",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "minilm",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "sentence",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "transformers",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "passage",
            "tf": 2,
            "weight": 0.022727
          }
        ],
        "unique_terms": 63,
        "total_terms": 88
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "CrossEncoder",
        "classification",
        "crossencoder",
        "encoding",
        "for",
        "joint",
        "model",
        "reranking",
        "scores",
        "similarity",
        "text"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.3211383819580078,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7471428571428571,
      "overall": 0.6560937463669549
    }
  },
  {
    "text": "## Purpose and Scope  The sentence-transformers library is a comprehensive Python framework for accessing, using, and training state-of-the-art embedding and reranker models. It provides three core model types that serve different purposes in natural language processing pipelines: `SentenceTransformer` for dense embeddings, `SparseEncoder` for sparse embeddings, and `CrossEncoder` for pairwise scoring and reranking. This document covers the high-level architecture and core concepts of the sentence-transformers library. For specific usage instructions, see [Quickstart Guide](#2.1). For detailed training procedures, see [Training](#3). For performance optimization, see [Advanced Topics](#7). Sources: [README.md:15-21](), [sentence_transformers/__init__.py:27-34]()",
    "metadata": {
      "chunk_id": "4a318e767b6a-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "filename": "Overview.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Purpose and Scope"
      ],
      "heading_text": "Purpose and Scope",
      "token_count": 157,
      "char_count": 772,
      "start_char": 0,
      "end_char": 772,
      "semantic_score": 0.32859212160110474,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7244827586206896,
      "chunking_strategy": "hybrid_adaptive",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:52:27.964634",
      "document_id": "4a318e767b6a",
      "document_name": "Overview",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "source_filename": "Overview.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers",
      "relative_path": "Docs\\sentence_transformers_docs\\UKPLab\\sentence-transformers\\Overview.md",
      "hierarchy_path": "Purpose and Scope",
      "chunk_hash": "0f0a81b36649c099",
      "content_digest": "0f0a81b36649c099",
      "chunk_length": 772,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "for",
          "and",
          "the",
          "sentence",
          "transformers",
          "training",
          "see",
          "library",
          "core",
          "embeddings",
          "purpose",
          "scope",
          "comprehensive",
          "python",
          "framework",
          "accessing",
          "using",
          "state",
          "art",
          "embedding"
        ],
        "term_weights": [
          {
            "term": "for",
            "tf": 7,
            "weight": 0.079545
          },
          {
            "term": "and",
            "tf": 6,
            "weight": 0.068182
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.045455
          },
          {
            "term": "sentence",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "transformers",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "training",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "see",
            "tf": 3,
            "weight": 0.034091
          },
          {
            "term": "library",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "core",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.022727
          },
          {
            "term": "purpose",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "scope",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "comprehensive",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "framework",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "accessing",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "state",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "art",
            "tf": 1,
            "weight": 0.011364
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.011364
          }
        ],
        "unique_terms": 63,
        "total_terms": 88
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Purpose and Scope",
        "and",
        "core",
        "embeddings",
        "for",
        "library",
        "see",
        "sentence",
        "the",
        "training",
        "transformers"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.32859212160110474,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7244827586206896,
      "overall": 0.6510249600739314
    }
  }
]
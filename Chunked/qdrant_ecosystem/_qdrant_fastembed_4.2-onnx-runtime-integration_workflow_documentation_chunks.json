[
  {
    "text": "## Implementation Details",
    "metadata": {
      "chunk_id": "cd3b5b89d645-0014",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Implementation Details"
      ],
      "heading_text": "Implementation Details",
      "token_count": 3,
      "char_count": 25,
      "start_char": 0,
      "end_char": 25,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:34:24.019832",
      "document_id": "cd3b5b89d645",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Implementation Details",
      "chunk_hash": "812a10c977ea5550",
      "content_digest": "812a10c977ea5550",
      "chunk_length": 25,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "implementation",
          "details"
        ],
        "term_weights": [
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.5
          },
          {
            "term": "details",
            "tf": 1,
            "weight": 0.5
          }
        ],
        "unique_terms": 2,
        "total_terms": 2
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Implementation Details",
        "details",
        "implementation"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "## ONNX Model Hierarchy  FastEmbed implements a hierarchical structure for its ONNX-based models, with a common base class and specialized subclasses for different modalities.",
    "metadata": {
      "chunk_id": "cd3b5b89d645-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ONNX Model Hierarchy"
      ],
      "heading_text": "ONNX Model Hierarchy",
      "token_count": 33,
      "char_count": 175,
      "start_char": 0,
      "end_char": 175,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.565,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:34:24.015953",
      "document_id": "cd3b5b89d645",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "ONNX Model Hierarchy",
      "chunk_hash": "41abc6a2f4a2e81b",
      "content_digest": "41abc6a2f4a2e81b",
      "chunk_length": 175,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "onnx",
          "for",
          "model",
          "hierarchy",
          "fastembed",
          "implements",
          "hierarchical",
          "structure",
          "its",
          "based",
          "models",
          "with",
          "common",
          "base",
          "class",
          "and",
          "specialized",
          "subclasses",
          "different",
          "modalities"
        ],
        "term_weights": [
          {
            "term": "onnx",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.090909
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "hierarchy",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "implements",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "hierarchical",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "structure",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "its",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "common",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "base",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "specialized",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "subclasses",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.045455
          },
          {
            "term": "modalities",
            "tf": 1,
            "weight": 0.045455
          }
        ],
        "unique_terms": 20,
        "total_terms": 22
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ONNX Model Hierarchy",
        "based",
        "fastembed",
        "for",
        "hierarchical",
        "hierarchy",
        "implements",
        "its",
        "model",
        "onnx",
        "structure"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.565,
      "overall": 0.7549999999999999
    }
  },
  {
    "text": "## ONNX Session Configuration  FastEmbed offers flexible configuration of ONNX Runtime sessions, enabling users to optimize for their specific hardware and performance requirements.",
    "metadata": {
      "chunk_id": "cd3b5b89d645-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ONNX Session Configuration"
      ],
      "heading_text": "ONNX Session Configuration",
      "token_count": 29,
      "char_count": 181,
      "start_char": 0,
      "end_char": 181,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5639130434782609,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:34:24.016592",
      "document_id": "cd3b5b89d645",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "ONNX Session Configuration",
      "chunk_hash": "a1e83dd1b5c0069c",
      "content_digest": "a1e83dd1b5c0069c",
      "chunk_length": 181,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "onnx",
          "configuration",
          "session",
          "fastembed",
          "offers",
          "flexible",
          "runtime",
          "sessions",
          "enabling",
          "users",
          "optimize",
          "for",
          "their",
          "specific",
          "hardware",
          "and",
          "performance",
          "requirements"
        ],
        "term_weights": [
          {
            "term": "onnx",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "configuration",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "session",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "offers",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "flexible",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "runtime",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "sessions",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "enabling",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "users",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "optimize",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "their",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "specific",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "hardware",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "requirements",
            "tf": 1,
            "weight": 0.05
          }
        ],
        "unique_terms": 18,
        "total_terms": 20
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ONNX Session Configuration",
        "configuration",
        "enabling",
        "fastembed",
        "flexible",
        "offers",
        "onnx",
        "runtime",
        "session",
        "sessions",
        "users"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5639130434782609,
      "overall": 0.7546376811594202
    }
  },
  {
    "text": "## Inference Pipeline  The ONNX-based inference pipeline in FastEmbed follows a consistent pattern across different model types, with modality-specific preprocessing and postprocessing steps. ``` ``` Sources: [fastembed/text/onnx\\_text\\_model.py62-90](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_text_model.py#L62-L90) [fastembed/image/onnx\\_image\\_model.py63-79](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/image/onnx_image_model.py#L63-L79) [fastembed/rerank/cross\\_encoder/onnx\\_text\\_model.py66-77](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/rerank/cross_encoder/onnx_text_model.py#L66-L77)",
    "metadata": {
      "chunk_id": "cd3b5b89d645-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Inference Pipeline"
      ],
      "heading_text": "Inference Pipeline",
      "token_count": 177,
      "char_count": 653,
      "start_char": 0,
      "end_char": 653,
      "semantic_score": 0.4375934600830078,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7589655172413793,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:34:24.017348",
      "document_id": "cd3b5b89d645",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "Inference Pipeline",
      "chunk_hash": "7cecbb346cc578dd",
      "content_digest": "7cecbb346cc578dd",
      "chunk_length": 653,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "fastembed",
          "onnx",
          "model",
          "text",
          "image",
          "https",
          "github",
          "com",
          "qdrant",
          "blob",
          "b785640b",
          "inference",
          "pipeline",
          "rerank",
          "cross",
          "encoder",
          "the",
          "based",
          "follows",
          "consistent"
        ],
        "term_weights": [
          {
            "term": "fastembed",
            "tf": 10,
            "weight": 0.114943
          },
          {
            "term": "onnx",
            "tf": 7,
            "weight": 0.08046
          },
          {
            "term": "model",
            "tf": 7,
            "weight": 0.08046
          },
          {
            "term": "text",
            "tf": 6,
            "weight": 0.068966
          },
          {
            "term": "image",
            "tf": 4,
            "weight": 0.045977
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "b785640b",
            "tf": 3,
            "weight": 0.034483
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "pipeline",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "rerank",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "cross",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "encoder",
            "tf": 2,
            "weight": 0.022989
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "follows",
            "tf": 1,
            "weight": 0.011494
          },
          {
            "term": "consistent",
            "tf": 1,
            "weight": 0.011494
          }
        ],
        "unique_terms": 41,
        "total_terms": 87
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Inference Pipeline",
        "blob",
        "com",
        "fastembed",
        "github",
        "https",
        "image",
        "model",
        "onnx",
        "qdrant",
        "text"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.4375934600830078,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7589655172413793,
      "overall": 0.6988529924414624
    }
  },
  {
    "text": "## GPU Acceleration  FastEmbed provides support for GPU acceleration through ONNX Runtime's CUDA execution provider.",
    "metadata": {
      "chunk_id": "cd3b5b89d645-0010",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "GPU Acceleration"
      ],
      "heading_text": "GPU Acceleration",
      "token_count": 21,
      "char_count": 116,
      "start_char": 0,
      "end_char": 116,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.35,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:34:24.018228",
      "document_id": "cd3b5b89d645",
      "document_name": "_qdrant_fastembed_4.2-onnx-runtime-integration",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_filename": "_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_4.2-onnx-runtime-integration.md",
      "hierarchy_path": "GPU Acceleration",
      "chunk_hash": "48cd92c0aa519ca6",
      "content_digest": "48cd92c0aa519ca6",
      "chunk_length": 116,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "gpu",
          "acceleration",
          "fastembed",
          "provides",
          "support",
          "for",
          "through",
          "onnx",
          "runtime",
          "cuda",
          "execution",
          "provider"
        ],
        "term_weights": [
          {
            "term": "gpu",
            "tf": 2,
            "weight": 0.142857
          },
          {
            "term": "acceleration",
            "tf": 2,
            "weight": 0.142857
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "onnx",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "runtime",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "cuda",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "execution",
            "tf": 1,
            "weight": 0.071429
          },
          {
            "term": "provider",
            "tf": 1,
            "weight": 0.071429
          }
        ],
        "unique_terms": 12,
        "total_terms": 14
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "GPU Acceleration",
        "acceleration",
        "cuda",
        "fastembed",
        "for",
        "gpu",
        "onnx",
        "provides",
        "runtime",
        "support",
        "through"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.35,
      "overall": 0.6833333333333332
    }
  }
]
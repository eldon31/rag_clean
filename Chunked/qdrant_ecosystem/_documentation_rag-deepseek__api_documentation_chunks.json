[
  {
    "text": "### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Essentials"
      ],
      "heading_text": "Essentials",
      "token_count": 189,
      "char_count": 673,
      "start_char": 688,
      "end_char": 1361,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5053846153846153,
      "chunking_strategy": "hierarchical_precise_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.550703",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Essentials",
      "chunk_hash": "b49cc869c6854f5f",
      "content_digest": "b49cc869c6854f5f",
      "chunk_length": 673,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "https",
          "tech",
          "documentation",
          "agentic",
          "with",
          "data",
          "ingestion",
          "beginners",
          "langgraph",
          "discord",
          "multimodal",
          "and",
          "deepseek",
          "n8n",
          "essentials",
          "for",
          "simple",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "documentation",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "agentic",
            "tf": 6,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "beginners",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "langgraph",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "discord",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "multimodal",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "deepseek",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "n8n",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "essentials",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 31,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Essentials",
        "agentic",
        "beginners",
        "data",
        "documentation",
        "https",
        "ingestion",
        "qdrant",
        "rag",
        "tech",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5053846153846153,
      "overall": 0.6351282051282051
    }
  },
  {
    "text": "### Integrations  [Data Management](https://qdrant.tech/documentation/data-management/)  - [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/) - [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/) - [Apache Spark](https://qdrant.tech/documentation/data-management/spark/) - [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/) - [cognee](https://qdrant.tech/documentation/data-management/cognee/) - [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/) - [DLT](https://qdrant.tech/documentation/data-management/dlt/) - [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/) - [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/) - [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)  [Embeddings](https://qdrant.tech/documentation/embeddings/)  - [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/) - [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/) - [Cohere](https://qdrant.tech/documentation/embeddings/cohere/) - [Gemini](https://qdrant.tech/documentation/embeddings/gemini/) - [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/) - [Mistral](https://qdrant.tech/documentation/embeddings/mistral/) - [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/) - [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/) - [Nomic](https://qdrant.tech/documentation/embeddings/nomic/) - [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/) - [Ollama](https://qdrant.tech/documentation/embeddings/ollama/) - [OpenAI](https://qdrant.tech/documentation/embeddings/openai/) - [Prem AI](https://qdrant.tech/documentation/embeddings/premai/) - [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/) - [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/) - [Upstage](https://qdrant.tech/documentation/embeddings/upstage/) - [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)  [Frameworks](https://qdrant.tech/documentation/frameworks/)  - [Autogen](https://qdrant.tech/documentation/frameworks/autogen/) - [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/) - [CamelAI](https://qdrant.tech/documentation/frameworks/camel/) - [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/) - [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/) - [Dagster](https://qdrant.tech/documentation/frameworks/dagster/) - [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/) - [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/) - [Feast](https://qdrant.tech/documentation/frameworks/feast/) - [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/) - [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/) - [Haystack](https://qdrant.tech/documentation/frameworks/haystack/) - [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/) - [Langchain](https://qdrant.tech/documentation/frameworks/langchain/) - [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/) - [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/) - [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/) - [Mastra](https://qdrant.tech/documentation/frameworks/mastra/) - [Mem0](https://qdrant.tech/documentation/frameworks/mem0/) - [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/) - [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/) - [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/) - [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/) - [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/) - [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/) - [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/) - [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/) - [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/) - [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/) - [txtai](https://qdrant.tech/documentation/frameworks/txtai/) - [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/) - [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/) - [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)  [Observability](https://qdrant.tech/documentation/observability/)  - [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/) - [OpenLIT](https://qdrant.tech/documentation/observability/openlit/) - [Datadog](https://qdrant.tech/documentation/observability/datadog/)  [Platforms](https://qdrant.tech/documentation/platforms/)  - [Apify](https://qdrant.tech/documentation/platforms/apify/) - [BuildShip](https://qdrant.tech/documentation/platforms/buildship/) - [Keboola](https://qdrant.tech/documentation/platforms/keboola/) - [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/) - [Make.com](https://qdrant.tech/documentation/platforms/make/) - [N8N](https://qdrant.tech/documentation/platforms/n8n/) - [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/) - [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/) - [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/) - [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/) - [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/) - [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integrations"
      ],
      "heading_text": "Integrations",
      "token_count": 1498,
      "char_count": 5661,
      "start_char": 1363,
      "end_char": 7024,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "chunking_strategy": "hierarchical_precise_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.555358",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Integrations",
      "chunk_hash": "8a3f2e84e2a75ae9",
      "content_digest": "8a3f2e84e2a75ae9",
      "chunk_length": 5661,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "frameworks",
          "embeddings",
          "platforms",
          "data",
          "management",
          "observability",
          "airbyte",
          "apache",
          "airflow",
          "spark",
          "cocoindex",
          "cognee",
          "confluent",
          "dlt",
          "fluvio",
          "redpanda"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "qdrant",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "tech",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "documentation",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "frameworks",
            "tf": 35,
            "weight": 0.058528
          },
          {
            "term": "embeddings",
            "tf": 21,
            "weight": 0.035117
          },
          {
            "term": "platforms",
            "tf": 14,
            "weight": 0.023411
          },
          {
            "term": "data",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "management",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "observability",
            "tf": 5,
            "weight": 0.008361
          },
          {
            "term": "airbyte",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "apache",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "airflow",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "spark",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cocoindex",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cognee",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "confluent",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "dlt",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "fluvio",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "redpanda",
            "tf": 2,
            "weight": 0.003344
          }
        ],
        "unique_terms": 113,
        "total_terms": 598
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integrations",
        "data",
        "documentation",
        "embeddings",
        "frameworks",
        "https",
        "management",
        "observability",
        "platforms",
        "qdrant",
        "tech"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "overall": 0.7576923076923077
    }
  },
  {
    "text": "### Examples  [Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)  - [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) - [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)  [Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)  - [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/) - [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/) - [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)  [Build Prototypes](https://qdrant.tech/documentation/examples/)  - [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/) - [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/) - [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/) - [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/) - [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/) - [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/) - [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/) - [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/) - [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/) - [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/) - [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/) - [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)  [Practice Datasets](https://qdrant.tech/documentation/datasets/)",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Examples"
      ],
      "heading_text": "Examples",
      "token_count": 576,
      "char_count": 2347,
      "start_char": 7026,
      "end_char": 9373,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.9076923076923078,
      "chunking_strategy": "hierarchical_precise_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.558555",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Examples",
      "chunk_hash": "59078d11dd9c9931",
      "content_digest": "59078d11dd9c9931",
      "chunk_length": 2347,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "https",
          "tech",
          "documentation",
          "examples",
          "search",
          "with",
          "rag",
          "data",
          "chatbot",
          "send",
          "system",
          "semantic",
          "and",
          "cohere",
          "precision",
          "reranking",
          "dspy",
          "for",
          "automate"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 30,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "tech",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "documentation",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "examples",
            "tf": 14,
            "weight": 0.05
          },
          {
            "term": "search",
            "tf": 10,
            "weight": 0.035714
          },
          {
            "term": "with",
            "tf": 9,
            "weight": 0.032143
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.032143
          },
          {
            "term": "data",
            "tf": 7,
            "weight": 0.025
          },
          {
            "term": "chatbot",
            "tf": 6,
            "weight": 0.021429
          },
          {
            "term": "send",
            "tf": 5,
            "weight": 0.017857
          },
          {
            "term": "system",
            "tf": 5,
            "weight": 0.017857
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "cohere",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "dspy",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "automate",
            "tf": 2,
            "weight": 0.007143
          }
        ],
        "unique_terms": 96,
        "total_terms": 280
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Examples",
        "chatbot",
        "data",
        "documentation",
        "examples",
        "https",
        "qdrant",
        "rag",
        "search",
        "tech",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.9076923076923078,
      "overall": 0.8358974358974359
    }
  },
  {
    "text": "### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Essentials"
      ],
      "heading_text": "Essentials",
      "token_count": 189,
      "char_count": 673,
      "start_char": 9375,
      "end_char": 10048,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5053846153846153,
      "chunking_strategy": "hierarchical_precise_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.559451",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Essentials",
      "chunk_hash": "b49cc869c6854f5f",
      "content_digest": "b49cc869c6854f5f",
      "chunk_length": 673,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "https",
          "tech",
          "documentation",
          "agentic",
          "with",
          "data",
          "ingestion",
          "beginners",
          "langgraph",
          "discord",
          "multimodal",
          "and",
          "deepseek",
          "n8n",
          "essentials",
          "for",
          "simple",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "documentation",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "agentic",
            "tf": 6,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "beginners",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "langgraph",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "discord",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "multimodal",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "deepseek",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "n8n",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "essentials",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 31,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Essentials",
        "agentic",
        "beginners",
        "data",
        "documentation",
        "https",
        "ingestion",
        "qdrant",
        "rag",
        "tech",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5053846153846153,
      "overall": 0.6351282051282051
    }
  },
  {
    "text": "### Integrations  [Data Management](https://qdrant.tech/documentation/data-management/)  - [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/) - [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/) - [Apache Spark](https://qdrant.tech/documentation/data-management/spark/) - [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/) - [cognee](https://qdrant.tech/documentation/data-management/cognee/) - [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/) - [DLT](https://qdrant.tech/documentation/data-management/dlt/) - [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/) - [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/) - [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)  [Embeddings](https://qdrant.tech/documentation/embeddings/)  - [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/) - [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/) - [Cohere](https://qdrant.tech/documentation/embeddings/cohere/) - [Gemini](https://qdrant.tech/documentation/embeddings/gemini/) - [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/) - [Mistral](https://qdrant.tech/documentation/embeddings/mistral/) - [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/) - [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/) - [Nomic](https://qdrant.tech/documentation/embeddings/nomic/) - [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/) - [Ollama](https://qdrant.tech/documentation/embeddings/ollama/) - [OpenAI](https://qdrant.tech/documentation/embeddings/openai/) - [Prem AI](https://qdrant.tech/documentation/embeddings/premai/) - [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/) - [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/) - [Upstage](https://qdrant.tech/documentation/embeddings/upstage/) - [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)  [Frameworks](https://qdrant.tech/documentation/frameworks/)  - [Autogen](https://qdrant.tech/documentation/frameworks/autogen/) - [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/) - [CamelAI](https://qdrant.tech/documentation/frameworks/camel/) - [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/) - [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/) - [Dagster](https://qdrant.tech/documentation/frameworks/dagster/) - [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/) - [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/) - [Feast](https://qdrant.tech/documentation/frameworks/feast/) - [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/) - [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/) - [Haystack](https://qdrant.tech/documentation/frameworks/haystack/) - [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/) - [Langchain](https://qdrant.tech/documentation/frameworks/langchain/) - [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/) - [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/) - [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/) - [Mastra](https://qdrant.tech/documentation/frameworks/mastra/) - [Mem0](https://qdrant.tech/documentation/frameworks/mem0/) - [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/) - [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/) - [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/) - [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/) - [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/) - [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/) - [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/) - [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/) - [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/) - [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/) - [txtai](https://qdrant.tech/documentation/frameworks/txtai/) - [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/) - [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/) - [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)  [Observability](https://qdrant.tech/documentation/observability/)  - [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/) - [OpenLIT](https://qdrant.tech/documentation/observability/openlit/) - [Datadog](https://qdrant.tech/documentation/observability/datadog/)  [Platforms](https://qdrant.tech/documentation/platforms/)  - [Apify](https://qdrant.tech/documentation/platforms/apify/) - [BuildShip](https://qdrant.tech/documentation/platforms/buildship/) - [Keboola](https://qdrant.tech/documentation/platforms/keboola/) - [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/) - [Make.com](https://qdrant.tech/documentation/platforms/make/) - [N8N](https://qdrant.tech/documentation/platforms/n8n/) - [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/) - [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/) - [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/) - [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/) - [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/) - [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integrations"
      ],
      "heading_text": "Integrations",
      "token_count": 1498,
      "char_count": 5661,
      "start_char": 10050,
      "end_char": 15711,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "chunking_strategy": "hierarchical_precise_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.563917",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Integrations",
      "chunk_hash": "8a3f2e84e2a75ae9",
      "content_digest": "8a3f2e84e2a75ae9",
      "chunk_length": 5661,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "frameworks",
          "embeddings",
          "platforms",
          "data",
          "management",
          "observability",
          "airbyte",
          "apache",
          "airflow",
          "spark",
          "cocoindex",
          "cognee",
          "confluent",
          "dlt",
          "fluvio",
          "redpanda"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "qdrant",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "tech",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "documentation",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "frameworks",
            "tf": 35,
            "weight": 0.058528
          },
          {
            "term": "embeddings",
            "tf": 21,
            "weight": 0.035117
          },
          {
            "term": "platforms",
            "tf": 14,
            "weight": 0.023411
          },
          {
            "term": "data",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "management",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "observability",
            "tf": 5,
            "weight": 0.008361
          },
          {
            "term": "airbyte",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "apache",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "airflow",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "spark",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cocoindex",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cognee",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "confluent",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "dlt",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "fluvio",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "redpanda",
            "tf": 2,
            "weight": 0.003344
          }
        ],
        "unique_terms": 113,
        "total_terms": 598
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integrations",
        "data",
        "documentation",
        "embeddings",
        "frameworks",
        "https",
        "management",
        "observability",
        "platforms",
        "qdrant",
        "tech"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "overall": 0.7576923076923077
    }
  },
  {
    "text": "### Examples  [Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)  - [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) - [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)  [Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)  - [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/) - [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/) - [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)  [Build Prototypes](https://qdrant.tech/documentation/examples/)  - [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/) - [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/) - [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/) - [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/) - [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/) - [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/) - [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/) - [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/) - [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/) - [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/) - [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/) - [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)  [Practice Datasets](https://qdrant.tech/documentation/datasets/)  - [Documentation](https://qdrant.tech/documentation/) - - 5 Minute RAG with Qdrant and DeepSeek",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Examples"
      ],
      "heading_text": "Examples",
      "token_count": 603,
      "char_count": 2444,
      "start_char": 15713,
      "end_char": 18157,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.89921875,
      "chunking_strategy": "hierarchical_precise_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.565861",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Examples",
      "chunk_hash": "2116bd4c39a901de",
      "content_digest": "2116bd4c39a901de",
      "chunk_length": 2444,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "documentation",
          "https",
          "tech",
          "examples",
          "search",
          "with",
          "rag",
          "data",
          "chatbot",
          "send",
          "and",
          "system",
          "semantic",
          "cohere",
          "precision",
          "reranking",
          "dspy",
          "for",
          "automate"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 32,
            "weight": 0.109966
          },
          {
            "term": "documentation",
            "tf": 23,
            "weight": 0.079038
          },
          {
            "term": "https",
            "tf": 22,
            "weight": 0.075601
          },
          {
            "term": "tech",
            "tf": 22,
            "weight": 0.075601
          },
          {
            "term": "examples",
            "tf": 14,
            "weight": 0.04811
          },
          {
            "term": "search",
            "tf": 10,
            "weight": 0.034364
          },
          {
            "term": "with",
            "tf": 10,
            "weight": 0.034364
          },
          {
            "term": "rag",
            "tf": 10,
            "weight": 0.034364
          },
          {
            "term": "data",
            "tf": 7,
            "weight": 0.024055
          },
          {
            "term": "chatbot",
            "tf": 6,
            "weight": 0.020619
          },
          {
            "term": "send",
            "tf": 5,
            "weight": 0.017182
          },
          {
            "term": "and",
            "tf": 5,
            "weight": 0.017182
          },
          {
            "term": "system",
            "tf": 5,
            "weight": 0.017182
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.013746
          },
          {
            "term": "cohere",
            "tf": 4,
            "weight": 0.013746
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010309
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.010309
          },
          {
            "term": "dspy",
            "tf": 3,
            "weight": 0.010309
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.010309
          },
          {
            "term": "automate",
            "tf": 2,
            "weight": 0.006873
          }
        ],
        "unique_terms": 98,
        "total_terms": 291
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Examples",
        "chatbot",
        "data",
        "documentation",
        "examples",
        "https",
        "qdrant",
        "rag",
        "search",
        "tech",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.89921875,
      "overall": 0.8330729166666666
    }
  },
  {
    "text": "# 5 Minute RAG with Qdrant and DeepSeek  | Time: 5 min | Level: Beginner | Output: [GitHub](https://github.com/qdrant/examples/blob/master/rag-with-qdrant-deepseek/deepseek-qdrant.ipynb) |   | | ----------- | --------------- | --------------------------------------------------------------------------------------------------------------- | - |  This tutorial demonstrates how to build a **Retrieval-Augmented Generation (RAG)** pipeline using Qdrant as a vector storage solution and DeepSeek for semantic query enrichment. RAG pipelines enhance Large Language Model (LLM) responses by providing contextually relevant data.",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0006",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "5 Minute RAG with Qdrant and DeepSeek"
      ],
      "heading_text": "5 Minute RAG with Qdrant and DeepSeek",
      "token_count": 129,
      "char_count": 623,
      "start_char": 18159,
      "end_char": 18782,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7218181818181818,
      "chunking_strategy": "hierarchical_precise_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.566438",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "5 Minute RAG with Qdrant and DeepSeek",
      "chunk_hash": "e9ed241924cf86f8",
      "content_digest": "e9ed241924cf86f8",
      "chunk_length": 623,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "deepseek",
          "with",
          "and",
          "github",
          "minute",
          "time",
          "min",
          "level",
          "beginner",
          "output",
          "https",
          "com",
          "examples",
          "blob",
          "master",
          "ipynb",
          "this",
          "tutorial"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 5,
            "weight": 0.084746
          },
          {
            "term": "rag",
            "tf": 4,
            "weight": 0.067797
          },
          {
            "term": "deepseek",
            "tf": 4,
            "weight": 0.067797
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.033898
          },
          {
            "term": "minute",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "time",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "min",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "level",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "beginner",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "output",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "com",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "examples",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "blob",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "master",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "ipynb",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.016949
          },
          {
            "term": "tutorial",
            "tf": 1,
            "weight": 0.016949
          }
        ],
        "unique_terms": 46,
        "total_terms": 59
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "5 Minute RAG with Qdrant and DeepSeek",
        "and",
        "deepseek",
        "github",
        "level",
        "min",
        "minute",
        "qdrant",
        "rag",
        "time",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7218181818181818,
      "overall": 0.8072727272727271
    }
  },
  {
    "text": "## Overview\n\nIn this tutorial, we will:\n\n1. Take sample text and turn it into vectors with FastEmbed.\n2. Send the vectors to a Qdrant collection.\n3. Connect Qdrant and DeepSeek into a minimal RAG pipeline.\n4. Ask DeepSeek different questions and test answer accuracy.\n5. Enrich DeepSeek prompts with content retrieved from Qdrant.\n6. Evaluate answer accuracy before and after.",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Overview"
      ],
      "heading_text": "Overview",
      "token_count": 88,
      "char_count": 376,
      "start_char": 18784,
      "end_char": 19160,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5359016393442623,
      "chunking_strategy": "hierarchical_precise_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.566746",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Overview",
      "chunk_hash": "6067eacf1da14247",
      "content_digest": "6067eacf1da14247",
      "chunk_length": 376,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "and",
          "qdrant",
          "deepseek",
          "into",
          "vectors",
          "with",
          "answer",
          "accuracy",
          "overview",
          "this",
          "tutorial",
          "will",
          "take",
          "sample",
          "text",
          "turn",
          "fastembed",
          "send",
          "the",
          "collection"
        ],
        "term_weights": [
          {
            "term": "and",
            "tf": 4,
            "weight": 0.083333
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.0625
          },
          {
            "term": "deepseek",
            "tf": 3,
            "weight": 0.0625
          },
          {
            "term": "into",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "vectors",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "answer",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "accuracy",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "overview",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "tutorial",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "will",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "take",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "sample",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "text",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "turn",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "send",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "collection",
            "tf": 1,
            "weight": 0.020833
          }
        ],
        "unique_terms": 36,
        "total_terms": 48
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Overview",
        "accuracy",
        "and",
        "answer",
        "deepseek",
        "into",
        "overview",
        "qdrant",
        "this",
        "vectors",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5359016393442623,
      "overall": 0.6786338797814208
    }
  },
  {
    "text": "## Setup Qdrant\n\n```python\npip install \"qdrant-client[fastembed]>=1.14.1\"\n```\n\n[Qdrant](https://qdrant.tech) will act as a knowledge base providing the context information for the prompts we’ll be sending to the LLM.\n\nYou can get a free-forever Qdrant cloud instance at <http://cloud.qdrant.io>. Learn about setting up your instance from the [Quickstart](https://qdrant.tech/documentation/quickstart-cloud/).\n\n```python\nQDRANT_URL = \"https://xyz-example.eu-central.aws.cloud.qdrant.io:6333\"\nQDRANT_API_KEY = \"<your-api-key>\"\n```",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0010",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Setup Qdrant"
      ],
      "heading_text": "Setup Qdrant",
      "token_count": 147,
      "char_count": 528,
      "start_char": 19400,
      "end_char": 19928,
      "semantic_score": 0.6,
      "structural_score": 0.7,
      "retrieval_quality": 0.5409090909090909,
      "chunking_strategy": "hierarchical_precise_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.567282",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Setup Qdrant",
      "chunk_hash": "6a9255b8f2757beb",
      "content_digest": "6a9255b8f2757beb",
      "chunk_length": 528,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "the",
          "cloud",
          "https",
          "python",
          "tech",
          "instance",
          "your",
          "quickstart",
          "api",
          "key",
          "setup",
          "pip",
          "install",
          "client",
          "fastembed",
          "will",
          "act",
          "knowledge",
          "base"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.147059
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.058824
          },
          {
            "term": "cloud",
            "tf": 4,
            "weight": 0.058824
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.044118
          },
          {
            "term": "python",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "tech",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "instance",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "your",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "quickstart",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "api",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "key",
            "tf": 2,
            "weight": 0.029412
          },
          {
            "term": "setup",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "pip",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "install",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "client",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "will",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "act",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "knowledge",
            "tf": 1,
            "weight": 0.014706
          },
          {
            "term": "base",
            "tf": 1,
            "weight": 0.014706
          }
        ],
        "unique_terms": 44,
        "total_terms": 68
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Setup Qdrant",
        "api",
        "cloud",
        "https",
        "instance",
        "python",
        "qdrant",
        "quickstart",
        "tech",
        "the",
        "your"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7,
      "retrieval_quality": 0.5409090909090909,
      "overall": 0.6136363636363636
    }
  },
  {
    "text": "### Instantiating Qdrant Client\n\n```python\nfrom qdrant_client import QdrantClient, models\n\nclient = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n```",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0011",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Instantiating Qdrant Client"
      ],
      "heading_text": "Instantiating Qdrant Client",
      "token_count": 47,
      "char_count": 156,
      "start_char": 19930,
      "end_char": 20086,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.57,
      "chunking_strategy": "hierarchical_precise_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.567400",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Instantiating Qdrant Client",
      "chunk_hash": "24c0443a95e2111e",
      "content_digest": "24c0443a95e2111e",
      "chunk_length": 156,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "qdrantclient",
          "url",
          "api",
          "key",
          "instantiating",
          "python",
          "from",
          "import",
          "models"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.2
          },
          {
            "term": "client",
            "tf": 3,
            "weight": 0.15
          },
          {
            "term": "qdrantclient",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "url",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "api",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "key",
            "tf": 2,
            "weight": 0.1
          },
          {
            "term": "instantiating",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "import",
            "tf": 1,
            "weight": 0.05
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.05
          }
        ],
        "unique_terms": 11,
        "total_terms": 20
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Instantiating Qdrant Client",
        "api",
        "client",
        "from",
        "import",
        "instantiating",
        "key",
        "python",
        "qdrant",
        "qdrantclient",
        "url"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.57,
      "overall": 0.69
    }
  },
  {
    "text": "### Building the knowledge base\n\nQdrant will use vector embeddings of our facts to enrich the original prompt with some context. Thus, we need to store the vector embeddings and the facts used to generate them.\n\nWe’ll be using the [bge-base-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5) model via [FastEmbed](https://github.com/qdrant/fastembed/) - A lightweight, fast, Python library for embeddings generation.\n\nThe Qdrant client provides a handy integration with FastEmbed that makes building a knowledge base very straighforward.\n\nFirst, we need to create a collection, so Qdrant would know what vectors it will be dealing with, and then, we just pass our raw documents wrapped into `models.Document` to compute and upload the embeddings.\n\n```python\ncollection_name = \"knowledge_base\"\nmodel_name = \"BAAI/bge-small-en-v1.5\"\nclient.create_collection(\n    collection_name=collection_name,\n    vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE)\n)\n```",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0012",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Building the knowledge base"
      ],
      "heading_text": "Building the knowledge base",
      "token_count": 228,
      "char_count": 986,
      "start_char": 20088,
      "end_char": 21074,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5086440677966101,
      "chunking_strategy": "hierarchical_precise_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.568530",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Building the knowledge base",
      "chunk_hash": "4cc34f633cc04e02",
      "content_digest": "4cc34f633cc04e02",
      "chunk_length": 986,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "collection",
          "base",
          "qdrant",
          "embeddings",
          "name",
          "knowledge",
          "with",
          "and",
          "bge",
          "fastembed",
          "models",
          "building",
          "will",
          "vector",
          "our",
          "facts",
          "need",
          "https",
          "baai"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 7,
            "weight": 0.056452
          },
          {
            "term": "collection",
            "tf": 5,
            "weight": 0.040323
          },
          {
            "term": "base",
            "tf": 4,
            "weight": 0.032258
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.032258
          },
          {
            "term": "embeddings",
            "tf": 4,
            "weight": 0.032258
          },
          {
            "term": "name",
            "tf": 4,
            "weight": 0.032258
          },
          {
            "term": "knowledge",
            "tf": 3,
            "weight": 0.024194
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.024194
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.024194
          },
          {
            "term": "bge",
            "tf": 3,
            "weight": 0.024194
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.024194
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.024194
          },
          {
            "term": "building",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "will",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "our",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "facts",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "need",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.016129
          },
          {
            "term": "baai",
            "tf": 2,
            "weight": 0.016129
          }
        ],
        "unique_terms": 75,
        "total_terms": 124
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Building the knowledge base",
        "and",
        "base",
        "bge",
        "collection",
        "embeddings",
        "knowledge",
        "name",
        "qdrant",
        "the",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5086440677966101,
      "overall": 0.6362146892655366
    }
  },
  {
    "text": "## Setup DeepSeek\n\nRAG changes the way we interact with Large Language Models. We’re converting a knowledge-oriented task, in which the model may create a counterfactual answer, into a language-oriented task. The latter expects the model to extract meaningful information and generate an answer. LLMs, when implemented correctly, are supposed to be carrying out language-oriented tasks.\n\nThe task starts with the original prompt sent by the user. The same prompt is then vectorized and used as a search query for the most relevant facts. Those facts are combined with the original prompt to build a longer prompt containing more information.\n\nBut let’s start simply by asking our question directly.\n\n```python\nprompt = \"\"\"\nWhat tools should I need to use to build a web service using vector embeddings for search?\n\"\"\"\n```\n\nUsing the Deepseek API requires providing the API key. You can obtain it from the [DeepSeek platform](https://platform.deepseek.com/api_keys).\n\nNow we can finally call the completion API.\n\n```python\nimport requests\nimport json",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0014",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Setup DeepSeek"
      ],
      "heading_text": "Setup DeepSeek",
      "token_count": 209,
      "char_count": 1049,
      "start_char": 23438,
      "end_char": 24487,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5085185185185185,
      "chunking_strategy": "hierarchical_precise_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.569149",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Setup DeepSeek",
      "chunk_hash": "5fbf966749e20306",
      "content_digest": "5fbf966749e20306",
      "chunk_length": 1049,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "prompt",
          "deepseek",
          "api",
          "with",
          "language",
          "oriented",
          "task",
          "model",
          "answer",
          "information",
          "and",
          "are",
          "original",
          "search",
          "for",
          "facts",
          "build",
          "python",
          "using"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 14,
            "weight": 0.097902
          },
          {
            "term": "prompt",
            "tf": 5,
            "weight": 0.034965
          },
          {
            "term": "deepseek",
            "tf": 4,
            "weight": 0.027972
          },
          {
            "term": "api",
            "tf": 4,
            "weight": 0.027972
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.020979
          },
          {
            "term": "language",
            "tf": 3,
            "weight": 0.020979
          },
          {
            "term": "oriented",
            "tf": 3,
            "weight": 0.020979
          },
          {
            "term": "task",
            "tf": 3,
            "weight": 0.020979
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "answer",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "information",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "original",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "facts",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "build",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "python",
            "tf": 2,
            "weight": 0.013986
          },
          {
            "term": "using",
            "tf": 2,
            "weight": 0.013986
          }
        ],
        "unique_terms": 97,
        "total_terms": 143
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Setup DeepSeek",
        "answer",
        "api",
        "deepseek",
        "language",
        "model",
        "oriented",
        "prompt",
        "task",
        "the",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5085185185185185,
      "overall": 0.6361728395061728
    }
  },
  {
    "text": "### Extending the prompt\n\nEven though the original answer sounds credible, it didn’t answer our question correctly. Instead, it gave us a generic description of an application stack. To improve the results, enriching the original prompt with the descriptions of the tools available seems like one of the possibilities. Let’s use a semantic knowledge base to augment the prompt with the descriptions of different technologies!\n\n```python\nresults = client.query_points(\n    collection_name=collection_name,\n    query=models.Document(text=prompt, model=model_name),\n    limit=3,\n)\nresults\n```\n\nHere is the response:\n\n```bash\nQueryResponse(points=[\n    ScoredPoint(id=0, version=0, score=0.67437416, payload={'document': 'Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!'}, vector=None, shard_key=None, order_value=None), \n    ScoredPoint(id=6, version=0, score=0.63144326, payload={'document': 'SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.'}, vector=None, shard_key=None, order_value=None), \n    ScoredPoint(id=5, version=0, score=0.6064749, payload={'document': 'FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.'}, vector=None, shard_key=None, order_value=None)\n])\n```\n\nWe used the original prompt to perform a semantic search over the set of tool descriptions. Now we can use these descriptions to augment the prompt and create more context.\n\n```python\ncontext = \"\\n\".join(r.payload['document'] for r in results.points)\ncontext\n```\n\nThe response is:",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0023",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 23,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Extending the prompt"
      ],
      "heading_text": "Extending the prompt",
      "token_count": 468,
      "char_count": 2129,
      "start_char": 29434,
      "end_char": 31563,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5295791044776119,
      "chunking_strategy": "hierarchical_precise_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.576907",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Extending the prompt",
      "chunk_hash": "a1ba639cee8c3b38",
      "content_digest": "a1ba639cee8c3b38",
      "chunk_length": 2129,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "none",
          "for",
          "prompt",
          "with",
          "python",
          "document",
          "vector",
          "can",
          "results",
          "descriptions",
          "semantic",
          "payload",
          "search",
          "embeddings",
          "original",
          "use",
          "points",
          "name",
          "text"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 16,
            "weight": 0.062016
          },
          {
            "term": "none",
            "tf": 9,
            "weight": 0.034884
          },
          {
            "term": "for",
            "tf": 7,
            "weight": 0.027132
          },
          {
            "term": "prompt",
            "tf": 6,
            "weight": 0.023256
          },
          {
            "term": "with",
            "tf": 6,
            "weight": 0.023256
          },
          {
            "term": "python",
            "tf": 5,
            "weight": 0.01938
          },
          {
            "term": "document",
            "tf": 5,
            "weight": 0.01938
          },
          {
            "term": "vector",
            "tf": 5,
            "weight": 0.01938
          },
          {
            "term": "can",
            "tf": 5,
            "weight": 0.01938
          },
          {
            "term": "results",
            "tf": 4,
            "weight": 0.015504
          },
          {
            "term": "descriptions",
            "tf": 4,
            "weight": 0.015504
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.015504
          },
          {
            "term": "payload",
            "tf": 4,
            "weight": 0.015504
          },
          {
            "term": "search",
            "tf": 4,
            "weight": 0.015504
          },
          {
            "term": "embeddings",
            "tf": 4,
            "weight": 0.015504
          },
          {
            "term": "original",
            "tf": 3,
            "weight": 0.011628
          },
          {
            "term": "use",
            "tf": 3,
            "weight": 0.011628
          },
          {
            "term": "points",
            "tf": 3,
            "weight": 0.011628
          },
          {
            "term": "name",
            "tf": 3,
            "weight": 0.011628
          },
          {
            "term": "text",
            "tf": 3,
            "weight": 0.011628
          }
        ],
        "unique_terms": 140,
        "total_terms": 258
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Extending the prompt",
        "can",
        "document",
        "for",
        "none",
        "prompt",
        "python",
        "results",
        "the",
        "vector",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5295791044776119,
      "overall": 0.6431930348258706
    }
  },
  {
    "text": "# Look at the full metaprompt\nprint(metaprompt)\n```\n\n**Response:**\n\n```bash\nYou are a software architect. \nAnswer the following question using the provided context. \nIf you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n    \nQuestion: What tools should I need to use to build a web service using vector embeddings for search?\n    \nContext: \nQdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\nFastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\nPyTorch is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing.\n    \nAnswer:\n```\n\nOur current prompt is much longer, and we also used a couple of strategies to make the responses even better:\n\n1. The LLM has the role of software architect.\n2. We provide more context to answer the question.\n3. If the context contains no meaningful information, the model shouldn’t make up an answer.\n\nLet’s find out if that works as expected.\n\n**Question:**\n\n```python\nquery_deepseek(metaprompt)\n```\n\n**Answer:**",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0025",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 25,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Look at the full metaprompt"
      ],
      "heading_text": "Look at the full metaprompt",
      "token_count": 303,
      "char_count": 1384,
      "start_char": 32831,
      "end_char": 34215,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5045792452830189,
      "chunking_strategy": "hierarchical_precise_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.578074",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Look at the full metaprompt",
      "chunk_hash": "07e6f242a0d56c48",
      "content_digest": "07e6f242a0d56c48",
      "chunk_length": 1384,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "answer",
          "for",
          "question",
          "context",
          "metaprompt",
          "you",
          "vector",
          "search",
          "and",
          "python",
          "full",
          "software",
          "architect",
          "using",
          "can",
          "find",
          "know",
          "web",
          "service"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 12,
            "weight": 0.070175
          },
          {
            "term": "answer",
            "tf": 7,
            "weight": 0.040936
          },
          {
            "term": "for",
            "tf": 5,
            "weight": 0.02924
          },
          {
            "term": "question",
            "tf": 4,
            "weight": 0.023392
          },
          {
            "term": "context",
            "tf": 4,
            "weight": 0.023392
          },
          {
            "term": "metaprompt",
            "tf": 3,
            "weight": 0.017544
          },
          {
            "term": "you",
            "tf": 3,
            "weight": 0.017544
          },
          {
            "term": "vector",
            "tf": 3,
            "weight": 0.017544
          },
          {
            "term": "search",
            "tf": 3,
            "weight": 0.017544
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.017544
          },
          {
            "term": "python",
            "tf": 3,
            "weight": 0.017544
          },
          {
            "term": "full",
            "tf": 2,
            "weight": 0.011696
          },
          {
            "term": "software",
            "tf": 2,
            "weight": 0.011696
          },
          {
            "term": "architect",
            "tf": 2,
            "weight": 0.011696
          },
          {
            "term": "using",
            "tf": 2,
            "weight": 0.011696
          },
          {
            "term": "can",
            "tf": 2,
            "weight": 0.011696
          },
          {
            "term": "find",
            "tf": 2,
            "weight": 0.011696
          },
          {
            "term": "know",
            "tf": 2,
            "weight": 0.011696
          },
          {
            "term": "web",
            "tf": 2,
            "weight": 0.011696
          },
          {
            "term": "service",
            "tf": 2,
            "weight": 0.011696
          }
        ],
        "unique_terms": 112,
        "total_terms": 171
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Look at the full metaprompt",
        "and",
        "answer",
        "context",
        "for",
        "metaprompt",
        "question",
        "search",
        "the",
        "vector",
        "you"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5045792452830189,
      "overall": 0.6681930817610061
    }
  },
  {
    "text": "### Testing out the RAG pipeline\n\nBy leveraging the semantic context we provided our model is doing a better job answering the question. Let’s enclose the RAG as a function, so we can call it more easily for different prompts.\n\n```python\ndef rag(question: str, n_points: int = 3) -> str:\n    results = client.query_points(\n        collection_name=collection_name,\n        query=models.Document(text=question, model=model_name),\n        limit=n_points,\n    )\n\n    context = \"\\n\".join(r.payload[\"document\"] for r in results.points)\n\n    metaprompt = f\"\"\"\n    You are a software architect. \n    Answer the following question using the provided context. \n    If you can't find the answer, do not pretend you know it, but only answer \"I don't know\".\n\n    Question: {question.strip()}\n\n    Context: \n    {context.strip()}\n\n    Answer:\n    \"\"\"\n\n    return query_deepseek(metaprompt)\n```\n\nNow it’s easier to ask a broad range of questions.\n\n**Question:**\n\n```python\nrag(\"What can the stack for a web api look like?\")\n```\n\n**Answer:**\n\n```bash\n'The stack for a web API can include the following components based on the provided context:\\n\\n1. **Web Framework**: FastAPI can be used as the web framework for building the API. It is modern, fast, and leverages Python type hints for better development and performance.\\n\\n2. **Reverse Proxy/Web Server**: NGINX can be used as a reverse proxy or web server to handle incoming HTTP requests, load balancing, and serving static content. It is known for its high performance and low resource consumption.\\n\\n3. **Containerization**: Docker can be used to containerize the application, making it easier to build, share, and run the API consistently across different environments without worrying about configuration issues.\\n\\nThis stack provides a robust, scalable, and efficient setup for building and deploying a web API.'\n```\n\n**Question:**\n\n```python\nrag(\"Where is the nearest grocery store?\")\n```\n\n**Answer:**\n\n```bash\n\"I don't know. The provided context does not contain any information about the location of the nearest grocery store.\"\n```\n\nOur model can now:\n\n1. Take advantage of the knowledge in our vector datastore.\n2. Answer, based on the provided context, that it can not provide an answer.",
    "metadata": {
      "chunk_id": "ee2c67aabb08-0027",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "filename": "_documentation_rag-deepseek_.md",
      "file_extension": ".md",
      "chunk_index": 27,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Testing out the RAG pipeline"
      ],
      "heading_text": "Testing out the RAG pipeline",
      "token_count": 500,
      "char_count": 2239,
      "start_char": 35585,
      "end_char": 37824,
      "semantic_score": 0.7,
      "structural_score": 0.9999999999999999,
      "retrieval_quality": 0.6908227848101265,
      "chunking_strategy": "hierarchical_precise_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:26.579567",
      "document_id": "ee2c67aabb08",
      "document_name": "_documentation_rag-deepseek_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "source_filename": "_documentation_rag-deepseek_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "hierarchy_path": "Testing out the RAG pipeline",
      "chunk_hash": "f7dfe152fee3386a",
      "content_digest": "f7dfe152fee3386a",
      "chunk_length": 2239,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "can",
          "context",
          "question",
          "for",
          "answer",
          "web",
          "and",
          "rag",
          "provided",
          "api",
          "model",
          "python",
          "points",
          "our",
          "query",
          "name",
          "you",
          "not",
          "know"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 21,
            "weight": 0.076364
          },
          {
            "term": "can",
            "tf": 9,
            "weight": 0.032727
          },
          {
            "term": "context",
            "tf": 8,
            "weight": 0.029091
          },
          {
            "term": "question",
            "tf": 8,
            "weight": 0.029091
          },
          {
            "term": "for",
            "tf": 8,
            "weight": 0.029091
          },
          {
            "term": "answer",
            "tf": 8,
            "weight": 0.029091
          },
          {
            "term": "web",
            "tf": 7,
            "weight": 0.025455
          },
          {
            "term": "and",
            "tf": 7,
            "weight": 0.025455
          },
          {
            "term": "rag",
            "tf": 5,
            "weight": 0.018182
          },
          {
            "term": "provided",
            "tf": 5,
            "weight": 0.018182
          },
          {
            "term": "api",
            "tf": 5,
            "weight": 0.018182
          },
          {
            "term": "model",
            "tf": 4,
            "weight": 0.014545
          },
          {
            "term": "python",
            "tf": 4,
            "weight": 0.014545
          },
          {
            "term": "points",
            "tf": 4,
            "weight": 0.014545
          },
          {
            "term": "our",
            "tf": 3,
            "weight": 0.010909
          },
          {
            "term": "query",
            "tf": 3,
            "weight": 0.010909
          },
          {
            "term": "name",
            "tf": 3,
            "weight": 0.010909
          },
          {
            "term": "you",
            "tf": 3,
            "weight": 0.010909
          },
          {
            "term": "not",
            "tf": 3,
            "weight": 0.010909
          },
          {
            "term": "know",
            "tf": 3,
            "weight": 0.010909
          }
        ],
        "unique_terms": 146,
        "total_terms": 275
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Testing out the RAG pipeline",
        "and",
        "answer",
        "can",
        "context",
        "for",
        "provided",
        "question",
        "rag",
        "the",
        "web"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.9999999999999999,
      "retrieval_quality": 0.6908227848101265,
      "overall": 0.796940928270042
    }
  }
]
[
  {
    "text": "## Performance Comparison  FastEmbed is designed to be faster than traditional embedding libraries by utilizing ONNX Runtime for inference and optimized model implementations.",
    "metadata": {
      "chunk_id": "faf9f8b66b10-0011",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance Comparison"
      ],
      "heading_text": "Performance Comparison",
      "token_count": 27,
      "char_count": 175,
      "start_char": 0,
      "end_char": 175,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:35:18.792648",
      "document_id": "faf9f8b66b10",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Performance Comparison",
      "chunk_hash": "5653f9c4ee4ceecd",
      "content_digest": "5653f9c4ee4ceecd",
      "chunk_length": 175,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "performance",
          "comparison",
          "fastembed",
          "designed",
          "faster",
          "than",
          "traditional",
          "embedding",
          "libraries",
          "utilizing",
          "onnx",
          "runtime",
          "for",
          "inference",
          "and",
          "optimized",
          "model",
          "implementations"
        ],
        "term_weights": [
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "comparison",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "designed",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "faster",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "than",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "traditional",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "libraries",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "utilizing",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "onnx",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "runtime",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "optimized",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.055556
          },
          {
            "term": "implementations",
            "tf": 1,
            "weight": 0.055556
          }
        ],
        "unique_terms": 18,
        "total_terms": 18
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance Comparison",
        "comparison",
        "designed",
        "embedding",
        "fastembed",
        "faster",
        "libraries",
        "performance",
        "than",
        "traditional",
        "utilizing"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.59,
      "overall": 0.7633333333333333
    }
  },
  {
    "text": "### Understanding Late Interaction  Late interaction models like ColBERT compute embeddings for each token in queries and documents, rather than pooling them into a single vector: ``` ```",
    "metadata": {
      "chunk_id": "faf9f8b66b10-0008",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Understanding Late Interaction"
      ],
      "heading_text": "Understanding Late Interaction",
      "token_count": 32,
      "char_count": 187,
      "start_char": 0,
      "end_char": 187,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5578571428571428,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:35:18.791898",
      "document_id": "faf9f8b66b10",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Understanding Late Interaction",
      "chunk_hash": "9de1ae862f4bb561",
      "content_digest": "9de1ae862f4bb561",
      "chunk_length": 187,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "late",
          "interaction",
          "understanding",
          "models",
          "like",
          "colbert",
          "compute",
          "embeddings",
          "for",
          "each",
          "token",
          "queries",
          "and",
          "documents",
          "rather",
          "than",
          "pooling",
          "them",
          "into",
          "single"
        ],
        "term_weights": [
          {
            "term": "late",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "interaction",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "understanding",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "like",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "colbert",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "compute",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "each",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "token",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "queries",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "rather",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "than",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "pooling",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "them",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "into",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "single",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 21,
        "total_terms": 23
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Understanding Late Interaction",
        "colbert",
        "compute",
        "each",
        "embeddings",
        "for",
        "interaction",
        "late",
        "like",
        "models",
        "understanding"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5578571428571428,
      "overall": 0.7526190476190475
    }
  },
  {
    "text": "## ColBERT and Late Interaction Models  FastEmbed supports late interaction models through the `LateInteractionTextEmbedding` class, which enables more precise retrieval by preserving token-level interactions.",
    "metadata": {
      "chunk_id": "faf9f8b66b10-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ColBERT and Late Interaction Models"
      ],
      "heading_text": "ColBERT and Late Interaction Models",
      "token_count": 36,
      "char_count": 209,
      "start_char": 0,
      "end_char": 209,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:35:18.791587",
      "document_id": "faf9f8b66b10",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "ColBERT and Late Interaction Models",
      "chunk_hash": "3bb1f33c4442a042",
      "content_digest": "3bb1f33c4442a042",
      "chunk_length": 209,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "late",
          "interaction",
          "models",
          "colbert",
          "and",
          "fastembed",
          "supports",
          "through",
          "the",
          "lateinteractiontextembedding",
          "class",
          "which",
          "enables",
          "more",
          "precise",
          "retrieval",
          "preserving",
          "token",
          "level",
          "interactions"
        ],
        "term_weights": [
          {
            "term": "late",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "interaction",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "colbert",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "through",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "lateinteractiontextembedding",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "which",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "enables",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "more",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "precise",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "retrieval",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "preserving",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "token",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "level",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "interactions",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 20,
        "total_terms": 23
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ColBERT and Late Interaction Models",
        "and",
        "colbert",
        "fastembed",
        "interaction",
        "late",
        "lateinteractiontextembedding",
        "models",
        "supports",
        "the",
        "through"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "overall": 0.7508333333333334
    }
  },
  {
    "text": "### Using ColBERT Model ``` ```",
    "metadata": {
      "chunk_id": "faf9f8b66b10-0009",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Using ColBERT Model"
      ],
      "heading_text": "Using ColBERT Model",
      "token_count": 7,
      "char_count": 31,
      "start_char": 0,
      "end_char": 31,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.54,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:35:18.791996",
      "document_id": "faf9f8b66b10",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Using ColBERT Model",
      "chunk_hash": "2cd0fee19272a423",
      "content_digest": "2cd0fee19272a423",
      "chunk_length": 31,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "using",
          "colbert",
          "model"
        ],
        "term_weights": [
          {
            "term": "using",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "colbert",
            "tf": 1,
            "weight": 0.333333
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.333333
          }
        ],
        "unique_terms": 3,
        "total_terms": 3
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Using ColBERT Model",
        "colbert",
        "model",
        "using"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.54,
      "overall": 0.7466666666666667
    }
  },
  {
    "text": "### Using Different Models  FastEmbed supports various embedding models with different capabilities: ``` ```",
    "metadata": {
      "chunk_id": "faf9f8b66b10-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "filename": "_qdrant_fastembed_7-usage-examples.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Using Different Models"
      ],
      "heading_text": "Using Different Models",
      "token_count": 17,
      "char_count": 108,
      "start_char": 0,
      "end_char": 108,
      "semantic_score": 0.8,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5257142857142857,
      "chunking_strategy": "hierarchical_balanced",
      "content_type": "hierarchical_section",
      "embedding_model": "nomic-ai/CodeRankEmbed",
      "processing_timestamp": "2025-10-19T15:35:18.790214",
      "document_id": "faf9f8b66b10",
      "document_name": "_qdrant_fastembed_7-usage-examples",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "source_filename": "_qdrant_fastembed_7-usage-examples.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
      "hierarchy_path": "Using Different Models",
      "chunk_hash": "2572deac203f0691",
      "content_digest": "2572deac203f0691",
      "chunk_length": 108,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "different",
          "models",
          "using",
          "fastembed",
          "supports",
          "various",
          "embedding",
          "with",
          "capabilities"
        ],
        "term_weights": [
          {
            "term": "different",
            "tf": 2,
            "weight": 0.181818
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.181818
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "fastembed",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "supports",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "various",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.090909
          },
          {
            "term": "capabilities",
            "tf": 1,
            "weight": 0.090909
          }
        ],
        "unique_terms": 9,
        "total_terms": 11
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Using Different Models",
        "capabilities",
        "different",
        "embedding",
        "fastembed",
        "models",
        "supports",
        "using",
        "various",
        "with"
      ],
      "quality_fallback": true,
      "quality_notes": "Promoted via relaxed thresholds"
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5257142857142857,
      "overall": 0.7419047619047618
    }
  }
]
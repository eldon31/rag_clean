[
  {
    "text": "## Purpose and Scope\n\nThis document describes the Local Inference system in qdrant-client, which enables automatic embedding of documents and images directly within the client application, without requiring an external embedding service. This system allows seamless integration of embedding models into vector search workflows by automatically detecting and processing objects that require inference.\n\nFor information about the FastEmbed integration, which provides pre-configured models, see [FastEmbed Integration](qdrant/qdrant-client/4.1-fastembed-integration.md).",
    "metadata": {
      "chunk_id": "840bd82e62ec-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Purpose and Scope"
      ],
      "heading_text": "Purpose and Scope",
      "token_count": 100,
      "char_count": 568,
      "start_char": 2671,
      "end_char": 3239,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5445454545454546,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.747659",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Purpose and Scope",
      "chunk_hash": "3c6dfa72a594df1e",
      "content_digest": "3c6dfa72a594df1e",
      "chunk_length": 568,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "integration",
          "and",
          "the",
          "qdrant",
          "client",
          "embedding",
          "fastembed",
          "this",
          "inference",
          "system",
          "which",
          "models",
          "purpose",
          "scope",
          "document",
          "describes",
          "local",
          "enables",
          "automatic",
          "documents"
        ],
        "term_weights": [
          {
            "term": "integration",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "client",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "embedding",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "this",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "system",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "which",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "purpose",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "scope",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "describes",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "local",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "enables",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "automatic",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.014925
          }
        ],
        "unique_terms": 47,
        "total_terms": 67
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Purpose and Scope",
        "and",
        "client",
        "embedding",
        "fastembed",
        "inference",
        "integration",
        "qdrant",
        "system",
        "the",
        "this"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5445454545454546,
      "overall": 0.7481818181818181
    }
  },
  {
    "text": "## Overview\n\nThe Local Inference system transparently converts high-level objects like text documents and images into vector embeddings that can be stored and searched in Qdrant. When you provide a `Document` or `Image` object to methods like `upsert()` or `query_points()`, the system automatically:\n\n1. Detects fields requiring embedding\n2. Loads the appropriate model\n3. Generates embeddings\n4. Replaces the original objects with their vector representations\n\n**Local Inference System Architecture**\n\n```\n```\n\nSources: [qdrant\\_client/embed/model\\_embedder.py42-444](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L42-L444) [qdrant\\_client/embed/embedder.py29-388](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L29-L388) [qdrant\\_client/fastembed\\_common.py36-267](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/fastembed_common.py#L36-L267)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Overview"
      ],
      "heading_text": "Overview",
      "token_count": 249,
      "char_count": 950,
      "start_char": 3241,
      "end_char": 4191,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.538,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.747659",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Overview",
      "chunk_hash": "22173666161e3188",
      "content_digest": "22173666161e3188",
      "chunk_length": 950,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "the",
          "embed",
          "embedder",
          "system",
          "model",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "local",
          "inference",
          "objects",
          "like",
          "and",
          "vector",
          "embeddings",
          "fastembed"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 13,
            "weight": 0.105691
          },
          {
            "term": "client",
            "tf": 9,
            "weight": 0.073171
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "embedder",
            "tf": 4,
            "weight": 0.03252
          },
          {
            "term": "system",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "ac6f6cd2",
            "tf": 3,
            "weight": 0.02439
          },
          {
            "term": "local",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "objects",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "like",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.01626
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.01626
          }
        ],
        "unique_terms": 71,
        "total_terms": 123
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Overview",
        "client",
        "com",
        "embed",
        "embedder",
        "github",
        "https",
        "model",
        "qdrant",
        "system",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.538,
      "overall": 0.6793333333333332
    }
  },
  {
    "text": "### ModelEmbedder\n\nThe `ModelEmbedder` class is the primary entry point for local inference. It coordinates the inspection, batching, and embedding processes:\n\n**Core Classes and Methods**\n\n```\n```\n\nSources: [qdrant\\_client/embed/model\\_embedder.py21-444](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L21-L444) [qdrant\\_client/embed/embedder.py23-388](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L23-L388) [qdrant\\_client/fastembed\\_common.py36-267](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/fastembed_common.py#L36-L267)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "ModelEmbedder"
      ],
      "heading_text": "ModelEmbedder",
      "token_count": 186,
      "char_count": 636,
      "start_char": 4213,
      "end_char": 4849,
      "semantic_score": 0.6,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5512903225806451,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.747659",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "ModelEmbedder",
      "chunk_hash": "0a11b59dfdcae966",
      "content_digest": "0a11b59dfdcae966",
      "chunk_length": 636,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "embed",
          "embedder",
          "the",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "modelembedder",
          "and",
          "model",
          "fastembed",
          "common",
          "class",
          "primary",
          "entry",
          "point",
          "for"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 12,
            "weight": 0.141176
          },
          {
            "term": "client",
            "tf": 9,
            "weight": 0.105882
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.047059
          },
          {
            "term": "embedder",
            "tf": 4,
            "weight": 0.047059
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "ac6f6cd2",
            "tf": 3,
            "weight": 0.035294
          },
          {
            "term": "modelembedder",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "common",
            "tf": 2,
            "weight": 0.023529
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "primary",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "entry",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "point",
            "tf": 1,
            "weight": 0.011765
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011765
          }
        ],
        "unique_terms": 43,
        "total_terms": 85
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "ModelEmbedder",
        "ac6f6cd2",
        "blob",
        "client",
        "com",
        "embed",
        "embedder",
        "github",
        "https",
        "qdrant",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5512903225806451,
      "overall": 0.6504301075268817
    }
  },
  {
    "text": "### Embedder\n\nThe `Embedder` class manages embedding models and performs the actual inference:\n\n- Maintains a registry of initialized models\n- Provides methods to embed text and images\n- Supports various model types (dense, sparse, late interaction, multimodal)\n- Handles model sharing and caching\n\nSources: [qdrant\\_client/embed/embedder.py32-385](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L32-L385)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Embedder"
      ],
      "heading_text": "Embedder",
      "token_count": 108,
      "char_count": 444,
      "start_char": 4851,
      "end_char": 5295,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5378260869565217,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.747659",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Embedder",
      "chunk_hash": "5d51df97dd3bfe5b",
      "content_digest": "5d51df97dd3bfe5b",
      "chunk_length": 444,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "embedder",
          "qdrant",
          "and",
          "embed",
          "client",
          "the",
          "models",
          "model",
          "class",
          "manages",
          "embedding",
          "performs",
          "actual",
          "inference",
          "maintains",
          "registry",
          "initialized",
          "provides",
          "methods",
          "text"
        ],
        "term_weights": [
          {
            "term": "embedder",
            "tf": 4,
            "weight": 0.070175
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.070175
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "embed",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "client",
            "tf": 3,
            "weight": 0.052632
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.035088
          },
          {
            "term": "class",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "manages",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "embedding",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "performs",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "actual",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "maintains",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "registry",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "initialized",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "provides",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "methods",
            "tf": 1,
            "weight": 0.017544
          },
          {
            "term": "text",
            "tf": 1,
            "weight": 0.017544
          }
        ],
        "unique_terms": 42,
        "total_terms": 57
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Embedder",
        "and",
        "class",
        "client",
        "embed",
        "embedder",
        "manages",
        "model",
        "models",
        "qdrant",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5378260869565217,
      "overall": 0.6792753623188404
    }
  },
  {
    "text": "### Type Inspection System\n\nThe type inspection system identifies fields in models that require inference:\n\n```\n```\n\nSources: [qdrant\\_client/embed/type\\_inspector.py12-149](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/type_inspector.py#L12-L149) [qdrant\\_client/embed/embed\\_inspector.py13-176](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embed_inspector.py#L13-L176) [qdrant\\_client/embed/schema\\_parser.py29-305](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/schema_parser.py#L29-L305)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0006",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Type Inspection System"
      ],
      "heading_text": "Type Inspection System",
      "token_count": 168,
      "char_count": 575,
      "start_char": 5297,
      "end_char": 5872,
      "semantic_score": 0.6,
      "structural_score": 0.7,
      "retrieval_quality": 0.5328571428571428,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.747659",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Type Inspection System",
      "chunk_hash": "9af7f4949f8b95c8",
      "content_digest": "9af7f4949f8b95c8",
      "chunk_length": 575,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "embed",
          "type",
          "inspector",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "inspection",
          "system",
          "schema",
          "parser",
          "the",
          "identifies",
          "fields",
          "models",
          "that",
          "require"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 12,
            "weight": 0.15
          },
          {
            "term": "client",
            "tf": 9,
            "weight": 0.1125
          },
          {
            "term": "embed",
            "tf": 8,
            "weight": 0.1
          },
          {
            "term": "type",
            "tf": 4,
            "weight": 0.05
          },
          {
            "term": "inspector",
            "tf": 4,
            "weight": 0.05
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.0375
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.0375
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.0375
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.0375
          },
          {
            "term": "ac6f6cd2",
            "tf": 3,
            "weight": 0.0375
          },
          {
            "term": "inspection",
            "tf": 2,
            "weight": 0.025
          },
          {
            "term": "system",
            "tf": 2,
            "weight": 0.025
          },
          {
            "term": "schema",
            "tf": 2,
            "weight": 0.025
          },
          {
            "term": "parser",
            "tf": 2,
            "weight": 0.025
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.0125
          },
          {
            "term": "identifies",
            "tf": 1,
            "weight": 0.0125
          },
          {
            "term": "fields",
            "tf": 1,
            "weight": 0.0125
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.0125
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.0125
          },
          {
            "term": "require",
            "tf": 1,
            "weight": 0.0125
          }
        ],
        "unique_terms": 34,
        "total_terms": 80
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Type Inspection System",
        "ac6f6cd2",
        "blob",
        "client",
        "com",
        "embed",
        "github",
        "https",
        "inspector",
        "qdrant",
        "type"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7,
      "retrieval_quality": 0.5328571428571428,
      "overall": 0.6109523809523809
    }
  },
  {
    "text": "## Inference Workflow\n\n**Local Inference Processing Flow**\n\n```\n```\n\nSources: [qdrant\\_client/embed/model\\_embedder.py124-156](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L124-L156) [qdrant\\_client/embed/embedder.py222-267](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L222-L267) [tests/embed\\_tests/test\\_local\\_inference.py133-237](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L133-L237)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Inference Workflow"
      ],
      "heading_text": "Inference Workflow",
      "token_count": 161,
      "char_count": 529,
      "start_char": 5874,
      "end_char": 6403,
      "semantic_score": 0.6,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5438461538461539,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.747659",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Inference Workflow",
      "chunk_hash": "c6bffbd9da281469",
      "content_digest": "c6bffbd9da281469",
      "chunk_length": 529,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "embed",
          "inference",
          "embedder",
          "tests",
          "local",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "model",
          "test",
          "workflow",
          "processing",
          "flow",
          "sources",
          "py124",
          "156"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.136986
          },
          {
            "term": "client",
            "tf": 7,
            "weight": 0.09589
          },
          {
            "term": "embed",
            "tf": 6,
            "weight": 0.082192
          },
          {
            "term": "inference",
            "tf": 4,
            "weight": 0.054795
          },
          {
            "term": "embedder",
            "tf": 4,
            "weight": 0.054795
          },
          {
            "term": "tests",
            "tf": 4,
            "weight": 0.054795
          },
          {
            "term": "local",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "ac6f6cd2",
            "tf": 3,
            "weight": 0.041096
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.027397
          },
          {
            "term": "workflow",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "processing",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "flow",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "py124",
            "tf": 1,
            "weight": 0.013699
          },
          {
            "term": "156",
            "tf": 1,
            "weight": 0.013699
          }
        ],
        "unique_terms": 30,
        "total_terms": 73
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Inference Workflow",
        "client",
        "com",
        "embed",
        "embedder",
        "github",
        "https",
        "inference",
        "local",
        "qdrant",
        "tests"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5438461538461539,
      "overall": 0.6479487179487179
    }
  },
  {
    "text": "## Supported Inference Objects\n\n**Inference Object Types**\n\n```\n```\n\nThe constant `INFERENCE_OBJECT_NAMES` contains the string names: `{\"Document\", \"Image\", \"InferenceObject\"}` and `INFERENCE_OBJECT_TYPES` is a Union type used throughout the system for type checking.\n\nSources: [qdrant\\_client/embed/common.py5-6](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/common.py#L5-L6)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0009",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Supported Inference Objects"
      ],
      "heading_text": "Supported Inference Objects",
      "token_count": 107,
      "char_count": 404,
      "start_char": 7319,
      "end_char": 7723,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5547058823529412,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.747659",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Supported Inference Objects",
      "chunk_hash": "be0fc9b57b799dfa",
      "content_digest": "be0fc9b57b799dfa",
      "chunk_length": 404,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "inference",
          "qdrant",
          "object",
          "the",
          "client",
          "types",
          "names",
          "type",
          "embed",
          "common",
          "supported",
          "objects",
          "constant",
          "contains",
          "string",
          "document",
          "image",
          "inferenceobject",
          "and",
          "union"
        ],
        "term_weights": [
          {
            "term": "inference",
            "tf": 4,
            "weight": 0.081633
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.081633
          },
          {
            "term": "object",
            "tf": 3,
            "weight": 0.061224
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.061224
          },
          {
            "term": "client",
            "tf": 3,
            "weight": 0.061224
          },
          {
            "term": "types",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "names",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "type",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "embed",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "common",
            "tf": 2,
            "weight": 0.040816
          },
          {
            "term": "supported",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "objects",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "constant",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "contains",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "string",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "image",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "inferenceobject",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.020408
          },
          {
            "term": "union",
            "tf": 1,
            "weight": 0.020408
          }
        ],
        "unique_terms": 32,
        "total_terms": 49
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Supported Inference Objects",
        "client",
        "common",
        "embed",
        "inference",
        "names",
        "object",
        "qdrant",
        "the",
        "type",
        "types"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5547058823529412,
      "overall": 0.6849019607843138
    }
  },
  {
    "text": "### Basic Usage\n\nLocal inference happens automatically when you provide `Document` or `Image` objects to client methods:\n\n```\n```\n\nSources: [tests/embed\\_tests/test\\_local\\_inference.py133-165](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L133-L165)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0011",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Basic Usage"
      ],
      "heading_text": "Basic Usage",
      "token_count": 77,
      "char_count": 300,
      "start_char": 7751,
      "end_char": 8051,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5757142857142857,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.747659",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Basic Usage",
      "chunk_hash": "0781954896fc3f2b",
      "content_digest": "0781954896fc3f2b",
      "chunk_length": 300,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "tests",
          "local",
          "inference",
          "client",
          "embed",
          "test",
          "qdrant",
          "basic",
          "usage",
          "happens",
          "automatically",
          "when",
          "you",
          "provide",
          "document",
          "image",
          "objects",
          "methods",
          "sources",
          "py133"
        ],
        "term_weights": [
          {
            "term": "tests",
            "tf": 4,
            "weight": 0.102564
          },
          {
            "term": "local",
            "tf": 3,
            "weight": 0.076923
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.076923
          },
          {
            "term": "client",
            "tf": 2,
            "weight": 0.051282
          },
          {
            "term": "embed",
            "tf": 2,
            "weight": 0.051282
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.051282
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.051282
          },
          {
            "term": "basic",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "usage",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "happens",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "automatically",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "when",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "provide",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "document",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "image",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "objects",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "methods",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.025641
          },
          {
            "term": "py133",
            "tf": 1,
            "weight": 0.025641
          }
        ],
        "unique_terms": 28,
        "total_terms": 39
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Basic Usage",
        "basic",
        "client",
        "embed",
        "happens",
        "inference",
        "local",
        "qdrant",
        "test",
        "tests",
        "usage"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5757142857142857,
      "overall": 0.6585714285714285
    }
  },
  {
    "text": "### Query-Time Inference\n\nThe system distinguishes between document and query embedding for models that have different embedding methods for documents and queries:\n\n```\n```\n\nSources: [qdrant\\_client/embed/embedder.py278-287](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L278-L287) [tests/embed\\_tests/test\\_local\\_inference.py352-581](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L352-L581)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0013",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Query-Time Inference"
      ],
      "heading_text": "Query-Time Inference",
      "token_count": 127,
      "char_count": 482,
      "start_char": 8306,
      "end_char": 8788,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5455555555555556,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.747659",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Query-Time Inference",
      "chunk_hash": "8b0251e82964dced",
      "content_digest": "8b0251e82964dced",
      "chunk_length": 482,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "embed",
          "tests",
          "inference",
          "query",
          "and",
          "embedding",
          "for",
          "embedder",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "test",
          "local",
          "time",
          "the",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.089552
          },
          {
            "term": "client",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "tests",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "embedder",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "ac6f6cd2",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "local",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "time",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.014925
          }
        ],
        "unique_terms": 39,
        "total_terms": 67
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Query-Time Inference",
        "and",
        "client",
        "embed",
        "embedder",
        "embedding",
        "for",
        "inference",
        "qdrant",
        "query",
        "tests"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5455555555555556,
      "overall": 0.6485185185185185
    }
  },
  {
    "text": "### Model Configuration Options\n\nYou can pass additional options to the embedding models:\n\n```\n```\n\nSources: [qdrant\\_client/embed/embedder.py61-67](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L61-L67) [tests/embed\\_tests/test\\_local\\_inference.py916-976](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L916-L976)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0015",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Configuration Options"
      ],
      "heading_text": "Model Configuration Options",
      "token_count": 115,
      "char_count": 404,
      "start_char": 8812,
      "end_char": 9216,
      "semantic_score": 0.6,
      "structural_score": 0.7,
      "retrieval_quality": 0.5566666666666666,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.747659",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Model Configuration Options",
      "chunk_hash": "90c9f939b87aa46f",
      "content_digest": "90c9f939b87aa46f",
      "chunk_length": 404,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "embed",
          "tests",
          "options",
          "embedder",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "test",
          "local",
          "inference",
          "model",
          "configuration",
          "you",
          "can",
          "pass",
          "additional"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.109091
          },
          {
            "term": "client",
            "tf": 4,
            "weight": 0.072727
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.072727
          },
          {
            "term": "tests",
            "tf": 4,
            "weight": 0.072727
          },
          {
            "term": "options",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "embedder",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "ac6f6cd2",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "local",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "configuration",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "pass",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "additional",
            "tf": 1,
            "weight": 0.018182
          }
        ],
        "unique_terms": 31,
        "total_terms": 55
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Configuration Options",
        "blob",
        "client",
        "com",
        "embed",
        "embedder",
        "github",
        "https",
        "options",
        "qdrant",
        "tests"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7,
      "retrieval_quality": 0.5566666666666666,
      "overall": 0.6188888888888888
    }
  },
  {
    "text": "### Parallel Processing\n\nFor large batches of documents, you can use parallel processing:\n\n```\n```\n\nSources: [qdrant\\_client/embed/model\\_embedder.py75-123](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L75-L123) [tests/embed\\_tests/test\\_local\\_inference.py310-350](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L310-L350)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0016",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Parallel Processing"
      ],
      "heading_text": "Parallel Processing",
      "token_count": 119,
      "char_count": 419,
      "start_char": 9218,
      "end_char": 9637,
      "semantic_score": 0.6,
      "structural_score": 0.7,
      "retrieval_quality": 0.5566666666666666,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.747659",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Parallel Processing",
      "chunk_hash": "015ef654bf44bb67",
      "content_digest": "015ef654bf44bb67",
      "chunk_length": 419,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "embed",
          "tests",
          "parallel",
          "processing",
          "model",
          "embedder",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "test",
          "local",
          "inference",
          "for",
          "large",
          "batches",
          "documents"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.103448
          },
          {
            "term": "client",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "tests",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "parallel",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "processing",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "embedder",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "ac6f6cd2",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "local",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "large",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "batches",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "documents",
            "tf": 1,
            "weight": 0.017241
          }
        ],
        "unique_terms": 32,
        "total_terms": 58
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Parallel Processing",
        "client",
        "embed",
        "embedder",
        "github",
        "https",
        "model",
        "parallel",
        "processing",
        "qdrant",
        "tests"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7,
      "retrieval_quality": 0.5566666666666666,
      "overall": 0.6188888888888888
    }
  },
  {
    "text": "### Object Detection and Processing\n\nThe system uses a multi-step process to detect and process objects requiring inference:\n\n1. **Model Processing**: The `ModelEmbedder._process_model()` method traverses model structures to find inference objects.\n2. **Object Accumulation**: The `_accumulate()` method collects `Document`, `Image`, and `InferenceObject` instances into batches grouped by model name.\n3. **Batch Embedding**: The `_embed_accumulator()` method calls `Embedder.embed()` to generate embeddings for accumulated objects.\n4. **Model Resolution**: The `_resolve_inference_object()` method converts `InferenceObject` instances to `Document` or `Image` objects.\n5. **Replacement**: The `_drain_accumulator()` method replaces original objects with their vector representations.\n\n**Processing Pipeline**\n\n```\n```\n\nSources: [qdrant\\_client/embed/model\\_embedder.py141-156](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L141-L156) [qdrant\\_client/embed/model\\_embedder.py247-275](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L247-L275) [qdrant\\_client/embed/model\\_embedder.py277-317](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/model_embedder.py#L277-L317)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0019",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Object Detection and Processing"
      ],
      "heading_text": "Object Detection and Processing",
      "token_count": 315,
      "char_count": 1284,
      "start_char": 12419,
      "end_char": 13703,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5233659793814432,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.747659",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Object Detection and Processing",
      "chunk_hash": "99d58dd69a5bdab1",
      "content_digest": "99d58dd69a5bdab1",
      "chunk_length": 1284,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "model",
          "client",
          "embed",
          "embedder",
          "the",
          "objects",
          "method",
          "object",
          "and",
          "processing",
          "process",
          "inference",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "document",
          "image"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 12,
            "weight": 0.078431
          },
          {
            "term": "model",
            "tf": 11,
            "weight": 0.071895
          },
          {
            "term": "client",
            "tf": 9,
            "weight": 0.058824
          },
          {
            "term": "embed",
            "tf": 8,
            "weight": 0.052288
          },
          {
            "term": "embedder",
            "tf": 7,
            "weight": 0.045752
          },
          {
            "term": "the",
            "tf": 6,
            "weight": 0.039216
          },
          {
            "term": "objects",
            "tf": 5,
            "weight": 0.03268
          },
          {
            "term": "method",
            "tf": 5,
            "weight": 0.03268
          },
          {
            "term": "object",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "processing",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "process",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "ac6f6cd2",
            "tf": 3,
            "weight": 0.019608
          },
          {
            "term": "document",
            "tf": 2,
            "weight": 0.013072
          },
          {
            "term": "image",
            "tf": 2,
            "weight": 0.013072
          }
        ],
        "unique_terms": 73,
        "total_terms": 153
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Object Detection and Processing",
        "and",
        "client",
        "embed",
        "embedder",
        "method",
        "model",
        "object",
        "objects",
        "qdrant",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5233659793814432,
      "overall": 0.674455326460481
    }
  },
  {
    "text": "### Model Management\n\nThe `Embedder` class efficiently manages embedding models through `ModelInstance` containers:\n\n- **Model Caching**: Each model type has its own dictionary (e.g., `embedding_models`, `sparse_embedding_models`) storing lists of `ModelInstance[T]` objects\n- **Configuration Tracking**: `ModelInstance` objects store model instances with their initialization options and deprecation status\n- **Lazy Loading**: Models are loaded only when first requested via `get_or_init_*` methods\n- **Option Matching**: Multiple instances of the same model with different configurations are supported by comparing options dictionaries\n- **Model Validation**: `FastEmbedMisc` provides validation methods for all supported model types\n\n**Model Instance Management**\n\n```\n```\n\nSources: [qdrant\\_client/embed/embedder.py23-27](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L23-L27) [qdrant\\_client/embed/embedder.py29-44](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L29-L44) [qdrant\\_client/embed/embedder.py46-221](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/embed/embedder.py#L46-L221)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0020",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Model Management"
      ],
      "heading_text": "Model Management",
      "token_count": 290,
      "char_count": 1192,
      "start_char": 13705,
      "end_char": 14897,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.5226530612244897,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.755106",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Model Management",
      "chunk_hash": "f6095b078a76e222",
      "content_digest": "f6095b078a76e222",
      "chunk_length": 1192,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "model",
          "embedder",
          "embed",
          "models",
          "embedding",
          "modelinstance",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "management",
          "the",
          "objects",
          "instances",
          "with",
          "options",
          "are"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 12,
            "weight": 0.082759
          },
          {
            "term": "client",
            "tf": 9,
            "weight": 0.062069
          },
          {
            "term": "model",
            "tf": 8,
            "weight": 0.055172
          },
          {
            "term": "embedder",
            "tf": 7,
            "weight": 0.048276
          },
          {
            "term": "embed",
            "tf": 6,
            "weight": 0.041379
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.027586
          },
          {
            "term": "embedding",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "modelinstance",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "https",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "blob",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "ac6f6cd2",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "management",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "objects",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "instances",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "options",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.013793
          }
        ],
        "unique_terms": 81,
        "total_terms": 145
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Model Management",
        "client",
        "embed",
        "embedder",
        "embedding",
        "github",
        "https",
        "model",
        "modelinstance",
        "models",
        "qdrant"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.5226530612244897,
      "overall": 0.6742176870748299
    }
  },
  {
    "text": "## Compatibility  The Local Inference system is designed to work with:  - **Local in-memory Qdrant instances**: `QdrantClient(\":memory:\")` - **Local persistent Qdrant instances**: `QdrantClient(path=\"/path/to/db\")` - **Remote Qdrant servers**: `QdrantClient(host=\"localhost\", port=6333)`  The system automatically handles embedding generation regardless of the backend, with the same API working across all deployment modes. Sources: [tests/embed\\_tests/test\\_local\\_inference.py134](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L134-L134) [tests/embed\\_tests/test\\_local\\_inference.py256-259](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L256-L259)",
    "metadata": {
      "chunk_id": "840bd82e62ec-0021",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Compatibility"
      ],
      "heading_text": "Compatibility",
      "token_count": 195,
      "char_count": 751,
      "start_char": 14899,
      "end_char": 15650,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5311764705882352,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.755106",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Compatibility",
      "chunk_hash": "6a3cead5a2a3dbd5",
      "content_digest": "6a3cead5a2a3dbd5",
      "chunk_length": 751,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "tests",
          "local",
          "qdrant",
          "inference",
          "the",
          "embed",
          "test",
          "qdrantclient",
          "system",
          "with",
          "memory",
          "instances",
          "path",
          "https",
          "github",
          "com",
          "client",
          "blob",
          "ac6f6cd2",
          "l134"
        ],
        "term_weights": [
          {
            "term": "tests",
            "tf": 8,
            "weight": 0.084211
          },
          {
            "term": "local",
            "tf": 7,
            "weight": 0.073684
          },
          {
            "term": "qdrant",
            "tf": 7,
            "weight": 0.073684
          },
          {
            "term": "inference",
            "tf": 5,
            "weight": 0.052632
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "embed",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "test",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "qdrantclient",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "system",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "memory",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "instances",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "path",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "client",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "ac6f6cd2",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "l134",
            "tf": 2,
            "weight": 0.021053
          }
        ],
        "unique_terms": 49,
        "total_terms": 95
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Compatibility",
        "embed",
        "inference",
        "local",
        "qdrant",
        "qdrantclient",
        "system",
        "test",
        "tests",
        "the",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5311764705882352,
      "overall": 0.710392156862745
    }
  },
  {
    "text": "## Limitations  - The FastEmbed library must be installed to use Local Inference - Not all embedding models are supported, only those available in FastEmbed - Embedding large batches may require significant memory  Sources: [tests/embed\\_tests/test\\_local\\_inference.py134-136](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/tests/embed_tests/test_local_inference.py#L134-L136) [qdrant\\_client/fastembed\\_common.py8-25](https://github.com/qdrant/qdrant-client/blob/ac6f6cd2/qdrant_client/fastembed_common.py#L8-L25)  Dismiss  Refresh this wiki  Enter email to refresh",
    "metadata": {
      "chunk_id": "840bd82e62ec-0022",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Limitations"
      ],
      "heading_text": "Limitations",
      "token_count": 150,
      "char_count": 574,
      "start_char": 15653,
      "end_char": 16227,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5490909090909091,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:46.755670",
      "document_id": "840bd82e62ec",
      "document_name": "_qdrant_qdrant-client_4.4-local-inference",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "source_filename": "_qdrant_qdrant-client_4.4-local-inference.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_qdrant-client",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_qdrant-client\\_qdrant_qdrant-client_4.4-local-inference.md",
      "hierarchy_path": "Limitations",
      "chunk_hash": "dff6926fd1d6acdc",
      "content_digest": "dff6926fd1d6acdc",
      "chunk_length": 574,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "fastembed",
          "tests",
          "client",
          "local",
          "inference",
          "embedding",
          "embed",
          "test",
          "https",
          "github",
          "com",
          "blob",
          "ac6f6cd2",
          "common",
          "refresh",
          "limitations",
          "the",
          "library",
          "must"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.078947
          },
          {
            "term": "fastembed",
            "tf": 4,
            "weight": 0.052632
          },
          {
            "term": "tests",
            "tf": 4,
            "weight": 0.052632
          },
          {
            "term": "client",
            "tf": 4,
            "weight": 0.052632
          },
          {
            "term": "local",
            "tf": 3,
            "weight": 0.039474
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.039474
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "embed",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "test",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "github",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "blob",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "ac6f6cd2",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "common",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "refresh",
            "tf": 2,
            "weight": 0.026316
          },
          {
            "term": "limitations",
            "tf": 1,
            "weight": 0.013158
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.013158
          },
          {
            "term": "library",
            "tf": 1,
            "weight": 0.013158
          },
          {
            "term": "must",
            "tf": 1,
            "weight": 0.013158
          }
        ],
        "unique_terms": 48,
        "total_terms": 76
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Limitations",
        "client",
        "embed",
        "embedding",
        "fastembed",
        "https",
        "inference",
        "local",
        "qdrant",
        "test",
        "tests"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5490909090909091,
      "overall": 0.7163636363636363
    }
  }
]
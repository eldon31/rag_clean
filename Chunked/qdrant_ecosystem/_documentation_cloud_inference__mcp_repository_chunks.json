[
  {
    "text": "### Managed Services  [Getting Started](https://qdrant.tech/documentation/cloud-getting-started/)  [Account Setup](https://qdrant.tech/documentation/cloud-account-setup/)  [Cloud RBAC](https://qdrant.tech/documentation/cloud-rbac/)  - [Role Management](https://qdrant.tech/documentation/cloud-rbac/role-management/) - [User Management](https://qdrant.tech/documentation/cloud-rbac/user-management/) - [Permission Reference](https://qdrant.tech/documentation/cloud-rbac/permission-reference/)  [Managed Cloud](https://qdrant.tech/documentation/cloud/)  - [Create a Cluster](https://qdrant.tech/documentation/cloud/create-cluster/) - [Authentication](https://qdrant.tech/documentation/cloud/authentication/) - [Cluster Access](https://qdrant.tech/documentation/cloud/cluster-access/) - [Scale Clusters](https://qdrant.tech/documentation/cloud/cluster-scaling/) - [Configure Clusters](https://qdrant.tech/documentation/cloud/configure-cluster/) - [Monitor Clusters](https://qdrant.tech/documentation/cloud/cluster-monitoring/) - [Update Clusters](https://qdrant.tech/documentation/cloud/cluster-upgrades/) - [Backup Clusters](https://qdrant.tech/documentation/cloud/backups/) - [Inference](https://qdrant.tech/documentation/cloud/inference/)  [Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/)  - [Setup Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/hybrid-cloud-setup/) - [Create a Cluster](https://qdrant.tech/documentation/hybrid-cloud/hybrid-cloud-cluster-creation/) - [Configure, Scale & Update Clusters](https://qdrant.tech/documentation/hybrid-cloud/configure-scale-upgrade/) - [Configure the Qdrant Operator](https://qdrant.tech/documentation/hybrid-cloud/operator-configuration/) - [Networking, Logging & Monitoring](https://qdrant.tech/documentation/hybrid-cloud/networking-logging-monitoring/) - [Deployment Platforms](https://qdrant.tech/documentation/hybrid-cloud/platform-deployment-options/)  [Private Cloud](https://qdrant.tech/documentation/private-cloud/)  - [Setup Private Cloud](https://qdrant.tech/documentation/private-cloud/private-cloud-setup/) - [Configuration](https://qdrant.tech/documentation/private-cloud/configuration/) - [Managing a Cluster](https://qdrant.tech/documentation/private-cloud/qdrant-cluster-management/) - [Backups](https://qdrant.tech/documentation/private-cloud/backups/) - [Logging & Monitoring](https://qdrant.tech/documentation/private-cloud/logging-monitoring/) - [API Reference](https://qdrant.tech/documentation/private-cloud/api-reference/) - [Changelog](https://qdrant.tech/documentation/private-cloud/changelog/)  [Billing & Payments](https://qdrant.tech/documentation/cloud-pricing-payments/)  [Premium Tier](https://qdrant.tech/documentation/cloud-premium/)",
    "metadata": {
      "chunk_id": "056d37d367b8-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Managed Services"
      ],
      "heading_text": "Managed Services",
      "token_count": 614,
      "char_count": 2741,
      "start_char": 754,
      "end_char": 3495,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7067961165048544,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.184454",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Managed Services",
      "chunk_hash": "81e21f320195534d",
      "content_digest": "81e21f320195534d",
      "chunk_length": 2741,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cloud",
          "qdrant",
          "https",
          "tech",
          "documentation",
          "cluster",
          "hybrid",
          "private",
          "setup",
          "clusters",
          "rbac",
          "management",
          "configure",
          "monitoring",
          "reference",
          "logging",
          "create",
          "scale",
          "backups",
          "configuration"
        ],
        "term_weights": [
          {
            "term": "cloud",
            "tf": 42,
            "weight": 0.134185
          },
          {
            "term": "qdrant",
            "tf": 35,
            "weight": 0.111821
          },
          {
            "term": "https",
            "tf": 33,
            "weight": 0.105431
          },
          {
            "term": "tech",
            "tf": 33,
            "weight": 0.105431
          },
          {
            "term": "documentation",
            "tf": 33,
            "weight": 0.105431
          },
          {
            "term": "cluster",
            "tf": 12,
            "weight": 0.038339
          },
          {
            "term": "hybrid",
            "tf": 11,
            "weight": 0.035144
          },
          {
            "term": "private",
            "tf": 11,
            "weight": 0.035144
          },
          {
            "term": "setup",
            "tf": 6,
            "weight": 0.019169
          },
          {
            "term": "clusters",
            "tf": 6,
            "weight": 0.019169
          },
          {
            "term": "rbac",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "management",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "configure",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "monitoring",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "reference",
            "tf": 4,
            "weight": 0.01278
          },
          {
            "term": "logging",
            "tf": 4,
            "weight": 0.01278
          },
          {
            "term": "create",
            "tf": 3,
            "weight": 0.009585
          },
          {
            "term": "scale",
            "tf": 3,
            "weight": 0.009585
          },
          {
            "term": "backups",
            "tf": 3,
            "weight": 0.009585
          },
          {
            "term": "configuration",
            "tf": 3,
            "weight": 0.009585
          }
        ],
        "unique_terms": 53,
        "total_terms": 313
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Managed Services",
        "cloud",
        "cluster",
        "clusters",
        "documentation",
        "https",
        "hybrid",
        "private",
        "qdrant",
        "setup",
        "tech"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7067961165048544,
      "overall": 0.7689320388349513
    }
  },
  {
    "text": "### Support  [Support](https://qdrant.tech/documentation/support/)  [Security](https://qdrant.tech/documentation/cloud-security/)  [Tutorials & Examples](https://qdrant.tech/documentation/tutorials-and-examples/)  - [Using Cloud Inference to Build Hybrid Search](https://qdrant.tech/documentation/tutorials-and-examples/cloud-inference-hybrid-search/) - [Monitoring Hybrid/Private Cloud with Prometheus and Grafana](https://qdrant.tech/documentation/tutorials-and-examples/hybrid-cloud-prometheus/)",
    "metadata": {
      "chunk_id": "056d37d367b8-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Support"
      ],
      "heading_text": "Support",
      "token_count": 110,
      "char_count": 498,
      "start_char": 3798,
      "end_char": 4296,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5639130434782609,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.185194",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Support",
      "chunk_hash": "bd66045741770c14",
      "content_digest": "bd66045741770c14",
      "chunk_length": 498,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "cloud",
          "tutorials",
          "examples",
          "and",
          "hybrid",
          "support",
          "security",
          "inference",
          "search",
          "prometheus",
          "using",
          "build",
          "monitoring",
          "private",
          "with",
          "grafana"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 5,
            "weight": 0.086207
          },
          {
            "term": "qdrant",
            "tf": 5,
            "weight": 0.086207
          },
          {
            "term": "tech",
            "tf": 5,
            "weight": 0.086207
          },
          {
            "term": "documentation",
            "tf": 5,
            "weight": 0.086207
          },
          {
            "term": "cloud",
            "tf": 5,
            "weight": 0.086207
          },
          {
            "term": "tutorials",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "examples",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "hybrid",
            "tf": 4,
            "weight": 0.068966
          },
          {
            "term": "support",
            "tf": 3,
            "weight": 0.051724
          },
          {
            "term": "security",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "prometheus",
            "tf": 2,
            "weight": 0.034483
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "build",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "monitoring",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "private",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.017241
          },
          {
            "term": "grafana",
            "tf": 1,
            "weight": 0.017241
          }
        ],
        "unique_terms": 20,
        "total_terms": 58
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Support",
        "and",
        "cloud",
        "documentation",
        "examples",
        "https",
        "hybrid",
        "qdrant",
        "support",
        "tech",
        "tutorials"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5639130434782609,
      "overall": 0.6879710144927537
    }
  },
  {
    "text": "### Managed Services  [Getting Started](https://qdrant.tech/documentation/cloud-getting-started/)  [Account Setup](https://qdrant.tech/documentation/cloud-account-setup/)  [Cloud RBAC](https://qdrant.tech/documentation/cloud-rbac/)  - [Role Management](https://qdrant.tech/documentation/cloud-rbac/role-management/) - [User Management](https://qdrant.tech/documentation/cloud-rbac/user-management/) - [Permission Reference](https://qdrant.tech/documentation/cloud-rbac/permission-reference/)  [Managed Cloud](https://qdrant.tech/documentation/cloud/)  - [Create a Cluster](https://qdrant.tech/documentation/cloud/create-cluster/) - [Authentication](https://qdrant.tech/documentation/cloud/authentication/) - [Cluster Access](https://qdrant.tech/documentation/cloud/cluster-access/) - [Scale Clusters](https://qdrant.tech/documentation/cloud/cluster-scaling/) - [Configure Clusters](https://qdrant.tech/documentation/cloud/configure-cluster/) - [Monitor Clusters](https://qdrant.tech/documentation/cloud/cluster-monitoring/) - [Update Clusters](https://qdrant.tech/documentation/cloud/cluster-upgrades/) - [Backup Clusters](https://qdrant.tech/documentation/cloud/backups/) - [Inference](https://qdrant.tech/documentation/cloud/inference/)  [Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/)  - [Setup Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/hybrid-cloud-setup/) - [Create a Cluster](https://qdrant.tech/documentation/hybrid-cloud/hybrid-cloud-cluster-creation/) - [Configure, Scale & Update Clusters](https://qdrant.tech/documentation/hybrid-cloud/configure-scale-upgrade/) - [Configure the Qdrant Operator](https://qdrant.tech/documentation/hybrid-cloud/operator-configuration/) - [Networking, Logging & Monitoring](https://qdrant.tech/documentation/hybrid-cloud/networking-logging-monitoring/) - [Deployment Platforms](https://qdrant.tech/documentation/hybrid-cloud/platform-deployment-options/)  [Private Cloud](https://qdrant.tech/documentation/private-cloud/)  - [Setup Private Cloud](https://qdrant.tech/documentation/private-cloud/private-cloud-setup/) - [Configuration](https://qdrant.tech/documentation/private-cloud/configuration/) - [Managing a Cluster](https://qdrant.tech/documentation/private-cloud/qdrant-cluster-management/) - [Backups](https://qdrant.tech/documentation/private-cloud/backups/) - [Logging & Monitoring](https://qdrant.tech/documentation/private-cloud/logging-monitoring/) - [API Reference](https://qdrant.tech/documentation/private-cloud/api-reference/) - [Changelog](https://qdrant.tech/documentation/private-cloud/changelog/)  [Billing & Payments](https://qdrant.tech/documentation/cloud-pricing-payments/)  [Premium Tier](https://qdrant.tech/documentation/cloud-premium/)",
    "metadata": {
      "chunk_id": "056d37d367b8-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Managed Services"
      ],
      "heading_text": "Managed Services",
      "token_count": 614,
      "char_count": 2741,
      "start_char": 4392,
      "end_char": 7133,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7067961165048544,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.186152",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Managed Services",
      "chunk_hash": "81e21f320195534d",
      "content_digest": "81e21f320195534d",
      "chunk_length": 2741,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "cloud",
          "qdrant",
          "https",
          "tech",
          "documentation",
          "cluster",
          "hybrid",
          "private",
          "setup",
          "clusters",
          "rbac",
          "management",
          "configure",
          "monitoring",
          "reference",
          "logging",
          "create",
          "scale",
          "backups",
          "configuration"
        ],
        "term_weights": [
          {
            "term": "cloud",
            "tf": 42,
            "weight": 0.134185
          },
          {
            "term": "qdrant",
            "tf": 35,
            "weight": 0.111821
          },
          {
            "term": "https",
            "tf": 33,
            "weight": 0.105431
          },
          {
            "term": "tech",
            "tf": 33,
            "weight": 0.105431
          },
          {
            "term": "documentation",
            "tf": 33,
            "weight": 0.105431
          },
          {
            "term": "cluster",
            "tf": 12,
            "weight": 0.038339
          },
          {
            "term": "hybrid",
            "tf": 11,
            "weight": 0.035144
          },
          {
            "term": "private",
            "tf": 11,
            "weight": 0.035144
          },
          {
            "term": "setup",
            "tf": 6,
            "weight": 0.019169
          },
          {
            "term": "clusters",
            "tf": 6,
            "weight": 0.019169
          },
          {
            "term": "rbac",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "management",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "configure",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "monitoring",
            "tf": 5,
            "weight": 0.015974
          },
          {
            "term": "reference",
            "tf": 4,
            "weight": 0.01278
          },
          {
            "term": "logging",
            "tf": 4,
            "weight": 0.01278
          },
          {
            "term": "create",
            "tf": 3,
            "weight": 0.009585
          },
          {
            "term": "scale",
            "tf": 3,
            "weight": 0.009585
          },
          {
            "term": "backups",
            "tf": 3,
            "weight": 0.009585
          },
          {
            "term": "configuration",
            "tf": 3,
            "weight": 0.009585
          }
        ],
        "unique_terms": 53,
        "total_terms": 313
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Managed Services",
        "cloud",
        "cluster",
        "clusters",
        "documentation",
        "https",
        "hybrid",
        "private",
        "qdrant",
        "setup",
        "tech"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7067961165048544,
      "overall": 0.7689320388349513
    }
  },
  {
    "text": "### Support  [Support](https://qdrant.tech/documentation/support/)  [Security](https://qdrant.tech/documentation/cloud-security/)  [Tutorials & Examples](https://qdrant.tech/documentation/tutorials-and-examples/)  - [Using Cloud Inference to Build Hybrid Search](https://qdrant.tech/documentation/tutorials-and-examples/cloud-inference-hybrid-search/) - [Monitoring Hybrid/Private Cloud with Prometheus and Grafana](https://qdrant.tech/documentation/tutorials-and-examples/hybrid-cloud-prometheus/)  * [Documentation](https://qdrant.tech/documentation/) * * [Cloud](https://qdrant.tech/documentation/cloud/) * * Inference",
    "metadata": {
      "chunk_id": "056d37d367b8-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Support"
      ],
      "heading_text": "Support",
      "token_count": 141,
      "char_count": 621,
      "start_char": 7436,
      "end_char": 8057,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.522258064516129,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.186949",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Support",
      "chunk_hash": "9eb4849eb649b14d",
      "content_digest": "9eb4849eb649b14d",
      "chunk_length": 621,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "documentation",
          "https",
          "qdrant",
          "tech",
          "cloud",
          "tutorials",
          "examples",
          "and",
          "hybrid",
          "support",
          "inference",
          "security",
          "search",
          "prometheus",
          "using",
          "build",
          "monitoring",
          "private",
          "with",
          "grafana"
        ],
        "term_weights": [
          {
            "term": "documentation",
            "tf": 8,
            "weight": 0.114286
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.1
          },
          {
            "term": "qdrant",
            "tf": 7,
            "weight": 0.1
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.1
          },
          {
            "term": "cloud",
            "tf": 7,
            "weight": 0.1
          },
          {
            "term": "tutorials",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "examples",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "hybrid",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "support",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "security",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "prometheus",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "build",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "monitoring",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "private",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "grafana",
            "tf": 1,
            "weight": 0.014286
          }
        ],
        "unique_terms": 20,
        "total_terms": 70
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Support",
        "and",
        "cloud",
        "documentation",
        "examples",
        "https",
        "hybrid",
        "qdrant",
        "support",
        "tech",
        "tutorials"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.522258064516129,
      "overall": 0.7074193548387097
    }
  },
  {
    "text": "# Inference in Qdrant Managed Cloud\n\nInference is the process of creating vector embeddings from text, images, or other data types using a machine learning model.\n\nQdrant Managed Cloud allows you to use inference directly in the cloud, without the need to set up and maintain your own inference infrastructure.\n\nInference is currently only available in US regions for paid clusters. Support for inference in other regions is coming soon.",
    "metadata": {
      "chunk_id": "056d37d367b8-0008",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Inference in Qdrant Managed Cloud"
      ],
      "heading_text": "Inference in Qdrant Managed Cloud",
      "token_count": 85,
      "char_count": 437,
      "start_char": 8059,
      "end_char": 8496,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5085714285714286,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.187896",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Inference in Qdrant Managed Cloud",
      "chunk_hash": "283f9ddf701bd86f",
      "content_digest": "283f9ddf701bd86f",
      "chunk_length": 437,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "inference",
          "cloud",
          "the",
          "qdrant",
          "managed",
          "other",
          "regions",
          "for",
          "process",
          "creating",
          "vector",
          "embeddings",
          "from",
          "text",
          "images",
          "data",
          "types",
          "using",
          "machine",
          "learning"
        ],
        "term_weights": [
          {
            "term": "inference",
            "tf": 6,
            "weight": 0.109091
          },
          {
            "term": "cloud",
            "tf": 3,
            "weight": 0.054545
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.054545
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "managed",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "other",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "regions",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.036364
          },
          {
            "term": "process",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "creating",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "embeddings",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "text",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "images",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "data",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "types",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "machine",
            "tf": 1,
            "weight": 0.018182
          },
          {
            "term": "learning",
            "tf": 1,
            "weight": 0.018182
          }
        ],
        "unique_terms": 41,
        "total_terms": 55
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Inference in Qdrant Managed Cloud",
        "cloud",
        "creating",
        "for",
        "inference",
        "managed",
        "other",
        "process",
        "qdrant",
        "regions",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5085714285714286,
      "overall": 0.7028571428571428
    }
  },
  {
    "text": "## Supported Models\n\nYou can see the list of supported models in the Inference tab of the Cluster Detail page in the Qdrant Cloud Console. The list includes models for text, both to produce dense and sparse vectors, as well as multi-modal models for images.",
    "metadata": {
      "chunk_id": "056d37d367b8-0009",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Supported Models"
      ],
      "heading_text": "Supported Models",
      "token_count": 54,
      "char_count": 257,
      "start_char": 8498,
      "end_char": 8755,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5033333333333333,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.188098",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Supported Models",
      "chunk_hash": "c2faf16c3c897577",
      "content_digest": "c2faf16c3c897577",
      "chunk_length": 257,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "models",
          "supported",
          "list",
          "for",
          "you",
          "can",
          "see",
          "inference",
          "tab",
          "cluster",
          "detail",
          "page",
          "qdrant",
          "cloud",
          "console",
          "includes",
          "text",
          "both",
          "produce"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 5,
            "weight": 0.131579
          },
          {
            "term": "models",
            "tf": 4,
            "weight": 0.105263
          },
          {
            "term": "supported",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "list",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.052632
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "see",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "tab",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "cluster",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "detail",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "page",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "console",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "includes",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "text",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "both",
            "tf": 1,
            "weight": 0.026316
          },
          {
            "term": "produce",
            "tf": 1,
            "weight": 0.026316
          }
        ],
        "unique_terms": 28,
        "total_terms": 38
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Supported Models",
        "can",
        "for",
        "inference",
        "list",
        "models",
        "see",
        "supported",
        "tab",
        "the",
        "you"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5033333333333333,
      "overall": 0.7344444444444443
    }
  },
  {
    "text": "## Enabling/Disabling Inference\n\nInference is enabled by default for all new clusters, created after July, 7th 2025. You can enable it for existing clusters directly from the Inference tab of the Cluster Detail page in the Qdrant Cloud Console. Activating inference will trigger a restart of your cluster to apply the new configuration.",
    "metadata": {
      "chunk_id": "056d37d367b8-0010",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Enabling/Disabling Inference"
      ],
      "heading_text": "Enabling/Disabling Inference",
      "token_count": 73,
      "char_count": 336,
      "start_char": 8757,
      "end_char": 9093,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5333962264150943,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.188407",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Enabling/Disabling Inference",
      "chunk_hash": "9ccc1d0e2aee8dda",
      "content_digest": "9ccc1d0e2aee8dda",
      "chunk_length": 336,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "inference",
          "the",
          "for",
          "new",
          "clusters",
          "cluster",
          "enabling",
          "disabling",
          "enabled",
          "default",
          "all",
          "created",
          "after",
          "july",
          "7th",
          "2025",
          "you",
          "can",
          "enable",
          "existing"
        ],
        "term_weights": [
          {
            "term": "inference",
            "tf": 4,
            "weight": 0.088889
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.088889
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "new",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "clusters",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "cluster",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "enabling",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "disabling",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "enabled",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "default",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "all",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "created",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "after",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "july",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "7th",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "2025",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "enable",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "existing",
            "tf": 1,
            "weight": 0.022222
          }
        ],
        "unique_terms": 35,
        "total_terms": 45
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Enabling/Disabling Inference",
        "cluster",
        "clusters",
        "default",
        "disabling",
        "enabled",
        "enabling",
        "for",
        "inference",
        "new",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5333962264150943,
      "overall": 0.711132075471698
    }
  },
  {
    "text": "## Billing\n\nInference is billed based on the number of tokens processed by the model. The cost is calculated per 1,000,000 tokens. The price depends on the model and is displayed ont the Inference tab of the Cluster Detail page. You also can see the current usage of each model there.",
    "metadata": {
      "chunk_id": "056d37d367b8-0011",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Billing"
      ],
      "heading_text": "Billing",
      "token_count": 63,
      "char_count": 284,
      "start_char": 9095,
      "end_char": 9379,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5076470588235293,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.188560",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Billing",
      "chunk_hash": "1d1f69a58a777413",
      "content_digest": "1d1f69a58a777413",
      "chunk_length": 284,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "model",
          "inference",
          "tokens",
          "000",
          "billing",
          "billed",
          "based",
          "number",
          "processed",
          "cost",
          "calculated",
          "per",
          "price",
          "depends",
          "and",
          "displayed",
          "ont",
          "tab",
          "cluster"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 8,
            "weight": 0.190476
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.071429
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "tokens",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "000",
            "tf": 2,
            "weight": 0.047619
          },
          {
            "term": "billing",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "billed",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "based",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "number",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "processed",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "cost",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "calculated",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "per",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "price",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "depends",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "displayed",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "ont",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "tab",
            "tf": 1,
            "weight": 0.02381
          },
          {
            "term": "cluster",
            "tf": 1,
            "weight": 0.02381
          }
        ],
        "unique_terms": 30,
        "total_terms": 42
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "000",
        "Billing",
        "based",
        "billed",
        "billing",
        "inference",
        "model",
        "number",
        "processed",
        "the",
        "tokens"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5076470588235293,
      "overall": 0.7025490196078431
    }
  },
  {
    "text": "## Using Inference\n\nInference can be easily used through the Qdrant SDKs and the REST or GRPC APIs when upserting points and when querying the database.\n\nInstead of a vector, you can use special *Interface Objects*:\n\n- **`Document`** object, used for text inference\n\n```js\n// Document\n{\n    // Text input\n    text: \"Your text\",\n    // Name of the model, to do inference with\n    model: \"<the-model-to-use>\",\n    // Extra parameters for the model, Optional\n    options: {}\n}\n```\n\n- **`Image`** object, used for image inference\n\n```js\n// Image\n{\n    // Image input\n    image: \"<url>\", // Or base64 encoded image\n    // Name of the model, to do inference with\n    model: \"<the-model-to-use>\",\n    // Extra parameters for the model, Optional\n    options: {}\n}\n```\n\n- **`Object`** object, reserved for other types of input, which might be implemented in the future.\n\nThe Qdrant API supports usage of these Inference Objects in all places, where regular vectors can be used.\n\nFor example:\n\n```http\nPOST /collections/<your-collection>/points/query\n{\n  \"query\": {\n    \"nearest\": [0.12, 0.34, 0.56, 0.78, ...]\n  }\n}\n```\n\nCan be replaced with\n\n```http\nPOST /collections/<your-collection>/points/query\n{\n  \"query\": {\n    \"nearest\": {\n      \"text\": \"My Query Text\",\n      \"model\": \"<the-model-to-use>\"\n    }\n  }\n}\n```\n\nIn this case, the Qdrant Cloud will use the configured embedding model to automatically create a vector from the Inference Object and then perform the search query with it. All of this happens within a low-latency network.\n\nThe input used for inference will not be saved anywhere. If you want to persist it in Qdrant, make sure to explicitly include it in the payload.",
    "metadata": {
      "chunk_id": "056d37d367b8-0012",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Using Inference"
      ],
      "heading_text": "Using Inference",
      "token_count": 427,
      "char_count": 1675,
      "start_char": 9381,
      "end_char": 11056,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.9999999999999999,
      "retrieval_quality": 0.6857470588235294,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.189277",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Using Inference",
      "chunk_hash": "e76b8b4c001fa4e2",
      "content_digest": "e76b8b4c001fa4e2",
      "chunk_length": 1675,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "model",
          "inference",
          "for",
          "text",
          "image",
          "query",
          "used",
          "use",
          "object",
          "can",
          "qdrant",
          "input",
          "with",
          "and",
          "points",
          "your",
          "when",
          "vector",
          "you"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 18,
            "weight": 0.091371
          },
          {
            "term": "model",
            "tf": 11,
            "weight": 0.055838
          },
          {
            "term": "inference",
            "tf": 9,
            "weight": 0.045685
          },
          {
            "term": "for",
            "tf": 7,
            "weight": 0.035533
          },
          {
            "term": "text",
            "tf": 6,
            "weight": 0.030457
          },
          {
            "term": "image",
            "tf": 6,
            "weight": 0.030457
          },
          {
            "term": "query",
            "tf": 6,
            "weight": 0.030457
          },
          {
            "term": "used",
            "tf": 5,
            "weight": 0.025381
          },
          {
            "term": "use",
            "tf": 5,
            "weight": 0.025381
          },
          {
            "term": "object",
            "tf": 5,
            "weight": 0.025381
          },
          {
            "term": "can",
            "tf": 4,
            "weight": 0.020305
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.020305
          },
          {
            "term": "input",
            "tf": 4,
            "weight": 0.020305
          },
          {
            "term": "with",
            "tf": 4,
            "weight": 0.020305
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "points",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "your",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "when",
            "tf": 2,
            "weight": 0.010152
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.010152
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.010152
          }
        ],
        "unique_terms": 93,
        "total_terms": 197
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Using Inference",
        "for",
        "image",
        "inference",
        "model",
        "object",
        "query",
        "text",
        "the",
        "use",
        "used"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.9999999999999999,
      "retrieval_quality": 0.6857470588235294,
      "overall": 0.8285823529411763
    }
  },
  {
    "text": "### Text Inference\n\nLet’s consider an example of using Cloud Inference with a text model producing dense vectors.\n\nHere, we create one point and use a simple search query with a `Document` Inference Object.\n\n```http",
    "metadata": {
      "chunk_id": "056d37d367b8-0013",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Text Inference"
      ],
      "heading_text": "Text Inference",
      "token_count": 46,
      "char_count": 215,
      "start_char": 11058,
      "end_char": 11273,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7385714285714285,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.189415",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Text Inference",
      "chunk_hash": "850e827b4fedc882",
      "content_digest": "850e827b4fedc882",
      "chunk_length": 215,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "inference",
          "text",
          "with",
          "let",
          "consider",
          "example",
          "using",
          "cloud",
          "model",
          "producing",
          "dense",
          "vectors",
          "here",
          "create",
          "one",
          "point",
          "and",
          "use",
          "simple",
          "search"
        ],
        "term_weights": [
          {
            "term": "inference",
            "tf": 3,
            "weight": 0.107143
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.071429
          },
          {
            "term": "let",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "consider",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "example",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "producing",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "dense",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "vectors",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "here",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "create",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "one",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "point",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.035714
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.035714
          }
        ],
        "unique_terms": 24,
        "total_terms": 28
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Text Inference",
        "cloud",
        "consider",
        "example",
        "inference",
        "let",
        "model",
        "producing",
        "text",
        "using",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7385714285714285,
      "overall": 0.7128571428571427
    }
  },
  {
    "text": "# Insert new points with cloud-side inference\nPUT /collections/<your-collection>/points?wait=true\n{\n  \"points\": [\n    {\n      \"id\": 1,\n      \"payload\": { \"topic\": \"cooking\", \"type\": \"dessert\" },\n      \"vector\": {\n        \"text\": \"Recipe for baking chocolate chip cookies\",\n        \"model\": \"<the-model-to-use>\"\n      }\n    }\n  ]\n}",
    "metadata": {
      "chunk_id": "056d37d367b8-0014",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Insert new points with cloud-side inference"
      ],
      "heading_text": "Insert new points with cloud-side inference",
      "token_count": 90,
      "char_count": 330,
      "start_char": 11274,
      "end_char": 11604,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.5494594594594595,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.189688",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Insert new points with cloud-side inference",
      "chunk_hash": "2d1f335731511ce0",
      "content_digest": "2d1f335731511ce0",
      "chunk_length": 330,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "points",
          "model",
          "insert",
          "new",
          "with",
          "cloud",
          "side",
          "inference",
          "put",
          "collections",
          "your",
          "collection",
          "wait",
          "true",
          "payload",
          "topic",
          "cooking",
          "type",
          "dessert",
          "vector"
        ],
        "term_weights": [
          {
            "term": "points",
            "tf": 3,
            "weight": 0.09375
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.0625
          },
          {
            "term": "insert",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "new",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "side",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "put",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "your",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "collection",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "wait",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "true",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "payload",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "topic",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "cooking",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "type",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "dessert",
            "tf": 1,
            "weight": 0.03125
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.03125
          }
        ],
        "unique_terms": 29,
        "total_terms": 32
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Insert new points with cloud-side inference",
        "cloud",
        "collections",
        "inference",
        "insert",
        "model",
        "new",
        "points",
        "put",
        "side",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.5494594594594595,
      "overall": 0.6831531531531532
    }
  },
  {
    "text": "# Search in the collection using cloud-side inference\nPOST /collections/<your-collection>/points/query\n{\n  \"query\": {\n    \"text\": \"How to bake cookies?\",\n    \"model\": \"<the-model-to-use>\"\n  }\n}\n```\n\n```bash",
    "metadata": {
      "chunk_id": "056d37d367b8-0015",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Search in the collection using cloud-side inference"
      ],
      "heading_text": "Search in the collection using cloud-side inference",
      "token_count": 53,
      "char_count": 206,
      "start_char": 11606,
      "end_char": 11812,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.765,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.189849",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Search in the collection using cloud-side inference",
      "chunk_hash": "3797b3a4cf1c212a",
      "content_digest": "3797b3a4cf1c212a",
      "chunk_length": 206,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "collection",
          "query",
          "model",
          "search",
          "using",
          "cloud",
          "side",
          "inference",
          "post",
          "collections",
          "your",
          "points",
          "text",
          "how",
          "bake",
          "cookies",
          "use",
          "bash"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "collection",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "side",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "post",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "your",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "points",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "text",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "how",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "bake",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "cookies",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "bash",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 19,
        "total_terms": 23
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Search in the collection using cloud-side inference",
        "cloud",
        "collection",
        "inference",
        "model",
        "post",
        "query",
        "search",
        "side",
        "the",
        "using"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.765,
      "overall": 0.755
    }
  },
  {
    "text": "# Create a new vector\ncurl -X PUT \"https://xyz-example.qdrant.io:6333/collections/<your-collection>/points?wait=true\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"api-key: <paste-your-api-key-here>\" \\\n  -d '{\n    \"points\": [\n      {\n        \"id\": 1,\n        \"payload\": { \"topic\": \"cooking\", \"type\": \"dessert\" },\n        \"vector\": {\n          \"text\": \"Recipe for baking chocolate chip cookies\",\n          \"model\": \"<the-model-to-use>\"\n        }\n      }\n    ]\n  }'",
    "metadata": {
      "chunk_id": "056d37d367b8-0016",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Create a new vector"
      ],
      "heading_text": "Create a new vector",
      "token_count": 136,
      "char_count": 465,
      "start_char": 11813,
      "end_char": 12278,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7517021276595744,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.190182",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Create a new vector",
      "chunk_hash": "681771792345d550",
      "content_digest": "681771792345d550",
      "chunk_length": 465,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "vector",
          "your",
          "points",
          "type",
          "api",
          "key",
          "model",
          "create",
          "new",
          "curl",
          "put",
          "https",
          "xyz",
          "example",
          "qdrant",
          "6333",
          "collections",
          "collection",
          "wait",
          "true"
        ],
        "term_weights": [
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "your",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "points",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "type",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "api",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "key",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "create",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "new",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "curl",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "put",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "xyz",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "example",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "6333",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "collection",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "wait",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "true",
            "tf": 1,
            "weight": 0.022222
          }
        ],
        "unique_terms": 38,
        "total_terms": 45
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Create a new vector",
        "api",
        "create",
        "curl",
        "key",
        "model",
        "new",
        "points",
        "type",
        "vector",
        "your"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7517021276595744,
      "overall": 0.783900709219858
    }
  },
  {
    "text": "# Perform a search query\ncurl -X POST \"https://xyz-example.qdrant.io:6333/collections/<your-collection>/points/query\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"api-key: <paste-your-api-key-here>\" \\\n  -d '{\n    \"query\": {\n      \"text\": \"How to bake cookies?\",\n      \"model\": \"<the-model-to-use>\"\n    }\n  }'\n```\n\n```python\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.models import PointStruct, Document\n\nclient = QdrantClient(\n    url=\"https://xyz-example.qdrant.io:6333\",\n    api_key=\"<paste-your-api-key-here>\",\n    # IMPORTANT\n    # If not enabled, inference will be performed locally\n    cloud_inference=True,\n)\n\npoints = [\n    PointStruct(\n        id=1,\n        payload={\"topic\": \"cooking\", \"type\": \"dessert\"},\n        vector=Document(\n            text=\"Recipe for baking chocolate chip cookies\",\n            model=\"<the-model-to-use>\"\n        )\n    )\n]\n\nclient.upsert(collection_name=\"<your-collection>\", points=points)\n\nresult = client.query_points(\n    collection_name=\"<your-collection>\",\n    query=Document(\n        text=\"How to bake cookies?\",\n        model=\"<the-model-to-use>\"\n    )\n)\n\nprint(result)\n```\n\n```typescript\nimport {QdrantClient} from \"@qdrant/js-client-rest\";\n\nconst client = new QdrantClient({\n    url: 'https://xyz-example.qdrant.io:6333',\n    apiKey: '<paste-your-api-key-here>',\n});\n\nconst points = [\n  {\n    id: 1,\n    payload: { topic: \"cooking\", type: \"dessert\" },\n    vector: {\n        text: \"Recipe for baking chocolate chip cookies\",\n        model: \"<the-model-to-use>\"\n      }\n  }\n];\n\nawait client.upsert(\"<your-collection>\", { wait: true, points });\n\nconst result = await client.query(\n    \"<your-collection>\",\n    {\n      query: {\n          text: \"How to bake cookies?\",\n          model: \"<the-model-to-use>\"\n      },\n    }\n)\n\nconsole.log(result);\n```\n\n```rust\nuse qdrant_client::qdrant::Query;\nuse qdrant_client::qdrant::QueryPointsBuilder;\nuse qdrant_client::Payload;\nuse qdrant_client::Qdrant;\nuse qdrant_client::qdrant::{Document};\nuse qdrant_client::qdrant::{PointStruct, UpsertPointsBuilder};\n\n#[tokio::main]\nasync fn main() {\n    let client = Qdrant::from_url(\"https://xyz-example.qdrant.io:6334\")\n        .api_key(\"<paste-your-api-key-here>\")\n        .build()\n        .unwrap();\n\n    let points = vec![\n        PointStruct::new(\n            1,\n            Document::new(\n                \"Recipe for baking chocolate chip cookies\",\n                \"<the-model-to-use>\"\n            ),\n            Payload::try_from(serde_json::json!(\n                {\"topic\": \"cooking\", \"type\": \"dessert\"}\n            )).unwrap(),\n        )\n    ];\n\n    let upsert_request = UpsertPointsBuilder::new(\n        \"<your-collection>\",\n        points\n    ).wait(true);\n\n    let _ = client.upsert_points(upsert_request).await;\n\n    let query_document = Document::new(\n        \"How to bake cookies?\",\n        \"<the-model-to-use>\"\n    );\n\n    let query_request = QueryPointsBuilder::new(\"<your-collection>\")\n        .query(Query::new_nearest(query_document));\n\n    let result = client.query(query_request).await.unwrap();\n    println!(\"Result: {:?}\", result);\n}\n```\n\n```java\npackage org.example;\n\nimport static io.qdrant.client.PointIdFactory.id;\nimport static io.qdrant.client.QueryFactory.nearest;\nimport static io.qdrant.client.ValueFactory.value;\nimport static io.qdrant.client.VectorsFactory.vectors;\n\nimport io.qdrant.client.grpc.Points;\nimport io.qdrant.client.grpc.Points.Document;\nimport io.qdrant.client.grpc.Points.PointStruct;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.concurrent.ExecutionException;\n\npublic class Main {\n  public static void main(String[] args)\n      throws ExecutionException, InterruptedException {\n    QdrantClient client =\n      new QdrantClient(\n        QdrantGrpcClient.newBuilder(\"xyz-example.qdrant.io\", 6334, true)\n        .withApiKey(\"<paste-your-api-key-here>\")\n        .build());",
    "metadata": {
      "chunk_id": "056d37d367b8-0017",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Perform a search query"
      ],
      "heading_text": "Perform a search query",
      "token_count": 957,
      "char_count": 3876,
      "start_char": 12280,
      "end_char": 16156,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.8764119601328904,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.193852",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Perform a search query",
      "chunk_hash": "e1367dc5153c20d8",
      "content_digest": "e1367dc5153c20d8",
      "chunk_length": 3876,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "query",
          "points",
          "use",
          "import",
          "your",
          "model",
          "collection",
          "document",
          "api",
          "key",
          "new",
          "cookies",
          "the",
          "result",
          "let",
          "example",
          "qdrantclient",
          "xyz"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 27,
            "weight": 0.066015
          },
          {
            "term": "client",
            "tf": 26,
            "weight": 0.06357
          },
          {
            "term": "query",
            "tf": 15,
            "weight": 0.036675
          },
          {
            "term": "points",
            "tf": 13,
            "weight": 0.031785
          },
          {
            "term": "use",
            "tf": 13,
            "weight": 0.031785
          },
          {
            "term": "import",
            "tf": 13,
            "weight": 0.031785
          },
          {
            "term": "your",
            "tf": 12,
            "weight": 0.02934
          },
          {
            "term": "model",
            "tf": 12,
            "weight": 0.02934
          },
          {
            "term": "collection",
            "tf": 9,
            "weight": 0.022005
          },
          {
            "term": "document",
            "tf": 9,
            "weight": 0.022005
          },
          {
            "term": "api",
            "tf": 8,
            "weight": 0.01956
          },
          {
            "term": "key",
            "tf": 8,
            "weight": 0.01956
          },
          {
            "term": "new",
            "tf": 8,
            "weight": 0.01956
          },
          {
            "term": "cookies",
            "tf": 7,
            "weight": 0.017115
          },
          {
            "term": "the",
            "tf": 7,
            "weight": 0.017115
          },
          {
            "term": "result",
            "tf": 7,
            "weight": 0.017115
          },
          {
            "term": "let",
            "tf": 7,
            "weight": 0.017115
          },
          {
            "term": "example",
            "tf": 6,
            "weight": 0.01467
          },
          {
            "term": "qdrantclient",
            "tf": 6,
            "weight": 0.01467
          },
          {
            "term": "xyz",
            "tf": 5,
            "weight": 0.012225
          }
        ],
        "unique_terms": 112,
        "total_terms": 409
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Perform a search query",
        "client",
        "collection",
        "document",
        "import",
        "model",
        "points",
        "qdrant",
        "query",
        "use",
        "your"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.8764119601328904,
      "overall": 0.7921373200442967
    }
  },
  {
    "text": "### Image Inference\n\nHere is another example of using Cloud Inference with an image model. This time, we will use the `CLIP` model to encode an image and then use a text query to search for it.\n\nSince the `CLIP` model is multimodal, we can use both image and text inputs on the same vector field.\n\n```http",
    "metadata": {
      "chunk_id": "056d37d367b8-0019",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Image Inference"
      ],
      "heading_text": "Image Inference",
      "token_count": 73,
      "char_count": 305,
      "start_char": 20181,
      "end_char": 20486,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7057894736842105,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.194707",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Image Inference",
      "chunk_hash": "24639d430d1a0216",
      "content_digest": "24639d430d1a0216",
      "chunk_length": 305,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "image",
          "model",
          "use",
          "the",
          "inference",
          "clip",
          "and",
          "text",
          "here",
          "another",
          "example",
          "using",
          "cloud",
          "with",
          "this",
          "time",
          "will",
          "encode",
          "then",
          "query"
        ],
        "term_weights": [
          {
            "term": "image",
            "tf": 4,
            "weight": 0.090909
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "use",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "clip",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "here",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "another",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "example",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "time",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "will",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "encode",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "then",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "query",
            "tf": 1,
            "weight": 0.022727
          }
        ],
        "unique_terms": 31,
        "total_terms": 44
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Image Inference",
        "and",
        "another",
        "clip",
        "here",
        "image",
        "inference",
        "model",
        "text",
        "the",
        "use"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7057894736842105,
      "overall": 0.7019298245614035
    }
  },
  {
    "text": "# Insert new points with cloud-side inference\nPUT /collections/<your-collection>/points?wait=true\n{\n  \"points\": [\n    {\n      \"id\": 1,\n      \"vector\": {\n        \"image\": \"https://qdrant.tech/example.png\",\n        \"model\": \"qdrant/clip-vit-b-32-vision\"\n      },\n      \"payload\": {\n        \"title\": \"Example Image\"\n      }\n    }\n  ]\n}",
    "metadata": {
      "chunk_id": "056d37d367b8-0020",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Insert new points with cloud-side inference"
      ],
      "heading_text": "Insert new points with cloud-side inference",
      "token_count": 95,
      "char_count": 332,
      "start_char": 20487,
      "end_char": 20819,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7416129032258064,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.194994",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Insert new points with cloud-side inference",
      "chunk_hash": "86419901fcc97d57",
      "content_digest": "86419901fcc97d57",
      "chunk_length": 332,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "points",
          "image",
          "qdrant",
          "example",
          "insert",
          "new",
          "with",
          "cloud",
          "side",
          "inference",
          "put",
          "collections",
          "your",
          "collection",
          "wait",
          "true",
          "vector",
          "https",
          "tech",
          "png"
        ],
        "term_weights": [
          {
            "term": "points",
            "tf": 3,
            "weight": 0.096774
          },
          {
            "term": "image",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "example",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "insert",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "new",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "side",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "put",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "your",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "collection",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "wait",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "true",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "vector",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "tech",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "png",
            "tf": 1,
            "weight": 0.032258
          }
        ],
        "unique_terms": 26,
        "total_terms": 31
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Insert new points with cloud-side inference",
        "cloud",
        "example",
        "image",
        "inference",
        "insert",
        "new",
        "points",
        "qdrant",
        "side",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7416129032258064,
      "overall": 0.7138709677419355
    }
  },
  {
    "text": "# Search in the collection using cloud-side inference\nPOST /collections/<your-collection>/points/query\n{\n  \"query\": {\n    \"text\": \"Mission to Mars\",\n    \"model\": \"qdrant/clip-vit-b-32-text\"\n  }\n}\n```\n\n```bash",
    "metadata": {
      "chunk_id": "056d37d367b8-0021",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Search in the collection using cloud-side inference"
      ],
      "heading_text": "Search in the collection using cloud-side inference",
      "token_count": 59,
      "char_count": 208,
      "start_char": 20821,
      "end_char": 21029,
      "semantic_score": 0.8,
      "structural_score": 0.7,
      "retrieval_quality": 0.5639130434782609,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.195171",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Search in the collection using cloud-side inference",
      "chunk_hash": "7f4efae81c734807",
      "content_digest": "7f4efae81c734807",
      "chunk_length": 208,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "collection",
          "query",
          "text",
          "search",
          "the",
          "using",
          "cloud",
          "side",
          "inference",
          "post",
          "collections",
          "your",
          "points",
          "mission",
          "mars",
          "model",
          "qdrant",
          "clip",
          "vit",
          "bash"
        ],
        "term_weights": [
          {
            "term": "collection",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "query",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.086957
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "the",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "cloud",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "side",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "inference",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "post",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "your",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "points",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "mission",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "mars",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "model",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "qdrant",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "clip",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "vit",
            "tf": 1,
            "weight": 0.043478
          },
          {
            "term": "bash",
            "tf": 1,
            "weight": 0.043478
          }
        ],
        "unique_terms": 20,
        "total_terms": 23
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Search in the collection using cloud-side inference",
        "cloud",
        "collection",
        "inference",
        "post",
        "query",
        "search",
        "side",
        "text",
        "the",
        "using"
      ]
    },
    "advanced_scores": {
      "semantic": 0.8,
      "structural": 0.7,
      "retrieval_quality": 0.5639130434782609,
      "overall": 0.6879710144927537
    }
  },
  {
    "text": "# Create a new vector\ncurl -X PUT \"https://xyz-example.qdrant.io:6333/collections/<your-collection>/points?wait=true\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"api-key: <paste-your-api-key-here>\" \\\n  -d '{\n    \"points\": [\n      {\n        \"id\": 1,\n        \"vector\": {\n          \"image\": \"https://qdrant.tech/example.png\",\n          \"model\": \"qdrant/clip-vit-b-32-vision\"\n        },\n        \"payload\": {\n          \"title\": \"Example Image\"\n        }\n      }\n    ]\n  }'",
    "metadata": {
      "chunk_id": "056d37d367b8-0022",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Create a new vector"
      ],
      "heading_text": "Create a new vector",
      "token_count": 141,
      "char_count": 471,
      "start_char": 21030,
      "end_char": 21501,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7460975609756098,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.195487",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Create a new vector",
      "chunk_hash": "e62a1413195e33ca",
      "content_digest": "e62a1413195e33ca",
      "chunk_length": 471,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "example",
          "qdrant",
          "vector",
          "https",
          "your",
          "points",
          "api",
          "key",
          "image",
          "create",
          "new",
          "curl",
          "put",
          "xyz",
          "6333",
          "collections",
          "collection",
          "wait",
          "true",
          "content"
        ],
        "term_weights": [
          {
            "term": "example",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.068182
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "your",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "points",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "api",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "key",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "image",
            "tf": 2,
            "weight": 0.045455
          },
          {
            "term": "create",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "new",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "curl",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "put",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "xyz",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "6333",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "collections",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "collection",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "wait",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "true",
            "tf": 1,
            "weight": 0.022727
          },
          {
            "term": "content",
            "tf": 1,
            "weight": 0.022727
          }
        ],
        "unique_terms": 33,
        "total_terms": 44
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Create a new vector",
        "api",
        "create",
        "example",
        "https",
        "image",
        "key",
        "points",
        "qdrant",
        "vector",
        "your"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7460975609756098,
      "overall": 0.7486991869918699
    }
  },
  {
    "text": "# Perform a search query\ncurl -X POST \"https://xyz-example.qdrant.io:6333/collections/<your-collection>/points/query\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"api-key: <paste-your-api-key-here>\" \\\n  -d '{\n    \"query\": {\n      \"text\": \"Mission to Mars\",\n      \"model\": \"qdrant/clip-vit-b-32-text\"\n    }\n  }'\n```\n\n```python\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.models import PointStruct, Image, Document\n\nclient = QdrantClient(\n    url=\"https://xyz-example.qdrant.io:6333\",\n    api_key=\"<paste-your-api-key-here>\",\n    # IMPORTANT\n    # If not enabled, inference will be performed locally\n    cloud_inference=True,\n)\n\npoints = [\n    PointStruct(\n        id=1,\n        vector=Image(\n            image=\"https://qdrant.tech/example.png\",\n            model=\"qdrant/clip-vit-b-32-vision\"\n        ),\n        payload={\n            \"title\": \"Example Image\"\n        }\n    )\n]\n\nclient.upsert(collection_name=\"<your-collection>\", points=points)\n\nresult = client.query_points(\n    collection_name=\"<your-collection>\",\n    query=Document(\n        text=\"Mission to Mars\",\n        model=\"qdrant/clip-vit-b-32-text\"\n    )\n)\n\nprint(result)\n```\n\n```typescript\nimport {QdrantClient} from \"@qdrant/js-client-rest\";\n\nconst client = new QdrantClient({\n    url: 'https://xyz-example.qdrant.io:6333',\n    apiKey: '<paste-your-api-key-here>',\n});\n\nconst points = [\n  {\n    id: 1,\n    vector: {\n      image: \"https://qdrant.tech/example.png\",\n      model: \"qdrant/clip-vit-b-32-vision\"\n    },\n    payload: {\n      title: \"Example Image\"\n    }\n  }\n];\n\nawait client.upsert(\"<your-collection>\", { wait: true, points });\n\nconst result = await client.query(\n    \"<your-collection>\",\n    {\n      query: {\n          text: \"Mission to Mars\",\n          model: \"qdrant/clip-vit-b-32-text\"\n      },\n    }\n)\n\nconsole.log(result);\n```\n\n```rust\nuse qdrant_client::qdrant::Query;\nuse qdrant_client::qdrant::QueryPointsBuilder;\nuse qdrant_client::Payload;\nuse qdrant_client::Qdrant;\nuse qdrant_client::qdrant::{Document, Image};\nuse qdrant_client::qdrant::{PointStruct, UpsertPointsBuilder};\n\n#[tokio::main]\nasync fn main() {\n    let client = Qdrant::from_url(\"https://xyz-example.qdrant.io:6334\")\n        .api_key(\"<paste-your-api-key-here>\")\n        .build()\n        .unwrap();\n\n    let points = vec![\n        PointStruct::new(\n            1,\n            Image::new_from_url(\n                \"https://qdrant.tech/example.png\",\n                \"qdrant/clip-vit-b-32-vision\"\n            ),\n            Payload::try_from(serde_json::json!({\n                \"title\": \"Example Image\"\n            })).unwrap(),\n        )\n    ];\n\n    let upsert_request = UpsertPointsBuilder::new(\n        \"<your-collection>\",\n        points\n    ).wait(true);\n\n    let _ = client.upsert_points(upsert_request).await;\n\n    let query_document = Document::new(\n        \"Mission to Mars\",\n        \"qdrant/clip-vit-b-32-text\"\n    );\n\n    let query_request = QueryPointsBuilder::new(\"<your-collection>\")\n        .query(Query::new_nearest(query_document));\n\n    let result = client.query(query_request).await.unwrap();\n    println!(\"Result: {:?}\", result);\n}\n```\n\n```java\npackage org.example;\n\nimport static io.qdrant.client.PointIdFactory.id;\nimport static io.qdrant.client.QueryFactory.nearest;\nimport static io.qdrant.client.ValueFactory.value;\nimport static io.qdrant.client.VectorsFactory.vectors;\n\nimport io.qdrant.client.grpc.Points;\nimport io.qdrant.client.grpc.Points.Document;\nimport io.qdrant.client.grpc.Points.Image;\nimport io.qdrant.client.grpc.Points.PointStruct;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.concurrent.ExecutionException;\n\npublic class Main {\n  public static void main(String[] args)\n      throws ExecutionException, InterruptedException {\n    QdrantClient client =\n      new QdrantClient(\n        QdrantGrpcClient.newBuilder(\"xyz-example.qdrant.io\", 6334, true)\n        .withApiKey(\"<paste-your-api-key-here>\")\n        .build());",
    "metadata": {
      "chunk_id": "056d37d367b8-0023",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 23,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Perform a search query"
      ],
      "heading_text": "Perform a search query",
      "token_count": 1013,
      "char_count": 3935,
      "start_char": 21503,
      "end_char": 25438,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.8831578947368421,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.199283",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Perform a search query",
      "chunk_hash": "57c30e3e78c1f98c",
      "content_digest": "57c30e3e78c1f98c",
      "chunk_length": 3935,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "client",
          "query",
          "points",
          "import",
          "example",
          "your",
          "image",
          "collection",
          "api",
          "key",
          "new",
          "https",
          "text",
          "clip",
          "vit",
          "document",
          "result",
          "let",
          "from"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 38,
            "weight": 0.091346
          },
          {
            "term": "client",
            "tf": 27,
            "weight": 0.064904
          },
          {
            "term": "query",
            "tf": 15,
            "weight": 0.036058
          },
          {
            "term": "points",
            "tf": 14,
            "weight": 0.033654
          },
          {
            "term": "import",
            "tf": 14,
            "weight": 0.033654
          },
          {
            "term": "example",
            "tf": 12,
            "weight": 0.028846
          },
          {
            "term": "your",
            "tf": 12,
            "weight": 0.028846
          },
          {
            "term": "image",
            "tf": 10,
            "weight": 0.024038
          },
          {
            "term": "collection",
            "tf": 9,
            "weight": 0.021635
          },
          {
            "term": "api",
            "tf": 8,
            "weight": 0.019231
          },
          {
            "term": "key",
            "tf": 8,
            "weight": 0.019231
          },
          {
            "term": "new",
            "tf": 8,
            "weight": 0.019231
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.016827
          },
          {
            "term": "text",
            "tf": 7,
            "weight": 0.016827
          },
          {
            "term": "clip",
            "tf": 7,
            "weight": 0.016827
          },
          {
            "term": "vit",
            "tf": 7,
            "weight": 0.016827
          },
          {
            "term": "document",
            "tf": 7,
            "weight": 0.016827
          },
          {
            "term": "result",
            "tf": 7,
            "weight": 0.016827
          },
          {
            "term": "let",
            "tf": 7,
            "weight": 0.016827
          },
          {
            "term": "from",
            "tf": 6,
            "weight": 0.014423
          }
        ],
        "unique_terms": 109,
        "total_terms": 416
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Perform a search query",
        "api",
        "client",
        "collection",
        "example",
        "image",
        "import",
        "points",
        "qdrant",
        "query",
        "your"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.8831578947368421,
      "overall": 0.7943859649122805
    }
  },
  {
    "text": "### Local Inference Compatibility\n\nThe Python SDK offers a unique capability: it supports both [local](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/) and cloud inference through an identical interface.\n\nYou can easily switch between local and cloud inference by setting the cloud\\_inference flag when initializing the QdrantClient. For example:\n\n```python\nclient = QdrantClient(\n    url=\"https://your-cluster.qdrant.io\",\n    api_key=\"<your-api-key>\",\n    cloud_inference=True,  # Set to False to use local inference\n)\n```\n\nThis flexibility allows you to develop and test your applications locally or in continuous integration (CI) environments without requiring access to cloud inference resources.\n\n- When `cloud_inference` is set to `False`, inference is performed locally usign `fastembed`.\n- When set to `True`, inference requests are handled by Qdrant Cloud.",
    "metadata": {
      "chunk_id": "056d37d367b8-0025",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 25,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Local Inference Compatibility"
      ],
      "heading_text": "Local Inference Compatibility",
      "token_count": 187,
      "char_count": 888,
      "start_char": 28988,
      "end_char": 29876,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.9999999999999999,
      "retrieval_quality": 0.5122222222222222,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.200380",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Local Inference Compatibility",
      "chunk_hash": "fd5549e06c2e7c17",
      "content_digest": "fd5549e06c2e7c17",
      "chunk_length": 888,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "inference",
          "cloud",
          "local",
          "the",
          "qdrant",
          "fastembed",
          "and",
          "when",
          "your",
          "set",
          "python",
          "https",
          "you",
          "qdrantclient",
          "api",
          "key",
          "true",
          "false",
          "locally",
          "compatibility"
        ],
        "term_weights": [
          {
            "term": "inference",
            "tf": 10,
            "weight": 0.095238
          },
          {
            "term": "cloud",
            "tf": 7,
            "weight": 0.066667
          },
          {
            "term": "local",
            "tf": 4,
            "weight": 0.038095
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "fastembed",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "when",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "your",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "set",
            "tf": 3,
            "weight": 0.028571
          },
          {
            "term": "python",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "qdrantclient",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "api",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "key",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "true",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "false",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "locally",
            "tf": 2,
            "weight": 0.019048
          },
          {
            "term": "compatibility",
            "tf": 1,
            "weight": 0.009524
          }
        ],
        "unique_terms": 64,
        "total_terms": 105
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Local Inference Compatibility",
        "and",
        "cloud",
        "fastembed",
        "inference",
        "local",
        "qdrant",
        "set",
        "the",
        "when",
        "your"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.9999999999999999,
      "retrieval_quality": 0.5122222222222222,
      "overall": 0.7707407407407407
    }
  },
  {
    "text": "##### Was this page useful? Yes No  Thank you for your feedback! 🙏  We are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/inference.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue. On this page:  - [Inference in Qdrant Managed Cloud](#inference-in-qdrant-managed-cloud.md)    - [Supported Models](#supported-models.md)    - [Enabling/Disabling Inference](#enablingdisabling-inference.md)    - [Billing](#billing.md)    - [Using Inference](#using-inference.md)      - [Text Inference](#text-inference.md)     - [Image Inference](#image-inference.md)     - [Local Inference Compatibility](#local-inference-compatibility.md)  * [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/inference.md) * [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)",
    "metadata": {
      "chunk_id": "056d37d367b8-0026",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "filename": "_documentation_cloud_inference_.md",
      "file_extension": ".md",
      "chunk_index": 26,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Was this page useful?"
      ],
      "heading_text": "Was this page useful?",
      "token_count": 261,
      "char_count": 972,
      "start_char": 29878,
      "end_char": 30850,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.53,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:21.200909",
      "document_id": "056d37d367b8",
      "document_name": "_documentation_cloud_inference_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "source_filename": "_documentation_cloud_inference_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_cloud_inference\\_documentation_cloud_inference_.md",
      "hierarchy_path": "Was this page useful?",
      "chunk_hash": "5cc5c6f5382f3cb9",
      "content_digest": "5cc5c6f5382f3cb9",
      "chunk_length": 972,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "inference",
          "qdrant",
          "page",
          "github",
          "landing",
          "https",
          "com",
          "cloud",
          "this",
          "you",
          "edit",
          "tree",
          "master",
          "content",
          "documentation",
          "create",
          "issues",
          "new",
          "choose",
          "issue"
        ],
        "term_weights": [
          {
            "term": "inference",
            "tf": 14,
            "weight": 0.125
          },
          {
            "term": "qdrant",
            "tf": 8,
            "weight": 0.071429
          },
          {
            "term": "page",
            "tf": 7,
            "weight": 0.0625
          },
          {
            "term": "github",
            "tf": 7,
            "weight": 0.0625
          },
          {
            "term": "landing",
            "tf": 6,
            "weight": 0.053571
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.035714
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.035714
          },
          {
            "term": "cloud",
            "tf": 4,
            "weight": 0.035714
          },
          {
            "term": "this",
            "tf": 3,
            "weight": 0.026786
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "edit",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "tree",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "master",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "content",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "documentation",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "create",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "issues",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "new",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "choose",
            "tf": 2,
            "weight": 0.017857
          },
          {
            "term": "issue",
            "tf": 2,
            "weight": 0.017857
          }
        ],
        "unique_terms": 44,
        "total_terms": 112
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Was this page useful?",
        "cloud",
        "com",
        "github",
        "https",
        "inference",
        "landing",
        "page",
        "qdrant",
        "this",
        "you"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.53,
      "overall": 0.6766666666666667
    }
  }
]
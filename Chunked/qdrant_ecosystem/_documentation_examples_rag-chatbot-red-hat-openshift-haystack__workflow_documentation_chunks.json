[
  {
    "text": "### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)",
    "metadata": {
      "chunk_id": "c6892d676c10-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Essentials"
      ],
      "heading_text": "Essentials",
      "token_count": 189,
      "char_count": 673,
      "start_char": 691,
      "end_char": 1364,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5053846153846153,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.707804",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Essentials",
      "chunk_hash": "b49cc869c6854f5f",
      "content_digest": "b49cc869c6854f5f",
      "chunk_length": 673,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "https",
          "tech",
          "documentation",
          "agentic",
          "with",
          "data",
          "ingestion",
          "beginners",
          "langgraph",
          "discord",
          "multimodal",
          "and",
          "deepseek",
          "n8n",
          "essentials",
          "for",
          "simple",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "documentation",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "agentic",
            "tf": 6,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "beginners",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "langgraph",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "discord",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "multimodal",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "deepseek",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "n8n",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "essentials",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 31,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Essentials",
        "agentic",
        "beginners",
        "data",
        "documentation",
        "https",
        "ingestion",
        "qdrant",
        "rag",
        "tech",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5053846153846153,
      "overall": 0.6351282051282051
    }
  },
  {
    "text": "### Integrations  [Data Management](https://qdrant.tech/documentation/data-management/)  - [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/) - [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/) - [Apache Spark](https://qdrant.tech/documentation/data-management/spark/) - [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/) - [cognee](https://qdrant.tech/documentation/data-management/cognee/) - [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/) - [DLT](https://qdrant.tech/documentation/data-management/dlt/) - [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/) - [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/) - [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)  [Embeddings](https://qdrant.tech/documentation/embeddings/)  - [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/) - [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/) - [Cohere](https://qdrant.tech/documentation/embeddings/cohere/) - [Gemini](https://qdrant.tech/documentation/embeddings/gemini/) - [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/) - [Mistral](https://qdrant.tech/documentation/embeddings/mistral/) - [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/) - [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/) - [Nomic](https://qdrant.tech/documentation/embeddings/nomic/) - [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/) - [Ollama](https://qdrant.tech/documentation/embeddings/ollama/) - [OpenAI](https://qdrant.tech/documentation/embeddings/openai/) - [Prem AI](https://qdrant.tech/documentation/embeddings/premai/) - [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/) - [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/) - [Upstage](https://qdrant.tech/documentation/embeddings/upstage/) - [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)  [Frameworks](https://qdrant.tech/documentation/frameworks/)  - [Autogen](https://qdrant.tech/documentation/frameworks/autogen/) - [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/) - [CamelAI](https://qdrant.tech/documentation/frameworks/camel/) - [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/) - [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/) - [Dagster](https://qdrant.tech/documentation/frameworks/dagster/) - [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/) - [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/) - [Feast](https://qdrant.tech/documentation/frameworks/feast/) - [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/) - [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/) - [Haystack](https://qdrant.tech/documentation/frameworks/haystack/) - [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/) - [Langchain](https://qdrant.tech/documentation/frameworks/langchain/) - [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/) - [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/) - [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/) - [Mastra](https://qdrant.tech/documentation/frameworks/mastra/) - [Mem0](https://qdrant.tech/documentation/frameworks/mem0/) - [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/) - [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/) - [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/) - [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/) - [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/) - [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/) - [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/) - [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/) - [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/) - [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/) - [txtai](https://qdrant.tech/documentation/frameworks/txtai/) - [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/) - [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/) - [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)  [Observability](https://qdrant.tech/documentation/observability/)  - [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/) - [OpenLIT](https://qdrant.tech/documentation/observability/openlit/) - [Datadog](https://qdrant.tech/documentation/observability/datadog/)  [Platforms](https://qdrant.tech/documentation/platforms/)  - [Apify](https://qdrant.tech/documentation/platforms/apify/) - [BuildShip](https://qdrant.tech/documentation/platforms/buildship/) - [Keboola](https://qdrant.tech/documentation/platforms/keboola/) - [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/) - [Make.com](https://qdrant.tech/documentation/platforms/make/) - [N8N](https://qdrant.tech/documentation/platforms/n8n/) - [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/) - [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/) - [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/) - [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/) - [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/) - [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)",
    "metadata": {
      "chunk_id": "c6892d676c10-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integrations"
      ],
      "heading_text": "Integrations",
      "token_count": 1498,
      "char_count": 5661,
      "start_char": 1366,
      "end_char": 7027,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.710183",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Integrations",
      "chunk_hash": "8a3f2e84e2a75ae9",
      "content_digest": "8a3f2e84e2a75ae9",
      "chunk_length": 5661,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "frameworks",
          "embeddings",
          "platforms",
          "data",
          "management",
          "observability",
          "airbyte",
          "apache",
          "airflow",
          "spark",
          "cocoindex",
          "cognee",
          "confluent",
          "dlt",
          "fluvio",
          "redpanda"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "qdrant",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "tech",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "documentation",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "frameworks",
            "tf": 35,
            "weight": 0.058528
          },
          {
            "term": "embeddings",
            "tf": 21,
            "weight": 0.035117
          },
          {
            "term": "platforms",
            "tf": 14,
            "weight": 0.023411
          },
          {
            "term": "data",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "management",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "observability",
            "tf": 5,
            "weight": 0.008361
          },
          {
            "term": "airbyte",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "apache",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "airflow",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "spark",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cocoindex",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cognee",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "confluent",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "dlt",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "fluvio",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "redpanda",
            "tf": 2,
            "weight": 0.003344
          }
        ],
        "unique_terms": 113,
        "total_terms": 598
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integrations",
        "data",
        "documentation",
        "embeddings",
        "frameworks",
        "https",
        "management",
        "observability",
        "platforms",
        "qdrant",
        "tech"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "overall": 0.7576923076923077
    }
  },
  {
    "text": "### Examples  [Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)  - [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) - [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)  [Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)  - [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/) - [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/) - [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)  [Build Prototypes](https://qdrant.tech/documentation/examples/)  - [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/) - [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/) - [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/) - [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/) - [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/) - [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/) - [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/) - [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/) - [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/) - [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/) - [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/) - [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)  [Practice Datasets](https://qdrant.tech/documentation/datasets/)",
    "metadata": {
      "chunk_id": "c6892d676c10-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Examples"
      ],
      "heading_text": "Examples",
      "token_count": 576,
      "char_count": 2347,
      "start_char": 7029,
      "end_char": 9376,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.9076923076923078,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.711648",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Examples",
      "chunk_hash": "59078d11dd9c9931",
      "content_digest": "59078d11dd9c9931",
      "chunk_length": 2347,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "https",
          "tech",
          "documentation",
          "examples",
          "search",
          "with",
          "rag",
          "data",
          "chatbot",
          "send",
          "system",
          "semantic",
          "and",
          "cohere",
          "precision",
          "reranking",
          "dspy",
          "for",
          "automate"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 30,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "tech",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "documentation",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "examples",
            "tf": 14,
            "weight": 0.05
          },
          {
            "term": "search",
            "tf": 10,
            "weight": 0.035714
          },
          {
            "term": "with",
            "tf": 9,
            "weight": 0.032143
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.032143
          },
          {
            "term": "data",
            "tf": 7,
            "weight": 0.025
          },
          {
            "term": "chatbot",
            "tf": 6,
            "weight": 0.021429
          },
          {
            "term": "send",
            "tf": 5,
            "weight": 0.017857
          },
          {
            "term": "system",
            "tf": 5,
            "weight": 0.017857
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "cohere",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "dspy",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "automate",
            "tf": 2,
            "weight": 0.007143
          }
        ],
        "unique_terms": 96,
        "total_terms": 280
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Examples",
        "chatbot",
        "data",
        "documentation",
        "examples",
        "https",
        "qdrant",
        "rag",
        "search",
        "tech",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.9076923076923078,
      "overall": 0.8358974358974359
    }
  },
  {
    "text": "### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)",
    "metadata": {
      "chunk_id": "c6892d676c10-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Essentials"
      ],
      "heading_text": "Essentials",
      "token_count": 189,
      "char_count": 673,
      "start_char": 9378,
      "end_char": 10051,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5053846153846153,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.712144",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Essentials",
      "chunk_hash": "b49cc869c6854f5f",
      "content_digest": "b49cc869c6854f5f",
      "chunk_length": 673,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "https",
          "tech",
          "documentation",
          "agentic",
          "with",
          "data",
          "ingestion",
          "beginners",
          "langgraph",
          "discord",
          "multimodal",
          "and",
          "deepseek",
          "n8n",
          "essentials",
          "for",
          "simple",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "documentation",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "agentic",
            "tf": 6,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "beginners",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "langgraph",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "discord",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "multimodal",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "deepseek",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "n8n",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "essentials",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 31,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Essentials",
        "agentic",
        "beginners",
        "data",
        "documentation",
        "https",
        "ingestion",
        "qdrant",
        "rag",
        "tech",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5053846153846153,
      "overall": 0.6351282051282051
    }
  },
  {
    "text": "### Integrations  [Data Management](https://qdrant.tech/documentation/data-management/)  - [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/) - [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/) - [Apache Spark](https://qdrant.tech/documentation/data-management/spark/) - [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/) - [cognee](https://qdrant.tech/documentation/data-management/cognee/) - [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/) - [DLT](https://qdrant.tech/documentation/data-management/dlt/) - [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/) - [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/) - [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)  [Embeddings](https://qdrant.tech/documentation/embeddings/)  - [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/) - [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/) - [Cohere](https://qdrant.tech/documentation/embeddings/cohere/) - [Gemini](https://qdrant.tech/documentation/embeddings/gemini/) - [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/) - [Mistral](https://qdrant.tech/documentation/embeddings/mistral/) - [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/) - [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/) - [Nomic](https://qdrant.tech/documentation/embeddings/nomic/) - [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/) - [Ollama](https://qdrant.tech/documentation/embeddings/ollama/) - [OpenAI](https://qdrant.tech/documentation/embeddings/openai/) - [Prem AI](https://qdrant.tech/documentation/embeddings/premai/) - [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/) - [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/) - [Upstage](https://qdrant.tech/documentation/embeddings/upstage/) - [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)  [Frameworks](https://qdrant.tech/documentation/frameworks/)  - [Autogen](https://qdrant.tech/documentation/frameworks/autogen/) - [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/) - [CamelAI](https://qdrant.tech/documentation/frameworks/camel/) - [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/) - [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/) - [Dagster](https://qdrant.tech/documentation/frameworks/dagster/) - [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/) - [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/) - [Feast](https://qdrant.tech/documentation/frameworks/feast/) - [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/) - [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/) - [Haystack](https://qdrant.tech/documentation/frameworks/haystack/) - [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/) - [Langchain](https://qdrant.tech/documentation/frameworks/langchain/) - [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/) - [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/) - [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/) - [Mastra](https://qdrant.tech/documentation/frameworks/mastra/) - [Mem0](https://qdrant.tech/documentation/frameworks/mem0/) - [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/) - [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/) - [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/) - [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/) - [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/) - [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/) - [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/) - [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/) - [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/) - [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/) - [txtai](https://qdrant.tech/documentation/frameworks/txtai/) - [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/) - [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/) - [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)  [Observability](https://qdrant.tech/documentation/observability/)  - [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/) - [OpenLIT](https://qdrant.tech/documentation/observability/openlit/) - [Datadog](https://qdrant.tech/documentation/observability/datadog/)  [Platforms](https://qdrant.tech/documentation/platforms/)  - [Apify](https://qdrant.tech/documentation/platforms/apify/) - [BuildShip](https://qdrant.tech/documentation/platforms/buildship/) - [Keboola](https://qdrant.tech/documentation/platforms/keboola/) - [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/) - [Make.com](https://qdrant.tech/documentation/platforms/make/) - [N8N](https://qdrant.tech/documentation/platforms/n8n/) - [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/) - [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/) - [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/) - [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/) - [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/) - [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)",
    "metadata": {
      "chunk_id": "c6892d676c10-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integrations"
      ],
      "heading_text": "Integrations",
      "token_count": 1498,
      "char_count": 5661,
      "start_char": 10053,
      "end_char": 15714,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.715876",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Integrations",
      "chunk_hash": "8a3f2e84e2a75ae9",
      "content_digest": "8a3f2e84e2a75ae9",
      "chunk_length": 5661,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "frameworks",
          "embeddings",
          "platforms",
          "data",
          "management",
          "observability",
          "airbyte",
          "apache",
          "airflow",
          "spark",
          "cocoindex",
          "cognee",
          "confluent",
          "dlt",
          "fluvio",
          "redpanda"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "qdrant",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "tech",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "documentation",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "frameworks",
            "tf": 35,
            "weight": 0.058528
          },
          {
            "term": "embeddings",
            "tf": 21,
            "weight": 0.035117
          },
          {
            "term": "platforms",
            "tf": 14,
            "weight": 0.023411
          },
          {
            "term": "data",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "management",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "observability",
            "tf": 5,
            "weight": 0.008361
          },
          {
            "term": "airbyte",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "apache",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "airflow",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "spark",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cocoindex",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cognee",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "confluent",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "dlt",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "fluvio",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "redpanda",
            "tf": 2,
            "weight": 0.003344
          }
        ],
        "unique_terms": 113,
        "total_terms": 598
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integrations",
        "data",
        "documentation",
        "embeddings",
        "frameworks",
        "https",
        "management",
        "observability",
        "platforms",
        "qdrant",
        "tech"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "overall": 0.7576923076923077
    }
  },
  {
    "text": "### Examples  [Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)  - [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) - [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)  [Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)  - [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/) - [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/) - [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)  [Build Prototypes](https://qdrant.tech/documentation/examples/)  - [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/) - [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/) - [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/) - [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/) - [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/) - [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/) - [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/) - [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/) - [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/) - [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/) - [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/) - [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)  [Practice Datasets](https://qdrant.tech/documentation/datasets/)  - [Documentation](https://qdrant.tech/documentation/) - - [Examples](https://qdrant.tech/documentation/examples/) - - Private Chatbot for Interactive Learning",
    "metadata": {
      "chunk_id": "c6892d676c10-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Examples"
      ],
      "heading_text": "Examples",
      "token_count": 611,
      "char_count": 2507,
      "start_char": 15716,
      "end_char": 18223,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.8976744186046512,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.717865",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Examples",
      "chunk_hash": "59f6ec1cfeaa3799",
      "content_digest": "59f6ec1cfeaa3799",
      "chunk_length": 2507,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "documentation",
          "https",
          "tech",
          "examples",
          "search",
          "with",
          "rag",
          "data",
          "chatbot",
          "send",
          "system",
          "semantic",
          "and",
          "for",
          "cohere",
          "precision",
          "reranking",
          "dspy",
          "private"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 32,
            "weight": 0.108108
          },
          {
            "term": "documentation",
            "tf": 24,
            "weight": 0.081081
          },
          {
            "term": "https",
            "tf": 23,
            "weight": 0.077703
          },
          {
            "term": "tech",
            "tf": 23,
            "weight": 0.077703
          },
          {
            "term": "examples",
            "tf": 16,
            "weight": 0.054054
          },
          {
            "term": "search",
            "tf": 10,
            "weight": 0.033784
          },
          {
            "term": "with",
            "tf": 9,
            "weight": 0.030405
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.030405
          },
          {
            "term": "data",
            "tf": 7,
            "weight": 0.023649
          },
          {
            "term": "chatbot",
            "tf": 7,
            "weight": 0.023649
          },
          {
            "term": "send",
            "tf": 5,
            "weight": 0.016892
          },
          {
            "term": "system",
            "tf": 5,
            "weight": 0.016892
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.013514
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.013514
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.013514
          },
          {
            "term": "cohere",
            "tf": 4,
            "weight": 0.013514
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010135
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.010135
          },
          {
            "term": "dspy",
            "tf": 3,
            "weight": 0.010135
          },
          {
            "term": "private",
            "tf": 3,
            "weight": 0.010135
          }
        ],
        "unique_terms": 96,
        "total_terms": 296
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Examples",
        "chatbot",
        "data",
        "documentation",
        "examples",
        "https",
        "qdrant",
        "rag",
        "search",
        "tech",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.8976744186046512,
      "overall": 0.8325581395348838
    }
  },
  {
    "text": "# Private Chatbot for Interactive Learning  | Time: 120 min | Level: Advanced |   |   | | ------------- | --------------- | - | - |  With chatbots, companies can scale their training programs to accommodate a large workforce, delivering consistent and standardized learning experiences across departments, locations, and time zones. Furthermore, having already completed their online training, corporate employees might want to refer back old course materials. Most of this information is proprietary to the company, and manually searching through an entire library of materials takes time. However, a chatbot built on this knowledge can respond in the blink of an eye. With a simple RAG pipeline, you can build a private chatbot. In this tutorial, you will combine open source tools inside of a closed infrastructure and tie them together with a reliable framework. This custom solution lets you run a chatbot without public internet access. You will be able to keep sensitive data secure without compromising privacy. **Figure 1:** The LLM and Qdrant Hybrid Cloud are containerized as separate services. Haystack combines them into a RAG pipeline and exposes the API via Hayhooks.",
    "metadata": {
      "chunk_id": "c6892d676c10-0006",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Private Chatbot for Interactive Learning"
      ],
      "heading_text": "Private Chatbot for Interactive Learning",
      "token_count": 229,
      "char_count": 1182,
      "start_char": 18225,
      "end_char": 19407,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5056756756756756,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "table_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.718680",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Private Chatbot for Interactive Learning",
      "chunk_hash": "cd39c18b8aaa93e8",
      "content_digest": "cd39c18b8aaa93e8",
      "chunk_length": 1182,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "and",
          "chatbot",
          "this",
          "the",
          "you",
          "time",
          "with",
          "can",
          "private",
          "learning",
          "their",
          "training",
          "materials",
          "rag",
          "pipeline",
          "will",
          "them",
          "without",
          "for",
          "interactive"
        ],
        "term_weights": [
          {
            "term": "and",
            "tf": 6,
            "weight": 0.041379
          },
          {
            "term": "chatbot",
            "tf": 4,
            "weight": 0.027586
          },
          {
            "term": "this",
            "tf": 4,
            "weight": 0.027586
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.027586
          },
          {
            "term": "you",
            "tf": 4,
            "weight": 0.027586
          },
          {
            "term": "time",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "can",
            "tf": 3,
            "weight": 0.02069
          },
          {
            "term": "private",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "learning",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "their",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "training",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "materials",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "rag",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "pipeline",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "will",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "them",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "without",
            "tf": 2,
            "weight": 0.013793
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.006897
          },
          {
            "term": "interactive",
            "tf": 1,
            "weight": 0.006897
          }
        ],
        "unique_terms": 112,
        "total_terms": 145
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Private Chatbot for Interactive Learning",
        "and",
        "can",
        "chatbot",
        "learning",
        "private",
        "the",
        "this",
        "time",
        "with",
        "you"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5056756756756756,
      "overall": 0.7018918918918918
    }
  },
  {
    "text": "## Components  To maintain complete data isolation, we need to limit ourselves to open-source tools and use them in a private environment, such as [Red Hat OpenShift](https://www.redhat.com/en/technologies/cloud-computing/openshift). The pipeline will run internally and will be inaccessible from the internet. - **Dataset:** [Red Hat Interactive Learning Portal](https://developers.redhat.com/learn), an online library of Red Hat course materials. - **LLM:** `mistralai/Mistral-7B-Instruct-v0.1`, deployed as a standalone service on OpenShift. - **Embedding Model:** `BAAI/bge-base-en-v1.5`, lightweight embedding model deployed from within the Haystack pipeline with [FastEmbed](https://github.com/qdrant/fastembed) - **Vector DB:** [Qdrant Hybrid Cloud](https://hybrid-cloud.qdrant.tech) running on OpenShift. - **Framework:** [Haystack 2.x](https://haystack.deepset.ai/) to connect all and [Hayhooks](https://docs.haystack.deepset.ai/docs/hayhooks) to serve the app through HTTP endpoints.",
    "metadata": {
      "chunk_id": "c6892d676c10-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Components"
      ],
      "heading_text": "Components",
      "token_count": 245,
      "char_count": 993,
      "start_char": 19411,
      "end_char": 20404,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5207692307692308,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.719198",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Components",
      "chunk_hash": "41d1ccebad77ae7c",
      "content_digest": "41d1ccebad77ae7c",
      "chunk_length": 993,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "openshift",
          "the",
          "haystack",
          "and",
          "red",
          "hat",
          "com",
          "cloud",
          "qdrant",
          "redhat",
          "pipeline",
          "will",
          "from",
          "deployed",
          "embedding",
          "model",
          "fastembed",
          "hybrid",
          "deepset"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 6,
            "weight": 0.051282
          },
          {
            "term": "openshift",
            "tf": 4,
            "weight": 0.034188
          },
          {
            "term": "the",
            "tf": 4,
            "weight": 0.034188
          },
          {
            "term": "haystack",
            "tf": 4,
            "weight": 0.034188
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "red",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "hat",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "cloud",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.025641
          },
          {
            "term": "redhat",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "pipeline",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "will",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "from",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "deployed",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "embedding",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "model",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "hybrid",
            "tf": 2,
            "weight": 0.017094
          },
          {
            "term": "deepset",
            "tf": 2,
            "weight": 0.017094
          }
        ],
        "unique_terms": 79,
        "total_terms": 117
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Components",
        "and",
        "cloud",
        "com",
        "hat",
        "haystack",
        "https",
        "openshift",
        "qdrant",
        "red",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5207692307692308,
      "overall": 0.7069230769230769
    }
  },
  {
    "text": "### Procedure\n\nThe [Haystack](https://haystack.deepset.ai/) framework leverages two pipelines, which combine our components sequentially to process data.\n\n1. The **Indexing Pipeline** will run offline in batches, when new data is added or updated.\n2. The **Search Pipeline** will retrieve information from Qdrant and use an LLM to produce an answer.\n\n> **Note:** We will define the pipelines in Python and then export them to YAML format, so that [Hayhooks](https://docs.haystack.deepset.ai/docs/hayhooks) can run them as a web service.",
    "metadata": {
      "chunk_id": "c6892d676c10-0008",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Procedure"
      ],
      "heading_text": "Procedure",
      "token_count": 124,
      "char_count": 536,
      "start_char": 20407,
      "end_char": 20943,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.538,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.719632",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Procedure",
      "chunk_hash": "0d8a6329e644da90",
      "content_digest": "0d8a6329e644da90",
      "chunk_length": 536,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "haystack",
          "will",
          "https",
          "deepset",
          "pipelines",
          "data",
          "pipeline",
          "run",
          "and",
          "them",
          "hayhooks",
          "docs",
          "procedure",
          "framework",
          "leverages",
          "two",
          "which",
          "combine",
          "our"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 4,
            "weight": 0.059701
          },
          {
            "term": "haystack",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "will",
            "tf": 3,
            "weight": 0.044776
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "deepset",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "pipelines",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "pipeline",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "run",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "them",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "hayhooks",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "docs",
            "tf": 2,
            "weight": 0.029851
          },
          {
            "term": "procedure",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "framework",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "leverages",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "two",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "which",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "combine",
            "tf": 1,
            "weight": 0.014925
          },
          {
            "term": "our",
            "tf": 1,
            "weight": 0.014925
          }
        ],
        "unique_terms": 50,
        "total_terms": 67
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Procedure",
        "and",
        "data",
        "deepset",
        "haystack",
        "https",
        "pipeline",
        "pipelines",
        "run",
        "the",
        "will"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.538,
      "overall": 0.7126666666666667
    }
  },
  {
    "text": "### Deploy the LLM to OpenShift\n\nFollow the steps in [Chapter 6. Serving large language models](https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.5/html/working_on_data_science_projects/serving-large-language-models_serving-large-language-models#doc-wrapper). This will download the LLM from the [HuggingFace](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1), and deploy it to OpenShift using a *single model serving platform*.\n\nYour LLM service will have a URL, which you need to store as an environment variable.\n\n```shell\nexport INFERENCE_ENDPOINT_URL=\"http://mistral-service.default.svc.cluster.local\"\n```\n\n```python\nimport os\n\nos.environ[\"INFERENCE_ENDPOINT_URL\"] = \"http://mistral-service.default.svc.cluster.local\"\n```",
    "metadata": {
      "chunk_id": "c6892d676c10-0010",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Deploy the LLM to OpenShift"
      ],
      "heading_text": "Deploy the LLM to OpenShift",
      "token_count": 189,
      "char_count": 767,
      "start_char": 20963,
      "end_char": 21730,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7270967741935483,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.720124",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Deploy the LLM to OpenShift",
      "chunk_hash": "5f40dae463bc268c",
      "content_digest": "5f40dae463bc268c",
      "chunk_length": 767,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "serving",
          "llm",
          "openshift",
          "large",
          "language",
          "models",
          "mistral",
          "service",
          "url",
          "deploy",
          "https",
          "will",
          "huggingface",
          "inference",
          "endpoint",
          "http",
          "default",
          "svc",
          "cluster"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "serving",
            "tf": 4,
            "weight": 0.042105
          },
          {
            "term": "llm",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "openshift",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "large",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "language",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "mistral",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "service",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "url",
            "tf": 3,
            "weight": 0.031579
          },
          {
            "term": "deploy",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "will",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "huggingface",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "inference",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "endpoint",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "http",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "default",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "svc",
            "tf": 2,
            "weight": 0.021053
          },
          {
            "term": "cluster",
            "tf": 2,
            "weight": 0.021053
          }
        ],
        "unique_terms": 62,
        "total_terms": 95
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Deploy the LLM to OpenShift",
        "language",
        "large",
        "llm",
        "mistral",
        "models",
        "openshift",
        "service",
        "serving",
        "the",
        "url"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7270967741935483,
      "overall": 0.7090322580645161
    }
  },
  {
    "text": "### Launch Qdrant Hybrid Cloud\n\nComplete **How to Set Up Qdrant on Red Hat OpenShift**. When in Hybrid Cloud, your Qdrant instance is private and and its nodes run on the same OpenShift infrastructure as your other components.\n\nRetrieve your Qdrant URL and API key and store them as environment variables:\n\n```shell\nexport QDRANT_URL=\"https://qdrant.example.com\"\nexport QDRANT_API_KEY=\"your-api-key\"\n```\n\n```python\nos.environ[\"QDRANT_URL\"] = \"https://qdrant.example.com\"\nos.environ[\"QDRANT_API_KEY\"] = \"your-api-key\"\n```",
    "metadata": {
      "chunk_id": "c6892d676c10-0011",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Launch Qdrant Hybrid Cloud"
      ],
      "heading_text": "Launch Qdrant Hybrid Cloud",
      "token_count": 135,
      "char_count": 520,
      "start_char": 21732,
      "end_char": 22252,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5253846153846153,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.720374",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Launch Qdrant Hybrid Cloud",
      "chunk_hash": "70a172f11aaa68c8",
      "content_digest": "70a172f11aaa68c8",
      "chunk_length": 520,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "your",
          "api",
          "key",
          "and",
          "url",
          "hybrid",
          "cloud",
          "openshift",
          "export",
          "https",
          "example",
          "com",
          "environ",
          "launch",
          "complete",
          "how",
          "set",
          "red",
          "hat"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.138889
          },
          {
            "term": "your",
            "tf": 5,
            "weight": 0.069444
          },
          {
            "term": "api",
            "tf": 5,
            "weight": 0.069444
          },
          {
            "term": "key",
            "tf": 5,
            "weight": 0.069444
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.055556
          },
          {
            "term": "url",
            "tf": 3,
            "weight": 0.041667
          },
          {
            "term": "hybrid",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "cloud",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "openshift",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "export",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "example",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "com",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "environ",
            "tf": 2,
            "weight": 0.027778
          },
          {
            "term": "launch",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "complete",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "how",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "set",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "red",
            "tf": 1,
            "weight": 0.013889
          },
          {
            "term": "hat",
            "tf": 1,
            "weight": 0.013889
          }
        ],
        "unique_terms": 38,
        "total_terms": 72
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Launch Qdrant Hybrid Cloud",
        "and",
        "api",
        "cloud",
        "export",
        "hybrid",
        "key",
        "openshift",
        "qdrant",
        "url",
        "your"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5253846153846153,
      "overall": 0.6417948717948717
    }
  },
  {
    "text": "## Implementation\n\nWe will first create an indexing pipeline to add documents to the system. Then, the search pipeline will retrieve relevant data from our documents. After the pipelines are tested, we will export them to YAML files.",
    "metadata": {
      "chunk_id": "c6892d676c10-0012",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Implementation"
      ],
      "heading_text": "Implementation",
      "token_count": 44,
      "char_count": 233,
      "start_char": 22254,
      "end_char": 22487,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5268421052631579,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.720499",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Implementation",
      "chunk_hash": "4d2e8f9d76514e7c",
      "content_digest": "4d2e8f9d76514e7c",
      "chunk_length": 233,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "will",
          "the",
          "pipeline",
          "documents",
          "implementation",
          "first",
          "create",
          "indexing",
          "add",
          "system",
          "then",
          "search",
          "retrieve",
          "relevant",
          "data",
          "from",
          "our",
          "after",
          "pipelines",
          "are"
        ],
        "term_weights": [
          {
            "term": "will",
            "tf": 3,
            "weight": 0.096774
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.096774
          },
          {
            "term": "pipeline",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "documents",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "implementation",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "first",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "create",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "indexing",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "add",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "then",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "retrieve",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "relevant",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "data",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "from",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "our",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "after",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "pipelines",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.032258
          }
        ],
        "unique_terms": 25,
        "total_terms": 31
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Implementation",
        "add",
        "create",
        "documents",
        "first",
        "implementation",
        "indexing",
        "pipeline",
        "system",
        "the",
        "will"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5268421052631579,
      "overall": 0.7089473684210525
    }
  },
  {
    "text": "### Indexing pipeline\n\n[Haystack 2.x](https://haystack.deepset.ai/) comes packed with a lot of useful components, from data fetching, through HTML parsing, up to the vector storage. Before we start, there are a few Python packages that we need to install:\n\n```shell\npip install haystack-ai \\\n    qdrant-client \\\n    qdrant-haystack \\\n    fastembed-haystack\n```\n\nFastEmbed uses ONNX runtime and does not require a GPU for the embedding models while still providing a fast inference speed.\n\nOur environment is now ready, so we can jump right into the code. Lets define an empty pipeline and gradually add components to it:\n\n```python\nfrom haystack import Pipeline\n\nindexing_pipeline = Pipeline()\n```",
    "metadata": {
      "chunk_id": "c6892d676c10-0013",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Indexing pipeline"
      ],
      "heading_text": "Indexing pipeline",
      "token_count": 158,
      "char_count": 698,
      "start_char": 22489,
      "end_char": 23187,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5433980582524272,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.720801",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Indexing pipeline",
      "chunk_hash": "b75b26c50497d251",
      "content_digest": "b75b26c50497d251",
      "chunk_length": 698,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "haystack",
          "pipeline",
          "the",
          "indexing",
          "components",
          "from",
          "python",
          "install",
          "qdrant",
          "fastembed",
          "and",
          "https",
          "deepset",
          "comes",
          "packed",
          "with",
          "lot",
          "useful",
          "data",
          "fetching"
        ],
        "term_weights": [
          {
            "term": "haystack",
            "tf": 6,
            "weight": 0.069767
          },
          {
            "term": "pipeline",
            "tf": 5,
            "weight": 0.05814
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.034884
          },
          {
            "term": "indexing",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "components",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "from",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "python",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "install",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.023256
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "deepset",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "comes",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "packed",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "with",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "lot",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "useful",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "data",
            "tf": 1,
            "weight": 0.011628
          },
          {
            "term": "fetching",
            "tf": 1,
            "weight": 0.011628
          }
        ],
        "unique_terms": 67,
        "total_terms": 86
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Indexing pipeline",
        "components",
        "fastembed",
        "from",
        "haystack",
        "indexing",
        "install",
        "pipeline",
        "python",
        "qdrant",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5433980582524272,
      "overall": 0.647799352750809
    }
  },
  {
    "text": "#### Chunking and creating the embeddings\n\nWe used `HTMLToDocument` to convert the HTML sources into `Document` instances of Haystack, which is a base class containing some data to be queried. However, a single document might be too long to be processed by the embedding model, and it also carries way too much information to make the search relevant.\n\nTherefore, we need to split the document into smaller parts and convert them into embeddings. For this, we will use the `DocumentSplitter` and `FastembedDocumentEmbedder` pointed to our `BAAI/bge-base-en-v1.5` model:\n\n```python\nfrom haystack.components.preprocessors import DocumentSplitter\nfrom haystack_integrations.components.embedders.fastembed import FastembedDocumentEmbedder\n\nsplitter = DocumentSplitter(split_by=\"sentence\", split_length=5, split_overlap=2)\nembedder = FastembedDocumentEmbedder(model=\"BAAI/bge-base-en-v1.5\")\nembedder.warm_up()\n\nindexing_pipeline.add_component(\"splitter\", splitter)\nindexing_pipeline.add_component(\"embedder\", embedder)\n\nindexing_pipeline.connect(\"converter.documents\", \"splitter.documents\")\nindexing_pipeline.connect(\"splitter.documents\", \"embedder.documents\")\n```",
    "metadata": {
      "chunk_id": "c6892d676c10-0015",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Chunking and creating the embeddings"
      ],
      "heading_text": "Chunking and creating the embeddings",
      "token_count": 257,
      "char_count": 1159,
      "start_char": 24436,
      "end_char": 25595,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.521578947368421,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.721653",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Chunking and creating the embeddings",
      "chunk_hash": "dab47d9081154180",
      "content_digest": "dab47d9081154180",
      "chunk_length": 1159,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "splitter",
          "embedder",
          "and",
          "split",
          "indexing",
          "pipeline",
          "documents",
          "into",
          "document",
          "haystack",
          "base",
          "model",
          "documentsplitter",
          "fastembeddocumentembedder",
          "embeddings",
          "convert",
          "too",
          "baai",
          "bge"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 6,
            "weight": 0.047244
          },
          {
            "term": "splitter",
            "tf": 5,
            "weight": 0.03937
          },
          {
            "term": "embedder",
            "tf": 5,
            "weight": 0.03937
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.031496
          },
          {
            "term": "split",
            "tf": 4,
            "weight": 0.031496
          },
          {
            "term": "indexing",
            "tf": 4,
            "weight": 0.031496
          },
          {
            "term": "pipeline",
            "tf": 4,
            "weight": 0.031496
          },
          {
            "term": "documents",
            "tf": 4,
            "weight": 0.031496
          },
          {
            "term": "into",
            "tf": 3,
            "weight": 0.023622
          },
          {
            "term": "document",
            "tf": 3,
            "weight": 0.023622
          },
          {
            "term": "haystack",
            "tf": 3,
            "weight": 0.023622
          },
          {
            "term": "base",
            "tf": 3,
            "weight": 0.023622
          },
          {
            "term": "model",
            "tf": 3,
            "weight": 0.023622
          },
          {
            "term": "documentsplitter",
            "tf": 3,
            "weight": 0.023622
          },
          {
            "term": "fastembeddocumentembedder",
            "tf": 3,
            "weight": 0.023622
          },
          {
            "term": "embeddings",
            "tf": 2,
            "weight": 0.015748
          },
          {
            "term": "convert",
            "tf": 2,
            "weight": 0.015748
          },
          {
            "term": "too",
            "tf": 2,
            "weight": 0.015748
          },
          {
            "term": "baai",
            "tf": 2,
            "weight": 0.015748
          },
          {
            "term": "bge",
            "tf": 2,
            "weight": 0.015748
          }
        ],
        "unique_terms": 74,
        "total_terms": 127
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Chunking and creating the embeddings",
        "and",
        "document",
        "documents",
        "embedder",
        "indexing",
        "into",
        "pipeline",
        "split",
        "splitter",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.521578947368421,
      "overall": 0.6405263157894736
    }
  },
  {
    "text": "#### Test the entire pipeline\n\nWe can finally run it on a list of URLs to index the content in Qdrant. We have a bunch of URLs to all the Red Hat OpenShift Foundations course lessons, so lets use them:\n\n```python\ncourse_urls = [\n    \"https://developers.redhat.com/learn/openshift/foundations-openshift\",\n    \"https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:openshift-and-developer-sandbox\",\n    \"https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:overview-web-console\",\n    \"https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:use-terminal-window-within-red-hat-openshift-web-console\",\n    \"https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:install-application-source-code-github-repository-using-openshift-web-console\",\n    \"https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:install-application-linux-container-image-repository-using-openshift-web-console\",\n    \"https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:install-application-linux-container-image-using-oc-cli-tool\",\n    \"https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:install-application-source-code-using-oc-cli-tool\",\n    \"https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:scale-applications-using-openshift-web-console\",\n    \"https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:scale-applications-using-oc-cli-tool\",\n    \"https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:work-databases-openshift-using-oc-cli-tool\",\n    \"https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:work-databases-openshift-web-console\",\n    \"https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:view-performance-information-using-openshift-web-console\",\n]\n\nindexing_pipeline.run(data={\n    \"fetcher\": {\n        \"urls\": course_urls,\n    }\n})\n```\n\nThe execution might take a while, as the model needs to process all the documents. After the process is finished, we should have all the documents stored in Qdrant, ready for search. You should see a short summary of processed documents:\n\n```shell\n{'writer': {'documents_written': 381}}\n```",
    "metadata": {
      "chunk_id": "c6892d676c10-0017",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Test the entire pipeline"
      ],
      "heading_text": "Test the entire pipeline",
      "token_count": 576,
      "char_count": 2523,
      "start_char": 26711,
      "end_char": 29234,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7357142857142858,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.723004",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Test the entire pipeline",
      "chunk_hash": "689362a3084b7b51",
      "content_digest": "689362a3084b7b51",
      "chunk_length": 2523,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "openshift",
          "foundations",
          "https",
          "developers",
          "redhat",
          "com",
          "learn",
          "learning",
          "resource",
          "resources",
          "the",
          "using",
          "web",
          "console",
          "urls",
          "install",
          "application",
          "cli",
          "tool",
          "documents"
        ],
        "term_weights": [
          {
            "term": "openshift",
            "tf": 35,
            "weight": 0.118243
          },
          {
            "term": "foundations",
            "tf": 14,
            "weight": 0.047297
          },
          {
            "term": "https",
            "tf": 13,
            "weight": 0.043919
          },
          {
            "term": "developers",
            "tf": 13,
            "weight": 0.043919
          },
          {
            "term": "redhat",
            "tf": 13,
            "weight": 0.043919
          },
          {
            "term": "com",
            "tf": 13,
            "weight": 0.043919
          },
          {
            "term": "learn",
            "tf": 13,
            "weight": 0.043919
          },
          {
            "term": "learning",
            "tf": 12,
            "weight": 0.040541
          },
          {
            "term": "resource",
            "tf": 12,
            "weight": 0.040541
          },
          {
            "term": "resources",
            "tf": 12,
            "weight": 0.040541
          },
          {
            "term": "the",
            "tf": 8,
            "weight": 0.027027
          },
          {
            "term": "using",
            "tf": 8,
            "weight": 0.027027
          },
          {
            "term": "web",
            "tf": 7,
            "weight": 0.023649
          },
          {
            "term": "console",
            "tf": 7,
            "weight": 0.023649
          },
          {
            "term": "urls",
            "tf": 5,
            "weight": 0.016892
          },
          {
            "term": "install",
            "tf": 4,
            "weight": 0.013514
          },
          {
            "term": "application",
            "tf": 4,
            "weight": 0.013514
          },
          {
            "term": "cli",
            "tf": 4,
            "weight": 0.013514
          },
          {
            "term": "tool",
            "tf": 4,
            "weight": 0.013514
          },
          {
            "term": "documents",
            "tf": 4,
            "weight": 0.013514
          }
        ],
        "unique_terms": 88,
        "total_terms": 296
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Test the entire pipeline",
        "com",
        "developers",
        "foundations",
        "https",
        "learn",
        "learning",
        "openshift",
        "redhat",
        "resource",
        "resources"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7357142857142858,
      "overall": 0.7119047619047619
    }
  },
  {
    "text": "### Search pipeline\n\nOur documents are now indexed and ready for search. The next pipeline is a bit simpler, but we still need to define a few components. Lets start again with an empty pipeline:\n\n```python\nsearch_pipeline = Pipeline()\n```\n\nOur second process takes user input, converts it into embeddings and then searches for the most relevant documents using the query embedding. This might look familiar, but we arent working with `Document` instances anymore, since the query only accepts raw text. Thus, some of the components will be different, especially the embedder, as it has to accept a single string as an input and produce a single embedding as an output:\n\n```python\nfrom haystack_integrations.components.embedders.fastembed import FastembedTextEmbedder\nfrom haystack_integrations.components.retrievers.qdrant import QdrantEmbeddingRetriever\n\nquery_embedder = FastembedTextEmbedder(model=\"BAAI/bge-base-en-v1.5\")\nquery_embedder.warm_up()\n\nretriever = QdrantEmbeddingRetriever(\n    document_store=document_store,  # The same document store as the one used for indexing\n    top_k=3,  # Number of documents to return\n)\n\nsearch_pipeline.add_component(\"query_embedder\", query_embedder)\nsearch_pipeline.add_component(\"retriever\", retriever)\n\nsearch_pipeline.connect(\"query_embedder.embedding\", \"retriever.query_embedding\")\n```",
    "metadata": {
      "chunk_id": "c6892d676c10-0018",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Search pipeline"
      ],
      "heading_text": "Search pipeline",
      "token_count": 296,
      "char_count": 1335,
      "start_char": 29236,
      "end_char": 30571,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.514025974025974,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.723442",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Search pipeline",
      "chunk_hash": "f01632a80be1470d",
      "content_digest": "f01632a80be1470d",
      "chunk_length": 1335,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "pipeline",
          "the",
          "query",
          "search",
          "embedder",
          "components",
          "embedding",
          "document",
          "retriever",
          "documents",
          "and",
          "for",
          "store",
          "our",
          "but",
          "with",
          "python",
          "input",
          "single",
          "from"
        ],
        "term_weights": [
          {
            "term": "pipeline",
            "tf": 8,
            "weight": 0.050314
          },
          {
            "term": "the",
            "tf": 8,
            "weight": 0.050314
          },
          {
            "term": "query",
            "tf": 8,
            "weight": 0.050314
          },
          {
            "term": "search",
            "tf": 6,
            "weight": 0.037736
          },
          {
            "term": "embedder",
            "tf": 6,
            "weight": 0.037736
          },
          {
            "term": "components",
            "tf": 4,
            "weight": 0.025157
          },
          {
            "term": "embedding",
            "tf": 4,
            "weight": 0.025157
          },
          {
            "term": "document",
            "tf": 4,
            "weight": 0.025157
          },
          {
            "term": "retriever",
            "tf": 4,
            "weight": 0.025157
          },
          {
            "term": "documents",
            "tf": 3,
            "weight": 0.018868
          },
          {
            "term": "and",
            "tf": 3,
            "weight": 0.018868
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.018868
          },
          {
            "term": "store",
            "tf": 3,
            "weight": 0.018868
          },
          {
            "term": "our",
            "tf": 2,
            "weight": 0.012579
          },
          {
            "term": "but",
            "tf": 2,
            "weight": 0.012579
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.012579
          },
          {
            "term": "python",
            "tf": 2,
            "weight": 0.012579
          },
          {
            "term": "input",
            "tf": 2,
            "weight": 0.012579
          },
          {
            "term": "single",
            "tf": 2,
            "weight": 0.012579
          },
          {
            "term": "from",
            "tf": 2,
            "weight": 0.012579
          }
        ],
        "unique_terms": 94,
        "total_terms": 159
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Search pipeline",
        "components",
        "document",
        "documents",
        "embedder",
        "embedding",
        "pipeline",
        "query",
        "retriever",
        "search",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.514025974025974,
      "overall": 0.638008658008658
    }
  },
  {
    "text": "#### Run a test query\n\nIf our goal was to just retrieve the relevant documents, we could stop here. Lets try the current pipeline on a simple query:\n\n```python\nquery = \"How to install an application using the OpenShift web console?\"\n\nsearch_pipeline.run(data={\n    \"query_embedder\": {\n        \"text\": query\n    }\n})\n```\n\nWe set the `top_k` parameter to 3, so the retriever should return the three most relevant documents. Your output should look like this:\n\n```text\n{\n    'retriever': {\n        'documents': [\n            Document(id=867b4aa4c37a91e72dc7ff452c47972c1a46a279a7531cd6af14169bcef1441b, content: 'Install a Node.js application from GitHub using the web console The following describes the steps r...', meta: {'content_type': 'text/html', 'source_id': 'f56e8f827dda86abe67c0ba3b4b11331d896e2d4f7b2b43c74d3ce973d07be0c', 'url': 'https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:work-databases-openshift-web-console'}, score: 0.9209432),\n            Document(id=0c74381c178597dd91335ebfde790d13bf5989b682d73bf5573c7734e6765af7, content: 'How to remove an application from OpenShift using the web console. In addition to providing the cap...', meta: {'content_type': 'text/html', 'source_id': '2a0759f3ce4a37d9f5c2af9c0ffcc80879077c102fb8e41e576e04833c9d24ce', 'url': 'https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:install-application-linux-container-image-repository-using-openshift-web-console'}, score: 0.9132109500000001),\n            Document(id=3e5f8923a34ab05611ef20783211e5543e880c709fd6534d9c1f63576edc4061, content: 'Path resource: Install an application from source code in a GitHub repository using the OpenShift w...', meta: {'content_type': 'text/html', 'source_id': 'a4c4cd62d07c0d9d240e3289d2a1cc0a3d1127ae70704529967f715601559089', 'url': 'https://developers.redhat.com/learning/learn:openshift:foundations-openshift/resource/resources:install-application-source-code-github-repository-using-openshift-web-console'}, score: 0.912748935)\n        ]\n    }\n}\n```",
    "metadata": {
      "chunk_id": "c6892d676c10-0019",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Run a test query"
      ],
      "heading_text": "Run a test query",
      "token_count": 630,
      "char_count": 2082,
      "start_char": 30573,
      "end_char": 32655,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7,
      "retrieval_quality": 0.6920731707317074,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.724348",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Run a test query",
      "chunk_hash": "f2966f555d843915",
      "content_digest": "f2966f555d843915",
      "chunk_length": 2082,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "openshift",
          "application",
          "using",
          "web",
          "console",
          "content",
          "query",
          "install",
          "text",
          "source",
          "resource",
          "documents",
          "document",
          "from",
          "github",
          "meta",
          "type",
          "html",
          "url"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 12,
            "weight": 0.060914
          },
          {
            "term": "openshift",
            "tf": 12,
            "weight": 0.060914
          },
          {
            "term": "application",
            "tf": 6,
            "weight": 0.030457
          },
          {
            "term": "using",
            "tf": 6,
            "weight": 0.030457
          },
          {
            "term": "web",
            "tf": 6,
            "weight": 0.030457
          },
          {
            "term": "console",
            "tf": 6,
            "weight": 0.030457
          },
          {
            "term": "content",
            "tf": 6,
            "weight": 0.030457
          },
          {
            "term": "query",
            "tf": 5,
            "weight": 0.025381
          },
          {
            "term": "install",
            "tf": 5,
            "weight": 0.025381
          },
          {
            "term": "text",
            "tf": 5,
            "weight": 0.025381
          },
          {
            "term": "source",
            "tf": 5,
            "weight": 0.025381
          },
          {
            "term": "resource",
            "tf": 4,
            "weight": 0.020305
          },
          {
            "term": "documents",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "document",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "from",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "github",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "meta",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "type",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "html",
            "tf": 3,
            "weight": 0.015228
          },
          {
            "term": "url",
            "tf": 3,
            "weight": 0.015228
          }
        ],
        "unique_terms": 88,
        "total_terms": 197
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Run a test query",
        "application",
        "console",
        "content",
        "install",
        "openshift",
        "query",
        "text",
        "the",
        "using",
        "web"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7,
      "retrieval_quality": 0.6920731707317074,
      "overall": 0.7306910569105692
    }
  },
  {
    "text": "#### Generating the answer\n\nRetrieval should serve more than just documents. Therefore, we will need to use an LLM to generate exact answers to our question. This is the final component of our second pipeline.\n\nHaystack will create a prompt which adds your documents to the models context.\n\n```python\nfrom haystack.components.builders.prompt_builder import PromptBuilder\nfrom haystack.components.generators import HuggingFaceTGIGenerator\n\nprompt_builder = PromptBuilder(\"\"\"\nGiven the following information, answer the question.\n\nContext: \n{% for document in documents %}\n    {{ document.content }}\n{% endfor %}\n\nQuestion: {{ query }}\n\"\"\")\nllm = HuggingFaceTGIGenerator(\n    model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n    url=os.environ[\"INFERENCE_ENDPOINT_URL\"],\n    generation_kwargs={\n        \"max_new_tokens\": 1000,  # Allow longer responses\n    },\n)\n\nsearch_pipeline.add_component(\"prompt_builder\", prompt_builder)\nsearch_pipeline.add_component(\"llm\", llm)\n\nsearch_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\nsearch_pipeline.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n```\n\nThe `PromptBuilder` is a Jinja2 template that will be filled with the documents and the query. The `HuggingFaceTGIGenerator` connects to the LLM service and generates the answer. Lets run the pipeline again:\n\n```python\nquery = \"How to install an application using the OpenShift web console?\"\n\nresponse = search_pipeline.run(data={\n    \"query_embedder\": {\n        \"text\": query\n    },\n    \"prompt_builder\": {\n        \"query\": query\n    },\n})\n```\n\nThe LLM may provide multiple replies, if asked to do so, so lets iterate over and print them out:\n\n```python\nfor reply in response[\"llm\"][\"replies\"]:\n    print(reply.strip())\n```\n\nIn our case there is a single response, which should be the answer to the question:\n\n```text\nAnswer: To install an application using the OpenShift web console, follow these steps:\n\n1. Select +Add on the left side of the web console.\n2. Identify the container image to install.\n3. Using your web browser, navigate to the Developer Sandbox for Red Hat OpenShift and select Start your Sandbox for free.\n4. Install an application from source code stored in a GitHub repository using the OpenShift web console.\n```\n\nOur final search pipeline might also be visualized, so we can see how the components are glued together:\n\n```python\nsearch_pipeline.draw(\"search_pipeline.png\")\n```",
    "metadata": {
      "chunk_id": "c6892d676c10-0020",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Generating the answer"
      ],
      "heading_text": "Generating the answer",
      "token_count": 530,
      "char_count": 2409,
      "start_char": 32657,
      "end_char": 35066,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.8857615894039736,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.725186",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Generating the answer",
      "chunk_hash": "50196474e3b1889a",
      "content_digest": "50196474e3b1889a",
      "chunk_length": 2409,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "pipeline",
          "prompt",
          "llm",
          "search",
          "builder",
          "query",
          "documents",
          "answer",
          "web",
          "our",
          "question",
          "python",
          "for",
          "and",
          "install",
          "using",
          "openshift",
          "console",
          "will"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 23,
            "weight": 0.08042
          },
          {
            "term": "pipeline",
            "tf": 10,
            "weight": 0.034965
          },
          {
            "term": "prompt",
            "tf": 10,
            "weight": 0.034965
          },
          {
            "term": "llm",
            "tf": 8,
            "weight": 0.027972
          },
          {
            "term": "search",
            "tf": 8,
            "weight": 0.027972
          },
          {
            "term": "builder",
            "tf": 7,
            "weight": 0.024476
          },
          {
            "term": "query",
            "tf": 7,
            "weight": 0.024476
          },
          {
            "term": "documents",
            "tf": 6,
            "weight": 0.020979
          },
          {
            "term": "answer",
            "tf": 5,
            "weight": 0.017483
          },
          {
            "term": "web",
            "tf": 5,
            "weight": 0.017483
          },
          {
            "term": "our",
            "tf": 4,
            "weight": 0.013986
          },
          {
            "term": "question",
            "tf": 4,
            "weight": 0.013986
          },
          {
            "term": "python",
            "tf": 4,
            "weight": 0.013986
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.013986
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.013986
          },
          {
            "term": "install",
            "tf": 4,
            "weight": 0.013986
          },
          {
            "term": "using",
            "tf": 4,
            "weight": 0.013986
          },
          {
            "term": "openshift",
            "tf": 4,
            "weight": 0.013986
          },
          {
            "term": "console",
            "tf": 4,
            "weight": 0.013986
          },
          {
            "term": "will",
            "tf": 3,
            "weight": 0.01049
          }
        ],
        "unique_terms": 140,
        "total_terms": 286
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Generating the answer",
        "answer",
        "builder",
        "documents",
        "llm",
        "pipeline",
        "prompt",
        "query",
        "search",
        "the",
        "web"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.8857615894039736,
      "overall": 0.7619205298013245
    }
  },
  {
    "text": "## Deployment\n\nThe pipelines are now ready, and we can export them to YAML. Hayhooks will use these files to run the pipelines as HTTP endpoints. To do this, specify both file paths and your environment variables.\n\n> Note: The indexing pipeline might be run inside your ETL tool, but search should be definitely exposed as an HTTP endpoint.\n\nLets run it on the local machine:\n\n```shell\npip install hayhooks\n```\n\nFirst of all, we need to save the pipelines to the YAML file:\n\n```python\nwith open(\"search-pipeline.yaml\", \"w\") as fp:\n    search_pipeline.dump(fp)\n```\n\nAnd now we are able to run the Hayhooks service:\n\n```shell\nhayhooks run\n```\n\nThe command should start the service on the default port, so you can access it at `http://localhost:1416`. The pipeline is not deployed yet, but we can do it with just another command:\n\n```shell\nhayhooks deploy search-pipeline.yaml\n```\n\nOnce its finished, you should be able to see the OpenAPI documentation at <http://localhost:1416/docs>, and test the newly created endpoint.\n\nOur search is now accessible through the HTTP endpoint, so we can integrate it with any other service. We can even control the other parameters, like the number of documents to return:\n\n```shell\ncurl -X 'POST' \\\n  'http://localhost:1416/search-pipeline' \\\n  -H 'Accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"llm\": {\n  },\n  \"prompt_builder\": {\n    \"query\": \"How can I remove an application?\"\n  },\n  \"query_embedder\": {\n    \"text\": \"How can I remove an application?\"\n  },\n  \"retriever\": {\n    \"top_k\": 5\n  }\n}'\n```\n\nThe response should be similar to the one we got in the Python before:\n\n```json\n{\n  \"llm\": {\n    \"replies\": [\n      \"\\n\\nAnswer: You can remove an application running in OpenShift by right-clicking on the circular graphic representing the application in Topology view and selecting the Delete Application text from the dialog that appears when you click the graphics outer ring. Alternatively, you can use the oc CLI tool to delete an installed application using the oc delete all command.\"\n    ],\n    \"meta\": [\n      {\n        \"model\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n        \"index\": 0,\n        \"finish_reason\": \"eos_token\",\n        \"usage\": {\n          \"completion_tokens\": 75,\n          \"prompt_tokens\": 642,\n          \"total_tokens\": 717\n        }\n      }\n    ]\n  }\n}\n```",
    "metadata": {
      "chunk_id": "c6892d676c10-0021",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Deployment"
      ],
      "heading_text": "Deployment",
      "token_count": 578,
      "char_count": 2353,
      "start_char": 35068,
      "end_char": 37421,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.6744186046511629,
      "chunking_strategy": "hierarchical_balanced_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.726038",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Deployment",
      "chunk_hash": "92bcc8fde150f2b3",
      "content_digest": "92bcc8fde150f2b3",
      "chunk_length": 2353,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "can",
          "application",
          "http",
          "pipeline",
          "search",
          "and",
          "hayhooks",
          "run",
          "you",
          "yaml",
          "should",
          "shell",
          "pipelines",
          "now",
          "endpoint",
          "with",
          "service",
          "command",
          "localhost"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 26,
            "weight": 0.094545
          },
          {
            "term": "can",
            "tf": 9,
            "weight": 0.032727
          },
          {
            "term": "application",
            "tf": 8,
            "weight": 0.029091
          },
          {
            "term": "http",
            "tf": 6,
            "weight": 0.021818
          },
          {
            "term": "pipeline",
            "tf": 6,
            "weight": 0.021818
          },
          {
            "term": "search",
            "tf": 6,
            "weight": 0.021818
          },
          {
            "term": "and",
            "tf": 5,
            "weight": 0.018182
          },
          {
            "term": "hayhooks",
            "tf": 5,
            "weight": 0.018182
          },
          {
            "term": "run",
            "tf": 5,
            "weight": 0.018182
          },
          {
            "term": "you",
            "tf": 5,
            "weight": 0.018182
          },
          {
            "term": "yaml",
            "tf": 4,
            "weight": 0.014545
          },
          {
            "term": "should",
            "tf": 4,
            "weight": 0.014545
          },
          {
            "term": "shell",
            "tf": 4,
            "weight": 0.014545
          },
          {
            "term": "pipelines",
            "tf": 3,
            "weight": 0.010909
          },
          {
            "term": "now",
            "tf": 3,
            "weight": 0.010909
          },
          {
            "term": "endpoint",
            "tf": 3,
            "weight": 0.010909
          },
          {
            "term": "with",
            "tf": 3,
            "weight": 0.010909
          },
          {
            "term": "service",
            "tf": 3,
            "weight": 0.010909
          },
          {
            "term": "command",
            "tf": 3,
            "weight": 0.010909
          },
          {
            "term": "localhost",
            "tf": 3,
            "weight": 0.010909
          }
        ],
        "unique_terms": 155,
        "total_terms": 275
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Deployment",
        "and",
        "application",
        "can",
        "hayhooks",
        "http",
        "pipeline",
        "run",
        "search",
        "the",
        "you"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.6744186046511629,
      "overall": 0.7581395348837209
    }
  },
  {
    "text": "## Next steps  - In this example, [Red Hat OpenShift](https://www.redhat.com/en/technologies/cloud-computing/openshift) is the infrastructure of choice for proprietary chatbots. [Read more](https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.8) about how to host AI projects in their [extensive documentation](https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.8). - [Haystacks documentation](https://docs.haystack.deepset.ai/docs/kubernetes) describes [how to deploy the Hayhooks service in a Kubernetes environment](https://docs.haystack.deepset.ai/docs/kubernetes), so you can easily move it to your own OpenShift infrastructure. - If you are just getting started and need more guidance on Qdrant, read the [quickstart](https://qdrant.tech/documentation/quick-start/) or try out our [beginner tutorial](https://qdrant.tech/documentation/tutorials/neural-search/).",
    "metadata": {
      "chunk_id": "c6892d676c10-0022",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Next steps"
      ],
      "heading_text": "Next steps",
      "token_count": 220,
      "char_count": 928,
      "start_char": 37423,
      "end_char": 38351,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.554935064935065,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.726413",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Next steps",
      "chunk_hash": "cdc4a861033ae981",
      "content_digest": "cdc4a861033ae981",
      "chunk_length": 928,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "documentation",
          "openshift",
          "docs",
          "red",
          "hat",
          "redhat",
          "com",
          "the",
          "haystack",
          "kubernetes",
          "qdrant",
          "infrastructure",
          "read",
          "more",
          "access",
          "self",
          "managed",
          "how",
          "deepset"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 7,
            "weight": 0.063063
          },
          {
            "term": "documentation",
            "tf": 6,
            "weight": 0.054054
          },
          {
            "term": "openshift",
            "tf": 5,
            "weight": 0.045045
          },
          {
            "term": "docs",
            "tf": 4,
            "weight": 0.036036
          },
          {
            "term": "red",
            "tf": 3,
            "weight": 0.027027
          },
          {
            "term": "hat",
            "tf": 3,
            "weight": 0.027027
          },
          {
            "term": "redhat",
            "tf": 3,
            "weight": 0.027027
          },
          {
            "term": "com",
            "tf": 3,
            "weight": 0.027027
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.027027
          },
          {
            "term": "haystack",
            "tf": 3,
            "weight": 0.027027
          },
          {
            "term": "kubernetes",
            "tf": 3,
            "weight": 0.027027
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.027027
          },
          {
            "term": "infrastructure",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "read",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "more",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "access",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "self",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "managed",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "how",
            "tf": 2,
            "weight": 0.018018
          },
          {
            "term": "deepset",
            "tf": 2,
            "weight": 0.018018
          }
        ],
        "unique_terms": 67,
        "total_terms": 111
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Next steps",
        "com",
        "docs",
        "documentation",
        "hat",
        "haystack",
        "https",
        "openshift",
        "red",
        "redhat",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.554935064935065,
      "overall": 0.7183116883116883
    }
  },
  {
    "text": "##### Was this page useful? Yes No  Thank you for your feedback!   We are sorry to hear that.  You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/rag-chatbot-red-hat-openshift-haystack.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue. On this page:  - [Private Chatbot for Interactive Learning](#private-chatbot-for-interactive-learning.md)    - [Components](#components.md)     - [Procedure](#procedure.md)    - [Prerequisites](#prerequisites.md)      - [Deploy the LLM to OpenShift](#deploy-the-llm-to-openshift.md)     - [Launch Qdrant Hybrid Cloud](#launch-qdrant-hybrid-cloud.md)    - [Implementation](#implementation.md)      - [Indexing pipeline](#indexing-pipeline.md)     - [Search pipeline](#search-pipeline.md)    - [Deployment](#deployment.md)    - [Next steps](#next-steps.md)  * [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/rag-chatbot-red-hat-openshift-haystack.md) * [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)",
    "metadata": {
      "chunk_id": "c6892d676c10-0023",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "file_extension": ".md",
      "chunk_index": 23,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Was this page useful?"
      ],
      "heading_text": "Was this page useful?",
      "token_count": 311,
      "char_count": 1150,
      "start_char": 38355,
      "end_char": 39505,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7211481012658228,
      "chunking_strategy": "hierarchical_balanced_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T09:14:02.727047",
      "document_id": "c6892d676c10",
      "document_name": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_filename": "_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_rag-chatbot-red-hat-openshift-haystack\\_documentation_examples_rag-chatbot-red-hat-openshift-haystack_.md",
      "hierarchy_path": "Was this page useful?",
      "chunk_hash": "5a1d92c35b02d258",
      "content_digest": "5a1d92c35b02d258",
      "chunk_length": 1150,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "page",
          "github",
          "landing",
          "https",
          "com",
          "chatbot",
          "openshift",
          "pipeline",
          "this",
          "for",
          "you",
          "edit",
          "tree",
          "master",
          "content",
          "documentation",
          "examples",
          "rag",
          "red"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 8,
            "weight": 0.06015
          },
          {
            "term": "page",
            "tf": 7,
            "weight": 0.052632
          },
          {
            "term": "github",
            "tf": 7,
            "weight": 0.052632
          },
          {
            "term": "landing",
            "tf": 6,
            "weight": 0.045113
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "chatbot",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "openshift",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "pipeline",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "this",
            "tf": 3,
            "weight": 0.022556
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.022556
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "edit",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "tree",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "master",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "content",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "documentation",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "rag",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "red",
            "tf": 2,
            "weight": 0.015038
          }
        ],
        "unique_terms": 56,
        "total_terms": 133
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Was this page useful?",
        "chatbot",
        "com",
        "github",
        "https",
        "landing",
        "openshift",
        "page",
        "pipeline",
        "qdrant",
        "this"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7211481012658228,
      "overall": 0.7403827004219409
    }
  }
]
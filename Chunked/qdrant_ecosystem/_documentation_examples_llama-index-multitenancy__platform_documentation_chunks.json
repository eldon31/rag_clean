[
  {
    "text": "### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)",
    "metadata": {
      "chunk_id": "c2c4824924ce-0000",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Essentials"
      ],
      "heading_text": "Essentials",
      "token_count": 189,
      "char_count": 673,
      "start_char": 679,
      "end_char": 1352,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5053846153846153,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.348820",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Essentials",
      "chunk_hash": "b49cc869c6854f5f",
      "content_digest": "b49cc869c6854f5f",
      "chunk_length": 673,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "https",
          "tech",
          "documentation",
          "agentic",
          "with",
          "data",
          "ingestion",
          "beginners",
          "langgraph",
          "discord",
          "multimodal",
          "and",
          "deepseek",
          "n8n",
          "essentials",
          "for",
          "simple",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "documentation",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "agentic",
            "tf": 6,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "beginners",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "langgraph",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "discord",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "multimodal",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "deepseek",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "n8n",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "essentials",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 31,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Essentials",
        "agentic",
        "beginners",
        "data",
        "documentation",
        "https",
        "ingestion",
        "qdrant",
        "rag",
        "tech",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5053846153846153,
      "overall": 0.6351282051282051
    }
  },
  {
    "text": "### Integrations  [Data Management](https://qdrant.tech/documentation/data-management/)  - [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/) - [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/) - [Apache Spark](https://qdrant.tech/documentation/data-management/spark/) - [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/) - [cognee](https://qdrant.tech/documentation/data-management/cognee/) - [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/) - [DLT](https://qdrant.tech/documentation/data-management/dlt/) - [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/) - [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/) - [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)  [Embeddings](https://qdrant.tech/documentation/embeddings/)  - [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/) - [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/) - [Cohere](https://qdrant.tech/documentation/embeddings/cohere/) - [Gemini](https://qdrant.tech/documentation/embeddings/gemini/) - [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/) - [Mistral](https://qdrant.tech/documentation/embeddings/mistral/) - [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/) - [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/) - [Nomic](https://qdrant.tech/documentation/embeddings/nomic/) - [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/) - [Ollama](https://qdrant.tech/documentation/embeddings/ollama/) - [OpenAI](https://qdrant.tech/documentation/embeddings/openai/) - [Prem AI](https://qdrant.tech/documentation/embeddings/premai/) - [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/) - [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/) - [Upstage](https://qdrant.tech/documentation/embeddings/upstage/) - [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)  [Frameworks](https://qdrant.tech/documentation/frameworks/)  - [Autogen](https://qdrant.tech/documentation/frameworks/autogen/) - [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/) - [CamelAI](https://qdrant.tech/documentation/frameworks/camel/) - [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/) - [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/) - [Dagster](https://qdrant.tech/documentation/frameworks/dagster/) - [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/) - [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/) - [Feast](https://qdrant.tech/documentation/frameworks/feast/) - [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/) - [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/) - [Haystack](https://qdrant.tech/documentation/frameworks/haystack/) - [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/) - [Langchain](https://qdrant.tech/documentation/frameworks/langchain/) - [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/) - [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/) - [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/) - [Mastra](https://qdrant.tech/documentation/frameworks/mastra/) - [Mem0](https://qdrant.tech/documentation/frameworks/mem0/) - [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/) - [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/) - [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/) - [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/) - [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/) - [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/) - [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/) - [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/) - [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/) - [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/) - [txtai](https://qdrant.tech/documentation/frameworks/txtai/) - [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/) - [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/) - [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)  [Observability](https://qdrant.tech/documentation/observability/)  - [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/) - [OpenLIT](https://qdrant.tech/documentation/observability/openlit/) - [Datadog](https://qdrant.tech/documentation/observability/datadog/)  [Platforms](https://qdrant.tech/documentation/platforms/)  - [Apify](https://qdrant.tech/documentation/platforms/apify/) - [BuildShip](https://qdrant.tech/documentation/platforms/buildship/) - [Keboola](https://qdrant.tech/documentation/platforms/keboola/) - [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/) - [Make.com](https://qdrant.tech/documentation/platforms/make/) - [N8N](https://qdrant.tech/documentation/platforms/n8n/) - [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/) - [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/) - [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/) - [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/) - [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/) - [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)",
    "metadata": {
      "chunk_id": "c2c4824924ce-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integrations"
      ],
      "heading_text": "Integrations",
      "token_count": 1498,
      "char_count": 5661,
      "start_char": 1354,
      "end_char": 7015,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.350754",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Integrations",
      "chunk_hash": "8a3f2e84e2a75ae9",
      "content_digest": "8a3f2e84e2a75ae9",
      "chunk_length": 5661,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "frameworks",
          "embeddings",
          "platforms",
          "data",
          "management",
          "observability",
          "airbyte",
          "apache",
          "airflow",
          "spark",
          "cocoindex",
          "cognee",
          "confluent",
          "dlt",
          "fluvio",
          "redpanda"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "qdrant",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "tech",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "documentation",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "frameworks",
            "tf": 35,
            "weight": 0.058528
          },
          {
            "term": "embeddings",
            "tf": 21,
            "weight": 0.035117
          },
          {
            "term": "platforms",
            "tf": 14,
            "weight": 0.023411
          },
          {
            "term": "data",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "management",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "observability",
            "tf": 5,
            "weight": 0.008361
          },
          {
            "term": "airbyte",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "apache",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "airflow",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "spark",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cocoindex",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cognee",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "confluent",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "dlt",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "fluvio",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "redpanda",
            "tf": 2,
            "weight": 0.003344
          }
        ],
        "unique_terms": 113,
        "total_terms": 598
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integrations",
        "data",
        "documentation",
        "embeddings",
        "frameworks",
        "https",
        "management",
        "observability",
        "platforms",
        "qdrant",
        "tech"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "overall": 0.7576923076923077
    }
  },
  {
    "text": "### Examples  [Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)  - [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) - [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)  [Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)  - [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/) - [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/) - [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)  [Build Prototypes](https://qdrant.tech/documentation/examples/)  - [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/) - [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/) - [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/) - [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/) - [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/) - [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/) - [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/) - [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/) - [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/) - [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/) - [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/) - [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)  [Practice Datasets](https://qdrant.tech/documentation/datasets/)",
    "metadata": {
      "chunk_id": "c2c4824924ce-0002",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Examples"
      ],
      "heading_text": "Examples",
      "token_count": 576,
      "char_count": 2347,
      "start_char": 7017,
      "end_char": 9364,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.9076923076923078,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.352315",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Examples",
      "chunk_hash": "59078d11dd9c9931",
      "content_digest": "59078d11dd9c9931",
      "chunk_length": 2347,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "https",
          "tech",
          "documentation",
          "examples",
          "search",
          "with",
          "rag",
          "data",
          "chatbot",
          "send",
          "system",
          "semantic",
          "and",
          "cohere",
          "precision",
          "reranking",
          "dspy",
          "for",
          "automate"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 30,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "tech",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "documentation",
            "tf": 21,
            "weight": 0.075
          },
          {
            "term": "examples",
            "tf": 14,
            "weight": 0.05
          },
          {
            "term": "search",
            "tf": 10,
            "weight": 0.035714
          },
          {
            "term": "with",
            "tf": 9,
            "weight": 0.032143
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.032143
          },
          {
            "term": "data",
            "tf": 7,
            "weight": 0.025
          },
          {
            "term": "chatbot",
            "tf": 6,
            "weight": 0.021429
          },
          {
            "term": "send",
            "tf": 5,
            "weight": 0.017857
          },
          {
            "term": "system",
            "tf": 5,
            "weight": 0.017857
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "cohere",
            "tf": 4,
            "weight": 0.014286
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "dspy",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.010714
          },
          {
            "term": "automate",
            "tf": 2,
            "weight": 0.007143
          }
        ],
        "unique_terms": 96,
        "total_terms": 280
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Examples",
        "chatbot",
        "data",
        "documentation",
        "examples",
        "https",
        "qdrant",
        "rag",
        "search",
        "tech",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.9076923076923078,
      "overall": 0.8358974358974359
    }
  },
  {
    "text": "### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)",
    "metadata": {
      "chunk_id": "c2c4824924ce-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Essentials"
      ],
      "heading_text": "Essentials",
      "token_count": 189,
      "char_count": 673,
      "start_char": 9366,
      "end_char": 10039,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5053846153846153,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.352844",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Essentials",
      "chunk_hash": "b49cc869c6854f5f",
      "content_digest": "b49cc869c6854f5f",
      "chunk_length": 673,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "rag",
          "https",
          "tech",
          "documentation",
          "agentic",
          "with",
          "data",
          "ingestion",
          "beginners",
          "langgraph",
          "discord",
          "multimodal",
          "and",
          "deepseek",
          "n8n",
          "essentials",
          "for",
          "simple",
          "system"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.119048
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.107143
          },
          {
            "term": "https",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "tech",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "documentation",
            "tf": 7,
            "weight": 0.083333
          },
          {
            "term": "agentic",
            "tf": 6,
            "weight": 0.071429
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.059524
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "ingestion",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "beginners",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "langgraph",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "discord",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "multimodal",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "deepseek",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "n8n",
            "tf": 2,
            "weight": 0.02381
          },
          {
            "term": "essentials",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.011905
          },
          {
            "term": "system",
            "tf": 1,
            "weight": 0.011905
          }
        ],
        "unique_terms": 31,
        "total_terms": 84
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Essentials",
        "agentic",
        "beginners",
        "data",
        "documentation",
        "https",
        "ingestion",
        "qdrant",
        "rag",
        "tech",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5053846153846153,
      "overall": 0.6351282051282051
    }
  },
  {
    "text": "### Integrations  [Data Management](https://qdrant.tech/documentation/data-management/)  - [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/) - [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/) - [Apache Spark](https://qdrant.tech/documentation/data-management/spark/) - [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/) - [cognee](https://qdrant.tech/documentation/data-management/cognee/) - [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/) - [DLT](https://qdrant.tech/documentation/data-management/dlt/) - [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/) - [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/) - [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)  [Embeddings](https://qdrant.tech/documentation/embeddings/)  - [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/) - [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/) - [Cohere](https://qdrant.tech/documentation/embeddings/cohere/) - [Gemini](https://qdrant.tech/documentation/embeddings/gemini/) - [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/) - [Mistral](https://qdrant.tech/documentation/embeddings/mistral/) - [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/) - [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/) - [Nomic](https://qdrant.tech/documentation/embeddings/nomic/) - [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/) - [Ollama](https://qdrant.tech/documentation/embeddings/ollama/) - [OpenAI](https://qdrant.tech/documentation/embeddings/openai/) - [Prem AI](https://qdrant.tech/documentation/embeddings/premai/) - [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/) - [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/) - [Upstage](https://qdrant.tech/documentation/embeddings/upstage/) - [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)  [Frameworks](https://qdrant.tech/documentation/frameworks/)  - [Autogen](https://qdrant.tech/documentation/frameworks/autogen/) - [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/) - [CamelAI](https://qdrant.tech/documentation/frameworks/camel/) - [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/) - [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/) - [Dagster](https://qdrant.tech/documentation/frameworks/dagster/) - [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/) - [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/) - [Feast](https://qdrant.tech/documentation/frameworks/feast/) - [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/) - [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/) - [Haystack](https://qdrant.tech/documentation/frameworks/haystack/) - [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/) - [Langchain](https://qdrant.tech/documentation/frameworks/langchain/) - [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/) - [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/) - [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/) - [Mastra](https://qdrant.tech/documentation/frameworks/mastra/) - [Mem0](https://qdrant.tech/documentation/frameworks/mem0/) - [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/) - [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/) - [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/) - [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/) - [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/) - [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/) - [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/) - [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/) - [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/) - [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/) - [txtai](https://qdrant.tech/documentation/frameworks/txtai/) - [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/) - [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/) - [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)  [Observability](https://qdrant.tech/documentation/observability/)  - [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/) - [OpenLIT](https://qdrant.tech/documentation/observability/openlit/) - [Datadog](https://qdrant.tech/documentation/observability/datadog/)  [Platforms](https://qdrant.tech/documentation/platforms/)  - [Apify](https://qdrant.tech/documentation/platforms/apify/) - [BuildShip](https://qdrant.tech/documentation/platforms/buildship/) - [Keboola](https://qdrant.tech/documentation/platforms/keboola/) - [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/) - [Make.com](https://qdrant.tech/documentation/platforms/make/) - [N8N](https://qdrant.tech/documentation/platforms/n8n/) - [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/) - [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/) - [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/) - [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/) - [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/) - [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)",
    "metadata": {
      "chunk_id": "c2c4824924ce-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Integrations"
      ],
      "heading_text": "Integrations",
      "token_count": 1498,
      "char_count": 5661,
      "start_char": 10041,
      "end_char": 15702,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.354628",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Integrations",
      "chunk_hash": "8a3f2e84e2a75ae9",
      "content_digest": "8a3f2e84e2a75ae9",
      "chunk_length": 5661,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "frameworks",
          "embeddings",
          "platforms",
          "data",
          "management",
          "observability",
          "airbyte",
          "apache",
          "airflow",
          "spark",
          "cocoindex",
          "cognee",
          "confluent",
          "dlt",
          "fluvio",
          "redpanda"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "qdrant",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "tech",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "documentation",
            "tf": 80,
            "weight": 0.133779
          },
          {
            "term": "frameworks",
            "tf": 35,
            "weight": 0.058528
          },
          {
            "term": "embeddings",
            "tf": 21,
            "weight": 0.035117
          },
          {
            "term": "platforms",
            "tf": 14,
            "weight": 0.023411
          },
          {
            "term": "data",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "management",
            "tf": 12,
            "weight": 0.020067
          },
          {
            "term": "observability",
            "tf": 5,
            "weight": 0.008361
          },
          {
            "term": "airbyte",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "apache",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "airflow",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "spark",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cocoindex",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "cognee",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "confluent",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "dlt",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "fluvio",
            "tf": 2,
            "weight": 0.003344
          },
          {
            "term": "redpanda",
            "tf": 2,
            "weight": 0.003344
          }
        ],
        "unique_terms": 113,
        "total_terms": 598
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Integrations",
        "data",
        "documentation",
        "embeddings",
        "frameworks",
        "https",
        "management",
        "observability",
        "platforms",
        "qdrant",
        "tech"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6730769230769231,
      "overall": 0.7576923076923077
    }
  },
  {
    "text": "### Examples  [Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)  - [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) - [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)  [Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)  - [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/) - [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/) - [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)  [Build Prototypes](https://qdrant.tech/documentation/examples/)  - [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/) - [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/) - [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/) - [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/) - [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/) - [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/) - [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/) - [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/) - [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/) - [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/) - [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/) - [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)  [Practice Datasets](https://qdrant.tech/documentation/datasets/)  - [Documentation](https://qdrant.tech/documentation/) - - [Examples](https://qdrant.tech/documentation/examples/) - - Multitenancy with LlamaIndex",
    "metadata": {
      "chunk_id": "c2c4824924ce-0005",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Examples"
      ],
      "heading_text": "Examples",
      "token_count": 612,
      "char_count": 2495,
      "start_char": 15704,
      "end_char": 18199,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.9007874015748032,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.356128",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Examples",
      "chunk_hash": "c765e91f1374c1ab",
      "content_digest": "c765e91f1374c1ab",
      "chunk_length": 2495,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "documentation",
          "https",
          "tech",
          "examples",
          "search",
          "with",
          "rag",
          "data",
          "chatbot",
          "send",
          "system",
          "semantic",
          "and",
          "cohere",
          "precision",
          "reranking",
          "dspy",
          "multitenancy",
          "llamaindex"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 32,
            "weight": 0.108844
          },
          {
            "term": "documentation",
            "tf": 24,
            "weight": 0.081633
          },
          {
            "term": "https",
            "tf": 23,
            "weight": 0.078231
          },
          {
            "term": "tech",
            "tf": 23,
            "weight": 0.078231
          },
          {
            "term": "examples",
            "tf": 16,
            "weight": 0.054422
          },
          {
            "term": "search",
            "tf": 10,
            "weight": 0.034014
          },
          {
            "term": "with",
            "tf": 10,
            "weight": 0.034014
          },
          {
            "term": "rag",
            "tf": 9,
            "weight": 0.030612
          },
          {
            "term": "data",
            "tf": 7,
            "weight": 0.02381
          },
          {
            "term": "chatbot",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "send",
            "tf": 5,
            "weight": 0.017007
          },
          {
            "term": "system",
            "tf": 5,
            "weight": 0.017007
          },
          {
            "term": "semantic",
            "tf": 4,
            "weight": 0.013605
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.013605
          },
          {
            "term": "cohere",
            "tf": 4,
            "weight": 0.013605
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.010204
          },
          {
            "term": "reranking",
            "tf": 3,
            "weight": 0.010204
          },
          {
            "term": "dspy",
            "tf": 3,
            "weight": 0.010204
          },
          {
            "term": "multitenancy",
            "tf": 3,
            "weight": 0.010204
          },
          {
            "term": "llamaindex",
            "tf": 3,
            "weight": 0.010204
          }
        ],
        "unique_terms": 96,
        "total_terms": 294
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Examples",
        "chatbot",
        "data",
        "documentation",
        "examples",
        "https",
        "qdrant",
        "rag",
        "search",
        "tech",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.9007874015748032,
      "overall": 0.8335958005249343
    }
  },
  {
    "text": "# Multitenancy with LlamaIndex\n\nIf you are building a service that serves vectors for many independent users, and you want to isolate their data, the best practice is to use a single collection with payload-based partitioning. This approach is called **multitenancy**. Our guide on the [Separate Partitions](https://qdrant.tech/documentation/guides/multiple-partitions/) describes how to set it up in general, but if you use [LlamaIndex](https://qdrant.tech/documentation/integrations/llama-index/) as a backend, you may prefer reading a more specific instruction. So here it is!",
    "metadata": {
      "chunk_id": "c2c4824924ce-0006",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Multitenancy with LlamaIndex"
      ],
      "heading_text": "Multitenancy with LlamaIndex",
      "token_count": 132,
      "char_count": 579,
      "start_char": 18201,
      "end_char": 18780,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.534,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.356714",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Multitenancy with LlamaIndex",
      "chunk_hash": "ea46bdff69848020",
      "content_digest": "ea46bdff69848020",
      "chunk_length": 579,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "you",
          "multitenancy",
          "with",
          "llamaindex",
          "the",
          "use",
          "partitions",
          "https",
          "qdrant",
          "tech",
          "documentation",
          "are",
          "building",
          "service",
          "that",
          "serves",
          "vectors",
          "for",
          "many",
          "independent"
        ],
        "term_weights": [
          {
            "term": "you",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "multitenancy",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "llamaindex",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "use",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "partitions",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "https",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "tech",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "documentation",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "are",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "building",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "service",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "serves",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "vectors",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "many",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "independent",
            "tf": 1,
            "weight": 0.014286
          }
        ],
        "unique_terms": 57,
        "total_terms": 70
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Multitenancy with LlamaIndex",
        "https",
        "llamaindex",
        "multitenancy",
        "partitions",
        "qdrant",
        "tech",
        "the",
        "use",
        "with",
        "you"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.534,
      "overall": 0.7113333333333333
    }
  },
  {
    "text": "## Prerequisites\n\nThis tutorial assumes that you have already installed Qdrant and LlamaIndex. If you haven’t, please run the following commands:\n\n```bash\npip install llama-index llama-index-vector-stores-qdrant\n```\n\nWe are going to use a local Docker-based instance of Qdrant. If you want to use a remote instance, please adjust the code accordingly. Here is how we can start a local instance:\n\n```bash\ndocker run -d --name qdrant -p 6333:6333 -p 6334:6334 qdrant/qdrant:latest\n```",
    "metadata": {
      "chunk_id": "c2c4824924ce-0007",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Prerequisites"
      ],
      "heading_text": "Prerequisites",
      "token_count": 127,
      "char_count": 482,
      "start_char": 18782,
      "end_char": 19264,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5233333333333333,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.356943",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Prerequisites",
      "chunk_hash": "6ebb736ba4491818",
      "content_digest": "6ebb736ba4491818",
      "chunk_length": 482,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "you",
          "instance",
          "please",
          "run",
          "the",
          "bash",
          "llama",
          "index",
          "use",
          "local",
          "docker",
          "6333",
          "6334",
          "prerequisites",
          "this",
          "tutorial",
          "assumes",
          "that",
          "have"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.092308
          },
          {
            "term": "you",
            "tf": 3,
            "weight": 0.046154
          },
          {
            "term": "instance",
            "tf": 3,
            "weight": 0.046154
          },
          {
            "term": "please",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "run",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "bash",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "llama",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "index",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "use",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "local",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "docker",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "6333",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "6334",
            "tf": 2,
            "weight": 0.030769
          },
          {
            "term": "prerequisites",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "this",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "tutorial",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "assumes",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "that",
            "tf": 1,
            "weight": 0.015385
          },
          {
            "term": "have",
            "tf": 1,
            "weight": 0.015385
          }
        ],
        "unique_terms": 45,
        "total_terms": 65
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Prerequisites",
        "bash",
        "index",
        "instance",
        "llama",
        "please",
        "qdrant",
        "run",
        "the",
        "use",
        "you"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5233333333333333,
      "overall": 0.6411111111111111
    }
  },
  {
    "text": "## Setting up LlamaIndex pipeline\n\nWe are going to implement an end-to-end example of multitenant application using LlamaIndex. We’ll be indexing the documentation of different Python libraries, and we definitely don’t want any users to see the results coming from a library they are not interested in. In real case scenarios, this is even more dangerous, as the documents may contain sensitive information.",
    "metadata": {
      "chunk_id": "c2c4824924ce-0008",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Setting up LlamaIndex pipeline"
      ],
      "heading_text": "Setting up LlamaIndex pipeline",
      "token_count": 80,
      "char_count": 407,
      "start_char": 19266,
      "end_char": 19673,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5614285714285714,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.357128",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Setting up LlamaIndex pipeline",
      "chunk_hash": "88e0f79f78327d8f",
      "content_digest": "88e0f79f78327d8f",
      "chunk_length": 407,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "llamaindex",
          "are",
          "end",
          "setting",
          "pipeline",
          "going",
          "implement",
          "example",
          "multitenant",
          "application",
          "using",
          "indexing",
          "documentation",
          "different",
          "python",
          "libraries",
          "and",
          "definitely",
          "don"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 3,
            "weight": 0.0625
          },
          {
            "term": "llamaindex",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "end",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "setting",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "pipeline",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "going",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "implement",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "example",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "multitenant",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "application",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "using",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "indexing",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "documentation",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "different",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "python",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "libraries",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "and",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "definitely",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "don",
            "tf": 1,
            "weight": 0.020833
          }
        ],
        "unique_terms": 43,
        "total_terms": 48
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Setting up LlamaIndex pipeline",
        "are",
        "end",
        "example",
        "going",
        "implement",
        "llamaindex",
        "multitenant",
        "pipeline",
        "setting",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5614285714285714,
      "overall": 0.7538095238095237
    }
  },
  {
    "text": "### Creating vector store\n\n[QdrantVectorStore](https://docs.llamaindex.ai/en/stable/examples/vector_stores/QdrantIndexDemo.html) is a wrapper around Qdrant that provides all the necessary methods to work with your vector database in LlamaIndex. Let’s create a vector store for our collection. It requires setting a collection name and passing an instance of `QdrantClient`.\n\n```python\nfrom qdrant_client import QdrantClient\nfrom llama_index.vector_stores.qdrant import QdrantVectorStore\n\n\nclient = QdrantClient(\"http://localhost:6333\")\n\nvector_store = QdrantVectorStore(\n    collection_name=\"my_collection\",\n    client=client,\n)\n```",
    "metadata": {
      "chunk_id": "c2c4824924ce-0009",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Creating vector store"
      ],
      "heading_text": "Creating vector store",
      "token_count": 152,
      "char_count": 632,
      "start_char": 19675,
      "end_char": 20307,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.751904761904762,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.357423",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Creating vector store",
      "chunk_hash": "eeee32356a6195af",
      "content_digest": "eeee32356a6195af",
      "chunk_length": 632,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "vector",
          "collection",
          "client",
          "store",
          "qdrantvectorstore",
          "qdrant",
          "qdrantclient",
          "llamaindex",
          "stores",
          "name",
          "from",
          "import",
          "creating",
          "https",
          "docs",
          "stable",
          "examples",
          "qdrantindexdemo",
          "html",
          "wrapper"
        ],
        "term_weights": [
          {
            "term": "vector",
            "tf": 6,
            "weight": 0.085714
          },
          {
            "term": "collection",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "client",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "store",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "qdrantvectorstore",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "qdrantclient",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "llamaindex",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "stores",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "name",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "from",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "import",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "creating",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "https",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "docs",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "stable",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "examples",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "qdrantindexdemo",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "html",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "wrapper",
            "tf": 1,
            "weight": 0.014286
          }
        ],
        "unique_terms": 46,
        "total_terms": 70
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Creating vector store",
        "client",
        "collection",
        "llamaindex",
        "name",
        "qdrant",
        "qdrantclient",
        "qdrantvectorstore",
        "store",
        "stores",
        "vector"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.751904761904762,
      "overall": 0.7173015873015873
    }
  },
  {
    "text": "### Defining chunking strategy and embedding model\n\nAny semantic search application requires a way to convert text queries into vectors - an embedding model. `ServiceContext` is a bundle of commonly used resources used during the indexing and querying stage in any LlamaIndex application. We can also use it to set up an embedding model - in our case, a local [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5). set up\n\n```python\nfrom llama_index.core import ServiceContext\n\nservice_context = ServiceContext.from_defaults(\n    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n)\n```\n\n*Note*, in case you are using Large Language Model different from OpenAI’s ChatGPT, you should specify `llm` parameter for `ServiceContext`.\n\nWe can also control how our documents are split into chunks, or nodes using LLamaIndex’s terminology. The `SimpleNodeParser` splits documents into fixed length chunks with an overlap. The defaults are reasonable, but we can also adjust them if we want to. Both values are defined in tokens.\n\n```python\nfrom llama_index.core.node_parser import SimpleNodeParser\n\nnode_parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=32)\n```\n\nNow we also need to inform the `ServiceContext` about our choices:\n\n```python\nservice_context = ServiceContext.from_defaults(\n    embed_model=\"local:BAAI/bge-large-en-v1.5\",\n    node_parser=node_parser,\n)\n```\n\nBoth embedding model and selected node parser will be implicitly used during the indexing and querying.",
    "metadata": {
      "chunk_id": "c2c4824924ce-0010",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Defining chunking strategy and embedding model"
      ],
      "heading_text": "Defining chunking strategy and embedding model",
      "token_count": 340,
      "char_count": 1499,
      "start_char": 20309,
      "end_char": 21808,
      "semantic_score": 0.7,
      "structural_score": 0.9999999999999999,
      "retrieval_quality": 0.5003870967741936,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.357978",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Defining chunking strategy and embedding model",
      "chunk_hash": "ca1588460a2a99a1",
      "content_digest": "ca1588460a2a99a1",
      "chunk_length": 1499,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "model",
          "servicecontext",
          "from",
          "the",
          "node",
          "parser",
          "and",
          "embedding",
          "also",
          "baai",
          "bge",
          "defaults",
          "are",
          "into",
          "used",
          "can",
          "our",
          "local",
          "small",
          "python"
        ],
        "term_weights": [
          {
            "term": "model",
            "tf": 7,
            "weight": 0.037433
          },
          {
            "term": "servicecontext",
            "tf": 6,
            "weight": 0.032086
          },
          {
            "term": "from",
            "tf": 6,
            "weight": 0.032086
          },
          {
            "term": "the",
            "tf": 5,
            "weight": 0.026738
          },
          {
            "term": "node",
            "tf": 5,
            "weight": 0.026738
          },
          {
            "term": "parser",
            "tf": 5,
            "weight": 0.026738
          },
          {
            "term": "and",
            "tf": 4,
            "weight": 0.02139
          },
          {
            "term": "embedding",
            "tf": 4,
            "weight": 0.02139
          },
          {
            "term": "also",
            "tf": 4,
            "weight": 0.02139
          },
          {
            "term": "baai",
            "tf": 4,
            "weight": 0.02139
          },
          {
            "term": "bge",
            "tf": 4,
            "weight": 0.02139
          },
          {
            "term": "defaults",
            "tf": 4,
            "weight": 0.02139
          },
          {
            "term": "are",
            "tf": 4,
            "weight": 0.02139
          },
          {
            "term": "into",
            "tf": 3,
            "weight": 0.016043
          },
          {
            "term": "used",
            "tf": 3,
            "weight": 0.016043
          },
          {
            "term": "can",
            "tf": 3,
            "weight": 0.016043
          },
          {
            "term": "our",
            "tf": 3,
            "weight": 0.016043
          },
          {
            "term": "local",
            "tf": 3,
            "weight": 0.016043
          },
          {
            "term": "small",
            "tf": 3,
            "weight": 0.016043
          },
          {
            "term": "python",
            "tf": 3,
            "weight": 0.016043
          }
        ],
        "unique_terms": 99,
        "total_terms": 187
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Defining chunking strategy and embedding model",
        "also",
        "and",
        "baai",
        "embedding",
        "from",
        "model",
        "node",
        "parser",
        "servicecontext",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.9999999999999999,
      "retrieval_quality": 0.5003870967741936,
      "overall": 0.7334623655913978
    }
  },
  {
    "text": "## Indexing documents\n\nNo matter how our documents are generated, LlamaIndex will automatically split them into nodes, if required, encode using selected embedding model, and then store in the vector store. Let’s define some documents manually and insert them into Qdrant collection. Our documents are going to have a single metadata attribute - a library name they belong to.\n\n```python\nfrom llama_index.core.schema import Document\n\ndocuments = [\n    Document(\n        text=\"LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models.\",\n        metadata={\n            \"library\": \"llama-index\",\n        },\n    ),\n    Document(\n        text=\"Qdrant is a vector database & vector similarity search engine.\",\n        metadata={\n            \"library\": \"qdrant\",\n        },\n    ),\n]\n```\n\nNow we can index them using our `VectorStoreIndex`:\n\n```python\nfor document in documents:\n    index.insert(document)\n```",
    "metadata": {
      "chunk_id": "c2c4824924ce-0012",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Indexing documents"
      ],
      "heading_text": "Indexing documents",
      "token_count": 194,
      "char_count": 952,
      "start_char": 22254,
      "end_char": 23206,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5162295081967213,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.358532",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Indexing documents",
      "chunk_hash": "0d83f5dab7f474c2",
      "content_digest": "0d83f5dab7f474c2",
      "chunk_length": 952,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "documents",
          "document",
          "index",
          "our",
          "them",
          "vector",
          "qdrant",
          "metadata",
          "library",
          "are",
          "llamaindex",
          "into",
          "using",
          "and",
          "store",
          "insert",
          "python",
          "llama",
          "text",
          "data"
        ],
        "term_weights": [
          {
            "term": "documents",
            "tf": 6,
            "weight": 0.057692
          },
          {
            "term": "document",
            "tf": 5,
            "weight": 0.048077
          },
          {
            "term": "index",
            "tf": 4,
            "weight": 0.038462
          },
          {
            "term": "our",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "them",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "vector",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "metadata",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "library",
            "tf": 3,
            "weight": 0.028846
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "llamaindex",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "into",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "using",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "store",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "insert",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "python",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "llama",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "text",
            "tf": 2,
            "weight": 0.019231
          },
          {
            "term": "data",
            "tf": 2,
            "weight": 0.019231
          }
        ],
        "unique_terms": 68,
        "total_terms": 104
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Indexing documents",
        "are",
        "document",
        "documents",
        "index",
        "library",
        "metadata",
        "our",
        "qdrant",
        "them",
        "vector"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5162295081967213,
      "overall": 0.6387431693989071
    }
  },
  {
    "text": "### Performance considerations\n\nOur documents have been split into nodes, encoded using the embedding model, and stored in the vector store. However, we don’t want to allow our users to search for all the documents in the collection, but only for the documents that belong to a library they are interested in. For that reason, we need to set up the Qdrant [payload index](https://qdrant.tech/documentation/concepts/indexing/#payload-index), so the search is more efficient.\n\n```python\nfrom qdrant_client import models\n\nclient.create_payload_index(\n    collection_name=\"my_collection\",\n    field_name=\"metadata.library\",\n    field_type=models.PayloadSchemaType.KEYWORD,\n)\n```\n\nThe payload index is not the only thing we want to change. Since none of the search queries will be executed on the whole collection, we can also change its configuration, so the HNSW graph is not built globally. This is also done due to [performance reasons](https://qdrant.tech/documentation/guides/multiple-partitions/#calibrate-performance). **You should not be changing these parameters, if you know there will be some global search operations done on the collection.**\n\n```python\nclient.update_collection(\n    collection_name=\"my_collection\",\n    hnsw_config=models.HnswConfigDiff(payload_m=16, m=0),\n)\n```\n\nOnce both operations are completed, we can start searching for our documents.\n\nThese steps are done just once, when you index your first documents!",
    "metadata": {
      "chunk_id": "c2c4824924ce-0013",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Performance considerations"
      ],
      "heading_text": "Performance considerations",
      "token_count": 305,
      "char_count": 1437,
      "start_char": 23208,
      "end_char": 24645,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6915000000000001,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.359021",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Performance considerations",
      "chunk_hash": "e95b04b138b908d1",
      "content_digest": "e95b04b138b908d1",
      "chunk_length": 1437,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "collection",
          "documents",
          "payload",
          "index",
          "search",
          "for",
          "qdrant",
          "performance",
          "our",
          "are",
          "client",
          "models",
          "name",
          "not",
          "done",
          "you",
          "want",
          "only",
          "that"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 13,
            "weight": 0.071038
          },
          {
            "term": "collection",
            "tf": 8,
            "weight": 0.043716
          },
          {
            "term": "documents",
            "tf": 5,
            "weight": 0.027322
          },
          {
            "term": "payload",
            "tf": 5,
            "weight": 0.027322
          },
          {
            "term": "index",
            "tf": 5,
            "weight": 0.027322
          },
          {
            "term": "search",
            "tf": 4,
            "weight": 0.021858
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.021858
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.021858
          },
          {
            "term": "performance",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "our",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "are",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "client",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "models",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "name",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "not",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "done",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "you",
            "tf": 3,
            "weight": 0.016393
          },
          {
            "term": "want",
            "tf": 2,
            "weight": 0.010929
          },
          {
            "term": "only",
            "tf": 2,
            "weight": 0.010929
          },
          {
            "term": "that",
            "tf": 2,
            "weight": 0.010929
          }
        ],
        "unique_terms": 108,
        "total_terms": 183
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Performance considerations",
        "collection",
        "documents",
        "for",
        "index",
        "our",
        "payload",
        "performance",
        "qdrant",
        "search",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6915000000000001,
      "overall": 0.7638333333333334
    }
  },
  {
    "text": "## Querying documents with constraints\n\nLet’s assume we are searching for some information about large language models, but are only allowed to use Qdrant documentation. LlamaIndex has a concept of retrievers, responsible for finding the most relevant nodes for a given query. Our `VectorStoreIndex` can be used as a retriever, with some additional constraints - in our case value of the `library` metadata attribute.\n\n```python\nfrom llama_index.core.vector_stores.types import MetadataFilters, ExactMatchFilter\n\nqdrant_retriever = index.as_retriever(\n    filters=MetadataFilters(\n        filters=[\n            ExactMatchFilter(\n                key=\"library\",\n                value=\"qdrant\",\n            )\n        ]\n    )\n)\n\nnodes_with_scores = qdrant_retriever.retrieve(\"large language models\")\nfor node in nodes_with_scores:\n    print(node.text, node.score)",
    "metadata": {
      "chunk_id": "c2c4824924ce-0014",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Querying documents with constraints"
      ],
      "heading_text": "Querying documents with constraints",
      "token_count": 181,
      "char_count": 859,
      "start_char": 24647,
      "end_char": 25506,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5351612903225806,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.359379",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Querying documents with constraints",
      "chunk_hash": "c982c6220f835a7f",
      "content_digest": "c982c6220f835a7f",
      "chunk_length": 859,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "with",
          "for",
          "qdrant",
          "retriever",
          "nodes",
          "node",
          "constraints",
          "are",
          "some",
          "large",
          "language",
          "models",
          "the",
          "our",
          "value",
          "library",
          "index",
          "metadatafilters",
          "exactmatchfilter",
          "filters"
        ],
        "term_weights": [
          {
            "term": "with",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "for",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "qdrant",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "retriever",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "nodes",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "node",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "constraints",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "some",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "large",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "language",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "our",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "value",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "library",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "index",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "metadatafilters",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "exactmatchfilter",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "filters",
            "tf": 2,
            "weight": 0.021277
          }
        ],
        "unique_terms": 63,
        "total_terms": 94
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Querying documents with constraints",
        "are",
        "constraints",
        "for",
        "large",
        "node",
        "nodes",
        "qdrant",
        "retriever",
        "some",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5351612903225806,
      "overall": 0.6450537634408602
    }
  },
  {
    "text": "# Output: Qdrant is a vector database & vector similarity search engine. 0.60551536\n```\n\nThe description of Qdrant was the best match, even though it didn’t mention large language models at all. However, it was the only document that belonged to the `qdrant` library, so there was no other choice. Let’s try to search for something that is not present in the collection.\n\nLet’s define another retrieve, this time for the `llama-index` library:\n\n```python\nllama_index_retriever = index.as_retriever(\n    filters=MetadataFilters(\n        filters=[\n            ExactMatchFilter(\n                key=\"library\",\n                value=\"llama-index\",\n            )\n        ]\n    )\n)\n\nnodes_with_scores = llama_index_retriever.retrieve(\"large language models\")\nfor node in nodes_with_scores:\n    print(node.text, node.score)",
    "metadata": {
      "chunk_id": "c2c4824924ce-0015",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Output: Qdrant is a vector database & vector similarity search engine. 0.60551536"
      ],
      "heading_text": "Output: Qdrant is a vector database & vector similarity search engine. 0.60551536",
      "token_count": 184,
      "char_count": 816,
      "start_char": 25507,
      "end_char": 26323,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.5219587628865979,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.359752",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Output: Qdrant is a vector database & vector similarity search engine. 0.60551536",
      "chunk_hash": "9ae3bb94c252fa56",
      "content_digest": "9ae3bb94c252fa56",
      "chunk_length": 816,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "the",
          "index",
          "llama",
          "qdrant",
          "was",
          "library",
          "for",
          "retriever",
          "node",
          "vector",
          "search",
          "large",
          "language",
          "models",
          "that",
          "let",
          "retrieve",
          "filters",
          "nodes",
          "with"
        ],
        "term_weights": [
          {
            "term": "the",
            "tf": 6,
            "weight": 0.06383
          },
          {
            "term": "index",
            "tf": 5,
            "weight": 0.053191
          },
          {
            "term": "llama",
            "tf": 4,
            "weight": 0.042553
          },
          {
            "term": "qdrant",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "was",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "library",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "retriever",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "node",
            "tf": 3,
            "weight": 0.031915
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "large",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "language",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "models",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "that",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "let",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "retrieve",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "filters",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "nodes",
            "tf": 2,
            "weight": 0.021277
          },
          {
            "term": "with",
            "tf": 2,
            "weight": 0.021277
          }
        ],
        "unique_terms": 58,
        "total_terms": 94
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Output: Qdrant is a vector database & vector similarity search engine. 0.60551536",
        "for",
        "index",
        "library",
        "llama",
        "node",
        "qdrant",
        "retriever",
        "the",
        "vector",
        "was"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.5219587628865979,
      "overall": 0.6406529209621993
    }
  },
  {
    "text": "# Output: LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models. 0.63576734\n```\n\nThe results returned by both retrievers are different, due to the different constraints, so we implemented a real multitenant search application!",
    "metadata": {
      "chunk_id": "c2c4824924ce-0016",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Output: LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models. 0.63576734"
      ],
      "heading_text": "Output: LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models. 0.63576734",
      "token_count": 59,
      "char_count": 280,
      "start_char": 26324,
      "end_char": 26604,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5607317073170732,
      "chunking_strategy": "hierarchical_context_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.359894",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Output: LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models. 0.63576734",
      "chunk_hash": "a54234ac63e6101c",
      "content_digest": "a54234ac63e6101c",
      "chunk_length": 280,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "data",
          "the",
          "different",
          "output",
          "llamaindex",
          "simple",
          "flexible",
          "framework",
          "for",
          "connecting",
          "custom",
          "sources",
          "large",
          "language",
          "models",
          "63576734",
          "results",
          "returned",
          "both",
          "retrievers"
        ],
        "term_weights": [
          {
            "term": "data",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "the",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "different",
            "tf": 2,
            "weight": 0.064516
          },
          {
            "term": "output",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "llamaindex",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "simple",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "flexible",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "framework",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "for",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "connecting",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "custom",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "sources",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "large",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "language",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "models",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "63576734",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "results",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "returned",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "both",
            "tf": 1,
            "weight": 0.032258
          },
          {
            "term": "retrievers",
            "tf": 1,
            "weight": 0.032258
          }
        ],
        "unique_terms": 28,
        "total_terms": 31
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Output: LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models. 0.63576734",
        "connecting",
        "data",
        "different",
        "flexible",
        "for",
        "framework",
        "llamaindex",
        "output",
        "simple",
        "the"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5607317073170732,
      "overall": 0.7535772357723577
    }
  },
  {
    "text": "##### Was this page useful? Yes No  Thank you for your feedback! 🙏  We are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/llama-index-multitenancy.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue. On this page:  - [Multitenancy with LlamaIndex](#multitenancy-with-llamaindex.md)    - [Prerequisites](#prerequisites.md)    - [Setting up LlamaIndex pipeline](#setting-up-llamaindex-pipeline.md)      - [Creating vector store](#creating-vector-store.md)     - [Defining chunking strategy and embedding model](#defining-chunking-strategy-and-embedding-model.md)     - [Combining everything together](#combining-everything-together.md)    - [Indexing documents](#indexing-documents.md)     - [Performance considerations](#performance-considerations.md)    - [Querying documents with constraints](#querying-documents-with-constraints.md)  * [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/llama-index-multitenancy.md) * [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)",
    "metadata": {
      "chunk_id": "c2c4824924ce-0017",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "filename": "_documentation_examples_llama-index-multitenancy_.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Was this page useful?"
      ],
      "heading_text": "Was this page useful?",
      "token_count": 310,
      "char_count": 1202,
      "start_char": 26606,
      "end_char": 27808,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.733,
      "chunking_strategy": "hierarchical_context_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "embedding_dimension": 1536,
      "processing_timestamp": "2025-10-20T07:48:23.360382",
      "document_id": "c2c4824924ce",
      "document_name": "_documentation_examples_llama-index-multitenancy_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "source_filename": "_documentation_examples_llama-index-multitenancy_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_examples_llama-index-multitenancy\\_documentation_examples_llama-index-multitenancy_.md",
      "hierarchy_path": "Was this page useful?",
      "chunk_hash": "00cc5a62b3018950",
      "content_digest": "00cc5a62b3018950",
      "chunk_length": 1202,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "page",
          "github",
          "qdrant",
          "landing",
          "https",
          "com",
          "multitenancy",
          "with",
          "llamaindex",
          "documents",
          "this",
          "you",
          "edit",
          "tree",
          "master",
          "content",
          "documentation",
          "examples",
          "llama",
          "index"
        ],
        "term_weights": [
          {
            "term": "page",
            "tf": 7,
            "weight": 0.052632
          },
          {
            "term": "github",
            "tf": 7,
            "weight": 0.052632
          },
          {
            "term": "qdrant",
            "tf": 6,
            "weight": 0.045113
          },
          {
            "term": "landing",
            "tf": 6,
            "weight": 0.045113
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "multitenancy",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "with",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "llamaindex",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "documents",
            "tf": 4,
            "weight": 0.030075
          },
          {
            "term": "this",
            "tf": 3,
            "weight": 0.022556
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "edit",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "tree",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "master",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "content",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "documentation",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "examples",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "llama",
            "tf": 2,
            "weight": 0.015038
          },
          {
            "term": "index",
            "tf": 2,
            "weight": 0.015038
          }
        ],
        "unique_terms": 57,
        "total_terms": 133
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Was this page useful?",
        "com",
        "documents",
        "github",
        "https",
        "landing",
        "llamaindex",
        "multitenancy",
        "page",
        "qdrant",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.733,
      "overall": 0.7776666666666666
    }
  }
]
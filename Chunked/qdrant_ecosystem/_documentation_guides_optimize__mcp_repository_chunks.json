[
  {
    "text": "### User Manual  [Concepts](https://qdrant.tech/documentation/concepts/)  - [Collections](https://qdrant.tech/documentation/concepts/collections/) - [Points](https://qdrant.tech/documentation/concepts/points/) - [Vectors](https://qdrant.tech/documentation/concepts/vectors/) - [Payload](https://qdrant.tech/documentation/concepts/payload/) - [Search](https://qdrant.tech/documentation/concepts/search/) - [Explore](https://qdrant.tech/documentation/concepts/explore/) - [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/) - [Filtering](https://qdrant.tech/documentation/concepts/filtering/) - [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/) - [Storage](https://qdrant.tech/documentation/concepts/storage/) - [Indexing](https://qdrant.tech/documentation/concepts/indexing/) - [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)  [Guides](https://qdrant.tech/documentation/guides/installation/)  - [Installation](https://qdrant.tech/documentation/guides/installation/) - [Administration](https://qdrant.tech/documentation/guides/administration/) - [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/) - [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/) - [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/) - [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/) - [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/) - [Quantization](https://qdrant.tech/documentation/guides/quantization/) - [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/) - [Configuration](https://qdrant.tech/documentation/guides/configuration/) - [Security](https://qdrant.tech/documentation/guides/security/) - [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/) - [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)",
    "metadata": {
      "chunk_id": "d737c08c924f-0001",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "User Manual"
      ],
      "heading_text": "User Manual",
      "token_count": 485,
      "char_count": 1968,
      "start_char": 1046,
      "end_char": 3014,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.733,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.556475",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "User Manual",
      "chunk_hash": "aa99483e94fddd20",
      "content_digest": "aa99483e94fddd20",
      "chunk_length": 1968,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "guides",
          "concepts",
          "installation",
          "collections",
          "points",
          "vectors",
          "payload",
          "search",
          "explore",
          "hybrid",
          "queries",
          "filtering",
          "optimizer",
          "storage",
          "indexing",
          "snapshots"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "qdrant",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "tech",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "documentation",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "guides",
            "tf": 15,
            "weight": 0.072816
          },
          {
            "term": "concepts",
            "tf": 14,
            "weight": 0.067961
          },
          {
            "term": "installation",
            "tf": 3,
            "weight": 0.014563
          },
          {
            "term": "collections",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "points",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "vectors",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "payload",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "explore",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "hybrid",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "queries",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "filtering",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "optimizer",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "storage",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "indexing",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "snapshots",
            "tf": 2,
            "weight": 0.009709
          }
        ],
        "unique_terms": 45,
        "total_terms": 206
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "User Manual",
        "collections",
        "concepts",
        "documentation",
        "guides",
        "https",
        "installation",
        "points",
        "qdrant",
        "tech",
        "vectors"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.733,
      "overall": 0.7776666666666666
    }
  },
  {
    "text": "### Tutorials  [Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)  - [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/) - [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/) - [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/) - [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)  [Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)  - [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/) - [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/) - [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/) - [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/) - [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)  [Using the Database](https://qdrant.tech/documentation/database-tutorials/)  - [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/) - [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/) - [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/) - [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/) - [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/) - [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/) - [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)",
    "metadata": {
      "chunk_id": "d737c08c924f-0003",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Tutorials"
      ],
      "heading_text": "Tutorials",
      "token_count": 459,
      "char_count": 1988,
      "start_char": 3696,
      "end_char": 5684,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7480092783505154,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.557290",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Tutorials",
      "chunk_hash": "f480f0283a04b78a",
      "content_digest": "f480f0283a04b78a",
      "chunk_length": 1988,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "tutorials",
          "https",
          "tech",
          "documentation",
          "search",
          "database",
          "advanced",
          "beginner",
          "with",
          "hybrid",
          "retrieval",
          "build",
          "scale",
          "neural",
          "fastembed",
          "quality",
          "multivector",
          "representations",
          "using"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 22,
            "weight": 0.098655
          },
          {
            "term": "tutorials",
            "tf": 20,
            "weight": 0.089686
          },
          {
            "term": "https",
            "tf": 19,
            "weight": 0.085202
          },
          {
            "term": "tech",
            "tf": 19,
            "weight": 0.085202
          },
          {
            "term": "documentation",
            "tf": 19,
            "weight": 0.085202
          },
          {
            "term": "search",
            "tf": 14,
            "weight": 0.06278
          },
          {
            "term": "database",
            "tf": 9,
            "weight": 0.040359
          },
          {
            "term": "advanced",
            "tf": 7,
            "weight": 0.03139
          },
          {
            "term": "beginner",
            "tf": 5,
            "weight": 0.022422
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.022422
          },
          {
            "term": "hybrid",
            "tf": 4,
            "weight": 0.017937
          },
          {
            "term": "retrieval",
            "tf": 4,
            "weight": 0.017937
          },
          {
            "term": "build",
            "tf": 3,
            "weight": 0.013453
          },
          {
            "term": "scale",
            "tf": 3,
            "weight": 0.013453
          },
          {
            "term": "neural",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "quality",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "multivector",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "representations",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "using",
            "tf": 2,
            "weight": 0.008969
          }
        ],
        "unique_terms": 64,
        "total_terms": 223
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Tutorials",
        "advanced",
        "beginner",
        "database",
        "documentation",
        "https",
        "qdrant",
        "search",
        "tech",
        "tutorials",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7480092783505154,
      "overall": 0.7826697594501718
    }
  },
  {
    "text": "### Support  [FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)  - [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/) - [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)  [Release Notes](https://github.com/qdrant/qdrant/releases)",
    "metadata": {
      "chunk_id": "d737c08c924f-0004",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Support"
      ],
      "heading_text": "Support",
      "token_count": 83,
      "char_count": 311,
      "start_char": 5686,
      "end_char": 5997,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5627272727272727,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.558330",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Support",
      "chunk_hash": "f059a5deb61e367d",
      "content_digest": "f059a5deb61e367d",
      "chunk_length": 311,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "faq",
          "https",
          "tech",
          "documentation",
          "fundamentals",
          "database",
          "optimization",
          "support",
          "release",
          "notes",
          "github",
          "com",
          "releases"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 8,
            "weight": 0.228571
          },
          {
            "term": "faq",
            "tf": 4,
            "weight": 0.114286
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.114286
          },
          {
            "term": "tech",
            "tf": 3,
            "weight": 0.085714
          },
          {
            "term": "documentation",
            "tf": 3,
            "weight": 0.085714
          },
          {
            "term": "fundamentals",
            "tf": 3,
            "weight": 0.085714
          },
          {
            "term": "database",
            "tf": 2,
            "weight": 0.057143
          },
          {
            "term": "optimization",
            "tf": 2,
            "weight": 0.057143
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "release",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "notes",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "github",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "com",
            "tf": 1,
            "weight": 0.028571
          },
          {
            "term": "releases",
            "tf": 1,
            "weight": 0.028571
          }
        ],
        "unique_terms": 14,
        "total_terms": 35
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Support",
        "database",
        "documentation",
        "faq",
        "fundamentals",
        "https",
        "optimization",
        "qdrant",
        "release",
        "support",
        "tech"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5627272727272727,
      "overall": 0.7209090909090908
    }
  },
  {
    "text": "### User Manual  [Concepts](https://qdrant.tech/documentation/concepts/)  - [Collections](https://qdrant.tech/documentation/concepts/collections/) - [Points](https://qdrant.tech/documentation/concepts/points/) - [Vectors](https://qdrant.tech/documentation/concepts/vectors/) - [Payload](https://qdrant.tech/documentation/concepts/payload/) - [Search](https://qdrant.tech/documentation/concepts/search/) - [Explore](https://qdrant.tech/documentation/concepts/explore/) - [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/) - [Filtering](https://qdrant.tech/documentation/concepts/filtering/) - [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/) - [Storage](https://qdrant.tech/documentation/concepts/storage/) - [Indexing](https://qdrant.tech/documentation/concepts/indexing/) - [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)  [Guides](https://qdrant.tech/documentation/guides/installation/)  - [Installation](https://qdrant.tech/documentation/guides/installation/) - [Administration](https://qdrant.tech/documentation/guides/administration/) - [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/) - [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/) - [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/) - [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/) - [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/) - [Quantization](https://qdrant.tech/documentation/guides/quantization/) - [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/) - [Configuration](https://qdrant.tech/documentation/guides/configuration/) - [Security](https://qdrant.tech/documentation/guides/security/) - [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/) - [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)",
    "metadata": {
      "chunk_id": "d737c08c924f-0006",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "User Manual"
      ],
      "heading_text": "User Manual",
      "token_count": 485,
      "char_count": 1968,
      "start_char": 6374,
      "end_char": 8342,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.733,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.558330",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "User Manual",
      "chunk_hash": "aa99483e94fddd20",
      "content_digest": "aa99483e94fddd20",
      "chunk_length": 1968,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "https",
          "qdrant",
          "tech",
          "documentation",
          "guides",
          "concepts",
          "installation",
          "collections",
          "points",
          "vectors",
          "payload",
          "search",
          "explore",
          "hybrid",
          "queries",
          "filtering",
          "optimizer",
          "storage",
          "indexing",
          "snapshots"
        ],
        "term_weights": [
          {
            "term": "https",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "qdrant",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "tech",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "documentation",
            "tf": 27,
            "weight": 0.131068
          },
          {
            "term": "guides",
            "tf": 15,
            "weight": 0.072816
          },
          {
            "term": "concepts",
            "tf": 14,
            "weight": 0.067961
          },
          {
            "term": "installation",
            "tf": 3,
            "weight": 0.014563
          },
          {
            "term": "collections",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "points",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "vectors",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "payload",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "search",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "explore",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "hybrid",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "queries",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "filtering",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "optimizer",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "storage",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "indexing",
            "tf": 2,
            "weight": 0.009709
          },
          {
            "term": "snapshots",
            "tf": 2,
            "weight": 0.009709
          }
        ],
        "unique_terms": 45,
        "total_terms": 206
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "User Manual",
        "collections",
        "concepts",
        "documentation",
        "guides",
        "https",
        "installation",
        "points",
        "qdrant",
        "tech",
        "vectors"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.733,
      "overall": 0.7776666666666666
    }
  },
  {
    "text": "### Tutorials  [Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)  - [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/) - [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/) - [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/) - [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)  [Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)  - [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/) - [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/) - [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/) - [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/) - [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)  [Using the Database](https://qdrant.tech/documentation/database-tutorials/)  - [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/) - [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/) - [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/) - [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/) - [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/) - [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/) - [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)",
    "metadata": {
      "chunk_id": "d737c08c924f-0008",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Tutorials"
      ],
      "heading_text": "Tutorials",
      "token_count": 459,
      "char_count": 1988,
      "start_char": 9024,
      "end_char": 11012,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7480092783505154,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.559321",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Tutorials",
      "chunk_hash": "f480f0283a04b78a",
      "content_digest": "f480f0283a04b78a",
      "chunk_length": 1988,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "tutorials",
          "https",
          "tech",
          "documentation",
          "search",
          "database",
          "advanced",
          "beginner",
          "with",
          "hybrid",
          "retrieval",
          "build",
          "scale",
          "neural",
          "fastembed",
          "quality",
          "multivector",
          "representations",
          "using"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 22,
            "weight": 0.098655
          },
          {
            "term": "tutorials",
            "tf": 20,
            "weight": 0.089686
          },
          {
            "term": "https",
            "tf": 19,
            "weight": 0.085202
          },
          {
            "term": "tech",
            "tf": 19,
            "weight": 0.085202
          },
          {
            "term": "documentation",
            "tf": 19,
            "weight": 0.085202
          },
          {
            "term": "search",
            "tf": 14,
            "weight": 0.06278
          },
          {
            "term": "database",
            "tf": 9,
            "weight": 0.040359
          },
          {
            "term": "advanced",
            "tf": 7,
            "weight": 0.03139
          },
          {
            "term": "beginner",
            "tf": 5,
            "weight": 0.022422
          },
          {
            "term": "with",
            "tf": 5,
            "weight": 0.022422
          },
          {
            "term": "hybrid",
            "tf": 4,
            "weight": 0.017937
          },
          {
            "term": "retrieval",
            "tf": 4,
            "weight": 0.017937
          },
          {
            "term": "build",
            "tf": 3,
            "weight": 0.013453
          },
          {
            "term": "scale",
            "tf": 3,
            "weight": 0.013453
          },
          {
            "term": "neural",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "fastembed",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "quality",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "multivector",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "representations",
            "tf": 2,
            "weight": 0.008969
          },
          {
            "term": "using",
            "tf": 2,
            "weight": 0.008969
          }
        ],
        "unique_terms": 64,
        "total_terms": 223
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Tutorials",
        "advanced",
        "beginner",
        "database",
        "documentation",
        "https",
        "qdrant",
        "search",
        "tech",
        "tutorials",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7480092783505154,
      "overall": 0.7826697594501718
    }
  },
  {
    "text": "### Support  [FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)  - [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/) - [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)  [Release Notes](https://github.com/qdrant/qdrant/releases)  - [Documentation](https://qdrant.tech/documentation/) - - [Guides](https://qdrant.tech/documentation/guides/) - - Optimize Performance",
    "metadata": {
      "chunk_id": "d737c08c924f-0009",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Support"
      ],
      "heading_text": "Support",
      "token_count": 118,
      "char_count": 447,
      "start_char": 11014,
      "end_char": 11461,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7000000000000001,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.560316",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Support",
      "chunk_hash": "72dfe4fa465cb533",
      "content_digest": "72dfe4fa465cb533",
      "chunk_length": 447,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "https",
          "documentation",
          "tech",
          "faq",
          "fundamentals",
          "database",
          "optimization",
          "guides",
          "support",
          "release",
          "notes",
          "github",
          "com",
          "releases",
          "optimize",
          "performance"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 10,
            "weight": 0.208333
          },
          {
            "term": "https",
            "tf": 6,
            "weight": 0.125
          },
          {
            "term": "documentation",
            "tf": 6,
            "weight": 0.125
          },
          {
            "term": "tech",
            "tf": 5,
            "weight": 0.104167
          },
          {
            "term": "faq",
            "tf": 4,
            "weight": 0.083333
          },
          {
            "term": "fundamentals",
            "tf": 3,
            "weight": 0.0625
          },
          {
            "term": "database",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "optimization",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "guides",
            "tf": 2,
            "weight": 0.041667
          },
          {
            "term": "support",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "release",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "notes",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "github",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "com",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "releases",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "optimize",
            "tf": 1,
            "weight": 0.020833
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.020833
          }
        ],
        "unique_terms": 17,
        "total_terms": 48
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Support",
        "database",
        "documentation",
        "faq",
        "fundamentals",
        "guides",
        "https",
        "optimization",
        "qdrant",
        "support",
        "tech"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7000000000000001,
      "overall": 0.7666666666666666
    }
  },
  {
    "text": "# Optimizing Qdrant Performance: Three Scenarios  Different use cases require different balances between memory usage, search speed, and precision. Qdrant is designed to be flexible and customizable so you can tune it to your specific needs. This guide will walk you three main optimization strategies:  - High Speed Search & Low Memory Usage - High Precision & Low Memory Usage - High Precision & High Speed Search",
    "metadata": {
      "chunk_id": "d737c08c924f-0010",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Optimizing Qdrant Performance: Three Scenarios"
      ],
      "heading_text": "Optimizing Qdrant Performance: Three Scenarios",
      "token_count": 81,
      "char_count": 415,
      "start_char": 11463,
      "end_char": 11878,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.6959701492537312,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.560316",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Optimizing Qdrant Performance: Three Scenarios",
      "chunk_hash": "a1a26161d01eec54",
      "content_digest": "a1a26161d01eec54",
      "chunk_length": 415,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "high",
          "memory",
          "usage",
          "search",
          "speed",
          "precision",
          "qdrant",
          "three",
          "different",
          "and",
          "you",
          "low",
          "optimizing",
          "performance",
          "scenarios",
          "use",
          "cases",
          "require",
          "balances",
          "between"
        ],
        "term_weights": [
          {
            "term": "high",
            "tf": 4,
            "weight": 0.074074
          },
          {
            "term": "memory",
            "tf": 3,
            "weight": 0.055556
          },
          {
            "term": "usage",
            "tf": 3,
            "weight": 0.055556
          },
          {
            "term": "search",
            "tf": 3,
            "weight": 0.055556
          },
          {
            "term": "speed",
            "tf": 3,
            "weight": 0.055556
          },
          {
            "term": "precision",
            "tf": 3,
            "weight": 0.055556
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "three",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "different",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "low",
            "tf": 2,
            "weight": 0.037037
          },
          {
            "term": "optimizing",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "scenarios",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "use",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "cases",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "require",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "balances",
            "tf": 1,
            "weight": 0.018519
          },
          {
            "term": "between",
            "tf": 1,
            "weight": 0.018519
          }
        ],
        "unique_terms": 35,
        "total_terms": 54
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Optimizing Qdrant Performance: Three Scenarios",
        "and",
        "different",
        "high",
        "memory",
        "precision",
        "qdrant",
        "search",
        "speed",
        "three",
        "usage"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.6959701492537312,
      "overall": 0.7986567164179103
    }
  },
  {
    "text": "## 1. High-Speed Search with Low Memory Usage\n\nTo achieve high search speed with minimal memory usage, you can store vectors on disk while minimizing the number of disk reads. Vector quantization is a technique that compresses vectors, allowing more of them to be stored in memory, thus reducing the need to read from disk.\n\nTo configure in-memory quantization, with on-disk original vectors, you need to create a collection with the following parameters:\n\n- `on_disk`: Stores original vectors on disk.\n- `quantization_config`: Compresses quantized vectors to `int8` using the `scalar` method.\n- `always_ram`: Keeps quantized vectors in RAM.\n\n```http\nPUT /collections/{collection_name}\n{\n    \"vectors\": {\n        \"size\": 768,\n        \"distance\": \"Cosine\",\n        \"on_disk\": true\n    },\n    \"quantization_config\": {\n        \"scalar\": {\n            \"type\": \"int8\",\n            \"always_ram\": true\n        }\n    }\n}\n```\n\n```python\nfrom qdrant_client import QdrantClient, models\n\nclient = QdrantClient(url=\"http://localhost:6333\")\n\nclient.create_collection(\n    collection_name=\"{collection_name}\",\n    vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE, on_disk=True),\n    quantization_config=models.ScalarQuantization(\n        scalar=models.ScalarQuantizationConfig(\n            type=models.ScalarType.INT8,\n            always_ram=True,\n        ),\n    ),\n)\n```\n\n```typescript\nimport { QdrantClient } from \"@qdrant/js-client-rest\";\n\nconst client = new QdrantClient({ host: \"localhost\", port: 6333 });\n\nclient.createCollection(\"{collection_name}\", {\n  vectors: {\n    size: 768,\n    distance: \"Cosine\",\n    on_disk: true,\n  },\n  quantization_config: {\n    scalar: {\n      type: \"int8\",\n      always_ram: true,\n    },\n  },\n});\n```\n\n```rust\nuse qdrant_client::qdrant::{\n    CreateCollectionBuilder, Distance, QuantizationType, ScalarQuantizationBuilder,\n    VectorParamsBuilder,\n};\nuse qdrant_client::Qdrant;\n\nlet client = Qdrant::from_url(\"http://localhost:6334\").build()?;\n\nclient\n    .create_collection(\n        CreateCollectionBuilder::new(\"{collection_name}\")\n            .vectors_config(VectorParamsBuilder::new(768, Distance::Cosine))\n            .quantization_config(\n                ScalarQuantizationBuilder::default()\n                    .r#type(QuantizationType::Int8.into())\n                    .always_ram(true),\n            ),\n    )\n    .await?;\n```\n\n```java\nimport io.qdrant.client.QdrantClient;\nimport io.qdrant.client.QdrantGrpcClient;\nimport io.qdrant.client.grpc.Collections.CreateCollection;\nimport io.qdrant.client.grpc.Collections.Distance;\nimport io.qdrant.client.grpc.Collections.OptimizersConfigDiff;\nimport io.qdrant.client.grpc.Collections.QuantizationConfig;\nimport io.qdrant.client.grpc.Collections.QuantizationType;\nimport io.qdrant.client.grpc.Collections.ScalarQuantization;\nimport io.qdrant.client.grpc.Collections.VectorParams;\nimport io.qdrant.client.grpc.Collections.VectorsConfig;",
    "metadata": {
      "chunk_id": "d737c08c924f-0011",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "1. High-Speed Search with Low Memory Usage"
      ],
      "heading_text": "1. High-Speed Search with Low Memory Usage",
      "token_count": 687,
      "char_count": 2937,
      "start_char": 11881,
      "end_char": 14818,
      "semantic_score": 0.7,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.7038461538461538,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.562960",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "1. High-Speed Search with Low Memory Usage",
      "chunk_hash": "82076ede08bbc4c3",
      "content_digest": "82076ede08bbc4c3",
      "chunk_length": 2937,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "client",
          "qdrant",
          "import",
          "vectors",
          "disk",
          "collections",
          "collection",
          "grpc",
          "quantization",
          "config",
          "distance",
          "true",
          "ram",
          "models",
          "int8",
          "always",
          "name",
          "qdrantclient",
          "with",
          "memory"
        ],
        "term_weights": [
          {
            "term": "client",
            "tf": 20,
            "weight": 0.06993
          },
          {
            "term": "qdrant",
            "tf": 17,
            "weight": 0.059441
          },
          {
            "term": "import",
            "tf": 12,
            "weight": 0.041958
          },
          {
            "term": "vectors",
            "tf": 10,
            "weight": 0.034965
          },
          {
            "term": "disk",
            "tf": 9,
            "weight": 0.031469
          },
          {
            "term": "collections",
            "tf": 9,
            "weight": 0.031469
          },
          {
            "term": "collection",
            "tf": 8,
            "weight": 0.027972
          },
          {
            "term": "grpc",
            "tf": 8,
            "weight": 0.027972
          },
          {
            "term": "quantization",
            "tf": 7,
            "weight": 0.024476
          },
          {
            "term": "config",
            "tf": 7,
            "weight": 0.024476
          },
          {
            "term": "distance",
            "tf": 7,
            "weight": 0.024476
          },
          {
            "term": "true",
            "tf": 7,
            "weight": 0.024476
          },
          {
            "term": "ram",
            "tf": 6,
            "weight": 0.020979
          },
          {
            "term": "models",
            "tf": 6,
            "weight": 0.020979
          },
          {
            "term": "int8",
            "tf": 5,
            "weight": 0.017483
          },
          {
            "term": "always",
            "tf": 5,
            "weight": 0.017483
          },
          {
            "term": "name",
            "tf": 5,
            "weight": 0.017483
          },
          {
            "term": "qdrantclient",
            "tf": 5,
            "weight": 0.017483
          },
          {
            "term": "with",
            "tf": 4,
            "weight": 0.013986
          },
          {
            "term": "memory",
            "tf": 4,
            "weight": 0.013986
          }
        ],
        "unique_terms": 97,
        "total_terms": 286
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "1. High-Speed Search with Low Memory Usage",
        "client",
        "collection",
        "collections",
        "config",
        "disk",
        "grpc",
        "import",
        "qdrant",
        "quantization",
        "vectors"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.7038461538461538,
      "overall": 0.7346153846153846
    }
  },
  {
    "text": "### Disable Rescoring for Faster Search (optional)\n\nThis is completely optional. Disabling rescoring with search `params` can further reduce the number of disk reads. Note that this might slightly decrease precision.\n\n```http\nPOST /collections/{collection_name}/points/query\n{\n    \"query\": [0.2, 0.1, 0.9, 0.7],\n    \"params\": {\n        \"quantization\": {\n            \"rescore\": false\n        }\n    },\n    \"limit\": 10\n}\n```\n\n```python\nfrom qdrant_client import QdrantClient, models\n\nclient = QdrantClient(url=\"http://localhost:6333\")\n\nclient.query_points(\n    collection_name=\"{collection_name}\",\n    query=[0.2, 0.1, 0.9, 0.7],\n    search_params=models.SearchParams(\n        quantization=models.QuantizationSearchParams(rescore=False)\n    ),\n)\n```\n\n```typescript\nimport { QdrantClient } from \"@qdrant/js-client-rest\";\n\nconst client = new QdrantClient({ host: \"localhost\", port: 6333 });\n\nclient.query(\"{collection_name}\", {\n    query: [0.2, 0.1, 0.9, 0.7],\n    params: {\n        quantization: {\n            rescore: false,\n        },\n    },\n});\n```\n\n```rust\nuse qdrant_client::qdrant::{\n    QuantizationSearchParamsBuilder, QueryPointsBuilder, SearchParamsBuilder,\n};\nuse qdrant_client::Qdrant;\n\nlet client = Qdrant::from_url(\"http://localhost:6334\").build()?;\n\nclient\n    .query(\n        QueryPointsBuilder::new(\"{collection_name}\")\n            .query(vec![0.2, 0.1, 0.9, 0.7])\n            .limit(3)\n            .params(\n                SearchParamsBuilder::default()\n                    .quantization(QuantizationSearchParamsBuilder::default().rescore(false)),\n            ),\n    )\n    .await?;\n```\n\n```java\nimport io.qdrant.client.QdrantClient;\nimport io.qdrant.client.QdrantGrpcClient;\nimport io.qdrant.client.grpc.Points.QuantizationSearchParams;\nimport io.qdrant.client.grpc.Points.QueryPoints;\nimport io.qdrant.client.grpc.Points.SearchParams;\n\nimport static io.qdrant.client.QueryFactory.nearest;\n\nQdrantClient client =\n    new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());\n\nclient.queryAsync(\n        QueryPoints.newBuilder()\n                .setCollectionName(\"{collection_name}\")\n                .setQuery(nearest(0.2f, 0.1f, 0.9f, 0.7f))\n                .setParams(\n                        SearchParams.newBuilder()\n                                .setQuantization(\n                                        QuantizationSearchParams.newBuilder().setRescore(false).build())\n                                .build())\n                .setLimit(3)\n                .build())\n        .get();\n```\n\n```csharp\nusing Qdrant.Client;\nusing Qdrant.Client.Grpc;\n\nvar client = new QdrantClient(\"localhost\", 6334);\n\nawait client.QueryAsync(\n\tcollectionName: \"{collection_name}\",\n\tquery: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },\n\tsearchParams: new SearchParams\n\t{\n\t\tQuantization = new QuantizationSearchParams { Rescore = false }\n\t},\n\tlimit: 3\n);\n```\n\n```go\nimport (\n\t\"context\"\n\n\t\"github.com/qdrant/go-client/qdrant\"\n)\n\nclient, err := qdrant.NewClient(&qdrant.Config{\n\tHost: \"localhost\",\n\tPort: 6334,\n})\n\nclient.Query(context.Background(), &qdrant.QueryPoints{\n\tCollectionName: \"{collection_name}\",\n\tQuery:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),\n\tParams: &qdrant.SearchParams{\n\t\tQuantization: &qdrant.QuantizationSearchParams{\n\t\t\tRescore: qdrant.PtrOf(true),\n\t\t},\n\t},\n})\n```",
    "metadata": {
      "chunk_id": "d737c08c924f-0013",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Disable Rescoring for Faster Search (optional)"
      ],
      "heading_text": "Disable Rescoring for Faster Search (optional)",
      "token_count": 883,
      "char_count": 3303,
      "start_char": 16809,
      "end_char": 20112,
      "semantic_score": 0.6,
      "structural_score": 0.7,
      "retrieval_quality": 0.6943319838056681,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.562960",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Disable Rescoring for Faster Search (optional)",
      "chunk_hash": "fc17ad9708dd61e5",
      "content_digest": "fc17ad9708dd61e5",
      "chunk_length": 3303,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "client",
          "qdrant",
          "query",
          "import",
          "collection",
          "name",
          "qdrantclient",
          "false",
          "new",
          "params",
          "quantization",
          "rescore",
          "localhost",
          "searchparams",
          "points",
          "quantizationsearchparams",
          "build",
          "6334",
          "grpc",
          "newbuilder"
        ],
        "term_weights": [
          {
            "term": "client",
            "tf": 25,
            "weight": 0.092593
          },
          {
            "term": "qdrant",
            "tf": 24,
            "weight": 0.088889
          },
          {
            "term": "query",
            "tf": 11,
            "weight": 0.040741
          },
          {
            "term": "import",
            "tf": 9,
            "weight": 0.033333
          },
          {
            "term": "collection",
            "tf": 8,
            "weight": 0.02963
          },
          {
            "term": "name",
            "tf": 8,
            "weight": 0.02963
          },
          {
            "term": "qdrantclient",
            "tf": 8,
            "weight": 0.02963
          },
          {
            "term": "false",
            "tf": 7,
            "weight": 0.025926
          },
          {
            "term": "new",
            "tf": 7,
            "weight": 0.025926
          },
          {
            "term": "params",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "quantization",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "rescore",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "localhost",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "searchparams",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "points",
            "tf": 5,
            "weight": 0.018519
          },
          {
            "term": "quantizationsearchparams",
            "tf": 5,
            "weight": 0.018519
          },
          {
            "term": "build",
            "tf": 5,
            "weight": 0.018519
          },
          {
            "term": "6334",
            "tf": 4,
            "weight": 0.014815
          },
          {
            "term": "grpc",
            "tf": 4,
            "weight": 0.014815
          },
          {
            "term": "newbuilder",
            "tf": 4,
            "weight": 0.014815
          }
        ],
        "unique_terms": 95,
        "total_terms": 270
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Disable Rescoring for Faster Search (optional)",
        "client",
        "collection",
        "false",
        "import",
        "name",
        "new",
        "params",
        "qdrant",
        "qdrantclient",
        "query"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7,
      "retrieval_quality": 0.6943319838056681,
      "overall": 0.6647773279352226
    }
  },
  {
    "text": "## 2. High Precision with Low Memory Usage\n\nIf you require high precision but have limited RAM, you can store both vectors and the HNSW index on disk. This setup reduces memory usage while maintaining search precision.\n\nTo store the vectors `on_disk`, you need to configure both the vectors and the HNSW index:\n\n```http\nPUT /collections/{collection_name}\n{\n    \"vectors\": {\n      \"size\": 768,\n      \"distance\": \"Cosine\",\n      \"on_disk\": true\n    },\n    \"hnsw_config\": {\n        \"on_disk\": true\n    }\n}\n```\n\n```python\nfrom qdrant_client import QdrantClient, models\n\nclient = QdrantClient(url=\"http://localhost:6333\")\n\nclient.create_collection(\n    collection_name=\"{collection_name}\",\n    vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE, on_disk=True),\n    hnsw_config=models.HnswConfigDiff(on_disk=True),\n)\n```\n\n```typescript\nimport { QdrantClient } from \"@qdrant/js-client-rest\";\n\nconst client = new QdrantClient({ host: \"localhost\", port: 6333 });\n\nclient.createCollection(\"{collection_name}\", {\n  vectors: {\n    size: 768,\n    distance: \"Cosine\",\n    on_disk: true,\n  },\n  hnsw_config: {\n    on_disk: true,\n  },\n});\n```\n\n```rust\nuse qdrant_client::qdrant::{\n    CreateCollectionBuilder, Distance, HnswConfigDiffBuilder,\n    VectorParamsBuilder,\n};\nuse qdrant_client::Qdrant;\n\nlet client = Qdrant::from_url(\"http://localhost:6334\").build()?;\n\nclient\n    .create_collection(\n        CreateCollectionBuilder::new(\"{collection_name}\")\n            .vectors_config(VectorParamsBuilder::new(768, Distance::Cosine).on_disk(true))\n            .hnsw_config(HnswConfigDiffBuilder::default().on_disk(true)),\n    )\n    .await?;\n```\n\n```java\nimport io.qdrant.client.QdrantClient;\nimport io.qdrant.client.QdrantGrpcClient;\nimport io.qdrant.client.grpc.Collections.CreateCollection;\nimport io.qdrant.client.grpc.Collections.Distance;\nimport io.qdrant.client.grpc.Collections.HnswConfigDiff;\nimport io.qdrant.client.grpc.Collections.VectorParams;\nimport io.qdrant.client.grpc.Collections.VectorsConfig;\n\nQdrantClient client =\n    new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());\n\nclient\n    .createCollectionAsync(\n        CreateCollection.newBuilder()\n            .setCollectionName(\"{collection_name}\")\n            .setVectorsConfig(\n                VectorsConfig.newBuilder()\n                    .setParams(\n                        VectorParams.newBuilder()\n                            .setSize(768)\n                            .setDistance(Distance.Cosine)\n                            .setOnDisk(true)\n                            .build())\n                    .build())\n            .setHnswConfig(HnswConfigDiff.newBuilder().setOnDisk(true).build())\n            .build())\n    .get();\n```\n\n```csharp\nusing Qdrant.Client;\nusing Qdrant.Client.Grpc;\n\nvar client = new QdrantClient(\"localhost\", 6334);\n\nawait client.CreateCollectionAsync(\n\tcollectionName: \"{collection_name}\",\n\tvectorsConfig: new VectorParams { Size = 768, Distance = Distance.Cosine, OnDisk = true },\n\thnswConfig: new HnswConfigDiff { OnDisk = true }\n);\n```\n\n```go\nimport (\n\t\"context\"\n\n\t\"github.com/qdrant/go-client/qdrant\"\n)",
    "metadata": {
      "chunk_id": "d737c08c924f-0014",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "2. High Precision with Low Memory Usage"
      ],
      "heading_text": "2. High Precision with Low Memory Usage",
      "token_count": 756,
      "char_count": 3140,
      "start_char": 20114,
      "end_char": 23254,
      "semantic_score": 0.6,
      "structural_score": 0.7,
      "retrieval_quality": 0.6952586206896552,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.562960",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "2. High Precision with Low Memory Usage",
      "chunk_hash": "675e572069e28cd0",
      "content_digest": "675e572069e28cd0",
      "chunk_length": 3140,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "client",
          "qdrant",
          "true",
          "disk",
          "distance",
          "import",
          "collection",
          "qdrantclient",
          "vectors",
          "name",
          "new",
          "hnsw",
          "collections",
          "768",
          "cosine",
          "config",
          "build",
          "grpc",
          "localhost",
          "newbuilder"
        ],
        "term_weights": [
          {
            "term": "client",
            "tf": 24,
            "weight": 0.080808
          },
          {
            "term": "qdrant",
            "tf": 18,
            "weight": 0.060606
          },
          {
            "term": "true",
            "tf": 12,
            "weight": 0.040404
          },
          {
            "term": "disk",
            "tf": 10,
            "weight": 0.03367
          },
          {
            "term": "distance",
            "tf": 10,
            "weight": 0.03367
          },
          {
            "term": "import",
            "tf": 10,
            "weight": 0.03367
          },
          {
            "term": "collection",
            "tf": 9,
            "weight": 0.030303
          },
          {
            "term": "qdrantclient",
            "tf": 8,
            "weight": 0.026936
          },
          {
            "term": "vectors",
            "tf": 7,
            "weight": 0.023569
          },
          {
            "term": "name",
            "tf": 7,
            "weight": 0.023569
          },
          {
            "term": "new",
            "tf": 7,
            "weight": 0.023569
          },
          {
            "term": "hnsw",
            "tf": 6,
            "weight": 0.020202
          },
          {
            "term": "collections",
            "tf": 6,
            "weight": 0.020202
          },
          {
            "term": "768",
            "tf": 6,
            "weight": 0.020202
          },
          {
            "term": "cosine",
            "tf": 6,
            "weight": 0.020202
          },
          {
            "term": "config",
            "tf": 6,
            "weight": 0.020202
          },
          {
            "term": "build",
            "tf": 6,
            "weight": 0.020202
          },
          {
            "term": "grpc",
            "tf": 6,
            "weight": 0.020202
          },
          {
            "term": "localhost",
            "tf": 5,
            "weight": 0.016835
          },
          {
            "term": "newbuilder",
            "tf": 5,
            "weight": 0.016835
          }
        ],
        "unique_terms": 94,
        "total_terms": 297
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "2. High Precision with Low Memory Usage",
        "client",
        "collection",
        "disk",
        "distance",
        "import",
        "name",
        "qdrant",
        "qdrantclient",
        "true",
        "vectors"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7,
      "retrieval_quality": 0.6952586206896552,
      "overall": 0.6650862068965516
    }
  },
  {
    "text": "## 3. High Precision with High-Speed Search\n\nFor scenarios requiring both high speed and high precision, keep as much data in RAM as possible. Apply quantization with re-scoring for tunable accuracy.\n\nHere is how you can configure scalar quantization for a collection:\n\n```http\nPUT /collections/{collection_name}\n{\n    \"vectors\": {\n      \"size\": 768,\n      \"distance\": \"Cosine\"\n    },\n    \"quantization_config\": {\n        \"scalar\": {\n            \"type\": \"int8\",\n            \"always_ram\": true\n        }\n    }\n}\n```\n\n```python\nfrom qdrant_client import QdrantClient, models\n\nclient = QdrantClient(url=\"http://localhost:6333\")\n\nclient.create_collection(\n    collection_name=\"{collection_name}\",\n    vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE),\n    quantization_config=models.ScalarQuantization(\n        scalar=models.ScalarQuantizationConfig(\n            type=models.ScalarType.INT8,\n            always_ram=True,\n        ),\n    ),\n)\n```\n\n```typescript\nimport { QdrantClient } from \"@qdrant/js-client-rest\";\n\nconst client = new QdrantClient({ host: \"localhost\", port: 6333 });\n\nclient.createCollection(\"{collection_name}\", {\n  vectors: {\n    size: 768,\n    distance: \"Cosine\",\n  },\n  quantization_config: {\n    scalar: {\n      type: \"int8\",\n      always_ram: true,\n    },\n  },\n});\n```\n\n```rust\nuse qdrant_client::qdrant::{\n    CreateCollectionBuilder, Distance, QuantizationType, ScalarQuantizationBuilder,\n    VectorParamsBuilder,\n};\nuse qdrant_client::Qdrant;\n\nlet client = Qdrant::from_url(\"http://localhost:6334\").build()?;\n\nclient\n    .create_collection(\n        CreateCollectionBuilder::new(\"{collection_name}\")\n            .vectors_config(VectorParamsBuilder::new(768, Distance::Cosine))\n            .quantization_config(\n                ScalarQuantizationBuilder::default()\n                    .r#type(QuantizationType::Int8.into())\n                    .always_ram(true),\n            ),\n    )\n    .await?;\n```\n\n```java\nimport io.qdrant.client.QdrantClient;\nimport io.qdrant.client.QdrantGrpcClient;\nimport io.qdrant.client.grpc.Collections.CreateCollection;\nimport io.qdrant.client.grpc.Collections.Distance;\nimport io.qdrant.client.grpc.Collections.OptimizersConfigDiff;\nimport io.qdrant.client.grpc.Collections.QuantizationConfig;\nimport io.qdrant.client.grpc.Collections.QuantizationType;\nimport io.qdrant.client.grpc.Collections.ScalarQuantization;\nimport io.qdrant.client.grpc.Collections.VectorParams;\nimport io.qdrant.client.grpc.Collections.VectorsConfig;\n\nQdrantClient client =\n    new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());",
    "metadata": {
      "chunk_id": "d737c08c924f-0017",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "3. High Precision with High-Speed Search"
      ],
      "heading_text": "3. High Precision with High-Speed Search",
      "token_count": 617,
      "char_count": 2610,
      "start_char": 24115,
      "end_char": 26725,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7133333333333334,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.569631",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "3. High Precision with High-Speed Search",
      "chunk_hash": "11ebd4cfc3ae4ad1",
      "content_digest": "11ebd4cfc3ae4ad1",
      "chunk_length": 2610,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "client",
          "qdrant",
          "import",
          "collections",
          "collection",
          "grpc",
          "distance",
          "qdrantclient",
          "quantization",
          "config",
          "models",
          "ram",
          "name",
          "high",
          "scalar",
          "vectors",
          "768",
          "cosine",
          "type",
          "int8"
        ],
        "term_weights": [
          {
            "term": "client",
            "tf": 21,
            "weight": 0.085366
          },
          {
            "term": "qdrant",
            "tf": 17,
            "weight": 0.069106
          },
          {
            "term": "import",
            "tf": 12,
            "weight": 0.04878
          },
          {
            "term": "collections",
            "tf": 9,
            "weight": 0.036585
          },
          {
            "term": "collection",
            "tf": 8,
            "weight": 0.03252
          },
          {
            "term": "grpc",
            "tf": 8,
            "weight": 0.03252
          },
          {
            "term": "distance",
            "tf": 7,
            "weight": 0.028455
          },
          {
            "term": "qdrantclient",
            "tf": 7,
            "weight": 0.028455
          },
          {
            "term": "quantization",
            "tf": 6,
            "weight": 0.02439
          },
          {
            "term": "config",
            "tf": 6,
            "weight": 0.02439
          },
          {
            "term": "models",
            "tf": 6,
            "weight": 0.02439
          },
          {
            "term": "ram",
            "tf": 5,
            "weight": 0.020325
          },
          {
            "term": "name",
            "tf": 5,
            "weight": 0.020325
          },
          {
            "term": "high",
            "tf": 4,
            "weight": 0.01626
          },
          {
            "term": "scalar",
            "tf": 4,
            "weight": 0.01626
          },
          {
            "term": "vectors",
            "tf": 4,
            "weight": 0.01626
          },
          {
            "term": "768",
            "tf": 4,
            "weight": 0.01626
          },
          {
            "term": "cosine",
            "tf": 4,
            "weight": 0.01626
          },
          {
            "term": "type",
            "tf": 4,
            "weight": 0.01626
          },
          {
            "term": "int8",
            "tf": 4,
            "weight": 0.01626
          }
        ],
        "unique_terms": 83,
        "total_terms": 246
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "3. High Precision with High-Speed Search",
        "client",
        "collection",
        "collections",
        "config",
        "distance",
        "grpc",
        "import",
        "qdrant",
        "qdrantclient",
        "quantization"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7133333333333334,
      "overall": 0.7044444444444444
    }
  },
  {
    "text": "### Fine-Tuning Search Parameters\n\nYou can adjust search parameters like `hnsw_ef` and `exact` to balance between speed and precision:\n\n**Key Parameters:**\n\n- `hnsw_ef`: Number of neighbors to visit during search (higher value = better accuracy, slower speed).\n- `exact`: Set to `true` for exact search, which is slower but more accurate. You can use it to compare results of the search with different `hnsw_ef` values versus the ground truth.\n\n```http\nPOST /collections/{collection_name}/points/query\n{\n    \"query\": [0.2, 0.1, 0.9, 0.7],\n    \"params\": {\n        \"hnsw_ef\": 128,\n        \"exact\": false\n    },\n    \"limit\": 3\n}\n```\n\n```python\nfrom qdrant_client import QdrantClient, models\n\nclient = QdrantClient(url=\"http://localhost:6333\")\n\nclient.query_points(\n    collection_name=\"{collection_name}\",\n    query=[0.2, 0.1, 0.9, 0.7],\n    search_params=models.SearchParams(hnsw_ef=128, exact=False),\n    limit=3,\n)\n```\n\n```typescript\nimport { QdrantClient } from \"@qdrant/js-client-rest\";\n\nconst client = new QdrantClient({ host: \"localhost\", port: 6333 });\n\nclient.query(\"{collection_name}\", {\n    query: [0.2, 0.1, 0.9, 0.7],\n    params: {\n        hnsw_ef: 128,\n        exact: false,\n    },\n    limit: 3,\n});\n```\n\n```rust\nuse qdrant_client::qdrant::{QueryPointsBuilder, SearchParamsBuilder};\nuse qdrant_client::Qdrant;\n\nlet client = Qdrant::from_url(\"http://localhost:6334\").build()?;\n\nclient\n    .query(\n        QueryPointsBuilder::new(\"{collection_name}\")\n            .query(vec![0.2, 0.1, 0.9, 0.7])\n            .limit(3)\n            .params(SearchParamsBuilder::default().hnsw_ef(128).exact(false)),\n    )\n    .await?;\n```\n\n```java\nimport io.qdrant.client.QdrantClient;\nimport io.qdrant.client.QdrantGrpcClient;\nimport io.qdrant.client.grpc.Points.QueryPoints;\nimport io.qdrant.client.grpc.Points.SearchParams;\n\nimport static io.qdrant.client.QueryFactory.nearest;\n\nQdrantClient client =\n    new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());\n\nclient.queryAsync(\n        QueryPoints.newBuilder()\n                .setCollectionName(\"{collection_name}\")\n                .setQuery(nearest(0.2f, 0.1f, 0.9f, 0.7f))\n                .setParams(SearchParams.newBuilder().setHnswEf(128).setExact(false).build())\n                .setLimit(3)\n                .build())\n        .get();\n```\n\n```csharp\nusing Qdrant.Client;\nusing Qdrant.Client.Grpc;\n\nvar client = new QdrantClient(\"localhost\", 6334);\n\nawait client.QueryAsync(\n\tcollectionName: \"{collection_name}\",\n\tquery: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },\n\tsearchParams: new SearchParams { HnswEf = 128, Exact = false },\n\tlimit: 3\n);\n```\n\n```go\nimport (\n\t\"context\"\n\n\t\"github.com/qdrant/go-client/qdrant\"\n)\n\nclient, err := qdrant.NewClient(&qdrant.Config{\n\tHost: \"localhost\",\n\tPort: 6334,\n})",
    "metadata": {
      "chunk_id": "d737c08c924f-0019",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Fine-Tuning Search Parameters"
      ],
      "heading_text": "Fine-Tuning Search Parameters",
      "token_count": 808,
      "char_count": 2770,
      "start_char": 28515,
      "end_char": 31285,
      "semantic_score": 0.6,
      "structural_score": 0.7999999999999998,
      "retrieval_quality": 0.699601593625498,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.571801",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Fine-Tuning Search Parameters",
      "chunk_hash": "334b4587c6fd3897",
      "content_digest": "334b4587c6fd3897",
      "chunk_length": 2770,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "client",
          "qdrant",
          "query",
          "exact",
          "import",
          "qdrantclient",
          "hnsw",
          "collection",
          "name",
          "false",
          "search",
          "128",
          "localhost",
          "new",
          "limit",
          "searchparams",
          "points",
          "params",
          "6334",
          "build"
        ],
        "term_weights": [
          {
            "term": "client",
            "tf": 23,
            "weight": 0.085185
          },
          {
            "term": "qdrant",
            "tf": 18,
            "weight": 0.066667
          },
          {
            "term": "query",
            "tf": 9,
            "weight": 0.033333
          },
          {
            "term": "exact",
            "tf": 8,
            "weight": 0.02963
          },
          {
            "term": "import",
            "tf": 8,
            "weight": 0.02963
          },
          {
            "term": "qdrantclient",
            "tf": 8,
            "weight": 0.02963
          },
          {
            "term": "hnsw",
            "tf": 7,
            "weight": 0.025926
          },
          {
            "term": "collection",
            "tf": 7,
            "weight": 0.025926
          },
          {
            "term": "name",
            "tf": 7,
            "weight": 0.025926
          },
          {
            "term": "false",
            "tf": 7,
            "weight": 0.025926
          },
          {
            "term": "search",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "128",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "localhost",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "new",
            "tf": 6,
            "weight": 0.022222
          },
          {
            "term": "limit",
            "tf": 5,
            "weight": 0.018519
          },
          {
            "term": "searchparams",
            "tf": 5,
            "weight": 0.018519
          },
          {
            "term": "points",
            "tf": 4,
            "weight": 0.014815
          },
          {
            "term": "params",
            "tf": 4,
            "weight": 0.014815
          },
          {
            "term": "6334",
            "tf": 4,
            "weight": 0.014815
          },
          {
            "term": "build",
            "tf": 4,
            "weight": 0.014815
          }
        ],
        "unique_terms": 107,
        "total_terms": 270
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": true,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Fine-Tuning Search Parameters",
        "client",
        "collection",
        "exact",
        "false",
        "hnsw",
        "import",
        "name",
        "qdrant",
        "qdrantclient",
        "query"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7999999999999998,
      "retrieval_quality": 0.699601593625498,
      "overall": 0.6998671978751659
    }
  },
  {
    "text": "## Balancing Latency and Throughput  When optimizing search performance, latency and throughput are two main metrics to consider:  - **Latency:** Time taken for a single request. - **Throughput:** Number of requests handled per second. The following optimization approaches are not mutually exclusive, but in some cases it might be preferable to optimize for one or another.",
    "metadata": {
      "chunk_id": "d737c08c924f-0021",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Balancing Latency and Throughput"
      ],
      "heading_text": "Balancing Latency and Throughput",
      "token_count": 73,
      "char_count": 374,
      "start_char": 31546,
      "end_char": 31920,
      "semantic_score": 0.7999999999999999,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.571801",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Balancing Latency and Throughput",
      "chunk_hash": "652059d509172a05",
      "content_digest": "652059d509172a05",
      "chunk_length": 374,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "latency",
          "throughput",
          "and",
          "are",
          "for",
          "balancing",
          "when",
          "optimizing",
          "search",
          "performance",
          "two",
          "main",
          "metrics",
          "consider",
          "time",
          "taken",
          "single",
          "request",
          "number",
          "requests"
        ],
        "term_weights": [
          {
            "term": "latency",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "throughput",
            "tf": 3,
            "weight": 0.066667
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "are",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "for",
            "tf": 2,
            "weight": 0.044444
          },
          {
            "term": "balancing",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "when",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "optimizing",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "performance",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "two",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "main",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "metrics",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "consider",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "time",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "taken",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "single",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "request",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "number",
            "tf": 1,
            "weight": 0.022222
          },
          {
            "term": "requests",
            "tf": 1,
            "weight": 0.022222
          }
        ],
        "unique_terms": 38,
        "total_terms": 45
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Balancing Latency and Throughput",
        "and",
        "are",
        "balancing",
        "for",
        "latency",
        "optimizing",
        "performance",
        "search",
        "throughput",
        "when"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7999999999999999,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.5525,
      "overall": 0.7508333333333331
    }
  },
  {
    "text": "### Minimizing Latency\n\nTo minimize latency, you can set up Qdrant to use as many cores as possible for a single request. You can do this by setting the number of segments in the collection to be equal to the number of cores in the system.\n\nIn this case, each segment will be processed in parallel, and the final result will be obtained faster.\n\n```http\nPUT /collections/{collection_name}\n{\n    \"vectors\": {\n      \"size\": 768,\n      \"distance\": \"Cosine\"\n    },\n    \"optimizers_config\": {\n        \"default_segment_number\": 16\n    }\n}\n```\n\n```python\nfrom qdrant_client import QdrantClient, models\n\nclient = QdrantClient(url=\"http://localhost:6333\")\n\nclient.create_collection(\n    collection_name=\"{collection_name}\",\n    vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE),\n    optimizers_config=models.OptimizersConfigDiff(default_segment_number=16),\n)\n```\n\n```typescript\nimport { QdrantClient } from \"@qdrant/js-client-rest\";\n\nconst client = new QdrantClient({ host: \"localhost\", port: 6333 });\n\nclient.createCollection(\"{collection_name}\", {\n  vectors: {\n    size: 768,\n    distance: \"Cosine\",\n  },\n  optimizers_config: {\n    default_segment_number: 16,\n  },\n});\n```\n\n```rust\nuse qdrant_client::qdrant::{\n    CreateCollectionBuilder, Distance, OptimizersConfigDiffBuilder, VectorParamsBuilder,\n};\nuse qdrant_client::Qdrant;\n\nlet client = Qdrant::from_url(\"http://localhost:6334\").build()?;\n\nclient\n    .create_collection(\n        CreateCollectionBuilder::new(\"{collection_name}\")\n            .vectors_config(VectorParamsBuilder::new(768, Distance::Cosine))\n            .optimizers_config(\n                OptimizersConfigDiffBuilder::default().default_segment_number(16),\n            ),\n    )\n    .await?;\n```\n\n```java\nimport io.qdrant.client.QdrantClient;\nimport io.qdrant.client.QdrantGrpcClient;\nimport io.qdrant.client.grpc.Collections.CreateCollection;\nimport io.qdrant.client.grpc.Collections.Distance;\nimport io.qdrant.client.grpc.Collections.OptimizersConfigDiff;\nimport io.qdrant.client.grpc.Collections.VectorParams;\nimport io.qdrant.client.grpc.Collections.VectorsConfig;\n\nQdrantClient client =\n    new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());\n\nclient\n    .createCollectionAsync(\n        CreateCollection.newBuilder()\n            .setCollectionName(\"{collection_name}\")\n            .setVectorsConfig(\n                VectorsConfig.newBuilder()\n                    .setParams(\n                        VectorParams.newBuilder()\n                            .setSize(768)\n                            .setDistance(Distance.Cosine)\n                            .build())\n                    .build())\n            .setOptimizersConfig(\n                OptimizersConfigDiff.newBuilder().setDefaultSegmentNumber(16).build())\n            .build())\n    .get();\n```\n\n```csharp\nusing Qdrant.Client;\nusing Qdrant.Client.Grpc;\n\nvar client = new QdrantClient(\"localhost\", 6334);\n\nawait client.CreateCollectionAsync(\n\tcollectionName: \"{collection_name}\",\n\tvectorsConfig: new VectorParams { Size = 768, Distance = Distance.Cosine },\n\toptimizersConfig: new OptimizersConfigDiff { DefaultSegmentNumber = 16 }\n);\n```\n\n```go\nimport (\n\t\"context\"\n\n\t\"github.com/qdrant/go-client/qdrant\"\n)\n\nclient, err := qdrant.NewClient(&qdrant.Config{\n\tHost: \"localhost\",\n\tPort: 6334,\n})",
    "metadata": {
      "chunk_id": "d737c08c924f-0022",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Minimizing Latency"
      ],
      "heading_text": "Minimizing Latency",
      "token_count": 774,
      "char_count": 3321,
      "start_char": 31923,
      "end_char": 35244,
      "semantic_score": 0.6,
      "structural_score": 0.7,
      "retrieval_quality": 0.7,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.571801",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Minimizing Latency",
      "chunk_hash": "b03f0d2603388c32",
      "content_digest": "b03f0d2603388c32",
      "chunk_length": 3321,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "client",
          "qdrant",
          "collection",
          "distance",
          "import",
          "qdrantclient",
          "name",
          "config",
          "new",
          "number",
          "collections",
          "768",
          "cosine",
          "localhost",
          "build",
          "grpc",
          "the",
          "segment",
          "default",
          "newbuilder"
        ],
        "term_weights": [
          {
            "term": "client",
            "tf": 25,
            "weight": 0.085034
          },
          {
            "term": "qdrant",
            "tf": 21,
            "weight": 0.071429
          },
          {
            "term": "collection",
            "tf": 10,
            "weight": 0.034014
          },
          {
            "term": "distance",
            "tf": 10,
            "weight": 0.034014
          },
          {
            "term": "import",
            "tf": 10,
            "weight": 0.034014
          },
          {
            "term": "qdrantclient",
            "tf": 8,
            "weight": 0.027211
          },
          {
            "term": "name",
            "tf": 7,
            "weight": 0.02381
          },
          {
            "term": "config",
            "tf": 7,
            "weight": 0.02381
          },
          {
            "term": "new",
            "tf": 7,
            "weight": 0.02381
          },
          {
            "term": "number",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "collections",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "768",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "cosine",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "localhost",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "build",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "grpc",
            "tf": 6,
            "weight": 0.020408
          },
          {
            "term": "the",
            "tf": 5,
            "weight": 0.017007
          },
          {
            "term": "segment",
            "tf": 5,
            "weight": 0.017007
          },
          {
            "term": "default",
            "tf": 5,
            "weight": 0.017007
          },
          {
            "term": "newbuilder",
            "tf": 5,
            "weight": 0.017007
          }
        ],
        "unique_terms": 98,
        "total_terms": 294
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Minimizing Latency",
        "client",
        "collection",
        "config",
        "distance",
        "import",
        "name",
        "new",
        "number",
        "qdrant",
        "qdrantclient"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.7,
      "retrieval_quality": 0.7,
      "overall": 0.6666666666666666
    }
  },
  {
    "text": "### Maximizing Throughput\n\nTo maximize throughput, configure Qdrant to use as many cores as possible to process multiple requests in parallel.\n\nTo do that, use fewer segments (usually 2) of larger size (default 200Mb per segment) to handle more requests in parallel.\n\nLarge segments benefit from the size of the index and overall smaller number of vector comparisons required to find the nearest neighbors. However, they will require more time to build the HNSW index.\n\n```http\nPUT /collections/{collection_name}\n{\n    \"vectors\": {\n      \"size\": 768,\n      \"distance\": \"Cosine\"\n    },\n    \"optimizers_config\": {\n        \"default_segment_number\": 2,\n        \"max_segment_size\": 5000000\n    }\n}\n```\n\n```python\nfrom qdrant_client import QdrantClient, models\n\nclient = QdrantClient(url=\"http://localhost:6333\")\n\nclient.create_collection(\n    collection_name=\"{collection_name}\",\n    vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE),\n    optimizers_config=models.OptimizersConfigDiff(default_segment_number=2, max_segment_size=5000000),\n)\n```\n\n```typescript\nimport { QdrantClient } from \"@qdrant/js-client-rest\";\n\nconst client = new QdrantClient({ host: \"localhost\", port: 6333 });\n\nclient.createCollection(\"{collection_name}\", {\n  vectors: {\n    size: 768,\n    distance: \"Cosine\",\n  },\n  optimizers_config: {\n    default_segment_number: 2,\n    max_segment_size: 5000000,\n  },\n});\n```\n\n```rust\nuse qdrant_client::qdrant::{\n    CreateCollectionBuilder, Distance, OptimizersConfigDiffBuilder, VectorParamsBuilder,\n};\nuse qdrant_client::Qdrant;\n\nlet client = Qdrant::from_url(\"http://localhost:6334\").build()?;\n\nclient\n    .create_collection(\n        CreateCollectionBuilder::new(\"{collection_name}\")\n            .vectors_config(VectorParamsBuilder::new(768, Distance::Cosine))\n            .optimizers_config(\n                OptimizersConfigDiffBuilder::default().default_segment_number(2).max_segment_size(5000000),\n            ),\n    )\n    .await?;\n```\n\n```java\nimport io.qdrant.client.QdrantClient;\nimport io.qdrant.client.QdrantGrpcClient;\nimport io.qdrant.client.grpc.Collections.CreateCollection;\nimport io.qdrant.client.grpc.Collections.Distance;\nimport io.qdrant.client.grpc.Collections.OptimizersConfigDiff;\nimport io.qdrant.client.grpc.Collections.VectorParams;\nimport io.qdrant.client.grpc.Collections.VectorsConfig;\n\nQdrantClient client =\n    new QdrantClient(QdrantGrpcClient.newBuilder(\"localhost\", 6334, false).build());\n\nclient\n    .createCollectionAsync(\n        CreateCollection.newBuilder()\n            .setCollectionName(\"{collection_name}\")\n            .setVectorsConfig(\n                VectorsConfig.newBuilder()\n                    .setParams(\n                        VectorParams.newBuilder()\n                            .setSize(768)\n                            .setDistance(Distance.Cosine)\n                            .build())\n                    .build())\n            .setOptimizersConfig(\n                OptimizersConfigDiff.newBuilder()\n                    .setDefaultSegmentNumber(2)\n                    .setMaxSegmentSize(5000000)\n                    .build()\n            )\n            .build())\n    .get();\n```\n\n```csharp\nusing Qdrant.Client;\nusing Qdrant.Client.Grpc;\n\nvar client = new QdrantClient(\"localhost\", 6334);\n\nawait client.CreateCollectionAsync(\n\tcollectionName: \"{collection_name}\",\n\tvectorsConfig: new VectorParams { Size = 768, Distance = Distance.Cosine },\n\toptimizersConfig: new OptimizersConfigDiff { DefaultSegmentNumber = 2, MaxSegmentSize = 5000000 }\n);\n```\n\n```go\nimport (\n\t\"context\"\n\n\t\"github.com/qdrant/go-client/qdrant\"\n)",
    "metadata": {
      "chunk_id": "d737c08c924f-0024",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 24,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Maximizing Throughput"
      ],
      "heading_text": "Maximizing Throughput",
      "token_count": 828,
      "char_count": 3603,
      "start_char": 35587,
      "end_char": 39190,
      "semantic_score": 0.7,
      "structural_score": 0.7,
      "retrieval_quality": 0.7042307692307692,
      "chunking_strategy": "hybrid_adaptive_semchunk",
      "content_type": "prose_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.571801",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Maximizing Throughput",
      "chunk_hash": "fdf783973f6a6c6b",
      "content_digest": "fdf783973f6a6c6b",
      "chunk_length": 3603,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "client",
          "qdrant",
          "size",
          "distance",
          "import",
          "segment",
          "collection",
          "qdrantclient",
          "build",
          "name",
          "new",
          "default",
          "collections",
          "768",
          "cosine",
          "config",
          "5000000",
          "grpc",
          "number",
          "localhost"
        ],
        "term_weights": [
          {
            "term": "client",
            "tf": 24,
            "weight": 0.075472
          },
          {
            "term": "qdrant",
            "tf": 19,
            "weight": 0.059748
          },
          {
            "term": "size",
            "tf": 10,
            "weight": 0.031447
          },
          {
            "term": "distance",
            "tf": 10,
            "weight": 0.031447
          },
          {
            "term": "import",
            "tf": 10,
            "weight": 0.031447
          },
          {
            "term": "segment",
            "tf": 9,
            "weight": 0.028302
          },
          {
            "term": "collection",
            "tf": 9,
            "weight": 0.028302
          },
          {
            "term": "qdrantclient",
            "tf": 8,
            "weight": 0.025157
          },
          {
            "term": "build",
            "tf": 7,
            "weight": 0.022013
          },
          {
            "term": "name",
            "tf": 7,
            "weight": 0.022013
          },
          {
            "term": "new",
            "tf": 7,
            "weight": 0.022013
          },
          {
            "term": "default",
            "tf": 6,
            "weight": 0.018868
          },
          {
            "term": "collections",
            "tf": 6,
            "weight": 0.018868
          },
          {
            "term": "768",
            "tf": 6,
            "weight": 0.018868
          },
          {
            "term": "cosine",
            "tf": 6,
            "weight": 0.018868
          },
          {
            "term": "config",
            "tf": 6,
            "weight": 0.018868
          },
          {
            "term": "5000000",
            "tf": 6,
            "weight": 0.018868
          },
          {
            "term": "grpc",
            "tf": 6,
            "weight": 0.018868
          },
          {
            "term": "number",
            "tf": 5,
            "weight": 0.015723
          },
          {
            "term": "localhost",
            "tf": 5,
            "weight": 0.015723
          }
        ],
        "unique_terms": 111,
        "total_terms": 318
      },
      "modal_hint": "code",
      "content_flags": {
        "has_code_block": true,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Maximizing Throughput",
        "build",
        "client",
        "collection",
        "distance",
        "import",
        "name",
        "qdrant",
        "qdrantclient",
        "segment",
        "size"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.7,
      "retrieval_quality": 0.7042307692307692,
      "overall": 0.7014102564102563
    }
  },
  {
    "text": "## Summary  By adjusting configurations like vector storage, quantization, and search parameters, you can optimize Qdrant for different use cases:  - **Low Memory + High Speed:** Use vector quantization. - **High Precision + Low Memory:** Store vectors and HNSW index on disk. - **High Precision + High Speed:** Keep data in RAM, use quantization with re-scoring. - **Latency vs. Throughput:** Adjust segment numbers based on the priority. Choose the strategy that best fits your use case to get the most out of Qdrant’s performance capabilities.",
    "metadata": {
      "chunk_id": "d737c08c924f-0026",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 26,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Summary"
      ],
      "heading_text": "Summary",
      "token_count": 120,
      "char_count": 546,
      "start_char": 39672,
      "end_char": 40218,
      "semantic_score": 0.7,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.53,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.571801",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Summary",
      "chunk_hash": "6648decb998c3179",
      "content_digest": "6648decb998c3179",
      "chunk_length": 546,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "use",
          "high",
          "quantization",
          "the",
          "vector",
          "and",
          "qdrant",
          "low",
          "memory",
          "speed",
          "precision",
          "summary",
          "adjusting",
          "configurations",
          "like",
          "storage",
          "search",
          "parameters",
          "you",
          "can"
        ],
        "term_weights": [
          {
            "term": "use",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "high",
            "tf": 4,
            "weight": 0.057143
          },
          {
            "term": "quantization",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "the",
            "tf": 3,
            "weight": 0.042857
          },
          {
            "term": "vector",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "and",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "qdrant",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "low",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "memory",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "speed",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "precision",
            "tf": 2,
            "weight": 0.028571
          },
          {
            "term": "summary",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "adjusting",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "configurations",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "like",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "storage",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "search",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "parameters",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "you",
            "tf": 1,
            "weight": 0.014286
          },
          {
            "term": "can",
            "tf": 1,
            "weight": 0.014286
          }
        ],
        "unique_terms": 53,
        "total_terms": 70
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Summary",
        "and",
        "high",
        "low",
        "memory",
        "qdrant",
        "quantization",
        "speed",
        "the",
        "use",
        "vector"
      ]
    },
    "advanced_scores": {
      "semantic": 0.7,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.53,
      "overall": 0.71
    }
  },
  {
    "text": "##### Was this page useful? Yes No  Thank you for your feedback! 🙏  We are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/optimize.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue. On this page:  - [Optimizing Qdrant Performance: Three Scenarios](#optimizing-qdrant-performance-three-scenarios.md)    - [1. High-Speed Search with Low Memory Usage](#1-high-speed-search-with-low-memory-usage.md)     - [Disable Rescoring for Faster Search (optional)](#disable-rescoring-for-faster-search-optional.md)    - [2. High Precision with Low Memory Usage](#2-high-precision-with-low-memory-usage.md)     - [Improving Precision](#improving-precision.md)    - [3. High Precision with High-Speed Search](#3-high-precision-with-high-speed-search.md)     - [Fine-Tuning Search Parameters](#fine-tuning-search-parameters.md)    - [Balancing Latency and Throughput](#balancing-latency-and-throughput.md)      - [Minimizing Latency](#minimizing-latency.md)     - [Maximizing Throughput](#maximizing-throughput.md)    - [Summary](#summary.md)  * [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/optimize.md) * [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)",
    "metadata": {
      "chunk_id": "d737c08c924f-0027",
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "filename": "_documentation_guides_optimize_.md",
      "file_extension": ".md",
      "chunk_index": 27,
      "document_level": 1,
      "parent_chunk_id": null,
      "child_chunk_ids": [],
      "section_path": [
        "Was this page useful?"
      ],
      "heading_text": "Was this page useful?",
      "token_count": 367,
      "char_count": 1375,
      "start_char": 40221,
      "end_char": 41596,
      "semantic_score": 0.6,
      "structural_score": 0.8999999999999999,
      "retrieval_quality": 0.7282818181818181,
      "chunking_strategy": "hybrid_adaptive_structural",
      "content_type": "list_section",
      "embedding_model": "jina-code-embeddings-1.5b",
      "processing_timestamp": "2025-10-20T04:38:42.571801",
      "document_id": "d737c08c924f",
      "document_name": "_documentation_guides_optimize_",
      "source_path": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "source_filename": "_documentation_guides_optimize_.md",
      "source_directory": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize",
      "relative_path": "Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_guides_optimize\\_documentation_guides_optimize_.md",
      "hierarchy_path": "Was this page useful?",
      "chunk_hash": "2ae95b5f9f776619",
      "content_digest": "2ae95b5f9f776619",
      "chunk_length": 1375,
      "payload_version": "1.3",
      "collection_hints": [
        "qdrant_ecosystem"
      ],
      "sparse_features": {
        "version": "1.0",
        "weighting": "tf-normalized",
        "top_terms": [
          "qdrant",
          "high",
          "search",
          "page",
          "github",
          "landing",
          "with",
          "precision",
          "https",
          "com",
          "speed",
          "low",
          "memory",
          "usage",
          "latency",
          "throughput",
          "this",
          "for",
          "you",
          "edit"
        ],
        "term_weights": [
          {
            "term": "qdrant",
            "tf": 8,
            "weight": 0.048485
          },
          {
            "term": "high",
            "tf": 8,
            "weight": 0.048485
          },
          {
            "term": "search",
            "tf": 8,
            "weight": 0.048485
          },
          {
            "term": "page",
            "tf": 7,
            "weight": 0.042424
          },
          {
            "term": "github",
            "tf": 7,
            "weight": 0.042424
          },
          {
            "term": "landing",
            "tf": 6,
            "weight": 0.036364
          },
          {
            "term": "with",
            "tf": 6,
            "weight": 0.036364
          },
          {
            "term": "precision",
            "tf": 6,
            "weight": 0.036364
          },
          {
            "term": "https",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "com",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "speed",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "low",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "memory",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "usage",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "latency",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "throughput",
            "tf": 4,
            "weight": 0.024242
          },
          {
            "term": "this",
            "tf": 3,
            "weight": 0.018182
          },
          {
            "term": "for",
            "tf": 3,
            "weight": 0.018182
          },
          {
            "term": "you",
            "tf": 2,
            "weight": 0.012121
          },
          {
            "term": "edit",
            "tf": 2,
            "weight": 0.012121
          }
        ],
        "unique_terms": 59,
        "total_terms": 165
      },
      "modal_hint": "prose",
      "content_flags": {
        "has_code_block": false,
        "has_table": false,
        "has_list": false,
        "has_json": false,
        "has_formula": false
      },
      "search_keywords": [
        "Was this page useful?",
        "com",
        "github",
        "high",
        "https",
        "landing",
        "page",
        "precision",
        "qdrant",
        "search",
        "with"
      ]
    },
    "advanced_scores": {
      "semantic": 0.6,
      "structural": 0.8999999999999999,
      "retrieval_quality": 0.7282818181818181,
      "overall": 0.7427606060606061
    }
  }
]
# ğŸ¯ Complete Processing Summary - All Collections

## âœ… GPU Configuration Confirmed

**ALL 4 SCRIPTS USE 2-GPU PARALLELISM:**

```python
# Every script has this configuration:
model = AutoModel.from_pretrained(
    "nomic-ai/nomic-embed-code",
    trust_remote_code=True,
    device_map="auto",      # âœ… Splits 26GB model across 2 GPUs
    torch_dtype=torch.float16  # âœ… FP16 reduces memory per GPU
)
```

**GPU Distribution:**
- ğŸ”· GPU 0 (Tesla T4): ~13GB of model layers
- ğŸ”· GPU 1 (Tesla T4): ~13GB of model layers
- âœ… **TOTAL: Both GPUs utilized for all 4 collections**

---

## ğŸ“‹ Collection Processing Matrix

| # | Collection | Script | GPU Usage | Process |
|---|------------|--------|-----------|---------|
| 1ï¸âƒ£ | **viator_api** | `kaggle_process_viator.py` | âœ… 2 GPUs | PDFâ†’MDâ†’Chunkâ†’Embed |
| 2ï¸âƒ£ | **fast_docs** | `kaggle_process_fast_docs.py` | âœ… 2 GPUs | MDâ†’Chunkâ†’Embed |
| 3ï¸âƒ£ | **pydantic_docs** | `kaggle_process_pydantic_docs.py` | âœ… 2 GPUs | MDâ†’Chunkâ†’Embed |
| 4ï¸âƒ£ | **inngest_ecosystem** | `kaggle_process_inngest_ecosystem.py` | âœ… 2 GPUs | MDâ†’Chunkâ†’Embed |

---

## ğŸ”„ Processing Workflows

### 1ï¸âƒ£ Viator API (With PDF Conversion)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: Docs/viator_api_documentation/                  â”‚
â”‚   â”œâ”€â”€ Affiliate Attribution.pdf                        â”‚
â”‚   â”œâ”€â”€ Technical Guide.pdf                              â”‚
â”‚   â”œâ”€â”€ Viator Partner API.pdf                           â”‚
â”‚   â””â”€â”€ openapi.json                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Convert Documents (Docling)                    â”‚
â”‚   â€¢ PDF â†’ Markdown (Docling converter)                 â”‚
â”‚   â€¢ JSON â†’ Markdown (code block wrapper)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Chunk Documents (HybridChunker)                â”‚
â”‚   â€¢ Heading-based splitting                            â”‚
â”‚   â€¢ Max: 1500 chars, Min: 100 chars                    â”‚
â”‚   â€¢ ID: viator_api:{subdir}:{file}:chunk:{N}          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Embed Chunks (nomic-embed-code)                â”‚
â”‚   â€¢ Model: 26GB across 2 GPUs                          â”‚
â”‚   â€¢ Batch size: 8                                       â”‚
â”‚   â€¢ Dimension: 768                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: output/viator_api/embeddings/                  â”‚
â”‚   â””â”€â”€ viator_api_embeddings.jsonl (~995 chunks)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Subdirectories:
  â€¢ affiliate/
  â€¢ technical_guides/
  â€¢ api_specs/

Duration: ~7-10 minutes
```

---

### 2ï¸âƒ£ Fast Docs (Markdown Only)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: Docs/fast_mcp_api_python/                       â”‚
â”‚   â”œâ”€â”€ fastapi/      (~40 markdown files)               â”‚
â”‚   â”œâ”€â”€ fastmcp/      (~35 markdown files)               â”‚
â”‚   â””â”€â”€ python_sdk/   (~34 markdown files)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Chunk Documents (HybridChunker)                â”‚
â”‚   â€¢ Direct markdown processing (no conversion)         â”‚
â”‚   â€¢ Heading-based splitting                            â”‚
â”‚   â€¢ ID: fast_docs:{subdir}:{file}:chunk:{N}           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Embed Chunks (nomic-embed-code)                â”‚
â”‚   â€¢ Model: 26GB across 2 GPUs                          â”‚
â”‚   â€¢ Batch size: 8                                       â”‚
â”‚   â€¢ Dimension: 768                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: output/fast_docs/embeddings/                   â”‚
â”‚   â””â”€â”€ fast_docs_embeddings.jsonl (~2K-3K chunks)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Subdirectories:
  â€¢ fastapi/
  â€¢ fastmcp/
  â€¢ python_sdk/

Duration: ~15-20 minutes
```

---

### 3ï¸âƒ£ Pydantic Docs (Largest by File Count)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: Docs/python_sdk_and_pydantic/pydantic/          â”‚
â”‚   â””â”€â”€ ~270 markdown files                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Chunk Documents (HybridChunker)                â”‚
â”‚   â€¢ Direct markdown processing                         â”‚
â”‚   â€¢ ID: pydantic_docs:{file}:chunk:{N}                â”‚
â”‚   â€¢ No subdirectories (single dir)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Embed Chunks (nomic-embed-code)                â”‚
â”‚   â€¢ Model: 26GB across 2 GPUs                          â”‚
â”‚   â€¢ Batch size: 8                                       â”‚
â”‚   â€¢ Dimension: 768                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: output/pydantic_docs/embeddings/               â”‚
â”‚   â””â”€â”€ pydantic_docs_embeddings.jsonl (~5K-8K chunks)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Subdirectories: None (standalone)

Duration: ~25-35 minutes
```

---

### 4ï¸âƒ£ Inngest Ecosystem (Most Complex Structure)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: Multiple directories (~295 markdown files)      â”‚
â”‚   â”œâ”€â”€ Docs/inngest_docs/inngest_overall/   (~80 files)â”‚
â”‚   â”œâ”€â”€ Docs/inngest_docs/agent_kit/         (~45 files)â”‚
â”‚   â”œâ”€â”€ Docs/agent_kit_github/               (~19 files)â”‚
â”‚   â”œâ”€â”€ Docs/inngest_docs/inngest/           (~80 files)â”‚
â”‚   â”œâ”€â”€ Docs/inngest_docs/inngest_js/        (~35 files)â”‚
â”‚   â””â”€â”€ Docs/inngest_docs/inngest_py/        (~36 files)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Chunk Documents (HybridChunker)                â”‚
â”‚   â€¢ Process each subdirectory                          â”‚
â”‚   â€¢ ID: inngest_ecosystem:{subdir}:{file}:chunk:{N}   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Embed Chunks (nomic-embed-code)                â”‚
â”‚   â€¢ Model: 26GB across 2 GPUs                          â”‚
â”‚   â€¢ Batch size: 8                                       â”‚
â”‚   â€¢ Dimension: 768                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: output/inngest_ecosystem/embeddings/           â”‚
â”‚   â””â”€â”€ inngest_ecosystem_embeddings.jsonl (~6K-10K)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Subdirectories: (6 total)
  â€¢ inngest_overall/
  â€¢ agent_kit/
  â€¢ agent_kit_github/
  â€¢ inngest/
  â€¢ inngest_js/
  â€¢ inngest_py/

Duration: ~30-40 minutes
```

---

## ğŸš€ Quick Start Commands

### For Each Collection - Copy to Kaggle:

#### 1ï¸âƒ£ Viator API
```python
# Cell 1: Dependencies (includes Docling)
!pip install -q --force-reinstall "numpy==1.26.4" "scipy==1.11.4" "scikit-learn==1.4.2"
!pip install -q docling docling-core transformers accelerate torch sentencepiece

# Cell 2: Process
!python scripts/kaggle_process_viator.py

# Cell 3: Download
!zip -r viator_api_embeddings.zip output/viator_api/embeddings/
```

#### 2ï¸âƒ£ Fast Docs
```python
# Cell 1: Dependencies (no Docling needed)
!pip install -q --force-reinstall "numpy==1.26.4" "scipy==1.11.4" "scikit-learn==1.4.2"
!pip install -q transformers accelerate torch sentencepiece

# Cell 2: Process
!python scripts/kaggle_process_fast_docs.py

# Cell 3: Download
!zip -r fast_docs_embeddings.zip output/fast_docs/embeddings/
```

#### 3ï¸âƒ£ Pydantic Docs
```python
# Cell 1: Dependencies
!pip install -q --force-reinstall "numpy==1.26.4" "scipy==1.11.4" "scikit-learn==1.4.2"
!pip install -q transformers accelerate torch sentencepiece

# Cell 2: Process
!python scripts/kaggle_process_pydantic_docs.py

# Cell 3: Download
!zip -r pydantic_docs_embeddings.zip output/pydantic_docs/embeddings/
```

#### 4ï¸âƒ£ Inngest Ecosystem
```python
# Cell 1: Dependencies
!pip install -q --force-reinstall "numpy==1.26.4" "scipy==1.11.4" "scikit-learn==1.4.2"
!pip install -q transformers accelerate torch sentencepiece

# Cell 2: Process
!python scripts/kaggle_process_inngest_ecosystem.py

# Cell 3: Download
!zip -r inngest_ecosystem_embeddings.zip output/inngest_ecosystem/embeddings/
```

---

## ğŸ“Š Final Statistics

| Collection | Files | Subdirs | Est. Chunks | Est. Time | GPU Config |
|------------|-------|---------|-------------|-----------|------------|
| viator_api | 4 | 3 | ~1,000 | 10 min | âœ… 2 GPUs |
| fast_docs | 109 | 3 | ~3,000 | 20 min | âœ… 2 GPUs |
| pydantic_docs | 270 | 0 | ~7,000 | 30 min | âœ… 2 GPUs |
| inngest_ecosystem | 295 | 6 | ~8,000 | 40 min | âœ… 2 GPUs |
| **TOTAL** | **678** | **12** | **~19,000** | **~100 min** | **âœ… All use 2 GPUs** |

---

## âœ… Verification

### How to Confirm 2-GPU Usage:

**During processing, run in separate cell:**
```python
!nvidia-smi
```

**Expected output:**
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 535.XX       Driver Version: 535.XX       CUDA Version: 12.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
|   0  Tesla T4           Off  | 00000000:00:04.0 Off |                    0 |
|      ~13GB / 16GB             | Used Memory                                 |
+-------------------------------+----------------------+----------------------+
|   1  Tesla T4           Off  | 00000000:00:05.0 Off |                    0 |
|      ~13GB / 16GB             | Used Memory                                 |
+-------------------------------+----------------------+----------------------+
```

**âœ… Both GPUs should show ~13GB usage when model is loaded!**

---

## ğŸ‰ Summary

**You now have:**
- âœ… 4 production-ready scripts
- âœ… All using 2-GPU parallelism (`device_map="auto"`)
- âœ… Consistent subdirectory structure
- âœ… Unique chunk IDs across all collections
- âœ… Single JSONL output per collection
- âœ… Ready for Qdrant upload with `upload_to_qdrant.py`

**Total processing time:** ~100 minutes on Kaggle GPU T4 x2 for all 4 collections! ğŸš€

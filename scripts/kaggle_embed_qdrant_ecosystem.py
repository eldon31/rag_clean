"""
Kaggle-optimized Qdrant Ecosystem Embedding Pipeline
For GPU T4 x2 with nomic-ai/nomic-embed-code (3584-dim) + DATA PARALLELISM

This script embeds pre-processed chunks from output/qdrant_ecosystem/
Collection name: qdrant_ecosystem

Subdirectories (processed by process_qdrant_ecosystem.py):
1. qdrant_documentation/   - Qdrant official documentation
2. qdrant_examples/        - Qdrant code examples
3. qdrant_fastembed/       - Qdrant FastEmbed library docs
4. qdrant_mcp-server-qdrant/ - MCP server for Qdrant
5. qdrant_qdrant/          - Qdrant core repository
6. qdrant_qdrant-client/   - Qdrant client library

PARALLELISM STRATEGY:
- Multi-process data parallelism (1 process per GPU)
- Each process handles a subset of subdirectories
- Shared model loading across processes
- Efficient batching within each process

UNIQUE ID STRATEGY:
- Format: qdrant_ecosystem:{subdir}:{filename}:chunk:{index}
- Example: qdrant_ecosystem:qdrant_documentation:getting-started.md:chunk:0
- IDs already generated by process_qdrant_ecosystem.py
"""

import os

# Prevent transformers from attempting to load TensorFlow
os.environ.setdefault("TRANSFORMERS_NO_TF", "1")
os.environ.setdefault("HF_HUB_DISABLE_TELEMETRY", "1")
# Enable PyTorch memory optimization
os.environ.setdefault("PYTORCH_CUDA_ALLOC_CONF", "expandable_segments:True")

import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple
import multiprocessing as mp
from functools import partial

import numpy as np
import torch
from sentence_transformers import SentenceTransformer

# Guard against NumPy 2.x
if tuple(map(int, np.__version__.split(".")[:2])) >= (2, 0):
    raise RuntimeError(
        "NumPy 2.x detected. Please run `pip install -q --force-reinstall \"numpy==1.26.4\" \"scikit-learn==1.4.2\"`"
    )

# Check GPU availability
print(f"\n{'='*60}")
print("GPU SETUP")
print(f"{'='*60}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    num_gpus = torch.cuda.device_count()
    print(f"Number of GPUs: {num_gpus}")
    for i in range(num_gpus):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
        print(f"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB")
else:
    num_gpus = 1
    print("No CUDA GPUs available, using CPU")
print(f"{'='*60}\n")

# Configuration
COLLECTION_NAME = "qdrant_ecosystem"

# Auto-detect path (GitHub clones into rad_clean, not RAG_CLEAN)
if Path("/kaggle/working/rad_clean/output/qdrant_ecosystem").exists():
    INPUT_DIR = Path("/kaggle/working/rad_clean/output/qdrant_ecosystem")
else:
    # Fallback for local testing
    INPUT_DIR = Path("output/qdrant_ecosystem")

OUTPUT_DIR = Path("/kaggle/working/embeddings")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Model configuration
MODEL_NAME = "nomic-ai/nomic-embed-code"
EMBEDDING_DIM = 3584
BATCH_SIZE = 32  # Per GPU
MAX_SEQ_LENGTH = 8192

# Parallelism configuration
NUM_WORKERS = min(num_gpus, mp.cpu_count())  # 1 worker per GPU


def load_chunks_from_subdirectory(subdir_path: Path) -> List[Dict]:
    """
    Load chunks from a subdirectory's chunks.json file.
    
    Args:
        subdir_path: Path to subdirectory (e.g., output/qdrant_ecosystem/qdrant_documentation/)
    
    Returns:
        List of chunk dictionaries with chunk_id, content, metadata
    """
    chunks_file = subdir_path / "chunks.json"
    
    if not chunks_file.exists():
        print(f"⚠️  No chunks.json found in {subdir_path.name}")
        return []
    
    with open(chunks_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    chunks = data.get('chunks', [])
    print(f"✅ Loaded {len(chunks)} chunks from {subdir_path.name}")
    
    return chunks


def embed_chunks_worker(
    subdir_names: List[str],
    worker_id: int,
    gpu_id: int,
    input_dir: Path,
    output_dir: Path
) -> Tuple[int, int]:
    """
    Worker function to embed chunks from assigned subdirectories.
    Each worker runs on a dedicated GPU.
    
    Args:
        subdir_names: List of subdirectory names to process
        worker_id: Worker process ID
        gpu_id: GPU device ID for this worker
        input_dir: Input directory path
        output_dir: Output directory path
    
    Returns:
        Tuple of (total_chunks_processed, total_subdirs_processed)
    """
    # Set GPU for this worker
    device = f"cuda:{gpu_id}" if torch.cuda.is_available() else "cpu"
    print(f"\n[Worker {worker_id}] Starting on {device}")
    print(f"[Worker {worker_id}] Assigned subdirectories: {subdir_names}")
    
    # Load model on assigned GPU
    print(f"[Worker {worker_id}] Loading {MODEL_NAME}...")
    model = SentenceTransformer(
        MODEL_NAME,
        device=device,
        trust_remote_code=True
    )
    model.max_seq_length = MAX_SEQ_LENGTH
    print(f"[Worker {worker_id}] Model loaded (dim={model.get_sentence_embedding_dimension()})")
    
    total_chunks = 0
    total_subdirs = 0
    
    for subdir_name in subdir_names:
        subdir_path = input_dir / subdir_name
        
        if not subdir_path.is_dir():
            print(f"[Worker {worker_id}] ⚠️  Skipping {subdir_name} (not a directory)")
            continue
        
        print(f"\n[Worker {worker_id}] Processing {subdir_name}...")
        
        # Load chunks
        chunks = load_chunks_from_subdirectory(subdir_path)
        
        if not chunks:
            print(f"[Worker {worker_id}] ⚠️  No chunks found in {subdir_name}")
            continue
        
        # Prepare texts for embedding (use search_document task)
        texts = [chunk['content'] for chunk in chunks]
        
        # Embed with batching and prompt_name for Nomic models
        print(f"[Worker {worker_id}] Embedding {len(texts)} chunks...")
        embeddings = model.encode(
            texts,
            batch_size=BATCH_SIZE,
            show_progress_bar=True,
            normalize_embeddings=True,
            convert_to_numpy=True,
            prompt_name="search_document"  # Nomic-specific for documents
        )
        
        # Add embeddings to chunks
        for chunk, embedding in zip(chunks, embeddings):
            chunk['embedding'] = embedding.tolist()
        
        # Save embedded chunks
        output_file = output_dir / f"{subdir_name}_embedded.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'collection': COLLECTION_NAME,
                'subdirectory': subdir_name,
                'total_chunks': len(chunks),
                'embedding_model': MODEL_NAME,
                'embedding_dim': EMBEDDING_DIM,
                'processed_at': datetime.now().isoformat(),
                'chunks': chunks
            }, f, indent=2, ensure_ascii=False)
        
        print(f"[Worker {worker_id}] ✅ Saved {len(chunks)} embedded chunks to {output_file.name}")
        total_chunks += len(chunks)
        total_subdirs += 1
    
    print(f"\n[Worker {worker_id}] Finished: {total_subdirs} subdirectories, {total_chunks} chunks")
    return total_chunks, total_subdirs


def main():
    """Main execution with data parallelism."""
    start_time = datetime.now()
    
    print(f"\n{'='*60}")
    print(f"QDRANT ECOSYSTEM EMBEDDING PIPELINE")
    print(f"{'='*60}")
    print(f"Collection: {COLLECTION_NAME}")
    print(f"Input: {INPUT_DIR}")
    print(f"Output: {OUTPUT_DIR}")
    print(f"Model: {MODEL_NAME}")
    print(f"Workers: {NUM_WORKERS} (parallel processes)")
    print(f"Batch size: {BATCH_SIZE} per GPU")
    print(f"{'='*60}\n")
    
    # Discover all subdirectories
    subdirs = [d for d in INPUT_DIR.iterdir() if d.is_dir()]
    subdir_names = [d.name for d in subdirs]
    
    print(f"Found {len(subdir_names)} subdirectories:")
    for name in subdir_names:
        print(f"  - {name}")
    
    if not subdir_names:
        print("❌ No subdirectories found. Exiting.")
        return
    
    # Split subdirectories across workers (data parallelism)
    subdirs_per_worker = [[] for _ in range(NUM_WORKERS)]
    for i, name in enumerate(subdir_names):
        worker_idx = i % NUM_WORKERS
        subdirs_per_worker[worker_idx].append(name)
    
    print(f"\n{'='*60}")
    print("WORK DISTRIBUTION")
    print(f"{'='*60}")
    for worker_id, assigned_subdirs in enumerate(subdirs_per_worker):
        gpu_id = worker_id % num_gpus if torch.cuda.is_available() else 0
        print(f"Worker {worker_id} (GPU {gpu_id}): {len(assigned_subdirs)} subdirs - {assigned_subdirs}")
    print(f"{'='*60}\n")
    
    # Create worker function with partial application
    worker_fn = partial(
        embed_chunks_worker,
        input_dir=INPUT_DIR,
        output_dir=OUTPUT_DIR
    )
    
    # Run workers in parallel
    if NUM_WORKERS > 1:
        print(f"🚀 Starting {NUM_WORKERS} parallel workers...\n")
        
        with mp.Pool(processes=NUM_WORKERS) as pool:
            # Create arguments for each worker
            worker_args = [
                (subdirs, worker_id, worker_id % num_gpus if torch.cuda.is_available() else 0)
                for worker_id, subdirs in enumerate(subdirs_per_worker)
                if subdirs  # Skip empty assignments
            ]
            
            # Execute in parallel
            results = pool.starmap(worker_fn, worker_args)
        
        # Aggregate results
        total_chunks = sum(r[0] for r in results)
        total_subdirs = sum(r[1] for r in results)
    else:
        print(f"🚀 Starting single worker (no parallelism)...\n")
        
        # Single worker mode
        gpu_id = 0 if torch.cuda.is_available() else 0
        total_chunks, total_subdirs = embed_chunks_worker(
            subdir_names=subdir_names,
            worker_id=0,
            gpu_id=gpu_id,
            input_dir=INPUT_DIR,
            output_dir=OUTPUT_DIR
        )
    
    # Summary
    elapsed_time = (datetime.now() - start_time).total_seconds()
    
    print(f"\n{'='*60}")
    print("EMBEDDING COMPLETE")
    print(f"{'='*60}")
    print(f"Total subdirectories: {total_subdirs}")
    print(f"Total chunks embedded: {total_chunks:,}")
    print(f"Elapsed time: {elapsed_time:.2f}s")
    print(f"Throughput: {total_chunks/elapsed_time:.2f} chunks/sec")
    print(f"Output directory: {OUTPUT_DIR}")
    print(f"{'='*60}\n")
    
    # List output files
    output_files = sorted(OUTPUT_DIR.glob("*_embedded.json"))
    print(f"Generated {len(output_files)} output files:")
    for file in output_files:
        size_mb = file.stat().st_size / 1e6
        print(f"  - {file.name} ({size_mb:.2f} MB)")
    
    print(f"\n✅ All embeddings saved to {OUTPUT_DIR}")


if __name__ == "__main__":
    # Set multiprocessing start method
    mp.set_start_method('spawn', force=True)
    main()

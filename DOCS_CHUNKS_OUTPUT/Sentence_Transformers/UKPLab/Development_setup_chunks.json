[
  {
    "text": "conda install -c conda-forge sentence-transformers accelerate datasets pre-commit pytest ruff\n```\n\nNote that ONNX and OpenVINO extras still require pip installation even when using conda for the base package.\n\n**Sources:** [docs/installation.md:12-110]()\n\n## Backend Dependencies\n\n### Training Dependencies\n\nFor training workflows, additional dependencies provide enhanced functionality:\n\n```mermaid\ngraph LR\n    subgraph \"Core Training\"\n        SentenceTransformers[\"sentence-transformers[train]\"]\n        Accelerate[\"accelerate\"]\n        Datasets[\"datasets\"]\n    end\n    \n    subgraph \"Optional Training Tools\"\n        WandB[\"wandb<br/>(tracking)\"]\n        CodeCarbon[\"codecarbon<br/>(emissions)\"]\n    end\n    \n    subgraph \"Training Components\"\n        SentenceTransformers --> Trainers[\"SentenceTransformerTrainer<br/>SparseEncoderTrainer<br/>CrossEncoderTrainer\"]\n        Accelerate --> DistributedTraining[\"Distributed training\"]\n        Datasets --> DataLoading[\"Dataset loading\"]\n        \n        WandB --> LogTracking[\"Training log tracking\"]\n        CodeCarbon --> ModelCards[\"Automatic model card generation\"]\n    end\n```\n\nInstall recommended training tools:\n```bash\npip install wandb        # For experiment tracking\npip install codecarbon   # For carbon emissions tracking\n```\n\n### Optimization Backends\n\nDifferent backends provide specific optimization capabilities:\n\n| Backend | Installation | Optimization Focus |\n|---------|-------------|-------------------|\n| PyTorch | Default | Standard deep learning operations |\n| ONNX Runtime | `[onnx]` or `[onnx-gpu]` | Cross-platform inference optimization |\n| OpenVINO | `[openvino]` | Intel CPU/GPU/VPU optimization |\n\n**Sources:** [docs/installation.md:46-52](), [docs/installation.md:96-102]()\n\n## Source Installation\n\n### Latest Development Version\n\nInstall directly from the GitHub repository to access the latest features:\n\n```bash\n# Default from source\npip install git+https://github.com/UKPLab/sentence-transformers.git\n\n# Training from source\npip install -U \"sentence-transformers[train] @ git+https://github.com/UKPLab/sentence-transformers.git\"\n\n# ONNX from source\npip install -U \"sentence-transformers[onnx-gpu] @ git+https://github.com/UKPLab/sentence-transformers.git\"\n```\n\n### Editable Development Install\n\nFor contributors and developers making changes to the library:\n\n```bash\ngit clone https://github.com/UKPLab/sentence-transformers\ncd sentence-transformers\npip install -e \".[train,dev]\"\n```\n\nThis creates a link between the cloned repository and your Python environment, enabling immediate testing of code changes.\n\n**Sources:** [docs/installation.md:112-174]()\n\n## GPU and CUDA Setup\n\n### PyTorch CUDA Installation\n\nFor GPU acceleration, install PyTorch with CUDA support before installing sentence-transformers:\n\n```mermaid\ngraph TD\n    subgraph \"CUDA Setup Process\"\n        CheckCUDA[\"Check CUDA availability\"]\n        InstallPyTorch[\"Install PyTorch with CUDA\"]\n        InstallST[\"Install sentence-transformers\"]\n        VerifyGPU[\"Verify GPU detection\"]\n    end\n    \n    subgraph \"Verification Commands\"\n        CheckCUDA --> CUDACheck[\"torch.cuda.is_available()\"]\n        InstallPyTorch --> PyTorchInstall[\"pip install torch torchvision<br/>--index-url https://download.pytorch.org/whl/cu121\"]\n        VerifyGPU --> GPUCheck[\"model.device<br/>torch.cuda.device_count()\"]\n    end\n```\n\nFollow the [PyTorch installation guide](https://pytorch.org/get-started/locally/) for your specific CUDA version and system configuration.\n\n**Sources:** [docs/installation.md:175-177]()\n\n## Installation Verification\n\n### Basic Functionality Test\n\nAfter installation, verify the setup works correctly:\n\n```python",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Sentence_Transformers\\UKPLab\\sentence-transformers\\Development_setup.md",
      "input_type": "sentence_transformers",
      "chunking_strategy": "programming_language_documentation",
      "token_count": 807,
      "character_count": 3681,
      "created_at": "2025-10-16T17:42:32.828643",
      "parent_context": null,
      "semantic_type": "sentence_transformers",
      "collection_name": "Sentence_Transformers",
      "subfolder_name": "UKPLab",
      "collection_strategy": "programming_language_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "UKPLab\\sentence-transformers\\Development_setup.md",
      "collection_context": "Sentence_Transformers/UKPLab"
    }
  }
]
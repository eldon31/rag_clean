[
  {
    "text": "This document covers the three core model architectures in the sentence-transformers library: `SentenceTransformer`, `SparseEncoder`, and `CrossEncoder`. Each serves distinct use cases in text encoding and similarity tasks.\n\nFor information about training these model types, see pages [3.1](#3.1), [3.2](#3.2), and [3.3](#3.3). For details on available pretrained models, see pages [5.1](#5.1), [5.2](#5.2), and [5.3](#5.3).\n\n## Architecture Overview\n\nThe sentence-transformers library provides three main model architectures that differ in their encoding approach and use cases:\n\n```mermaid\ngraph TB\n    subgraph \"Input Processing\"\n        Text[\"Text Input(s)\"]\n    end\n    \n    subgraph \"Core Model Types\"\n        ST[\"SentenceTransformer<br/>Dense Embeddings\"]\n        SE[\"SparseEncoder<br/>Sparse Embeddings\"]\n        CE[\"CrossEncoder<br/>Pairwise Scoring\"]\n    end\n    \n    subgraph \"Output Types\"\n        Dense[\"Dense Vectors<br/>[batch_size, embedding_dim]\"]\n        Sparse[\"Sparse Vectors<br/>[batch_size, vocab_size]\"]\n        Scores[\"Similarity Scores<br/>[batch_size] or [batch_size, num_labels]\"]\n    end\n    \n    subgraph \"Use Cases\"\n        SemanticSearch[\"Semantic Search\"]\n        Clustering[\"Clustering\"]\n        LexicalSearch[\"Neural Lexical Search\"]\n        HybridRetrieval[\"Hybrid Retrieval\"]\n        Reranking[\"Reranking\"]\n        Classification[\"Text Classification\"]\n    end\n    \n    Text --> ST\n    Text --> SE\n    Text --> CE\n    \n    ST --> Dense\n    SE --> Sparse\n    CE --> Scores\n    \n    Dense --> SemanticSearch\n    Dense --> Clustering\n    Sparse --> LexicalSearch\n    Sparse --> HybridRetrieval\n    Scores --> Reranking\n    Scores --> Classification\n```\n\n**Sources:** [sentence_transformers/SentenceTransformer.py:61-163](), [sentence_transformers/sparse_encoder/SparseEncoder.py:27-129](), [sentence_transformers/cross_encoder/CrossEncoder.py:48-116](), [README.md:15-17]()\n\n## SentenceTransformer\n\nThe `SentenceTransformer` class is the primary model for generating dense vector embeddings from text. It encodes individual sentences or documents into fixed-size dense vectors suitable for semantic similarity tasks.\n\n### Core Architecture\n\n```mermaid\ngraph LR\n    subgraph \"SentenceTransformer Pipeline\"\n        Input[\"Text Input\"]\n        Tokenizer[\"tokenize()\"]\n        Transformer[\"Transformer Module\"]\n        Pooling[\"Pooling Module\"]\n        Optional[\"Optional Modules<br/>(Normalize, Dense, etc.)\"]\n        Output[\"Dense Embedding\"]\n    end\n    \n    Input --> Tokenizer\n    Tokenizer --> Transformer\n    Transformer --> Pooling\n    Pooling --> Optional\n    Optional --> Output\n    \n    subgraph \"Key Methods\"\n        Encode[\"encode()\"]\n        EncodeQuery[\"encode_query()\"]\n        EncodeDoc[\"encode_document()\"]\n        Similarity[\"similarity()\"]\n    end\n```\n\nThe `SentenceTransformer` class inherits from `nn.Sequential`, `FitMixin`, and `PeftAdapterMixin`, allowing it to function as a sequential pipeline of modules while supporting training and PEFT adapters.\n\n### Key Features\n\n- **Modular Design**: Composed of sequential modules like `Transformer`, `Pooling`, `Normalize`\n- **Prompt Support**: Configurable prompts for different tasks via `prompts` dictionary\n- **Task-Specific Encoding**: `encode_query()` and `encode_document()` methods for asymmetric retrieval\n- **Multiple Backends**: Supports PyTorch, ONNX, and OpenVINO backends\n- **Similarity Functions**: Built-in similarity computation with configurable functions\n\n### Usage Patterns\n\n```python",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Sentence_Transformers\\UKPLab\\sentence-transformers\\Core_Model_Types.md",
      "input_type": "sentence_transformers",
      "chunking_strategy": "programming_language_documentation",
      "token_count": 801,
      "character_count": 3502,
      "created_at": "2025-10-16T17:42:32.800132",
      "parent_context": null,
      "semantic_type": "sentence_transformers",
      "collection_name": "Sentence_Transformers",
      "subfolder_name": "UKPLab",
      "collection_strategy": "programming_language_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "UKPLab\\sentence-transformers\\Core_Model_Types.md",
      "collection_context": "Sentence_Transformers/UKPLab"
    }
  }
]
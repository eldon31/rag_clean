[
  {
    "text": "This document covers the NanoBEIR evaluation system in sentence-transformers, which provides rapid multi-dataset information retrieval evaluation using a collection of smaller BEIR-based datasets. For comprehensive single-dataset IR evaluation, see [SentenceTransformer Evaluators](#4.1). For sparse encoder specific evaluations, see [SparseEncoder Evaluators](#4.2).\n\n## Overview\n\nThe NanoBEIR evaluation system enables quick assessment of model performance across multiple information retrieval tasks using significantly smaller datasets compared to the full BEIR benchmark. The system supports both dense embedding models (`SentenceTransformer`) and sparse embedding models (`SparseEncoder`), providing the same metrics as standard IR evaluation but aggregated across multiple datasets.\n\nThe core evaluators are `NanoBEIREvaluator` for dense models and `SparseNanoBEIREvaluator` for sparse models, both extending the functionality of `InformationRetrievalEvaluator` to handle multiple datasets efficiently.\n\nSources: [sentence_transformers/evaluation/NanoBEIREvaluator.py:72-79](), [sentence_transformers/sparse_encoder/evaluation/SparseNanoBEIREvaluator.py:26-35]()\n\n## Architecture\n\n### Evaluator Class Hierarchy\n\n```mermaid\ngraph TD\n    SentenceEvaluator[\"SentenceEvaluator<br/>__call__(), primary_metric\"]\n    \n    InformationRetrievalEvaluator[\"InformationRetrievalEvaluator<br/>compute_metrices(), embed_inputs()\"]\n    SparseInformationRetrievalEvaluator[\"SparseInformationRetrievalEvaluator<br/>+ sparsity_stats, max_active_dims\"]\n    \n    NanoBEIREvaluator[\"NanoBEIREvaluator<br/>_load_dataset(), aggregate_fn\"]\n    SparseNanoBEIREvaluator[\"SparseNanoBEIREvaluator<br/>information_retrieval_class\"]\n    \n    SentenceEvaluator --> InformationRetrievalEvaluator\n    SentenceEvaluator --> NanoBEIREvaluator\n    InformationRetrievalEvaluator --> SparseInformationRetrievalEvaluator\n    NanoBEIREvaluator --> SparseNanoBEIREvaluator\n    \n    SparseNanoBEIREvaluator -.->|\"information_retrieval_class = <br/>SparseInformationRetrievalEvaluator\"| SparseInformationRetrievalEvaluator\n    NanoBEIREvaluator -.->|\"information_retrieval_class = <br/>InformationRetrievalEvaluator\"| InformationRetrievalEvaluator\n```\n\nSources: [sentence_transformers/evaluation/NanoBEIREvaluator.py:191](), [sentence_transformers/sparse_encoder/evaluation/SparseNanoBEIREvaluator.py:157](), [sentence_transformers/evaluation/InformationRetrievalEvaluator.py:23](), [sentence_transformers/sparse_encoder/evaluation/SparseInformationRetrievalEvaluator.py:23]()\n\n### Dataset Collection and Evaluation Flow\n\n```mermaid\ngraph LR\n    subgraph \"Dataset Loading\"\n        DatasetNameType[\"DatasetNameType<br/>(13 supported datasets)\"]\n        dataset_name_to_id[\"dataset_name_to_id<br/>mapping dictionary\"]\n        HuggingFaceHub[\"ðŸ¤— Hub<br/>zeta-alpha-ai/Nano*\"]\n    end\n    \n    subgraph \"Per-Dataset Evaluation\"\n        _load_dataset[\"_load_dataset()<br/>creates IR evaluator\"]\n        InformationRetrievalEvaluator[\"InformationRetrievalEvaluator<br/>or SparseInformationRetrievalEvaluator\"]\n        compute_metrics[\"compute_metrics()<br/>MRR, NDCG, MAP, etc.\"]\n    end\n    \n    subgraph \"Aggregation\"\n        aggregate_fn[\"aggregate_fn<br/>(default: np.mean)\"]\n        per_metric_results[\"per_metric_results<br/>dict[metric, list[values]]\"]\n        agg_results[\"aggregated results<br/>dict[metric, float]\"]\n    end\n    \n    DatasetNameType --> dataset_name_to_id\n    dataset_name_to_id --> HuggingFaceHub\n    HuggingFaceHub --> _load_dataset\n    _load_dataset --> InformationRetrievalEvaluator\n    InformationRetrievalEvaluator --> compute_metrics\n    compute_metrics --> per_metric_results\n    per_metric_results --> aggregate_fn\n    aggregate_fn --> agg_results\n```\n\nSources: [sentence_transformers/evaluation/NanoBEIREvaluator.py:404-434](), [sentence_transformers/evaluation/NanoBEIREvaluator.py:310-325]()\n\n## Dataset Collection\n\nThe NanoBEIR collection consists of 13 datasets, each significantly smaller than their full BEIR counterparts:",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Sentence_Transformers\\UKPLab\\sentence-transformers\\NanoBEIR_Evaluation.md",
      "input_type": "sentence_transformers",
      "chunking_strategy": "programming_language_documentation",
      "token_count": 873,
      "character_count": 4021,
      "created_at": "2025-10-16T17:42:33.037146",
      "parent_context": null,
      "semantic_type": "sentence_transformers",
      "collection_name": "Sentence_Transformers",
      "subfolder_name": "UKPLab",
      "collection_strategy": "programming_language_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "UKPLab\\sentence-transformers\\NanoBEIR_Evaluation.md",
      "collection_context": "Sentence_Transformers/UKPLab"
    }
  },
  {
    "text": "| Dataset | Full Name | Hub Path |\n|---------|-----------|----------|\n| `climatefever` | ClimateFEVER | `zeta-alpha-ai/NanoClimateFEVER` |\n| `dbpedia` | DBPedia | `zeta-alpha-ai/NanoDBPedia` |\n| `fever` | FEVER | `zeta-alpha-ai/NanoFEVER` |\n| `fiqa2018` | FiQA2018 | `zeta-alpha-ai/NanoFiQA2018` |\n| `hotpotqa` | HotpotQA | `zeta-alpha-ai/NanoHotpotQA` |\n| `msmarco` | MSMARCO | `zeta-alpha-ai/NanoMSMARCO` |\n| `nfcorpus` | NFCorpus | `zeta-alpha-ai/NanoNFCorpus` |\n| `nq` | NQ | `zeta-alpha-ai/NanoNQ` |\n| `quoraretrieval` | QuoraRetrieval | `zeta-alpha-ai/NanoQuoraRetrieval` |\n| `scidocs` | SCIDOCS | `zeta-alpha-ai/NanoSCIDOCS` |\n| `arguana` | ArguAna | `zeta-alpha-ai/NanoArguAna` |\n| `scifact` | SciFact | `zeta-alpha-ai/NanoSciFact` |\n| `touche2020` | Touche2020 | `zeta-alpha-ai/NanoTouche2020` |\n\nEach dataset contains three splits: `corpus`, `queries`, and `qrels` (query relevance judgments).\n\nSources: [sentence_transformers/evaluation/NanoBEIREvaluator.py:39-69]()\n\n## Usage Patterns\n\n### Dense Model Evaluation\n\n```python\nfrom sentence_transformers import SentenceTransformer\nfrom sentence_transformers.evaluation import NanoBEIREvaluator",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Sentence_Transformers\\UKPLab\\sentence-transformers\\NanoBEIR_Evaluation.md",
      "input_type": "sentence_transformers",
      "chunking_strategy": "programming_language_documentation",
      "token_count": 407,
      "character_count": 1152,
      "created_at": "2025-10-16T17:42:33.037979",
      "parent_context": null,
      "semantic_type": "sentence_transformers",
      "collection_name": "Sentence_Transformers",
      "subfolder_name": "UKPLab",
      "collection_strategy": "programming_language_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "UKPLab\\sentence-transformers\\NanoBEIR_Evaluation.md",
      "collection_context": "Sentence_Transformers/UKPLab"
    }
  }
]
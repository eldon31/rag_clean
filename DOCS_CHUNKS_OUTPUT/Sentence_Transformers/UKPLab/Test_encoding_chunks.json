[
  {
    "text": "sentences = [\"This is a test sentence\", \"This is another test\"]\nembeddings = model.encode(sentences)\nprint(f\"Generated embeddings shape: {embeddings.shape}\")\n```\n\n### Backend-Specific Verification\n\nTest different backends if installed:\n\n```python\n# Test ONNX backend (if installed)\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2', backend='onnx')\n\n# Test OpenVINO backend (if installed)  \nmodel = SentenceTransformer('all-MiniLM-L6-v2', backend='openvino')\n\n# Check GPU availability\nimport torch\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"GPU count: {torch.cuda.device_count()}\")\n```\n\n**Sources:** [docs/installation.md:1-177]()",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Sentence_Transformers\\UKPLab\\sentence-transformers\\Test_encoding.md",
      "input_type": "sentence_transformers",
      "chunking_strategy": "programming_language_documentation",
      "token_count": 170,
      "character_count": 700,
      "created_at": "2025-10-16T17:42:33.291402",
      "parent_context": null,
      "semantic_type": "sentence_transformers",
      "collection_name": "Sentence_Transformers",
      "subfolder_name": "UKPLab",
      "collection_strategy": "programming_language_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "UKPLab\\sentence-transformers\\Test_encoding.md",
      "collection_context": "Sentence_Transformers/UKPLab"
    }
  }
]
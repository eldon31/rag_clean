[
  {
    "text": "router = Router(\n    sub_modules={\n        \"query\": [efficient_module],\n        \"document\": [contextual_module, pooling_module]\n    },\n    default_route=\"document\"\n)\n```\n\nKey attributes:\n- `sub_modules`: `nn.ModuleDict` mapping task types to `nn.Sequential` module chains\n- `default_route`: Default task when `task` not specified in features\n- `allow_empty_key`: Whether to allow no default route\n- `forward_kwargs`: List of kwargs forwarded to modules (includes `\"task\"`)\n\nSources: [sentence_transformers/models/Router.py:22-418](), [sentence_transformers/models/Router.py:187-215](), [sentence_transformers/models/Router.py:217-245]()\n\n## Module Composition Examples\n\n### Dense Embedding Model (SentenceTransformer)\n\n```mermaid\ngraph LR\n    Text[\"Input Text\"] --> Transformer[\"Transformer<br/>(bert-base-uncased)\"]\n    Transformer --> Pooling[\"Pooling<br/>(mean pooling)\"]\n    Pooling --> Normalize[\"Normalize<br/>(L2 normalization)\"]\n    Normalize --> Embedding[\"Dense Embedding<br/>(768-dim vector)\"]\n    \n    subgraph \"modules[0]\"\n        Transformer\n    end\n    subgraph \"modules[1]\"\n        Pooling\n    end\n    subgraph \"modules[2]\"\n        Normalize\n    end\n```\n\n### Asymmetric Model with Router\n\n#### Asymmetric SparseEncoder Architecture\n\n```mermaid\ngraph TD\n    EncodeQuery[\"model.encode_query()\"] --> RouterQuery[\"Router(task='query')\"]\n    EncodeDoc[\"model.encode_document()\"] --> RouterDoc[\"Router(task='document')\"]\n    \n    RouterQuery --> QueryPath[\"sub_modules['query']\"]\n    RouterDoc --> DocPath[\"sub_modules['document']\"]\n    \n    QueryPath --> StaticEmb[\"SparseStaticEmbedding<br/>Pre-computed static weights\"]\n    DocPath --> MLMTrans[\"MLMTransformer<br/>Contextual MLM head\"]\n    \n    StaticEmb --> QueryEmb[\"Sparse Query Embedding<br/>(efficient)\"]\n    MLMTrans --> SpladePool[\"SpladePooling<br/>max + log1p_relu activation\"]\n    SpladePool --> DocEmb[\"Sparse Document Embedding<br/>(contextual)\"]\n    \n    subgraph RouterModule[\"Router Module\"]\n        QueryPath\n        DocPath\n        StaticEmb\n        MLMTrans\n        SpladePool\n    end\n```\n\n#### Router Training Requirements\n\n```python\n# Training args must specify router_mapping\nargs = SparseEncoderTrainingArguments(\n    router_mapping={\n        \"question\": \"query\",      # Dataset column -> router task\n        \"positive\": \"document\", \n        \"negative\": \"document\"\n    }\n)\n\n# Data collator uses mapping to set task in features\ncollator = SparseEncoderDataCollator(\n    tokenize_fn=model.tokenize,\n    router_mapping=args.router_mapping\n)\n```\n\nSources: [sentence_transformers/models/Router.py:104-156](), [sentence_transformers/sparse_encoder/trainer.py:180-186](), [sentence_transformers/sparse_encoder/data_collator.py:55-68]()\n\n### Training Pipeline Integration\n\n```mermaid\nflowchart TD\n    Dataset[\"Training Dataset\"] --> Collator[\"SentenceTransformerDataCollator\"]\n    Collator --> RouterMap{router_mapping?}\n    \n    RouterMap -->|Yes| TaskRoute[\"Add task to features<br/>based on column mapping\"]\n    RouterMap -->|No| DirectProcess[\"Process normally\"]\n    \n    TaskRoute --> Model[\"Model.forward()\"]\n    DirectProcess --> Model\n    \n    Model --> Features[\"Processed Features\"]\n    Features --> Loss[\"Loss Function<br/>(MultipleNegativesRankingLoss, etc.)\"]\n```\n\nSources: [sentence_transformers/trainer.py:198-204](), [sentence_transformers/data_collator.py:55-68]()\n\n## Module Loading and Saving\n\n### Module Configuration System\n\nEach module uses a configuration system for persistence:\n\n```mermaid\ngraph TD\n    Module[\"Module Instance\"] --> Config[\"get_config_dict()\"]\n    Config --> Keys[\"config_keys<br/>['param1', 'param2']\"]\n    Keys --> JSON[\"config.json<br/>{param1: value1, param2: value2}\"]\n    \n    subgraph \"Save Process\"\n        Config\n        Keys\n        JSON\n    end\n    \n    LoadJSON[\"config.json\"] --> LoadConfig[\"load_config()\"]\n    LoadConfig --> LoadModule[\"Module.load()\"]\n    LoadModule --> NewInstance[\"Module Instance\"]\n    \n    subgraph \"Load Process\"\n        LoadJSON\n        LoadConfig\n        LoadModule\n        NewInstance\n    end\n```\n\nKey configuration attributes:\n- `config_keys`: List of attributes to save/load\n- `config_file_name`: Name of config file (usually `\"config.json\"`)\n- `save_in_root`: Whether to save in model root or subfolder\n\n### Model Directory Structure",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Sentence_Transformers\\UKPLab\\sentence-transformers\\Or_manual_configuration.md",
      "input_type": "sentence_transformers",
      "chunking_strategy": "programming_language_documentation",
      "token_count": 1021,
      "character_count": 4297,
      "created_at": "2025-10-16T17:42:33.046017",
      "parent_context": null,
      "semantic_type": "sentence_transformers",
      "collection_name": "Sentence_Transformers",
      "subfolder_name": "UKPLab",
      "collection_strategy": "programming_language_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "UKPLab\\sentence-transformers\\Or_manual_configuration.md",
      "collection_context": "Sentence_Transformers/UKPLab"
    }
  },
  {
    "text": "```mermaid\ngraph TD\n    ModelDir[\"model_directory/\"] --> ModulesJSON[\"modules.json<br/>(module metadata)\"]\n    ModelDir --> ConfigST[\"config_sentence_transformers.json<br/>(model-level config)\"]\n    \n    ModelDir --> Module0[\"0_Transformer/<br/>(or root if save_in_root=True)\"]\n    ModelDir --> Module1[\"1_Pooling/\"]\n    ModelDir --> Module2[\"2_Normalize/\"]\n    \n    Module0 --> TransConfig[\"sentence_bert_config.json\"]\n    Module0 --> ModelFiles[\"model.safetensors<br/>tokenizer files\"]\n    \n    Module1 --> PoolConfig[\"config.json\"]\n    Module2 --> NormConfig[\"(empty - no config needed)\"]\n```\n\nThe `modules.json` file contains metadata about each module:\n\n| Field | Description |\n|-------|-------------|\n| `idx` | Module index in pipeline |\n| `name` | Module identifier |\n| `path` | Directory path relative to model root |\n| `type` | Full Python class path |\n\nSources: [docs/sentence_transformer/usage/custom_models.rst:43-101]()\n\n## Training Integration\n\n### Data Flow in Training\n\n```mermaid\nsequenceDiagram\n    participant Dataset\n    participant Collator as SentenceTransformerDataCollator\n    participant Model as Model Pipeline\n    participant Loss as Loss Function\n    \n    Dataset->>Collator: Raw text columns\n    Note over Collator: Apply prompts, router_mapping\n    Collator->>Model: Tokenized features + task info\n    \n    loop For each module\n        Model->>Model: module.forward(features)\n        Note over Model: Update features dict\n    end\n    \n    Model->>Loss: Final features\n    Loss->>Loss: Compute loss value\n```\n\n### Router Training Requirements\n\nWhen using `Router` modules, additional training configuration is required:\n\n```python",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Sentence_Transformers\\UKPLab\\sentence-transformers\\Or_manual_configuration.md",
      "input_type": "sentence_transformers",
      "chunking_strategy": "programming_language_documentation",
      "token_count": 390,
      "character_count": 1659,
      "created_at": "2025-10-16T17:42:33.047405",
      "parent_context": null,
      "semantic_type": "sentence_transformers",
      "collection_name": "Sentence_Transformers",
      "subfolder_name": "UKPLab",
      "collection_strategy": "programming_language_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "UKPLab\\sentence-transformers\\Or_manual_configuration.md",
      "collection_context": "Sentence_Transformers/UKPLab"
    }
  }
]
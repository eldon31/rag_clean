[
  {
    "text": "Framework Integrations | docling-project/docling | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[docling-project/docling](https://github.com/docling-project/docling \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 12 October 2025 ([f7244a](https://github.com/docling-project/docling/commits/f7244a43))",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 115,
      "character_count": 423,
      "created_at": "2025-10-16T17:42:17.786549",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 0,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [Overview](docling-project/docling/1-overview.md)\n- [Installation](docling-project/docling/1.1-installation.md)\n- [Quick Start](docling-project/docling/1.2-quick-start.md)\n- [Core Architecture](docling-project/docling/2-core-architecture.md)\n- [Document Conversion Flow](docling-project/docling/2.1-document-conversion-flow.md)\n- [DoclingDocument Data Model](docling-project/docling/2.2-doclingdocument-data-model.md)\n- [Configuration and Pipeline Options](docling-project/docling/2.3-configuration-and-pipeline-options.md)\n- [Format Detection and Routing](docling-project/docling/2.4-format-detection-and-routing.md)\n- [Document Backends](docling-project/docling/3-document-backends.md)\n- [PDF Processing Backends](docling-project/docling/3.1-pdf-processing-backends.md)\n- [Office Document Backends](docling-project/docling/3.2-office-document-backends.md)\n- [Web and Markup Backends](docling-project/docling/3.3-web-and-markup-backends.md)\n- [AI/ML Models](docling-project/docling/4-aiml-models.md)\n- [OCR Models](docling-project/docling/4.1-ocr-models.md)\n- [Layout and Table Structure Models](docling-project/docling/4.2-layout-and-table-structure-models.md)\n- [Vision Language Models](docling-project/docling/4.3-vision-language-models.md)\n- [Inline VLM Models](docling-project/docling/4.3.1-inline-vlm-models.md)\n- [API-Based VLM Models](docling-project/docling/4.3.2-api-based-vlm-models.md)\n- [Enrichment Models](docling-project/docling/4.4-enrichment-models.md)\n- [Processing Pipelines](docling-project/docling/5-processing-pipelines.md)\n- [Standard PDF Pipeline](docling-project/docling/5.1-standard-pdf-pipeline.md)\n- [Threaded PDF Pipeline](docling-project/docling/5.2-threaded-pdf-pipeline.md)\n- [VLM Pipeline](docling-project/docling/5.3-vlm-pipeline.md)\n- [Extraction Pipeline](docling-project/docling/5.4-extraction-pipeline.md)\n- [ASR Pipeline](docling-project/docling/5.5-asr-pipeline.md)\n- [Base Pipeline Architecture](docling-project/docling/5.6-base-pipeline-architecture.md)\n- [Command Line Interface](docling-project/docling/6-command-line-interface.md)\n- [Document Conversion CLI](docling-project/docling/6.1-document-conversion-cli.md)\n- [Model Management CLI](docling-project/docling/6.2-model-management-cli.md)\n- [Python SDK](docling-project/docling/7-python-sdk.md)\n- [DocumentConverter API](docling-project/docling/7.1-documentconverter-api.md)\n- [DocumentExtractor API](docling-project/docling/7.2-documentextractor-api.md)\n- [Usage Examples](docling-project/docling/7.3-usage-examples.md)\n- [Output and Integration](docling-project/docling/8-output-and-integration.md)\n- [Export Formats](docling-project/docling/8.1-export-formats.md)\n- [Document Chunking](docling-project/docling/8.2-document-chunking.md)\n- [Framework Integrations](docling-project/docling/8.3-framework-integrations.md)\n- [Development and Testing](docling-project/docling/9-development-and-testing.md)\n- [Testing Framework](docling-project/docling/9.1-testing-framework.md)\n- [Ground Truth Data](docling-project/docling/9.2-ground-truth-data.md)\n- [CI/CD and Development Workflow](docling-project/docling/9.3-cicd-and-development-workflow.md)\n- [Deployment](docling-project/docling/10-deployment.md)\n- [Docker Deployment](docling-project/docling/10.1-docker-deployment.md)\n- [Model Artifacts Management](docling-project/docling/10.2-model-artifacts-management.md)\n\nMenu\n\n# Framework Integrations\n\nRelevant source files",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 927,
      "character_count": 3421,
      "created_at": "2025-10-16T17:42:17.788872",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 1,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [.github/SECURITY.md](https://github.com/docling-project/docling/blob/f7244a43/.github/SECURITY.md)\n- [CHANGELOG.md](https://github.com/docling-project/docling/blob/f7244a43/CHANGELOG.md)\n- [CITATION.cff](https://github.com/docling-project/docling/blob/f7244a43/CITATION.cff)\n- [README.md](https://github.com/docling-project/docling/blob/f7244a43/README.md)\n- [docs/examples/minimal\\_vlm\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docs/examples/minimal_vlm_pipeline.py)\n- [docs/index.md](https://github.com/docling-project/docling/blob/f7244a43/docs/index.md)\n- [docs/usage/index.md](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/index.md)\n- [docs/usage/mcp.md](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/mcp.md)\n- [docs/usage/vision\\_models.md](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/vision_models.md)\n- [mkdocs.yml](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml)\n- [pyproject.toml](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml)\n- [uv.lock](https://github.com/docling-project/docling/blob/f7244a43/uv.lock)\n\n## Purpose and Scope\n\nThis page documents how Docling integrates with AI development frameworks, vector databases, data processing pipelines, and agentic systems. It covers the architectural patterns, export formats, and protocols that enable seamless integration with the broader GenAI ecosystem.\n\nFor information about export format options and serialization, see [Export Formats](docling-project/docling/8.1-export-formats.md). For chunking strategies used in retrieval pipelines, see [Document Chunking](docling-project/docling/8.2-document-chunking.md).\n\n---\n\n## Integration Architecture Overview\n\nDocling's integration strategy is built on three foundational principles:\n\n1. **Unified Representation**: The `DoclingDocument` class provides a consistent document model that all downstream systems consume\n2. **Multiple Export Formats**: Support for Markdown, JSON, HTML, and DocTags enables compatibility with diverse framework requirements\n3. **Standardized Protocols**: MCP (Model Context Protocol) support for agentic AI systems\n\n```\n```\n\n**Diagram: Docling Integration Architecture**\n\nSources: [pyproject.toml1-280](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L1-L280) [README.md109-113](https://github.com/docling-project/docling/blob/f7244a43/README.md#L109-L113) [mkdocs.yml128-155](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L128-L155)\n\n---\n\n## DoclingDocument as Integration Foundation\n\nThe `DoclingDocument` class serves as the universal interchange format for all integrations. It provides:\n\n- **Hierarchical Structure**: Nested document elements with parent-child relationships\n- **Content Layers**: Separation of body content from furniture elements (headers, footers, page numbers)\n- **Rich Metadata**: Provenance information, bounding boxes, confidence scores\n- **Multiple Serialization**: JSON, Markdown, HTML, and DocTags output\n\n### Key Export Methods\n\n| Method                 | Output Format | Primary Use Case                     | Framework Compatibility         |\n| ---------------------- | ------------- | ------------------------------------ | ------------------------------- |\n| `export_to_markdown()` | Markdown      | RAG pipelines, LLM consumption       | LangChain, LlamaIndex, Haystack |\n| `export_to_json()`     | JSON          | Structured data processing           | All frameworks                  |\n| `export_to_html()`     | HTML          | Web display, rich formatting         | Custom applications             |\n| DocTags                | Custom XML    | VLM training, fine-grained structure | Research, model development     |\n\n```\n```\n\n**Diagram: DoclingDocument Structure and Export Pathways**\n\nSources: [README.md26-27](https://github.com/docling-project/docling/blob/f7244a43/README.md#L26-L27) [docs/index.md26-27](https://github.com/docling-project/docling/blob/f7244a43/docs/index.md#L26-L27) [pyproject.toml47](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L47-L47)\n\n---\n\n## Model Context Protocol (MCP) Integration",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 1002,
      "character_count": 4211,
      "created_at": "2025-10-16T17:42:17.795949",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 2,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "The Model Context Protocol (MCP) is an emerging standard for connecting AI applications to external tools and data sources. Docling provides a dedicated MCP server that enables agentic AI systems to access document processing capabilities.\n\n### MCP Server Architecture\n\n```\n```\n\n**Diagram: MCP Server Integration Flow**\n\n### Configuration Example\n\nMCP clients connect to the Docling server through a configuration file specifying the command and arguments:\n\n```\n```\n\nThis configuration is used in:\n\n- **Claude Desktop**: `claude_desktop_config.json`\n- **LM Studio**: `mcp.json`\n- **Custom clients**: Any MCP-compatible client\n\nThe MCP server exposes Docling's document conversion and extraction capabilities as tools that AI agents can invoke autonomously. This enables use cases such as:\n\n- Document Q\\&A with automatic parsing\n- Multi-document synthesis workflows\n- Automated data extraction from forms and tables\n- Document-based reasoning chains\n\nSources: [docs/usage/mcp.md1-31](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/mcp.md#L1-L31) [README.md41-42](https://github.com/docling-project/docling/blob/f7244a43/README.md#L41-L42)\n\n---\n\n## AI Framework Integrations\n\n### LangChain Integration\n\nLangChain integration leverages Docling's Markdown export and chunking capabilities for RAG (Retrieval-Augmented Generation) pipelines.\n\n**Integration Pattern:**\n\n1. Convert documents using `DocumentConverter`\n2. Export to Markdown with `export_to_markdown()`\n3. Apply chunking via `HybridChunker` from `docling-core`\n4. Create LangChain `Document` objects\n5. Index in vector store (Milvus, Qdrant, etc.)\n\n```\n```\n\n**Diagram: LangChain RAG Pipeline with Docling**\n\n**Key Dependencies:**\n\n- `langchain-huggingface>=0.0.3` - Embedding models\n- `langchain-milvus~=0.1` - Milvus vector store\n- `langchain-text-splitters~=0.2` - Text splitting utilities\n\nSources: [pyproject.toml144-146](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L144-L146) [mkdocs.yml134](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L134-L134)\n\n---\n\n### LlamaIndex Integration\n\nLlamaIndex integration follows a similar pattern but uses LlamaIndex-specific abstractions for document loading and indexing.\n\n**Integration Components:**\n\n| Component    | Purpose            | Docling Interface                 |\n| ------------ | ------------------ | --------------------------------- |\n| Reader       | Document ingestion | `DocumentConverter.convert()`     |\n| Node Parser  | Chunking           | `HybridChunker` from docling-core |\n| Vector Store | Embedding storage  | Weaviate, MongoDB, etc.           |\n| Query Engine | Retrieval          | Standard LlamaIndex query         |\n\n```\n```\n\n**Diagram: LlamaIndex Integration Architecture**\n\nSources: [mkdocs.yml136](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L136-L136) [mkdocs.yml109](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L109-L109)\n\n---\n\n### Haystack Integration\n\nHaystack integration uses Docling as a document converter within Haystack pipelines, enabling preprocessing before RAG or search operations.\n\n**Typical Haystack Pipeline:**\n\n1. `DocumentConverter` as preprocessing step\n2. Export to structured format\n3. Pass to Haystack `Pipeline`\n4. Route to retriever or generator components\n\n**Supported Vector Stores:**\n\n- OpenSearch\n- Azure Cognitive Search\n\nSources: [mkdocs.yml133](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L133-L133) [mkdocs.yml123](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L123-L123)\n\n---\n\n### Agentic AI Frameworks\n\nMultiple agentic frameworks integrate Docling to provide document understanding capabilities to autonomous agents:\n\n| Framework           | Integration Type | Key Feature                    |\n| ------------------- | ---------------- | ------------------------------ |\n| Crew AI             | Tool             | Document parsing as crew task  |\n| Bee Agent Framework | Tool             | Multi-agent document workflows |\n| Langflow            | Node             | Visual pipeline integration    |\n| txtai               | Pipeline         | Embedded document processing   |\n\n```\n```\n\n**Diagram: Agentic Framework Integration Patterns**",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 977,
      "character_count": 4271,
      "created_at": "2025-10-16T17:42:17.806151",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 3,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "Sources: [mkdocs.yml131-137](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L131-L137) [README.md29](https://github.com/docling-project/docling/blob/f7244a43/README.md#L29-L29)\n\n---\n\n## Vector Database Integrations\n\nDocling's chunking and embedding-friendly output formats enable integration with major vector databases for semantic search and RAG applications.\n\n### Supported Vector Databases\n\n| Vector DB    | Primary Framework | Integration Path                |\n| ------------ | ----------------- | ------------------------------- |\n| Milvus       | LangChain         | `langchain-milvus` connector    |\n| Qdrant       | LangChain, Direct | Python client, LangChain loader |\n| Weaviate     | LlamaIndex        | Weaviate vector store           |\n| MongoDB      | LlamaIndex        | MongoDB Atlas vector search     |\n| OpenSearch   | Haystack          | OpenSearch document store       |\n| Azure Search | Haystack          | Azure Cognitive Search          |\n\n**General Integration Flow:**\n\n1. Process document with `DocumentConverter`\n2. Extract text via `export_to_markdown()` or iterate over elements\n3. Apply `HybridChunker` for semantic chunking\n4. Generate embeddings (typically with sentence-transformers or OpenAI)\n5. Store in vector database with metadata\n\n```\n```\n\n**Diagram: Vector Database Integration Flow**\n\nSources: [mkdocs.yml122-125](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L122-L125) [pyproject.toml145](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L145-L145)\n\n---\n\n## Data Processing Framework Integrations\n\nBeyond real-time RAG, Docling integrates with data processing frameworks for batch document processing, training data preparation, and enterprise workflows.\n\n### Data Prep Kit (DPK)\n\nData Prep Kit is a framework for large-scale data preparation pipelines. Docling integration enables:\n\n- **Batch Processing**: Convert thousands of documents in parallel\n- **Transform Pipelines**: Clean, chunk, and tokenize documents\n- **Training Data Generation**: Prepare datasets for model fine-tuning\n\n**Example Pipeline:**\n\n```\nIngest → Docling Convert → DPK Transform → Chunk → Tokenize → Store\n```\n\nSources: [mkdocs.yml140](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L140-L140) [mkdocs.yml119](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L119-L119)\n\n---\n\n### InstructLab Integration\n\nInstructLab uses Docling for preparing training data from documents in knowledge base construction workflows.\n\n**Integration Points:**\n\n- Document parsing for instruction-tuning datasets\n- Structured extraction of Q\\&A pairs\n- Metadata preservation for provenance tracking\n\nSources: [mkdocs.yml141](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L141-L141)\n\n---\n\n### Enterprise & Production Integrations\n\n| Integration | Category            | Purpose                                    |\n| ----------- | ------------------- | ------------------------------------------ |\n| Apify Actor | Cloud Platform      | Serverless document processing             |\n| Prodigy     | Annotation          | Active learning for document understanding |\n| spaCy       | NLP Pipeline        | Entity extraction from parsed documents    |\n| RHEL AI     | Enterprise Platform | On-premises AI deployments                 |\n| NVIDIA      | GPU Acceleration    | Optimized VLM inference                    |\n| Quarkus     | Java Framework      | JVM-based microservices                    |\n\n```\n```\n\n**Diagram: Enterprise Integration Landscape**\n\nSources: [mkdocs.yml139-155](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L139-L155) [README.md109-113](https://github.com/docling-project/docling/blob/f7244a43/README.md#L109-L113)\n\n---\n\n## Integration Development Patterns\n\n### Common Integration Pattern\n\nMost integrations follow this general structure:\n\n1. **Initialization**: Create `DocumentConverter` with appropriate options\n2. **Conversion**: Call `convert()` or `convert_all()` for batch processing\n3. **Export**: Use `export_to_markdown()`, `export_to_json()`, or iterate over elements\n4. **Transform**: Apply framework-specific transformations (chunking, embedding, etc.)\n5. **Downstream Processing**: Pass to framework-specific components\n\n### Code Structure Example\n\n```\n```\n\n### Export Format Selection",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 968,
      "character_count": 4366,
      "created_at": "2025-10-16T17:42:17.818680",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 4,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "| Use Case              | Recommended Format | Rationale                       |\n| --------------------- | ------------------ | ------------------------------- |\n| RAG with LLMs         | Markdown           | Readable, preserves structure   |\n| Structured extraction | JSON               | Programmatic access to elements |\n| Web display           | HTML               | Styled rendering                |\n| Model training        | DocTags            | Fine-grained structure labels   |\n| Search indexing       | Markdown or JSON   | Depends on search engine        |\n\nSources: [README.md69-78](https://github.com/docling-project/docling/blob/f7244a43/README.md#L69-L78) [docs/usage/index.md1-46](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/index.md#L1-L46)\n\n---\n\n## Environment Variables and Configuration\n\nSeveral environment variables control integration behavior:\n\n| Variable              | Purpose                                | Default        |\n| --------------------- | -------------------------------------- | -------------- |\n| `DOCLING_DEVICE`      | Accelerator device (CPU/CUDA/MPS/AUTO) | AUTO           |\n| `OMP_NUM_THREADS`     | Thread count for CPU models            | System default |\n| `DOCLING_NUM_THREADS` | Alternative thread control             | System default |\n\nThese settings affect model inference performance in integration scenarios, particularly for VLM-based pipelines and OCR operations.\n\nSources: [pyproject.toml1-280](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L1-L280)\n\n---\n\n## Installation for Integrations\n\nTo use Docling with specific integrations, install with appropriate extras:\n\n| Extra         | Frameworks Enabled                      | Install Command                  |\n| ------------- | --------------------------------------- | -------------------------------- |\n| `[vlm]`       | Vision models (Transformers, MLX, vLLM) | `pip install docling[vlm]`       |\n| `[easyocr]`   | EasyOCR engine                          | `pip install docling[easyocr]`   |\n| `[tesserocr]` | Tesseract OCR                           | `pip install docling[tesserocr]` |\n| `[asr]`       | Audio transcription (Whisper)           | `pip install docling[asr]`       |\n\n**Example Dependencies in `pyproject.toml`:**\n\n- VLM support: `transformers>=4.46.0`, `accelerate>=1.2.1`, `mlx-vlm>=0.3.0`, `vllm>=0.10.0`\n- Chunking: `docling-core[chunking]>=2.48.2`\n\nSources: [pyproject.toml91-111](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L91-L111) [README.md56-65](https://github.com/docling-project/docling/blob/f7244a43/README.md#L56-L65)\n\n---\n\n## Summary\n\nDocling's integration ecosystem is built on:\n\n1. **DoclingDocument**: Universal document representation\n2. **Flexible Export**: Multiple formats for different use cases\n3. **MCP Protocol**: Standard interface for agentic AI\n4. **Framework Adapters**: Native support for LangChain, LlamaIndex, Haystack\n5. **Chunking API**: Semantic document segmentation via `docling-core`\n6. **Batch Processing**: Efficient handling of document collections\n\nThe integration architecture prioritizes **modularity** (components can be mixed and matched), **extensibility** (new integrations follow established patterns), and **interoperability** (standard formats and protocols).\n\nFor specific integration examples, see the [Examples](docling-project/docling/7.3-usage-examples.md) section. For details on export format options, see [Export Formats](docling-project/docling/8.1-export-formats.md). For chunking strategies, see [Document Chunking](docling-project/docling/8.2-document-chunking.md).\n\nSources: [README.md1-161](https://github.com/docling-project/docling/blob/f7244a43/README.md#L1-L161) [docs/index.md1-70](https://github.com/docling-project/docling/blob/f7244a43/docs/index.md#L1-L70) [mkdocs.yml128-162](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L128-L162) [pyproject.toml1-280](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L1-L280)\n\nDismiss\n\nRefresh this wiki\n\nThis wiki was recently refreshed. Please wait 4 days to refresh again.\n\n### On this page",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 991,
      "character_count": 4159,
      "created_at": "2025-10-16T17:42:17.827907",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 5,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [Framework Integrations](#framework-integrations.md)\n- [Purpose and Scope](#purpose-and-scope.md)\n- [Integration Architecture Overview](#integration-architecture-overview.md)\n- [DoclingDocument as Integration Foundation](#doclingdocument-as-integration-foundation.md)\n- [Key Export Methods](#key-export-methods.md)\n- [Model Context Protocol (MCP) Integration](#model-context-protocol-mcp-integration.md)\n- [MCP Server Architecture](#mcp-server-architecture.md)\n- [Configuration Example](#configuration-example.md)\n- [AI Framework Integrations](#ai-framework-integrations.md)\n- [LangChain Integration](#langchain-integration.md)\n- [LlamaIndex Integration](#llamaindex-integration.md)\n- [Haystack Integration](#haystack-integration.md)\n- [Agentic AI Frameworks](#agentic-ai-frameworks.md)\n- [Vector Database Integrations](#vector-database-integrations.md)\n- [Supported Vector Databases](#supported-vector-databases.md)\n- [Data Processing Framework Integrations](#data-processing-framework-integrations.md)\n- [Data Prep Kit (DPK)](#data-prep-kit-dpk.md)\n- [InstructLab Integration](#instructlab-integration.md)\n- [Enterprise & Production Integrations](#enterprise-production-integrations.md)\n- [Integration Development Patterns](#integration-development-patterns.md)\n- [Common Integration Pattern](#common-integration-pattern.md)\n- [Code Structure Example](#code-structure-example.md)\n- [Export Format Selection](#export-format-selection.md)\n- [Environment Variables and Configuration](#environment-variables-and-configuration.md)\n- [Installation for Integrations](#installation-for-integrations.md)\n- [Summary](#summary.md)",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 380,
      "character_count": 1623,
      "created_at": "2025-10-16T17:42:17.828109",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 6,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8.3-framework-integrations.md",
      "collection_context": "Docling"
    }
  }
]
[
  {
    "text": "Installation | docling-project/docling | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[docling-project/docling](https://github.com/docling-project/docling \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 12 October 2025 ([f7244a](https://github.com/docling-project/docling/commits/f7244a43))",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 113,
      "character_count": 413,
      "created_at": "2025-10-16T17:42:16.356812",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 0,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [Overview](docling-project/docling/1-overview.md)\n- [Installation](docling-project/docling/1.1-installation.md)\n- [Quick Start](docling-project/docling/1.2-quick-start.md)\n- [Core Architecture](docling-project/docling/2-core-architecture.md)\n- [Document Conversion Flow](docling-project/docling/2.1-document-conversion-flow.md)\n- [DoclingDocument Data Model](docling-project/docling/2.2-doclingdocument-data-model.md)\n- [Configuration and Pipeline Options](docling-project/docling/2.3-configuration-and-pipeline-options.md)\n- [Format Detection and Routing](docling-project/docling/2.4-format-detection-and-routing.md)\n- [Document Backends](docling-project/docling/3-document-backends.md)\n- [PDF Processing Backends](docling-project/docling/3.1-pdf-processing-backends.md)\n- [Office Document Backends](docling-project/docling/3.2-office-document-backends.md)\n- [Web and Markup Backends](docling-project/docling/3.3-web-and-markup-backends.md)\n- [AI/ML Models](docling-project/docling/4-aiml-models.md)\n- [OCR Models](docling-project/docling/4.1-ocr-models.md)\n- [Layout and Table Structure Models](docling-project/docling/4.2-layout-and-table-structure-models.md)\n- [Vision Language Models](docling-project/docling/4.3-vision-language-models.md)\n- [Inline VLM Models](docling-project/docling/4.3.1-inline-vlm-models.md)\n- [API-Based VLM Models](docling-project/docling/4.3.2-api-based-vlm-models.md)\n- [Enrichment Models](docling-project/docling/4.4-enrichment-models.md)\n- [Processing Pipelines](docling-project/docling/5-processing-pipelines.md)\n- [Standard PDF Pipeline](docling-project/docling/5.1-standard-pdf-pipeline.md)\n- [Threaded PDF Pipeline](docling-project/docling/5.2-threaded-pdf-pipeline.md)\n- [VLM Pipeline](docling-project/docling/5.3-vlm-pipeline.md)\n- [Extraction Pipeline](docling-project/docling/5.4-extraction-pipeline.md)\n- [ASR Pipeline](docling-project/docling/5.5-asr-pipeline.md)\n- [Base Pipeline Architecture](docling-project/docling/5.6-base-pipeline-architecture.md)\n- [Command Line Interface](docling-project/docling/6-command-line-interface.md)\n- [Document Conversion CLI](docling-project/docling/6.1-document-conversion-cli.md)\n- [Model Management CLI](docling-project/docling/6.2-model-management-cli.md)\n- [Python SDK](docling-project/docling/7-python-sdk.md)\n- [DocumentConverter API](docling-project/docling/7.1-documentconverter-api.md)\n- [DocumentExtractor API](docling-project/docling/7.2-documentextractor-api.md)\n- [Usage Examples](docling-project/docling/7.3-usage-examples.md)\n- [Output and Integration](docling-project/docling/8-output-and-integration.md)\n- [Export Formats](docling-project/docling/8.1-export-formats.md)\n- [Document Chunking](docling-project/docling/8.2-document-chunking.md)\n- [Framework Integrations](docling-project/docling/8.3-framework-integrations.md)\n- [Development and Testing](docling-project/docling/9-development-and-testing.md)\n- [Testing Framework](docling-project/docling/9.1-testing-framework.md)\n- [Ground Truth Data](docling-project/docling/9.2-ground-truth-data.md)\n- [CI/CD and Development Workflow](docling-project/docling/9.3-cicd-and-development-workflow.md)\n- [Deployment](docling-project/docling/10-deployment.md)\n- [Docker Deployment](docling-project/docling/10.1-docker-deployment.md)\n- [Model Artifacts Management](docling-project/docling/10.2-model-artifacts-management.md)\n\nMenu\n\n# Installation\n\nRelevant source files",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 925,
      "character_count": 3411,
      "created_at": "2025-10-16T17:42:16.359071",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 1,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [.github/SECURITY.md](https://github.com/docling-project/docling/blob/f7244a43/.github/SECURITY.md)\n- [CHANGELOG.md](https://github.com/docling-project/docling/blob/f7244a43/CHANGELOG.md)\n- [CITATION.cff](https://github.com/docling-project/docling/blob/f7244a43/CITATION.cff)\n- [docling/cli/models.py](https://github.com/docling-project/docling/blob/f7244a43/docling/cli/models.py)\n- [docling/models/auto\\_ocr\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/auto_ocr_model.py)\n- [docling/models/picture\\_description\\_vlm\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/picture_description_vlm_model.py)\n- [docling/models/plugins/defaults.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/plugins/defaults.py)\n- [docling/models/rapid\\_ocr\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/rapid_ocr_model.py)\n- [docling/utils/model\\_downloader.py](https://github.com/docling-project/docling/blob/f7244a43/docling/utils/model_downloader.py)\n- [pyproject.toml](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml)\n- [uv.lock](https://github.com/docling-project/docling/blob/f7244a43/uv.lock)\n\n## Purpose and Scope\n\nThis page provides comprehensive instructions for installing Docling, including system requirements, dependency management, and model artifact setup. It covers base installation, optional feature packages, platform-specific considerations, and offline deployment scenarios.\n\nFor information about using Docling after installation, see [Quick Start](docling-project/docling/1.2-quick-start.md). For advanced configuration options, see [Configuration and Pipeline Options](docling-project/docling/2.3-configuration-and-pipeline-options.md).\n\n---\n\n## System Requirements\n\n### Python Version\n\nDocling requires **Python 3.9 or higher, but less than 4.0**. The package supports Python 3.9 through 3.13.\n\n```\nrequires-python = '>=3.9,<4.0'\n```\n\n### Platform Support\n\nDocling is tested and supported on:\n\n| Platform    | Architecture                             | Notes                                        |\n| ----------- | ---------------------------------------- | -------------------------------------------- |\n| **macOS**   | x86\\_64, arm64                           | Full support including native OCR (`ocrmac`) |\n| **Linux**   | x86\\_64, aarch64, armv7l, ppc64le, s390x | vLLM backend only on x86\\_64                 |\n| **Windows** | x86\\_64, i686                            | Full support                                 |\n\nSources: [pyproject.toml19-32](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L19-L32) [pyproject.toml94-100](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L94-L100)\n\n---\n\n## Base Installation\n\n### Standard Installation\n\nInstall Docling using pip or uv:\n\n```\n```\n\nor with uv:\n\n```\n```\n\nThis installs the core package with the following key dependencies:\n\n| Dependency                   | Purpose                                  |\n| ---------------------------- | ---------------------------------------- |\n| `docling-core`               | Unified document data model and chunking |\n| `docling-parse`              | Text extraction from PDFs                |\n| `docling-ibm-models`         | AI model implementations                 |\n| `pypdfium2`                  | PDF rendering backend                    |\n| `rapidocr`                   | Default OCR engine (Python <3.14)        |\n| `python-docx`, `python-pptx` | Office document parsing                  |\n| `beautifulsoup4`, `lxml`     | HTML/XML parsing                         |\n| `openpyxl`                   | Excel file support                       |\n| `pillow`                     | Image processing                         |\n| `transformers`, `accelerate` | ML model inference                       |\n\n### Installation Architecture\n\n```\n```\n\nSources: [pyproject.toml45-76](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L45-L76) [pyproject.toml91-110](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L91-L110)\n\n---\n\n## Optional Extras\n\nDocling provides several optional feature packages installed via extras syntax:\n\n```\n```\n\n### OCR Engines\n\n#### EasyOCR\n\nDeep learning-based OCR engine:\n\n```\n```",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 1023,
      "character_count": 4354,
      "created_at": "2025-10-16T17:42:16.370132",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 2,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "Installs: `easyocr>=1.7,<2.0`\n\n#### Tesseract OCR\n\nPython binding for Tesseract OCR:\n\n```\n```\n\nInstalls: `tesserocr>=2.7.1,<3.0.0`\n\n**Note**: Requires Tesseract system libraries. On RHEL/CentOS, also install OSD data:\n\n```\n```\n\n#### macOS Native OCR\n\nNative Vision framework OCR (macOS only):\n\n```\n```\n\nInstalls: `ocrmac>=1.0.0,<2.0.0` (only on Darwin systems)\n\n#### RapidOCR with ONNX Runtime\n\nOptimized OCR with ONNX backend:\n\n```\n```\n\nInstalls: `rapidocr>=3.3,<4.0.0` + `onnxruntime>=1.7.0,<2.0.0`\n\n**Note**: `rapidocr` is included in base installation for Python <3.14, but without `onnxruntime`. This extra adds ONNX acceleration.\n\n### Vision Language Models (VLM)\n\nFor end-to-end document understanding with VLMs:\n\n```\n```\n\nIncludes:\n\n- `transformers>=4.46.0,<5.0.0` - HuggingFace Transformers backend\n- `accelerate>=1.2.1,<2.0.0` - Model acceleration\n- `mlx-vlm>=0.3.0,<1.0.0` - Apple Silicon acceleration (macOS arm64, Python ≥3.10)\n- `vllm>=0.10.0,<1.0.0` - Optimized inference (Linux x86\\_64, Python ≥3.10)\n- `qwen-vl-utils>=0.0.11` - Qwen VL utilities\n\n**Platform Requirements**:\n\n- `mlx-vlm`: macOS (arm64) and Python ≥3.10\n- `vllm`: Linux (x86\\_64) and Python ≥3.10\n\n### Audio Transcription (ASR)\n\nFor processing audio files:\n\n```\n```\n\nInstalls: `openai-whisper>=20250625`\n\n### Optional Extras Summary Table\n\n| Extra       | Purpose                | Platform Constraints                                             | Key Dependencies                          |\n| ----------- | ---------------------- | ---------------------------------------------------------------- | ----------------------------------------- |\n| `easyocr`   | Deep learning OCR      | All                                                              | `easyocr>=1.7`                            |\n| `tesserocr` | Tesseract binding      | All (requires system libs)                                       | `tesserocr>=2.7.1`                        |\n| `ocrmac`    | Native macOS OCR       | macOS only                                                       | `ocrmac>=1.0.0`                           |\n| `rapidocr`  | ONNX-accelerated OCR   | All                                                              | `rapidocr>=3.3`, `onnxruntime>=1.7.0`     |\n| `vlm`       | Vision language models | mlx: macOS arm64, Python ≥3.10 vllm: Linux x86\\_64, Python ≥3.10 | `transformers>=4.46.0`, `mlx-vlm`, `vllm` |\n| `asr`       | Audio transcription    | All                                                              | `openai-whisper>=20250625`                |\n\nSources: [pyproject.toml91-110](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L91-L110)\n\n---\n\n## Model Artifacts\n\nDocling uses pre-trained AI models for document understanding. Models can be downloaded automatically (online mode) or pre-downloaded for offline deployment.\n\n### Automatic Download (Online Mode)\n\nBy default, models are downloaded automatically on first use from HuggingFace or ModelScope. They are cached in:\n\n```\n~/.cache/docling/models/\n```\n\nor the directory specified by the `DOCLING_CACHE_DIR` environment variable.\n\n### Pre-downloading Models (Offline Mode)\n\nThe `docling-tools` CLI provides commands for pre-downloading models.\n\n#### Download Default Models\n\nDownload the standard set of models (layout, tableformer, code\\_formula, picture\\_classifier, rapidocr):\n\n```\n```\n\n#### Download Specific Models\n\n```\n```\n\n#### Download All Available Models\n\n```\n```\n\n#### Available Model Options",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 888,
      "character_count": 3473,
      "created_at": "2025-10-16T17:42:16.380617",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 3,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "| Model                | Description                                  | Default |\n| -------------------- | -------------------------------------------- | ------- |\n| `layout`             | Heron layout analysis model                  | ✓       |\n| `tableformer`        | Table structure recognition                  | ✓       |\n| `code_formula`       | Code and formula detection                   | ✓       |\n| `picture_classifier` | Image classification                         | ✓       |\n| `rapidocr`           | RapidOCR models (both torch and onnxruntime) | ✓       |\n| `easyocr`            | EasyOCR models                               | ✗       |\n| `smolvlm`            | SmolVLM vision model                         | ✗       |\n| `granitedocling`     | GraniteDocling VLM (Transformers)            | ✗       |\n| `granitedocling_mlx` | GraniteDocling VLM (MLX, macOS)              | ✗       |\n| `smoldocling`        | SmolDocling VLM (Transformers)               | ✗       |\n| `smoldocling_mlx`    | SmolDocling VLM (MLX, macOS)                 | ✗       |\n| `granite_vision`     | Granite Vision picture description           | ✗       |\n\n#### Download Arbitrary HuggingFace Models\n\nFor custom models or repositories:\n\n```\n```\n\n### Using Pre-downloaded Models\n\nAfter downloading, configure Docling to use local artifacts:\n\n**CLI**:\n\n```\n```\n\n**Python**:\n\n```\n```\n\n### Model Download Architecture\n\n```\n```\n\nSources: [docling/cli/models.py54-136](https://github.com/docling-project/docling/blob/f7244a43/docling/cli/models.py#L54-L136) [docling/utils/model\\_downloader.py30-158](https://github.com/docling-project/docling/blob/f7244a43/docling/utils/model_downloader.py#L30-L158)\n\n---\n\n## OCR Engine Selection\n\nDocling's `OcrAutoModel` automatically selects the best available OCR engine based on platform and installed packages.\n\n### Selection Priority\n\nThe auto-selection follows this priority order:\n\n```\n```\n\n**Priority Order**:\n\n1. **OcrMacModel** (macOS only) - Uses native Vision framework\n2. **RapidOcrModel with onnxruntime** - Fast ONNX-accelerated inference\n3. **EasyOcrModel** - Deep learning-based OCR\n4. **RapidOcrModel with torch** - PyTorch-based inference\n\nIf no engine is found, a warning is logged: \"No OCR engine found. Please review the install details.\"\n\nSources: [docling/models/auto\\_ocr\\_model.py41-121](https://github.com/docling-project/docling/blob/f7244a43/docling/models/auto_ocr_model.py#L41-L121)\n\n---\n\n## RapidOCR Model Configuration\n\nRapidOCR requires model files to be downloaded. The system automatically manages this through `RapidOcrModel.download_models()`.\n\n### Default Models\n\nRapidOCR uses PP-OCRv4 models from ModelScope:\n\n| Component      | Purpose               | ONNX Path                                                     | Torch Path                                              |\n| -------------- | --------------------- | ------------------------------------------------------------- | ------------------------------------------------------- |\n| Detection      | Text region detection | `onnx/PP-OCRv4/det/ch_PP-OCRv4_det_infer.onnx`                | `torch/PP-OCRv4/det/ch_PP-OCRv4_det_infer.pth`          |\n| Classification | Text orientation      | `onnx/PP-OCRv4/cls/ch_ppocr_mobile_v2.0_cls_infer.onnx`       | `torch/PP-OCRv4/cls/ch_ptocr_mobile_v2.0_cls_infer.pth` |\n| Recognition    | Character recognition | `onnx/PP-OCRv4/rec/ch_PP-OCRv4_rec_infer.onnx`                | `torch/PP-OCRv4/rec/ch_PP-OCRv4_rec_infer.pth`          |\n| Keys           | Character dictionary  | `paddle/PP-OCRv4/rec/ch_PP-OCRv4_rec_infer/ppocr_keys_v1.txt` | Same                                                    |\n\n### Model Download Process\n\nWhen `docling-tools download rapidocr` is executed:\n\n1. Both `onnxruntime` and `torch` backend models are downloaded\n2. Models are fetched from ModelScope CDN\n3. Files are stored in `{cache_dir}/models/RapidOcr/`\n4. Model paths follow the structure defined in `_default_models` dictionary",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 952,
      "character_count": 3981,
      "created_at": "2025-10-16T17:42:16.390928",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 4,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "Sources: [docling/models/rapid\\_ocr\\_model.py38-80](https://github.com/docling-project/docling/blob/f7244a43/docling/models/rapid_ocr_model.py#L38-L80) [docling/models/rapid\\_ocr\\_model.py202-224](https://github.com/docling-project/docling/blob/f7244a43/docling/models/rapid_ocr_model.py#L202-L224)\n\n---\n\n## Platform-Specific Setup\n\n### macOS\n\n**Native OCR**:\n\n- Install `ocrmac` extra for native Vision framework OCR\n- Automatically selected by `OcrAutoModel` on macOS\n- Best performance on Apple Silicon with MLX models\n\n**MLX Acceleration**:\n\n- For VLM models on Apple Silicon (arm64), install `vlm` extra\n- Enables `mlx-vlm>=0.3.0` (Python ≥3.10 required)\n- Provides hardware acceleration for M1/M2/M3 chips\n\n**Example**:\n\n```\n```\n\n### Linux\n\n**CUDA Support**:\n\n- Core dependencies support CUDA acceleration\n- VLM extra includes `vllm` for optimized inference (x86\\_64 only, Python ≥3.10)\n- Use `--device=cuda` or `DOCLING_DEVICE=cuda` for GPU acceleration\n\n**System Dependencies for Tesseract**:\n\n```\n```\n\n**Example**:\n\n```\n```\n\n### Windows\n\nWindows is fully supported for core functionality and most OCR engines.\n\n**Limitations**:\n\n- `vllm` backend not available (Linux x86\\_64 only)\n- `mlx-vlm` not available (macOS only)\n\n**Example**:\n\n```\n```\n\nSources: [pyproject.toml55](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L55-L55) [pyproject.toml94-99](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L94-L99)\n\n---\n\n## Verification\n\n### Verify Installation\n\nCheck that Docling is installed correctly:\n\n```\n```\n\n### Verify OCR Engine\n\nTest OCR engine selection:\n\n```\n```\n\nExpected log output:\n\n```\nINFO: Auto OCR model selected rapidocr with onnxruntime.\n```\n\nor\n\n```\nINFO: Auto OCR model selected ocrmac.\n```\n\n### Verify Model Downloads\n\nCheck that models are cached:\n\n```\n```\n\nExpected directories:\n\n- `Heron/` - Layout model\n- `TableFormer/` - Table structure model\n- `RapidOcr/` - OCR models\n- Other model directories based on usage\n\n### Verify VLM Installation\n\nIf VLM extra is installed:\n\n```\n```\n\nSources: [docling/models/auto\\_ocr\\_model.py42-120](https://github.com/docling-project/docling/blob/f7244a43/docling/models/auto_ocr_model.py#L42-L120) [docling/cli/models.py54-136](https://github.com/docling-project/docling/blob/f7244a43/docling/cli/models.py#L54-L136)\n\n---\n\n## Troubleshooting\n\n### Common Issues\n\n**Issue**: `No OCR engine found` warning\n\n**Solution**: Install at least one OCR engine:\n\n```\n```\n\n**Issue**: `ImportError: transformers >=4.46 is not installed`\n\n**Solution**: Install VLM extra:\n\n```\n```\n\n**Issue**: RapidOCR returns empty results\n\n**Solution**: Ensure models are downloaded:\n\n```\n```\n\n**Issue**: Tesseract OSD errors on RHEL\n\n**Solution**: Install OSD data package:\n\n```\n```\n\n### Dependency Conflicts\n\nIf you encounter dependency conflicts, consider using `uv` for better dependency resolution:\n\n```\n```\n\nSources: [docling/models/rapid\\_ocr\\_model.py100-106](https://github.com/docling-project/docling/blob/f7244a43/docling/models/rapid_ocr_model.py#L100-L106) [docling/models/picture\\_description\\_vlm\\_model.py56-62](https://github.com/docling-project/docling/blob/f7244a43/docling/models/picture_description_vlm_model.py#L56-L62)\n\n---\n\n## Environment Variables\n\nThe following environment variables affect installation and runtime behavior:\n\n| Variable              | Purpose                               | Default                    |\n| --------------------- | ------------------------------------- | -------------------------- |\n| `DOCLING_CACHE_DIR`   | Model cache directory                 | `~/.cache/docling`         |\n| `DOCLING_DEVICE`      | Compute device (cpu, cuda, mps, auto) | `auto`                     |\n| `OMP_NUM_THREADS`     | OpenMP thread count                   | System default             |\n| `DOCLING_NUM_THREADS` | Docling-specific thread count         | Value of `OMP_NUM_THREADS` |\n\nExample:\n\n```\n```",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 1009,
      "character_count": 3924,
      "created_at": "2025-10-16T17:42:16.407813",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 5,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "Sources: [pyproject.toml1-110](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L1-L110)\n\nDismiss\n\nRefresh this wiki\n\nThis wiki was recently refreshed. Please wait 4 days to refresh again.\n\n### On this page\n\n- [Installation](#installation.md)\n- [Purpose and Scope](#purpose-and-scope.md)\n- [System Requirements](#system-requirements.md)\n- [Python Version](#python-version.md)\n- [Platform Support](#platform-support.md)\n- [Base Installation](#base-installation.md)\n- [Standard Installation](#standard-installation.md)\n- [Installation Architecture](#installation-architecture.md)\n- [Optional Extras](#optional-extras.md)\n- [OCR Engines](#ocr-engines.md)\n- [EasyOCR](#easyocr.md)\n- [Tesseract OCR](#tesseract-ocr.md)\n- [macOS Native OCR](#macos-native-ocr.md)\n- [RapidOCR with ONNX Runtime](#rapidocr-with-onnx-runtime.md)\n- [Vision Language Models (VLM)](#vision-language-models-vlm.md)\n- [Audio Transcription (ASR)](#audio-transcription-asr.md)\n- [Optional Extras Summary Table](#optional-extras-summary-table.md)\n- [Model Artifacts](#model-artifacts.md)\n- [Automatic Download (Online Mode)](#automatic-download-online-mode.md)\n- [Pre-downloading Models (Offline Mode)](#pre-downloading-models-offline-mode.md)\n- [Download Default Models](#download-default-models.md)\n- [Download Specific Models](#download-specific-models.md)\n- [Download All Available Models](#download-all-available-models.md)\n- [Available Model Options](#available-model-options.md)\n- [Download Arbitrary HuggingFace Models](#download-arbitrary-huggingface-models.md)\n- [Using Pre-downloaded Models](#using-pre-downloaded-models.md)\n- [Model Download Architecture](#model-download-architecture.md)\n- [OCR Engine Selection](#ocr-engine-selection.md)\n- [Selection Priority](#selection-priority.md)\n- [RapidOCR Model Configuration](#rapidocr-model-configuration.md)\n- [Default Models](#default-models.md)\n- [Model Download Process](#model-download-process.md)\n- [Platform-Specific Setup](#platform-specific-setup.md)\n- [macOS](#macos.md)\n- [Linux](#linux.md)\n- [Windows](#windows.md)\n- [Verification](#verification.md)\n- [Verify Installation](#verify-installation.md)\n- [Verify OCR Engine](#verify-ocr-engine.md)\n- [Verify Model Downloads](#verify-model-downloads.md)\n- [Verify VLM Installation](#verify-vlm-installation.md)\n- [Troubleshooting](#troubleshooting.md)\n- [Common Issues](#common-issues.md)\n- [Dependency Conflicts](#dependency-conflicts.md)\n- [Environment Variables](#environment-variables.md)",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 634,
      "character_count": 2495,
      "created_at": "2025-10-16T17:42:16.408544",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 6,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_1.1-installation.md",
      "collection_context": "Docling"
    }
  }
]
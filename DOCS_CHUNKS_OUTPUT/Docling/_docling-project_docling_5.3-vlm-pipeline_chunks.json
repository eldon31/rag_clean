[
  {
    "text": "VLM Pipeline | docling-project/docling | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[docling-project/docling](https://github.com/docling-project/docling \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 12 October 2025 ([f7244a](https://github.com/docling-project/docling/commits/f7244a43))",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 115,
      "character_count": 413,
      "created_at": "2025-10-16T17:42:17.278983",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 0,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [Overview](docling-project/docling/1-overview.md)\n- [Installation](docling-project/docling/1.1-installation.md)\n- [Quick Start](docling-project/docling/1.2-quick-start.md)\n- [Core Architecture](docling-project/docling/2-core-architecture.md)\n- [Document Conversion Flow](docling-project/docling/2.1-document-conversion-flow.md)\n- [DoclingDocument Data Model](docling-project/docling/2.2-doclingdocument-data-model.md)\n- [Configuration and Pipeline Options](docling-project/docling/2.3-configuration-and-pipeline-options.md)\n- [Format Detection and Routing](docling-project/docling/2.4-format-detection-and-routing.md)\n- [Document Backends](docling-project/docling/3-document-backends.md)\n- [PDF Processing Backends](docling-project/docling/3.1-pdf-processing-backends.md)\n- [Office Document Backends](docling-project/docling/3.2-office-document-backends.md)\n- [Web and Markup Backends](docling-project/docling/3.3-web-and-markup-backends.md)\n- [AI/ML Models](docling-project/docling/4-aiml-models.md)\n- [OCR Models](docling-project/docling/4.1-ocr-models.md)\n- [Layout and Table Structure Models](docling-project/docling/4.2-layout-and-table-structure-models.md)\n- [Vision Language Models](docling-project/docling/4.3-vision-language-models.md)\n- [Inline VLM Models](docling-project/docling/4.3.1-inline-vlm-models.md)\n- [API-Based VLM Models](docling-project/docling/4.3.2-api-based-vlm-models.md)\n- [Enrichment Models](docling-project/docling/4.4-enrichment-models.md)\n- [Processing Pipelines](docling-project/docling/5-processing-pipelines.md)\n- [Standard PDF Pipeline](docling-project/docling/5.1-standard-pdf-pipeline.md)\n- [Threaded PDF Pipeline](docling-project/docling/5.2-threaded-pdf-pipeline.md)\n- [VLM Pipeline](docling-project/docling/5.3-vlm-pipeline.md)\n- [Extraction Pipeline](docling-project/docling/5.4-extraction-pipeline.md)\n- [ASR Pipeline](docling-project/docling/5.5-asr-pipeline.md)\n- [Base Pipeline Architecture](docling-project/docling/5.6-base-pipeline-architecture.md)\n- [Command Line Interface](docling-project/docling/6-command-line-interface.md)\n- [Document Conversion CLI](docling-project/docling/6.1-document-conversion-cli.md)\n- [Model Management CLI](docling-project/docling/6.2-model-management-cli.md)\n- [Python SDK](docling-project/docling/7-python-sdk.md)\n- [DocumentConverter API](docling-project/docling/7.1-documentconverter-api.md)\n- [DocumentExtractor API](docling-project/docling/7.2-documentextractor-api.md)\n- [Usage Examples](docling-project/docling/7.3-usage-examples.md)\n- [Output and Integration](docling-project/docling/8-output-and-integration.md)\n- [Export Formats](docling-project/docling/8.1-export-formats.md)\n- [Document Chunking](docling-project/docling/8.2-document-chunking.md)\n- [Framework Integrations](docling-project/docling/8.3-framework-integrations.md)\n- [Development and Testing](docling-project/docling/9-development-and-testing.md)\n- [Testing Framework](docling-project/docling/9.1-testing-framework.md)\n- [Ground Truth Data](docling-project/docling/9.2-ground-truth-data.md)\n- [CI/CD and Development Workflow](docling-project/docling/9.3-cicd-and-development-workflow.md)\n- [Deployment](docling-project/docling/10-deployment.md)\n- [Docker Deployment](docling-project/docling/10.1-docker-deployment.md)\n- [Model Artifacts Management](docling-project/docling/10.2-model-artifacts-management.md)\n\nMenu\n\n# VLM Pipeline\n\nRelevant source files",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 927,
      "character_count": 3411,
      "created_at": "2025-10-16T17:42:17.281561",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 1,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [README.md](https://github.com/docling-project/docling/blob/f7244a43/README.md)\n- [docling/datamodel/extraction.py](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/extraction.py)\n- [docling/document\\_extractor.py](https://github.com/docling-project/docling/blob/f7244a43/docling/document_extractor.py)\n- [docling/models/vlm\\_models\\_inline/nuextract\\_transformers\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/vlm_models_inline/nuextract_transformers_model.py)\n- [docling/pipeline/asr\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py)\n- [docling/pipeline/base\\_extraction\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/base_extraction_pipeline.py)\n- [docling/pipeline/base\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/base_pipeline.py)\n- [docling/pipeline/extraction\\_vlm\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/extraction_vlm_pipeline.py)\n- [docling/pipeline/simple\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/simple_pipeline.py)\n- [docling/pipeline/threaded\\_standard\\_pdf\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/threaded_standard_pdf_pipeline.py)\n- [docling/pipeline/vlm\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py)\n- [docs/examples/minimal\\_vlm\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docs/examples/minimal_vlm_pipeline.py)\n- [docs/index.md](https://github.com/docling-project/docling/blob/f7244a43/docs/index.md)\n- [docs/usage/index.md](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/index.md)\n- [docs/usage/mcp.md](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/mcp.md)\n- [docs/usage/vision\\_models.md](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/vision_models.md)\n- [mkdocs.yml](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml)\n\nThe VLM Pipeline provides vision-language model based document processing capabilities for converting documents (primarily PDFs) into structured formats using AI models that can understand both text and images. This pipeline leverages various VLM backends including local models via HuggingFace Transformers, MLX for Apple Silicon optimization, VLLM for high-throughput inference, and remote API services.\n\nFor traditional PDF processing without VLM capabilities, see [Standard PDF Pipeline](docling-project/docling/5.1-standard-pdf-pipeline.md). For base pipeline architecture and common functionality, see [Base Pipeline Architecture](docling-project/docling/5.3-vlm-pipeline.md).\n\n## Architecture Overview\n\nThe VLM Pipeline architecture centers around the `VlmPipeline` class which orchestrates different VLM model implementations to process document pages as images and generate structured output.\n\n### VLM Pipeline System Architecture\n\n```\n```\n\nSources: [docling/pipeline/vlm\\_pipeline.py50-125](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L50-L125) [docling/datamodel/pipeline\\_options\\_vlm\\_model.py11-101](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options_vlm_model.py#L11-L101)\n\n### VLM Model Class Hierarchy\n\n```\n```",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 870,
      "character_count": 3472,
      "created_at": "2025-10-16T17:42:17.285717",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 2,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "Sources: [docling/models/base\\_model.py40-120](https://github.com/docling-project/docling/blob/f7244a43/docling/models/base_model.py#L40-L120) [docling/models/vlm\\_models\\_inline/hf\\_transformers\\_model.py32](https://github.com/docling-project/docling/blob/f7244a43/docling/models/vlm_models_inline/hf_transformers_model.py#L32-L32) [docling/models/vlm\\_models\\_inline/mlx\\_model.py30](https://github.com/docling-project/docling/blob/f7244a43/docling/models/vlm_models_inline/mlx_model.py#L30-L30) [docling/models/api\\_vlm\\_model.py13](https://github.com/docling-project/docling/blob/f7244a43/docling/models/api_vlm_model.py#L13-L13)\n\n## VLM Model Implementations\n\nThe VLM Pipeline supports multiple backend implementations for different use cases and hardware configurations.\n\n### HuggingFace Transformers Model\n\nThe `HuggingFaceTransformersVlmModel` provides local inference using the HuggingFace Transformers library with support for various model architectures.\n\n**Key Features:**\n\n- Supports multiple `TransformersModelType`: `AUTOMODEL`, `AUTOMODEL_VISION2SEQ`, `AUTOMODEL_CAUSALLM`, `AUTOMODEL_IMAGETEXTTOTEXT`\n- Batch processing with proper padding and attention handling\n- Flash Attention 2 support for CUDA devices\n- Quantization support via `BitsAndBytesConfig`\n- Multiple prompt styles: `CHAT`, `RAW`, `NONE`\n\n**Configuration Options:**\n\n- `repo_id`: HuggingFace model repository identifier\n- `quantized`: Enable 8-bit quantization\n- `torch_dtype`: Specify torch data type\n- `stop_strings`: Custom stopping criteria\n- `max_new_tokens`: Maximum generation length\n\nSources: [docling/models/vlm\\_models\\_inline/hf\\_transformers\\_model.py32-315](https://github.com/docling-project/docling/blob/f7244a43/docling/models/vlm_models_inline/hf_transformers_model.py#L32-L315) [docling/datamodel/pipeline\\_options\\_vlm\\_model.py52-84](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options_vlm_model.py#L52-L84)\n\n### MLX Model Implementation\n\nThe `HuggingFaceMlxModel` provides optimized inference for Apple Silicon using the MLX framework.\n\n**Key Features:**\n\n- Thread-safe with global locking mechanism (`_MLX_GLOBAL_LOCK`)\n- Stream generation with token-level processing\n- Optimized for Apple Silicon hardware\n- Support for stop string termination\n- Token-level logprob tracking\n\n**Thread Safety:**\n\n```\n```\n\nSources: [docling/models/vlm\\_models\\_inline/mlx\\_model.py25-261](https://github.com/docling-project/docling/blob/f7244a43/docling/models/vlm_models_inline/mlx_model.py#L25-L261)\n\n### API-Based VLM Model\n\nThe `ApiVlmModel` enables integration with remote VLM services through standardized chat completion APIs.\n\n**Key Features:**\n\n- Concurrent processing with `ThreadPoolExecutor`\n- Configurable timeout and concurrency limits\n- Custom headers and parameters support\n- Compatible with OpenAI-style chat completion APIs\n\n**Configuration Example:**\n\n- `url`: API endpoint (default: `http://localhost:11434/v1/chat/completions`)\n- `params`: API-specific parameters (model, temperature, etc.)\n- `headers`: Authentication and custom headers\n- `concurrency`: Maximum concurrent requests\n\nSources: [docling/models/api\\_vlm\\_model.py13-73](https://github.com/docling-project/docling/blob/f7244a43/docling/models/api_vlm_model.py#L13-L73) [docling/datamodel/pipeline\\_options\\_vlm\\_model.py90-101](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options_vlm_model.py#L90-L101)\n\n## Response Formats and Processing\n\nThe VLM Pipeline supports multiple response formats, each processed differently to generate the final `DoclingDocument`.\n\n### Response Format Processing Flow\n\n```\n```\n\nSources: [docling/pipeline/vlm\\_pipeline.py148-392](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L148-L392)\n\n### DocTags Format Processing\n\nDocTags format provides the most structured output with precise bounding box information and element classification.\n\n**Key Features:**",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 977,
      "character_count": 3980,
      "created_at": "2025-10-16T17:42:17.295783",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 3,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- Direct conversion to `DoclingDocument` via `DocTagsDocument.from_doctags_and_image_pairs()`\n- Preserves spatial relationships and element types\n- Optional backend text extraction with `force_backend_text`\n- Support for picture image generation\n\n**Backend Text Extraction:** When `force_backend_text=True` and `response_format=ResponseFormat.DOCTAGS`, the pipeline extracts actual text from the PDF backend using predicted bounding boxes instead of relying on VLM-generated text.\n\nSources: [docling/pipeline/vlm\\_pipeline.py200-238](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L200-L238)\n\n### Markdown and HTML Processing\n\nBoth Markdown and HTML formats follow similar processing patterns, using respective document backends for conversion.\n\n**Processing Steps:**\n\n1. Extract content from code blocks (triple backticks)\n2. Create temporary `BytesIO` stream with extracted content\n3. Use `MarkdownDocumentBackend` or `HTMLDocumentBackend` for conversion\n4. Generate page structure with image dimensions\n5. Add provenance information with placeholder bounding boxes\n\nSources: [docling/pipeline/vlm\\_pipeline.py240-392](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L240-L392)\n\n## Pipeline Configuration\n\nThe VLM Pipeline uses `VlmPipelineOptions` for configuration, which includes VLM-specific options and general pipeline settings.\n\n### Configuration Class Hierarchy\n\n```\n```\n\nSources: [docling/datamodel/pipeline\\_options.py](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options.py) [docling/datamodel/pipeline\\_options\\_vlm\\_model.py11-101](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options_vlm_model.py#L11-L101)\n\n### Key Configuration Parameters\n\n| Parameter                 | Type             | Description                                  |\n| ------------------------- | ---------------- | -------------------------------------------- |\n| `vlm_options`             | `BaseVlmOptions` | VLM model configuration (inline or API)      |\n| `force_backend_text`      | `bool`           | Extract text from backend vs VLM response    |\n| `generate_page_images`    | `bool`           | Generate page images for processing          |\n| `generate_picture_images` | `bool`           | Generate cropped images for picture elements |\n| `images_scale`            | `float`          | Image scaling factor                         |\n| `enable_remote_services`  | `bool`           | Allow API-based VLM calls                    |\n\nSources: [docling/pipeline/vlm\\_pipeline.py51-77](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L51-L77)\n\n## Pipeline Execution Flow\n\nThe VLM Pipeline follows the standard pipeline execution pattern with VLM-specific customizations.\n\n### VLM Pipeline Execution Sequence\n\n```\n```\n\nSources: [docling/pipeline/base\\_pipeline.py39-61](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/base_pipeline.py#L39-L61) [docling/pipeline/vlm\\_pipeline.py126-198](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L126-L198)\n\n### Page Initialization Process\n\nThe `initialize_page()` method prepares pages for VLM processing:\n\n1. **Backend Loading**: Load page backend via `conv_res.input._backend.load_page(page.page_no)`\n2. **Size Calculation**: Set `page.size` from backend dimensions\n3. **Conditional Text Extraction**: If `force_backend_text=True`, extract `parsed_page` for prompt construction\n\n**Backend Text Extraction Logic:**\n\n```\n```\n\nSources: [docling/pipeline/vlm\\_pipeline.py126-135](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L126-L135)\n\n## Integration with Base Pipeline\n\nThe VLM Pipeline extends `PaginatedPipeline` and integrates with the base pipeline architecture through standardized interfaces.\n\n### Pipeline Integration Points\n\n```\n```\n\nSources: [docling/pipeline/base\\_pipeline.py32-105](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/base_pipeline.py#L32-L105) [docling/pipeline/vlm\\_pipeline.py50-401](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L50-L401)\n\n### Backend Compatibility\n\nThe VLM Pipeline supports specific backend types through the `is_backend_supported()` method:\n\n```\n```\n\nCurrently, only `PdfDocumentBackend` instances are supported, limiting VLM processing to PDF documents.",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 1020,
      "character_count": 4521,
      "created_at": "2025-10-16T17:42:17.307716",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 4,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "Sources: [docling/pipeline/vlm\\_pipeline.py398-400](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L398-L400)\n\nDismiss\n\nRefresh this wiki\n\nThis wiki was recently refreshed. Please wait 4 days to refresh again.\n\n### On this page\n\n- [VLM Pipeline](#vlm-pipeline.md)\n- [Architecture Overview](#architecture-overview.md)\n- [VLM Pipeline System Architecture](#vlm-pipeline-system-architecture.md)\n- [VLM Model Class Hierarchy](#vlm-model-class-hierarchy.md)\n- [VLM Model Implementations](#vlm-model-implementations.md)\n- [HuggingFace Transformers Model](#huggingface-transformers-model.md)\n- [MLX Model Implementation](#mlx-model-implementation.md)\n- [API-Based VLM Model](#api-based-vlm-model.md)\n- [Response Formats and Processing](#response-formats-and-processing.md)\n- [Response Format Processing Flow](#response-format-processing-flow.md)\n- [DocTags Format Processing](#doctags-format-processing.md)\n- [Markdown and HTML Processing](#markdown-and-html-processing.md)\n- [Pipeline Configuration](#pipeline-configuration.md)\n- [Configuration Class Hierarchy](#configuration-class-hierarchy.md)\n- [Key Configuration Parameters](#key-configuration-parameters.md)\n- [Pipeline Execution Flow](#pipeline-execution-flow.md)\n- [VLM Pipeline Execution Sequence](#vlm-pipeline-execution-sequence.md)\n- [Page Initialization Process](#page-initialization-process.md)\n- [Integration with Base Pipeline](#integration-with-base-pipeline.md)\n- [Pipeline Integration Points](#pipeline-integration-points.md)\n- [Backend Compatibility](#backend-compatibility.md)",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 376,
      "character_count": 1584,
      "created_at": "2025-10-16T17:42:17.308262",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 5,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.3-vlm-pipeline.md",
      "collection_context": "Docling"
    }
  }
]
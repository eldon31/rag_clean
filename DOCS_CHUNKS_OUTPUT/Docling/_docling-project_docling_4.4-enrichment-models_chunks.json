[
  {
    "text": "Enrichment Models | docling-project/docling | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[docling-project/docling](https://github.com/docling-project/docling \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 12 October 2025 ([f7244a](https://github.com/docling-project/docling/commits/f7244a43))",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 116,
      "character_count": 418,
      "created_at": "2025-10-16T17:42:17.112335",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 0,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [Overview](docling-project/docling/1-overview.md)\n- [Installation](docling-project/docling/1.1-installation.md)\n- [Quick Start](docling-project/docling/1.2-quick-start.md)\n- [Core Architecture](docling-project/docling/2-core-architecture.md)\n- [Document Conversion Flow](docling-project/docling/2.1-document-conversion-flow.md)\n- [DoclingDocument Data Model](docling-project/docling/2.2-doclingdocument-data-model.md)\n- [Configuration and Pipeline Options](docling-project/docling/2.3-configuration-and-pipeline-options.md)\n- [Format Detection and Routing](docling-project/docling/2.4-format-detection-and-routing.md)\n- [Document Backends](docling-project/docling/3-document-backends.md)\n- [PDF Processing Backends](docling-project/docling/3.1-pdf-processing-backends.md)\n- [Office Document Backends](docling-project/docling/3.2-office-document-backends.md)\n- [Web and Markup Backends](docling-project/docling/3.3-web-and-markup-backends.md)\n- [AI/ML Models](docling-project/docling/4-aiml-models.md)\n- [OCR Models](docling-project/docling/4.1-ocr-models.md)\n- [Layout and Table Structure Models](docling-project/docling/4.2-layout-and-table-structure-models.md)\n- [Vision Language Models](docling-project/docling/4.3-vision-language-models.md)\n- [Inline VLM Models](docling-project/docling/4.3.1-inline-vlm-models.md)\n- [API-Based VLM Models](docling-project/docling/4.3.2-api-based-vlm-models.md)\n- [Enrichment Models](docling-project/docling/4.4-enrichment-models.md)\n- [Processing Pipelines](docling-project/docling/5-processing-pipelines.md)\n- [Standard PDF Pipeline](docling-project/docling/5.1-standard-pdf-pipeline.md)\n- [Threaded PDF Pipeline](docling-project/docling/5.2-threaded-pdf-pipeline.md)\n- [VLM Pipeline](docling-project/docling/5.3-vlm-pipeline.md)\n- [Extraction Pipeline](docling-project/docling/5.4-extraction-pipeline.md)\n- [ASR Pipeline](docling-project/docling/5.5-asr-pipeline.md)\n- [Base Pipeline Architecture](docling-project/docling/5.6-base-pipeline-architecture.md)\n- [Command Line Interface](docling-project/docling/6-command-line-interface.md)\n- [Document Conversion CLI](docling-project/docling/6.1-document-conversion-cli.md)\n- [Model Management CLI](docling-project/docling/6.2-model-management-cli.md)\n- [Python SDK](docling-project/docling/7-python-sdk.md)\n- [DocumentConverter API](docling-project/docling/7.1-documentconverter-api.md)\n- [DocumentExtractor API](docling-project/docling/7.2-documentextractor-api.md)\n- [Usage Examples](docling-project/docling/7.3-usage-examples.md)\n- [Output and Integration](docling-project/docling/8-output-and-integration.md)\n- [Export Formats](docling-project/docling/8.1-export-formats.md)\n- [Document Chunking](docling-project/docling/8.2-document-chunking.md)\n- [Framework Integrations](docling-project/docling/8.3-framework-integrations.md)\n- [Development and Testing](docling-project/docling/9-development-and-testing.md)\n- [Testing Framework](docling-project/docling/9.1-testing-framework.md)\n- [Ground Truth Data](docling-project/docling/9.2-ground-truth-data.md)\n- [CI/CD and Development Workflow](docling-project/docling/9.3-cicd-and-development-workflow.md)\n- [Deployment](docling-project/docling/10-deployment.md)\n- [Docker Deployment](docling-project/docling/10.1-docker-deployment.md)\n- [Model Artifacts Management](docling-project/docling/10.2-model-artifacts-management.md)\n\nMenu\n\n# Enrichment Models\n\nRelevant source files",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 928,
      "character_count": 3416,
      "created_at": "2025-10-16T17:42:17.114853",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 1,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [docling/cli/models.py](https://github.com/docling-project/docling/blob/f7244a43/docling/cli/models.py)\n- [docling/models/auto\\_ocr\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/auto_ocr_model.py)\n- [docling/models/base\\_ocr\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/base_ocr_model.py)\n- [docling/models/code\\_formula\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/code_formula_model.py)\n- [docling/models/document\\_picture\\_classifier.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/document_picture_classifier.py)\n- [docling/models/easyocr\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/easyocr_model.py)\n- [docling/models/layout\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/layout_model.py)\n- [docling/models/page\\_assemble\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/page_assemble_model.py)\n- [docling/models/page\\_preprocessing\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/page_preprocessing_model.py)\n- [docling/models/picture\\_description\\_vlm\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/picture_description_vlm_model.py)\n- [docling/models/plugins/defaults.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/plugins/defaults.py)\n- [docling/models/rapid\\_ocr\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/rapid_ocr_model.py)\n- [docling/models/table\\_structure\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/table_structure_model.py)\n- [docling/pipeline/standard\\_pdf\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/standard_pdf_pipeline.py)\n- [docling/utils/model\\_downloader.py](https://github.com/docling-project/docling/blob/f7244a43/docling/utils/model_downloader.py)\n- [tests/test\\_document\\_picture\\_classifier.py](https://github.com/docling-project/docling/blob/f7244a43/tests/test_document_picture_classifier.py)\n- [tests/test\\_options.py](https://github.com/docling-project/docling/blob/f7244a43/tests/test_options.py)\n\n## Purpose and Scope\n\nEnrichment Models operate on assembled document items after the initial extraction and layout analysis phases. They enhance document elements with additional information such as LaTeX formulas, code snippets with language detection, picture classifications, and image captions. Unlike page-level models (see [Layout and Table Structure Models](docling-project/docling/4.2-layout-and-table-structure-models.md)), enrichment models process individual document items (text blocks, code blocks, pictures) along with their cropped images.\n\nThis page documents the three main types of enrichment models:\n\n- **CodeFormulaModel**: Extracts LaTeX formulas and code with language detection\n- **DocumentPictureClassifier**: Classifies pictures into 16 semantic categories\n- **PictureDescriptionVlmModel**: Generates natural language descriptions of images\n\nFor VLM-based document processing that operates at the page level, see [Vision Language Models](docling-project/docling/4.3-vision-language-models.md). For the pipeline execution flow that includes enrichment, see [Base Pipeline Architecture](docling-project/docling/5.6-base-pipeline-architecture.md).\n\n---\n\n## Enrichment Architecture\n\n### Processing Flow\n\nEnrichment models are invoked during the `_enrich_document` phase of the pipeline, after document assembly is complete. They process items in batches, receiving both the document item and its cropped image.\n\n**Diagram: Enrichment Processing Flow**\n\n```\n```\n\nSources: [docling/pipeline/base\\_pipeline.py177-206](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/base_pipeline.py#L177-L206) [docling/pipeline/standard\\_pdf\\_pipeline.py77-90](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/standard_pdf_pipeline.py#L77-L90)\n\n---\n\n### Base Class Interface\n\nAll enrichment models inherit from `BaseItemAndImageEnrichmentModel`, which defines the standard interface for item-level processing.\n\n**Diagram: Enrichment Model Class Hierarchy**\n\n```\n```",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 1016,
      "character_count": 4326,
      "created_at": "2025-10-16T17:42:17.122556",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 2,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "Sources: [docling/models/base\\_model.py67-113](https://github.com/docling-project/docling/blob/f7244a43/docling/models/base_model.py#L67-L113) [docling/models/code\\_formula\\_model.py45-66](https://github.com/docling-project/docling/blob/f7244a43/docling/models/code_formula_model.py#L45-L66) [docling/models/document\\_picture\\_classifier.py36-60](https://github.com/docling-project/docling/blob/f7244a43/docling/models/document_picture_classifier.py#L36-L60) [docling/models/picture\\_description\\_vlm\\_model.py24-46](https://github.com/docling-project/docling/blob/f7244a43/docling/models/picture_description_vlm_model.py#L24-L46)\n\n---\n\n### Item and Image Element Structure\n\nEnrichment models receive `ItemAndImageEnrichmentElement` objects that bundle the document item with its cropped image and bounding box information.\n\n| Field        | Type                        | Description                                         |\n| ------------ | --------------------------- | --------------------------------------------------- |\n| `item`       | `NodeItem`                  | The document item (CodeItem, TextItem, PictureItem) |\n| `image`      | `Image.Image \\| np.ndarray` | Cropped image of the item                           |\n| `page_image` | `Image.Image`               | Full page image (for context)                       |\n| `bbox`       | `BoundingBox`               | Item's bounding box on the page                     |\n| `page_no`    | `int`                       | Page number containing the item                     |\n\nSources: [docling/datamodel/base\\_models.py285-294](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/base_models.py#L285-L294)\n\n---\n\n## Code and Formula Enrichment\n\n### CodeFormulaModel\n\nThe `CodeFormulaModel` processes code blocks and formula elements to extract structured representations. It uses a vision-language model fine-tuned for converting images of code and formulas into their text representations.\n\n**Model Details:**\n\n| Attribute        | Value                         | Purpose                      |\n| ---------------- | ----------------------------- | ---------------------------- |\n| Repository       | `ds4sd/CodeFormulaV2`         | Hugging Face model ID        |\n| Model Type       | `AutoModelForImageTextToText` | Florence-based architecture  |\n| Batch Size       | `5`                           | Elements processed per batch |\n| Image Scale      | `1.67` (120 DPI)              | Resolution for image input   |\n| Expansion Factor | `0.18`                        | Bounding box expansion (18%) |\n\nSources: [docling/models/code\\_formula\\_model.py68-72](https://github.com/docling-project/docling/blob/f7244a43/docling/models/code_formula_model.py#L68-L72)\n\n---\n\n### Processing Logic\n\n**Diagram: CodeFormulaModel Processing Pipeline**\n\n```\n```\n\nSources: [docling/models/code\\_formula\\_model.py277-337](https://github.com/docling-project/docling/blob/f7244a43/docling/models/code_formula_model.py#L277-L337)\n\n---\n\n### Code Language Detection\n\nThe model outputs code with a language prefix in the format `<_language_>`. The `_extract_code_language` method extracts this information:\n\n**Pattern:** `^<_([^_>]+)_>\\s*(.*)`\n\n**Example Output:**\n\n- Input: `<_python_>def main():\\n print(\"Hello\")`\n- Extracted Language: `python`\n- Remainder: `def main():\\n print(\"Hello\")`\n\nThe language string is then converted to a `CodeLanguageLabel` enum member. If the language is unrecognized or missing, it defaults to `CodeLanguageLabel.UNKNOWN`.\n\nSources: [docling/models/code\\_formula\\_model.py156-206](https://github.com/docling-project/docling/blob/f7244a43/docling/models/code_formula_model.py#L156-L206)\n\n---\n\n### Formula Extraction\n\nFor formula elements (identified by `DocItemLabel.FORMULA`), the model extracts LaTeX representations:\n\n**Example:**\n\n- Input: Image of mathematical formula\n- Output: `E = mc^2`\n\nThe extracted LaTeX is stored in the `TextItem.text` field, replacing any placeholder text from layout analysis.\n\nSources: [docling/models/code\\_formula\\_model.py208-245](https://github.com/docling-project/docling/blob/f7244a43/docling/models/code_formula_model.py#L208-L245)\n\n---\n\n## Picture Classification\n\n### DocumentPictureClassifier\n\nThe `DocumentPictureClassifier` categorizes picture elements into semantic classes such as charts, diagrams, photographs, and maps.\n\n**Model Details:**",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 984,
      "character_count": 4374,
      "created_at": "2025-10-16T17:42:17.137227",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 3,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "| Attribute         | Value                            |\n| ----------------- | -------------------------------- |\n| Repository        | `ds4sd/DocumentFigureClassifier` |\n| Revision          | `v1.0.1`                         |\n| Image Scale       | `2` (144 DPI)                    |\n| Number of Classes | `16`                             |\n| Output Type       | `PictureClassificationData`      |\n\nSources: [docling/models/document\\_picture\\_classifier.py62-105](https://github.com/docling-project/docling/blob/f7244a43/docling/models/document_picture_classifier.py#L62-L105)\n\n---\n\n### Classification Classes\n\nThe classifier predicts probabilities for 16 figure types. Results are sorted by confidence in descending order.\n\n**Common Classification Classes:**\n\n- `bar_chart`\n- `line_chart`\n- `pie_chart`\n- `scatter_plot`\n- `map`\n- `photograph`\n- `diagram`\n- `flowchart`\n- `table` (visual table representation)\n- `equation`\n- `schematic`\n- `illustration`\n\nSources: [tests/test\\_document\\_picture\\_classifier.py54-79](https://github.com/docling-project/docling/blob/f7244a43/tests/test_document_picture_classifier.py#L54-L79)\n\n---\n\n### Output Structure\n\n**Diagram: PictureClassificationData Structure**\n\n```\n```\n\n**Example:**\n\n```\n```\n\nSources: [docling/models/document\\_picture\\_classifier.py136-185](https://github.com/docling-project/docling/blob/f7244a43/docling/models/document_picture_classifier.py#L136-L185) [tests/test\\_document\\_picture\\_classifier.py47-64](https://github.com/docling-project/docling/blob/f7244a43/tests/test_document_picture_classifier.py#L47-L64)\n\n---\n\n## Picture Description\n\n### PictureDescriptionVlmModel\n\nThe `PictureDescriptionVlmModel` generates natural language descriptions of images using vision-language models. It supports multiple VLM backends and custom prompts.\n\n**Supported Models:**\n\n| Model Name     | Repository                             | Use Case                |\n| -------------- | -------------------------------------- | ----------------------- |\n| SmolVLM        | `HuggingFaceTB/SmolVLM2-1.7B-Instruct` | Lightweight description |\n| Granite Vision | `ibm-granite/granite-vision-3.1-2b`    | IBM Granite family      |\n| Custom VLM     | User-specified                         | Any compatible VLM      |\n\nSources: [docling/datamodel/pipeline\\_options.py416-438](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options.py#L416-L438) [docling/models/picture\\_description\\_vlm\\_model.py24-81](https://github.com/docling-project/docling/blob/f7244a43/docling/models/picture_description_vlm_model.py#L24-L81)\n\n---\n\n### Description Generation\n\n**Diagram: Picture Description Pipeline**\n\n```\n```\n\nSources: [docling/models/picture\\_description\\_vlm\\_model.py82-116](https://github.com/docling-project/docling/blob/f7244a43/docling/models/picture_description_vlm_model.py#L82-L116)\n\n---\n\n### Custom Prompts\n\nThe `PictureDescriptionVlmOptions` allows customization of the description prompt:\n\n**Default Configuration:**\n\n```\n```\n\n**Message Format:**\n\n```\n```\n\nSources: [docling/models/picture\\_description\\_vlm\\_model.py86-103](https://github.com/docling-project/docling/blob/f7244a43/docling/models/picture_description_vlm_model.py#L86-L103) [docling/datamodel/pipeline\\_options.py416-438](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options.py#L416-L438)\n\n---\n\n### API-Based Picture Description\n\nThe `PictureDescriptionApiModel` provides an alternative that uses OpenAI-compatible APIs instead of local model inference.\n\n**Configuration:**\n\n```\n```\n\nSources: [docling/models/picture\\_description\\_api\\_model.py1-100](https://github.com/docling-project/docling/blob/f7244a43/docling/models/picture_description_api_model.py#L1-L100) [docling/datamodel/pipeline\\_options.py441-466](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options.py#L441-L466)\n\n---\n\n## Configuration\n\n### Pipeline Options\n\nEnrichment models are configured through `PdfPipelineOptions`:\n\n**Configuration Table:**",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 961,
      "character_count": 4041,
      "created_at": "2025-10-16T17:42:17.151508",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 4,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "| Option                        | Type    | Default | Description                   |\n| ----------------------------- | ------- | ------- | ----------------------------- |\n| `do_code_enrichment`          | `bool`  | `False` | Enable code extraction        |\n| `do_formula_enrichment`       | `bool`  | `False` | Enable formula extraction     |\n| `do_picture_classification`   | `bool`  | `False` | Enable picture classification |\n| `do_picture_description`      | `bool`  | `False` | Enable picture description    |\n| `picture_description_options` | Options | `None`  | VLM or API configuration      |\n\n**Example Configuration:**\n\n```\n```\n\nSources: [docling/pipeline/standard\\_pdf\\_pipeline.py77-98](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/standard_pdf_pipeline.py#L77-L98) [docling/datamodel/pipeline\\_options.py184-204](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options.py#L184-L204)\n\n---\n\n### Model Downloading\n\nEnrichment models are downloaded from Hugging Face using the `download_models` utility:\n\n**CLI Command:**\n\n```\n```\n\n**Programmatic Download:**\n\n```\n```\n\n**Downloaded Artifacts:**\n\n| Model                     | Folder                                  | Size     |\n| ------------------------- | --------------------------------------- | -------- |\n| CodeFormulaModel          | `ds4sd--CodeFormulaV2`                  | \\~6 GB   |\n| DocumentPictureClassifier | `ds4sd--DocumentFigureClassifier`       | \\~500 MB |\n| SmolVLM                   | `HuggingFaceTB--SmolVLM2-1.7B-Instruct` | \\~3.5 GB |\n\nSources: [docling/utils/model\\_downloader.py30-158](https://github.com/docling-project/docling/blob/f7244a43/docling/utils/model_downloader.py#L30-L158) [docling/cli/models.py30-50](https://github.com/docling-project/docling/blob/f7244a43/docling/cli/models.py#L30-L50)\n\n---\n\n## Integration with Pipeline\n\n### Enrichment Pipe Construction\n\nThe `StandardPdfPipeline` constructs the enrichment pipeline by prepending the `CodeFormulaModel` to inherited enrichment models:\n\n**File:** [docling/pipeline/standard\\_pdf\\_pipeline.py77-90](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/standard_pdf_pipeline.py#L77-L90)\n\n```\n```\n\nSources: [docling/pipeline/standard\\_pdf\\_pipeline.py77-90](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/standard_pdf_pipeline.py#L77-L90)\n\n---\n\n### Execution Flow in ConvertPipeline\n\nThe `ConvertPipeline` base class implements the `_enrich_document` method that orchestrates enrichment processing:\n\n**Diagram: Enrichment Execution in ConvertPipeline**\n\n```\n```\n\nSources: [docling/pipeline/base\\_pipeline.py177-206](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/base_pipeline.py#L177-L206)\n\n---\n\n### Image Scaling and Cropping\n\nEnrichment models specify their required image resolution through `images_scale` and bounding box expansion through `expansion_factor`:\n\n**Scaling Calculation:**\n\n```\n```\n\n**Scaling Values by Model:**\n\n| Model                      | `images_scale` | `expansion_factor` | Effective DPI |\n| -------------------------- | -------------- | ------------------ | ------------- |\n| CodeFormulaModel           | 1.67           | 0.18               | 120 DPI       |\n| DocumentPictureClassifier  | 2.0            | 0.0                | 144 DPI       |\n| PictureDescriptionVlmModel | 1.0            | 0.0                | 72 DPI        |\n\nSources: [docling/models/code\\_formula\\_model.py70-71](https://github.com/docling-project/docling/blob/f7244a43/docling/models/code_formula_model.py#L70-L71) [docling/models/document\\_picture\\_classifier.py63](https://github.com/docling-project/docling/blob/f7244a43/docling/models/document_picture_classifier.py#L63-L63) [docling/pipeline/base\\_pipeline.py177-206](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/base_pipeline.py#L177-L206)\n\n---\n\n### Backend Retention for Enrichment\n\nWhen enrichment models are enabled, the pipeline retains the document backend after assembly to support image cropping:",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 990,
      "character_count": 4081,
      "created_at": "2025-10-16T17:42:17.163439",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 5,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "**File:** [docling/pipeline/standard\\_pdf\\_pipeline.py92-98](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/standard_pdf_pipeline.py#L92-L98)\n\n```\n```\n\nThis ensures that page images remain accessible during the enrichment phase, allowing models to crop item-specific regions from the full page images.\n\nSources: [docling/pipeline/standard\\_pdf\\_pipeline.py92-98](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/standard_pdf_pipeline.py#L92-L98)\n\n---\n\n## Plugin System for Enrichment\n\nEnrichment models are discoverable through the plugin system using Python entry points. The `docling_defaults` entry point provides default enrichment implementations:\n\n**File:** [docling/models/plugins/defaults.py21-30](https://github.com/docling-project/docling/blob/f7244a43/docling/models/plugins/defaults.py#L21-L30)\n\n```\n```\n\nThis allows third-party packages to register additional enrichment models by defining their own entry points.\n\nSources: [docling/models/plugins/defaults.py21-30](https://github.com/docling-project/docling/blob/f7244a43/docling/models/plugins/defaults.py#L21-L30) [docling/models/factories.py1-50](https://github.com/docling-project/docling/blob/f7244a43/docling/models/factories.py#L1-L50)\n\nDismiss\n\nRefresh this wiki\n\nThis wiki was recently refreshed. Please wait 4 days to refresh again.\n\n### On this page\n\n- [Enrichment Models](#enrichment-models.md)\n- [Purpose and Scope](#purpose-and-scope.md)\n- [Enrichment Architecture](#enrichment-architecture.md)\n- [Processing Flow](#processing-flow.md)\n- [Base Class Interface](#base-class-interface.md)\n- [Item and Image Element Structure](#item-and-image-element-structure.md)\n- [Code and Formula Enrichment](#code-and-formula-enrichment.md)\n- [CodeFormulaModel](#codeformulamodel.md)\n- [Processing Logic](#processing-logic.md)\n- [Code Language Detection](#code-language-detection.md)\n- [Formula Extraction](#formula-extraction.md)\n- [Picture Classification](#picture-classification.md)\n- [DocumentPictureClassifier](#documentpictureclassifier.md)\n- [Classification Classes](#classification-classes.md)\n- [Output Structure](#output-structure.md)\n- [Picture Description](#picture-description.md)\n- [PictureDescriptionVlmModel](#picturedescriptionvlmmodel.md)\n- [Description Generation](#description-generation.md)\n- [Custom Prompts](#custom-prompts.md)\n- [API-Based Picture Description](#api-based-picture-description.md)\n- [Configuration](#configuration.md)\n- [Pipeline Options](#pipeline-options.md)\n- [Model Downloading](#model-downloading.md)\n- [Integration with Pipeline](#integration-with-pipeline.md)\n- [Enrichment Pipe Construction](#enrichment-pipe-construction.md)\n- [Execution Flow in ConvertPipeline](#execution-flow-in-convertpipeline.md)\n- [Image Scaling and Cropping](#image-scaling-and-cropping.md)\n- [Backend Retention for Enrichment](#backend-retention-for-enrichment.md)\n- [Plugin System for Enrichment](#plugin-system-for-enrichment.md)",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 724,
      "character_count": 2970,
      "created_at": "2025-10-16T17:42:17.165595",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 6,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.4-enrichment-models.md",
      "collection_context": "Docling"
    }
  }
]
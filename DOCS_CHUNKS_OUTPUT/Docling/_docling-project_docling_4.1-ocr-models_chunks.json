[
  {
    "text": "OCR Models | docling-project/docling | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[docling-project/docling](https://github.com/docling-project/docling \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 12 October 2025 ([f7244a](https://github.com/docling-project/docling/commits/f7244a43))",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 114,
      "character_count": 411,
      "created_at": "2025-10-16T17:42:16.907763",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 0,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [Overview](docling-project/docling/1-overview.md)\n- [Installation](docling-project/docling/1.1-installation.md)\n- [Quick Start](docling-project/docling/1.2-quick-start.md)\n- [Core Architecture](docling-project/docling/2-core-architecture.md)\n- [Document Conversion Flow](docling-project/docling/2.1-document-conversion-flow.md)\n- [DoclingDocument Data Model](docling-project/docling/2.2-doclingdocument-data-model.md)\n- [Configuration and Pipeline Options](docling-project/docling/2.3-configuration-and-pipeline-options.md)\n- [Format Detection and Routing](docling-project/docling/2.4-format-detection-and-routing.md)\n- [Document Backends](docling-project/docling/3-document-backends.md)\n- [PDF Processing Backends](docling-project/docling/3.1-pdf-processing-backends.md)\n- [Office Document Backends](docling-project/docling/3.2-office-document-backends.md)\n- [Web and Markup Backends](docling-project/docling/3.3-web-and-markup-backends.md)\n- [AI/ML Models](docling-project/docling/4-aiml-models.md)\n- [OCR Models](docling-project/docling/4.1-ocr-models.md)\n- [Layout and Table Structure Models](docling-project/docling/4.2-layout-and-table-structure-models.md)\n- [Vision Language Models](docling-project/docling/4.3-vision-language-models.md)\n- [Inline VLM Models](docling-project/docling/4.3.1-inline-vlm-models.md)\n- [API-Based VLM Models](docling-project/docling/4.3.2-api-based-vlm-models.md)\n- [Enrichment Models](docling-project/docling/4.4-enrichment-models.md)\n- [Processing Pipelines](docling-project/docling/5-processing-pipelines.md)\n- [Standard PDF Pipeline](docling-project/docling/5.1-standard-pdf-pipeline.md)\n- [Threaded PDF Pipeline](docling-project/docling/5.2-threaded-pdf-pipeline.md)\n- [VLM Pipeline](docling-project/docling/5.3-vlm-pipeline.md)\n- [Extraction Pipeline](docling-project/docling/5.4-extraction-pipeline.md)\n- [ASR Pipeline](docling-project/docling/5.5-asr-pipeline.md)\n- [Base Pipeline Architecture](docling-project/docling/5.6-base-pipeline-architecture.md)\n- [Command Line Interface](docling-project/docling/6-command-line-interface.md)\n- [Document Conversion CLI](docling-project/docling/6.1-document-conversion-cli.md)\n- [Model Management CLI](docling-project/docling/6.2-model-management-cli.md)\n- [Python SDK](docling-project/docling/7-python-sdk.md)\n- [DocumentConverter API](docling-project/docling/7.1-documentconverter-api.md)\n- [DocumentExtractor API](docling-project/docling/7.2-documentextractor-api.md)\n- [Usage Examples](docling-project/docling/7.3-usage-examples.md)\n- [Output and Integration](docling-project/docling/8-output-and-integration.md)\n- [Export Formats](docling-project/docling/8.1-export-formats.md)\n- [Document Chunking](docling-project/docling/8.2-document-chunking.md)\n- [Framework Integrations](docling-project/docling/8.3-framework-integrations.md)\n- [Development and Testing](docling-project/docling/9-development-and-testing.md)\n- [Testing Framework](docling-project/docling/9.1-testing-framework.md)\n- [Ground Truth Data](docling-project/docling/9.2-ground-truth-data.md)\n- [CI/CD and Development Workflow](docling-project/docling/9.3-cicd-and-development-workflow.md)\n- [Deployment](docling-project/docling/10-deployment.md)\n- [Docker Deployment](docling-project/docling/10.1-docker-deployment.md)\n- [Model Artifacts Management](docling-project/docling/10.2-model-artifacts-management.md)\n\nMenu\n\n# OCR Models\n\nRelevant source files",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 926,
      "character_count": 3409,
      "created_at": "2025-10-16T17:42:16.909999",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 1,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [docling/cli/models.py](https://github.com/docling-project/docling/blob/f7244a43/docling/cli/models.py)\n- [docling/models/auto\\_ocr\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/auto_ocr_model.py)\n- [docling/models/picture\\_description\\_vlm\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/picture_description_vlm_model.py)\n- [docling/models/plugins/defaults.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/plugins/defaults.py)\n- [docling/models/rapid\\_ocr\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/rapid_ocr_model.py)\n- [docling/models/tesseract\\_ocr\\_cli\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/tesseract_ocr_cli_model.py)\n- [docling/models/tesseract\\_ocr\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/tesseract_ocr_model.py)\n- [docling/utils/model\\_downloader.py](https://github.com/docling-project/docling/blob/f7244a43/docling/utils/model_downloader.py)\n- [tests/data\\_scanned/sample\\_with\\_rotation\\_mismatch.pdf](https://github.com/docling-project/docling/blob/f7244a43/tests/data_scanned/sample_with_rotation_mismatch.pdf)\n- [tests/test\\_backend\\_docling\\_parse.py](https://github.com/docling-project/docling/blob/f7244a43/tests/test_backend_docling_parse.py)\n- [tests/test\\_backend\\_docling\\_parse\\_v2.py](https://github.com/docling-project/docling/blob/f7244a43/tests/test_backend_docling_parse_v2.py)\n- [tests/test\\_backend\\_pdfium.py](https://github.com/docling-project/docling/blob/f7244a43/tests/test_backend_pdfium.py)\n- [tests/test\\_e2e\\_ocr\\_conversion.py](https://github.com/docling-project/docling/blob/f7244a43/tests/test_e2e_ocr_conversion.py)\n\nThis document covers the Optical Character Recognition (OCR) models and engines available in Docling's document processing pipeline. OCR models are responsible for extracting text from image regions in documents, particularly scanned PDFs and bitmap areas where programmatic text extraction is not possible.\n\nFor information about layout analysis and document structure recognition, see [Layout and Table Structure Models](docling-project/docling/4.2-layout-and-table-structure-models.md). For details about vision-language models that can understand document content, see [Vision Language Models](docling-project/docling/4.3-vision-language-models.md).\n\n## OCR Architecture Overview\n\nDocling provides a flexible OCR framework that supports multiple OCR engines through a common interface. The system automatically detects areas requiring OCR processing and applies the configured engine to extract text.\n\n### OCR Model Class Hierarchy\n\n```\n```\n\n**Sources:** [docling/models/base\\_ocr\\_model.py24-228](https://github.com/docling-project/docling/blob/f7244a43/docling/models/base_ocr_model.py#L24-L228) [docling/models/tesseract\\_ocr\\_model.py29-255](https://github.com/docling-project/docling/blob/f7244a43/docling/models/tesseract_ocr_model.py#L29-L255) [docling/models/tesseract\\_ocr\\_cli\\_model.py35-328](https://github.com/docling-project/docling/blob/f7244a43/docling/models/tesseract_ocr_cli_model.py#L35-L328) [docling/models/easyocr\\_model.py28-201](https://github.com/docling-project/docling/blob/f7244a43/docling/models/easyocr_model.py#L28-L201)\n\n## Base OCR Model Framework\n\nThe `BaseOcrModel` class provides the foundation for all OCR implementations in Docling. It defines the common interface and shared functionality used by all OCR engines.\n\n### Core Functionality\n\n| Method                 | Purpose                                              | Implementation                                     |\n| ---------------------- | ---------------------------------------------------- | -------------------------------------------------- |\n| `get_ocr_rects()`      | Identifies bitmap regions requiring OCR              | Uses bitmap detection and morphological operations |\n| `post_process_cells()` | Integrates OCR results with existing text            | Handles cell filtering and re-indexing             |\n| `_filter_ocr_cells()`  | Removes OCR cells overlapping with programmatic text | Uses R-tree spatial indexing for efficiency        |\n| `_combine_cells()`     | Merges OCR and programmatic text cells               | Handles full-page OCR vs. selective OCR modes      |\n\n### OCR Region Detection",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 1011,
      "character_count": 4406,
      "created_at": "2025-10-16T17:42:16.914554",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 2,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "The base class implements intelligent OCR region detection in `get_ocr_rects()`:\n\n1. **Bitmap Analysis**: Identifies image regions in the document using `page._backend.get_bitmap_rects()`\n2. **Morphological Processing**: Uses binary dilation to merge nearby bitmap regions\n3. **Coverage Calculation**: Determines if full-page OCR is needed based on bitmap coverage\n4. **Threshold-based Decision**: Compares coverage against `bitmap_area_threshold` and `force_full_page_ocr` settings\n\n**Sources:** [docling/models/base\\_ocr\\_model.py40-113](https://github.com/docling-project/docling/blob/f7244a43/docling/models/base_ocr_model.py#L40-L113) [docling/models/base\\_ocr\\_model.py140-172](https://github.com/docling-project/docling/blob/f7244a43/docling/models/base_ocr_model.py#L140-L172)\n\n## Supported OCR Engines\n\nDocling supports multiple OCR engines through a plugin-based architecture. Each engine has specific strengths and implementation characteristics.\n\n### OcrAutoModel (Automatic Engine Selection)\n\nThe `OcrAutoModel` implements intelligent fallback logic to automatically select the best available OCR engine on the current system.\n\n#### Selection Priority\n\nThe auto-selection follows this priority order:\n\n1. **OcrMac** (Darwin/macOS only) - Native macOS OCR API via `ocrmac` library\n2. **RapidOcrModel** with ONNX backend - If `onnxruntime` is installed\n3. **EasyOcrModel** - If `easyocr` is installed\n4. **RapidOcrModel** with Torch backend - If `torch` is installed\n\n#### Implementation\n\nThe selection logic is implemented in `OcrAutoModel.__init__()`:\n\n```\n```\n\n**Sources:** [docling/models/auto\\_ocr\\_model.py25-133](https://github.com/docling-project/docling/blob/f7244a43/docling/models/auto_ocr_model.py#L25-L133)\n\n### RapidOcrModel\n\nThe `RapidOcrModel` provides a lightweight OCR solution with multiple backend options (ONNX and PyTorch).\n\n#### Architecture\n\nRapidOCR uses a three-stage pipeline:\n\n- **Detection**: Locates text regions in images\n- **Classification**: Determines text orientation\n- **Recognition**: Extracts text from detected regions\n\n#### Backend Support\n\n| Backend       | Library        | Use Case                         |\n| ------------- | -------------- | -------------------------------- |\n| `onnxruntime` | ONNX Runtime   | Default, CPU-optimized inference |\n| `torch`       | PyTorch        | GPU acceleration support         |\n| `openvino`    | Intel OpenVINO | Intel hardware optimization      |\n| `paddle`      | PaddlePaddle   | PaddleOCR native backend         |\n\n#### Model Artifacts\n\nRapidOCR uses PP-OCRv4 models downloaded from ModelScope:\n\n```\n```\n\n#### Configuration Options\n\nRapidOcrOptions provides extensive control over the OCR pipeline:\n\n| Option            | Type             | Default         | Description                       |\n| ----------------- | ---------------- | --------------- | --------------------------------- |\n| `backend`         | `str`            | `\"onnxruntime\"` | Backend engine to use             |\n| `use_det`         | `bool`           | `True`          | Enable text detection             |\n| `use_cls`         | `bool`           | `True`          | Enable orientation classification |\n| `use_rec`         | `bool`           | `True`          | Enable text recognition           |\n| `text_score`      | `float`          | `0.5`           | Minimum confidence threshold      |\n| `det_model_path`  | `Optional[str]`  | `None`          | Custom detection model path       |\n| `cls_model_path`  | `Optional[str]`  | `None`          | Custom classification model path  |\n| `rec_model_path`  | `Optional[str]`  | `None`          | Custom recognition model path     |\n| `rec_keys_path`   | `Optional[str]`  | `None`          | Custom character dictionary path  |\n| `rapidocr_params` | `Optional[dict]` | `None`          | Advanced RapidOCR parameters      |\n\n#### Processing Flow\n\nThe implementation in `RapidOcrModel.__call__()` processes each OCR rectangle:\n\n1. Extract image region with 3x scaling (216 DPI)\n2. Convert to numpy array\n3. Call `self.reader(im, use_det=..., use_cls=..., use_rec=...)`\n4. Parse results as `(boxes, texts, scores)` tuples\n5. Transform coordinates back to page coordinate system\n6. Create `TextCell` objects with bounding rectangles",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 993,
      "character_count": 4243,
      "created_at": "2025-10-16T17:42:16.921017",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 3,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "**Sources:** [docling/models/rapid\\_ocr\\_model.py36-306](https://github.com/docling-project/docling/blob/f7244a43/docling/models/rapid_ocr_model.py#L36-L306)\n\n### TesseractOcrModel\n\nThe `TesseractOcrModel` provides direct integration with Tesseract via the `tesserocr` Python binding.\n\n#### Key Features\n\n- **Direct API Access**: Uses `tesserocr.PyTessBaseAPI` for optimal performance\n- **Automatic Language Detection**: Script detection with automatic language switching via `lang=[\"auto\"]`\n- **Orientation Detection**: OSD (Orientation and Script Detection) via separate `osd_reader`\n- **Multi-script Support**: Maintains separate `script_readers` dictionary for detected scripts\n- **PSM Configuration**: Configurable Page Segmentation Mode via `psm` option\n\n#### Language Detection Implementation\n\nWhen `lang=[\"auto\"]` is configured:\n\n1. **OSD Detection**: `osd_reader.DetectOrientationScript()` identifies script and orientation\n2. **Script Mapping**: `map_tesseract_script()` converts Tesseract script names to language codes\n3. **Language Validation**: Checks if detected language exists in `_tesserocr_languages`\n4. **Reader Creation**: Creates script-specific `PyTessBaseAPI` instance and caches in `script_readers`\n5. **Dynamic Switching**: Uses appropriate reader for each OCR rectangle\n\n#### Configuration Options\n\n| Option | Type            | Default   | Description                                |\n| ------ | --------------- | --------- | ------------------------------------------ |\n| `lang` | `List[str]`     | `[\"eng\"]` | Language codes or `[\"auto\"]` for detection |\n| `path` | `Optional[str]` | `None`    | Custom tessdata directory path             |\n| `psm`  | `Optional[int]` | `None`    | Page Segmentation Mode (0-13)              |\n\n**Sources:** [docling/models/tesseract\\_ocr\\_model.py29-265](https://github.com/docling-project/docling/blob/f7244a43/docling/models/tesseract_ocr_model.py#L29-L265)\n\n### TesseractOcrCliModel\n\nThe `TesseractOcrCliModel` provides CLI-based Tesseract integration as an alternative when `tesserocr` binding is unavailable.\n\n#### Implementation Characteristics\n\n- **Subprocess Execution**: Uses `subprocess.run()` to invoke tesseract CLI\n- **TSV Output**: Parses Tesseract's tab-separated value output format\n- **Temporary Files**: Creates temporary PNG files for each OCR rectangle\n- **OSD via CLI**: Runs `tesseract --psm 0 -l osd` for orientation detection\n- **Language Enumeration**: Uses `tesseract --list-langs` to discover installed languages\n\n#### Key Methods\n\n| Method                        | Purpose                                                 |\n| ----------------------------- | ------------------------------------------------------- |\n| `_get_name_and_version()`     | Executes `tesseract --version` to validate installation |\n| `_set_languages_and_prefix()` | Discovers installed languages and script prefix         |\n| `_perform_osd()`              | Runs OSD mode for orientation/script detection          |\n| `_parse_language()`           | Maps detected script to language code                   |\n| `_run_tesseract()`            | Executes main OCR with language and PSM settings        |\n\n#### Configuration Options\n\n| Option          | Type            | Default       | Description                  |\n| --------------- | --------------- | ------------- | ---------------------------- |\n| `tesseract_cmd` | `str`           | `\"tesseract\"` | Path to tesseract executable |\n| `lang`          | `List[str]`     | `[\"eng\"]`     | Language codes or `[\"auto\"]` |\n| `path`          | `Optional[str]` | `None`        | Custom tessdata directory    |\n| `psm`           | `Optional[int]` | `None`        | Page Segmentation Mode       |\n\n**Sources:** [docling/models/tesseract\\_ocr\\_cli\\_model.py35-332](https://github.com/docling-project/docling/blob/f7244a43/docling/models/tesseract_ocr_cli_model.py#L35-L332)\n\n### EasyOcrModel\n\nThe `EasyOcrModel` integrates the EasyOCR library, providing deep learning-based OCR.\n\n#### Key Features\n\n- **GPU Acceleration**: Supports CUDA and MPS via `accelerator_options`\n- **Neural Networks**: Uses deep learning models for text recognition\n- **Multi-language**: Built-in support for 80+ languages\n- **Model Management**: Automatic model downloading via `download_models()` static method\n\n#### Configuration Options",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 961,
      "character_count": 4322,
      "created_at": "2025-10-16T17:42:16.927516",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 4,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "| Option                    | Type             | Default      | Description                                |\n| ------------------------- | ---------------- | ------------ | ------------------------------------------ |\n| `lang`                    | `List[str]`      | `[\"en\"]`     | EasyOCR language codes                     |\n| `use_gpu`                 | `Optional[bool]` | `None`       | GPU usage (auto-detected from accelerator) |\n| `confidence_threshold`    | `float`          | `0.5`        | Minimum confidence for results             |\n| `recog_network`           | `str`            | `\"standard\"` | Recognition network architecture           |\n| `model_storage_directory` | `Optional[str]`  | `None`       | Custom model cache directory               |\n\n**Sources:** [docling/models/easyocr\\_model.py28-201](https://github.com/docling-project/docling/blob/f7244a43/docling/models/easyocr_model.py#L28-L201)\n\n### OcrMacModel\n\nThe `OcrMacModel` provides macOS-specific OCR using native system APIs via the `ocrmac` library.\n\n#### Platform Requirements\n\n- **Platform**: macOS (Darwin) only\n- **Library**: `ocrmac` Python package\n- **System**: Uses macOS Vision framework\n\n**Sources:** [docling/models/auto\\_ocr\\_model.py43-58](https://github.com/docling-project/docling/blob/f7244a43/docling/models/auto_ocr_model.py#L43-L58)\n\n## OCR Processing Pipeline\n\nThe OCR processing flow integrates with Docling's document processing pipeline through the `BaseOcrModel` framework.\n\n### End-to-End OCR Flow\n\n```\n```\n\n### Coordinate Transformation\n\nOCR engines return coordinates in the scaled image space. The `tesseract_box_to_bounding_rectangle()` utility transforms these to page coordinates:\n\n1. **Apply Rotation**: If document has rotation from OSD, apply inverse rotation\n2. **Scale Factor**: Divide by scale factor (typically 3)\n3. **Offset Translation**: Add OCR rectangle origin offset\n4. **Coordinate Origin**: Convert from TOPLEFT to BOTTOMLEFT if needed\n\n**Sources:** [docling/models/base\\_ocr\\_model.py40-228](https://github.com/docling-project/docling/blob/f7244a43/docling/models/base_ocr_model.py#L40-L228) [docling/models/tesseract\\_ocr\\_model.py125-260](https://github.com/docling-project/docling/blob/f7244a43/docling/models/tesseract_ocr_model.py#L125-L260) [docling/models/tesseract\\_ocr\\_cli\\_model.py208-319](https://github.com/docling-project/docling/blob/f7244a43/docling/models/tesseract_ocr_cli_model.py#L208-L319) [docling/models/rapid\\_ocr\\_model.py226-301](https://github.com/docling-project/docling/blob/f7244a43/docling/models/rapid_ocr_model.py#L226-L301) [docling/utils/ocr\\_utils.py](https://github.com/docling-project/docling/blob/f7244a43/docling/utils/ocr_utils.py)\n\n### OCR Cell Post-Processing\n\nThe `post_process_cells()` method handles integration of OCR results:\n\n```\n```\n\n**Sources:** [docling/models/base\\_ocr\\_model.py140-228](https://github.com/docling-project/docling/blob/f7244a43/docling/models/base_ocr_model.py#L140-L228)\n\n## Configuration and Options\n\nOCR behavior is controlled through `PdfPipelineOptions.ocr_options`, with engine selection via the options factory pattern.\n\n### OCR Options Factory\n\nThe options class determines which OCR engine is instantiated:\n\n```\n```\n\n### Common Options (All Engines)\n\n| Option                  | Type        | Default   | Description                                            |\n| ----------------------- | ----------- | --------- | ------------------------------------------------------ |\n| `bitmap_area_threshold` | `float`     | `0.05`    | Minimum bitmap coverage (0.0-1.0) to trigger OCR       |\n| `force_full_page_ocr`   | `bool`      | `False`   | Force OCR on entire page regardless of bitmap coverage |\n| `lang`                  | `List[str]` | `[\"eng\"]` | Language codes for OCR engine                          |\n\n### Usage Examples\n\n```\n```\n\n### Integration with Accelerator Options\n\nOCR engines respect global `AcceleratorOptions` for device and threading:\n\n| AcceleratorOption | Effect on OCR                                |\n| ----------------- | -------------------------------------------- |\n| `device = CUDA`   | Enables GPU for EasyOCR and RapidOCR (torch) |\n| `device = CPU`    | Forces CPU execution                         |\n| `device = AUTO`   | Uses DirectML on Windows for RapidOCR ONNX   |\n| `num_threads = N` | Sets `intra_op_num_threads` for RapidOCR     |",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 1012,
      "character_count": 4373,
      "created_at": "2025-10-16T17:42:16.936997",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 5,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "**Sources:** [docling/datamodel/pipeline\\_options.py](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/pipeline_options.py) [docling/models/rapid\\_ocr\\_model.py82-200](https://github.com/docling-project/docling/blob/f7244a43/docling/models/rapid_ocr_model.py#L82-L200) [docling/models/easyocr\\_model.py57-73](https://github.com/docling-project/docling/blob/f7244a43/docling/models/easyocr_model.py#L57-L73) [tests/test\\_e2e\\_ocr\\_conversion.py39-56](https://github.com/docling-project/docling/blob/f7244a43/tests/test_e2e_ocr_conversion.py#L39-L56)\n\n## Performance and Capabilities\n\n### Engine Comparison\n\n| Feature                | TesseractOCR   | TesseractCLI   | EasyOCR        | RapidOCR       | OCR Mac    |\n| ---------------------- | -------------- | -------------- | -------------- | -------------- | ---------- |\n| **Performance**        | High           | Medium         | Medium         | High           | High       |\n| **GPU Support**        | No             | No             | Yes            | No             | No         |\n| **Language Detection** | Yes            | Yes            | No             | Limited        | Yes        |\n| **Rotation Handling**  | Yes            | Yes            | No             | No             | Yes        |\n| **Installation**       | Complex        | Simple         | Simple         | Simple         | Built-in   |\n| **Platform Support**   | Cross-platform | Cross-platform | Cross-platform | Cross-platform | macOS only |\n\n### Processing Characteristics\n\n- **Image Scaling**: All engines scale input images to 216 DPI (3x multiplier) for optimal OCR accuracy\n- **Confidence Scoring**: Each engine provides confidence scores for extracted text\n- **Spatial Indexing**: Uses R-tree indexing for efficient cell overlap detection\n- **Memory Management**: Implements proper cleanup for large image processing\n\n### Quality Assessment\n\nThe system includes text quality rating in `PagePreprocessingModel.rate_text_quality()` to assess OCR results:\n\n- Detects problematic patterns (glyph codes, fragmented text)\n- Applies penalties for low-quality OCR output\n- Integrates with overall document confidence scoring\n\n**Sources:** [docling/models/base\\_ocr\\_model.py173-217](https://github.com/docling-project/docling/blob/f7244a43/docling/models/base_ocr_model.py#L173-L217) [docling/models/page\\_preprocessing\\_model.py120-146](https://github.com/docling-project/docling/blob/f7244a43/docling/models/page_preprocessing_model.py#L120-L146) [tests/test\\_e2e\\_ocr\\_conversion.py59-101](https://github.com/docling-project/docling/blob/f7244a43/tests/test_e2e_ocr_conversion.py#L59-L101)\n\nDismiss\n\nRefresh this wiki\n\nThis wiki was recently refreshed. Please wait 4 days to refresh again.\n\n### On this page",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 645,
      "character_count": 2762,
      "created_at": "2025-10-16T17:42:16.941264",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 6,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [OCR Models](#ocr-models.md)\n- [OCR Architecture Overview](#ocr-architecture-overview.md)\n- [OCR Model Class Hierarchy](#ocr-model-class-hierarchy.md)\n- [Base OCR Model Framework](#base-ocr-model-framework.md)\n- [Core Functionality](#core-functionality.md)\n- [OCR Region Detection](#ocr-region-detection.md)\n- [Supported OCR Engines](#supported-ocr-engines.md)\n- [OcrAutoModel (Automatic Engine Selection)](#ocrautomodel-automatic-engine-selection.md)\n- [Selection Priority](#selection-priority.md)\n- [Implementation](#implementation.md)\n- [RapidOcrModel](#rapidocrmodel.md)\n- [Architecture](#architecture.md)\n- [Backend Support](#backend-support.md)\n- [Model Artifacts](#model-artifacts.md)\n- [Configuration Options](#configuration-options.md)\n- [Processing Flow](#processing-flow.md)\n- [TesseractOcrModel](#tesseractocrmodel.md)\n- [Key Features](#key-features.md)\n- [Language Detection Implementation](#language-detection-implementation.md)\n- [Configuration Options](#configuration-options-1.md)\n- [TesseractOcrCliModel](#tesseractocrclimodel.md)\n- [Implementation Characteristics](#implementation-characteristics.md)\n- [Key Methods](#key-methods.md)\n- [Configuration Options](#configuration-options-2.md)\n- [EasyOcrModel](#easyocrmodel.md)\n- [Key Features](#key-features-1.md)\n- [Configuration Options](#configuration-options-3.md)\n- [OcrMacModel](#ocrmacmodel.md)\n- [Platform Requirements](#platform-requirements.md)\n- [OCR Processing Pipeline](#ocr-processing-pipeline.md)\n- [End-to-End OCR Flow](#end-to-end-ocr-flow.md)\n- [Coordinate Transformation](#coordinate-transformation.md)\n- [OCR Cell Post-Processing](#ocr-cell-post-processing.md)\n- [Configuration and Options](#configuration-and-options.md)\n- [OCR Options Factory](#ocr-options-factory.md)\n- [Common Options (All Engines)](#common-options-all-engines.md)\n- [Usage Examples](#usage-examples.md)\n- [Integration with Accelerator Options](#integration-with-accelerator-options.md)\n- [Performance and Capabilities](#performance-and-capabilities.md)\n- [Engine Comparison](#engine-comparison.md)\n- [Processing Characteristics](#processing-characteristics.md)\n- [Quality Assessment](#quality-assessment.md)",
    "metadata": {
      "chunk_id": 7,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 538,
      "character_count": 2167,
      "created_at": "2025-10-16T17:42:16.941515",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 7,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_4.1-ocr-models.md",
      "collection_context": "Docling"
    }
  }
]
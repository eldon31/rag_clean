[
  {
    "text": "Output and Integration | docling-project/docling | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[docling-project/docling](https://github.com/docling-project/docling \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 12 October 2025 ([f7244a](https://github.com/docling-project/docling/commits/f7244a43))",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 115,
      "character_count": 423,
      "created_at": "2025-10-16T17:42:17.681506",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 0,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [Overview](docling-project/docling/1-overview.md)\n- [Installation](docling-project/docling/1.1-installation.md)\n- [Quick Start](docling-project/docling/1.2-quick-start.md)\n- [Core Architecture](docling-project/docling/2-core-architecture.md)\n- [Document Conversion Flow](docling-project/docling/2.1-document-conversion-flow.md)\n- [DoclingDocument Data Model](docling-project/docling/2.2-doclingdocument-data-model.md)\n- [Configuration and Pipeline Options](docling-project/docling/2.3-configuration-and-pipeline-options.md)\n- [Format Detection and Routing](docling-project/docling/2.4-format-detection-and-routing.md)\n- [Document Backends](docling-project/docling/3-document-backends.md)\n- [PDF Processing Backends](docling-project/docling/3.1-pdf-processing-backends.md)\n- [Office Document Backends](docling-project/docling/3.2-office-document-backends.md)\n- [Web and Markup Backends](docling-project/docling/3.3-web-and-markup-backends.md)\n- [AI/ML Models](docling-project/docling/4-aiml-models.md)\n- [OCR Models](docling-project/docling/4.1-ocr-models.md)\n- [Layout and Table Structure Models](docling-project/docling/4.2-layout-and-table-structure-models.md)\n- [Vision Language Models](docling-project/docling/4.3-vision-language-models.md)\n- [Inline VLM Models](docling-project/docling/4.3.1-inline-vlm-models.md)\n- [API-Based VLM Models](docling-project/docling/4.3.2-api-based-vlm-models.md)\n- [Enrichment Models](docling-project/docling/4.4-enrichment-models.md)\n- [Processing Pipelines](docling-project/docling/5-processing-pipelines.md)\n- [Standard PDF Pipeline](docling-project/docling/5.1-standard-pdf-pipeline.md)\n- [Threaded PDF Pipeline](docling-project/docling/5.2-threaded-pdf-pipeline.md)\n- [VLM Pipeline](docling-project/docling/5.3-vlm-pipeline.md)\n- [Extraction Pipeline](docling-project/docling/5.4-extraction-pipeline.md)\n- [ASR Pipeline](docling-project/docling/5.5-asr-pipeline.md)\n- [Base Pipeline Architecture](docling-project/docling/5.6-base-pipeline-architecture.md)\n- [Command Line Interface](docling-project/docling/6-command-line-interface.md)\n- [Document Conversion CLI](docling-project/docling/6.1-document-conversion-cli.md)\n- [Model Management CLI](docling-project/docling/6.2-model-management-cli.md)\n- [Python SDK](docling-project/docling/7-python-sdk.md)\n- [DocumentConverter API](docling-project/docling/7.1-documentconverter-api.md)\n- [DocumentExtractor API](docling-project/docling/7.2-documentextractor-api.md)\n- [Usage Examples](docling-project/docling/7.3-usage-examples.md)\n- [Output and Integration](docling-project/docling/8-output-and-integration.md)\n- [Export Formats](docling-project/docling/8.1-export-formats.md)\n- [Document Chunking](docling-project/docling/8.2-document-chunking.md)\n- [Framework Integrations](docling-project/docling/8.3-framework-integrations.md)\n- [Development and Testing](docling-project/docling/9-development-and-testing.md)\n- [Testing Framework](docling-project/docling/9.1-testing-framework.md)\n- [Ground Truth Data](docling-project/docling/9.2-ground-truth-data.md)\n- [CI/CD and Development Workflow](docling-project/docling/9.3-cicd-and-development-workflow.md)\n- [Deployment](docling-project/docling/10-deployment.md)\n- [Docker Deployment](docling-project/docling/10.1-docker-deployment.md)\n- [Model Artifacts Management](docling-project/docling/10.2-model-artifacts-management.md)\n\nMenu\n\n# Output and Integration\n\nRelevant source files",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 927,
      "character_count": 3421,
      "created_at": "2025-10-16T17:42:17.683860",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 1,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [.github/SECURITY.md](https://github.com/docling-project/docling/blob/f7244a43/.github/SECURITY.md)\n- [CHANGELOG.md](https://github.com/docling-project/docling/blob/f7244a43/CHANGELOG.md)\n- [CITATION.cff](https://github.com/docling-project/docling/blob/f7244a43/CITATION.cff)\n- [README.md](https://github.com/docling-project/docling/blob/f7244a43/README.md)\n- [docs/examples/minimal\\_vlm\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docs/examples/minimal_vlm_pipeline.py)\n- [docs/index.md](https://github.com/docling-project/docling/blob/f7244a43/docs/index.md)\n- [docs/usage/index.md](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/index.md)\n- [docs/usage/mcp.md](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/mcp.md)\n- [docs/usage/vision\\_models.md](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/vision_models.md)\n- [mkdocs.yml](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml)\n- [pyproject.toml](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml)\n- [uv.lock](https://github.com/docling-project/docling/blob/f7244a43/uv.lock)\n\n## Purpose and Scope\n\nThis document provides an overview of Docling's output capabilities and integration ecosystem. After documents are processed through pipelines and assembled into a `DoclingDocument` (see [DoclingDocument Data Model](docling-project/docling/2.2-doclingdocument-data-model.md)), they can be exported to multiple formats and integrated with downstream tools. This page covers:\n\n1. **Export formats**: Markdown, JSON, HTML, and DOCTAGS serialization from `DoclingDocument`\n2. **Document chunking**: Breaking documents into smaller segments for retrieval systems\n3. **Framework integrations**: Connecting with LangChain, LlamaIndex, Haystack, vector databases, and AI agents via MCP\n\nFor detailed information on specific export format options and methods, see [Export Formats](docling-project/docling/8.1-export-formats.md). For chunking strategies and configuration, see [Document Chunking](docling-project/docling/8.2-document-chunking.md). For framework-specific integration patterns, see [Framework Integrations](docling-project/docling/8.3-framework-integrations.md).\n\nSources: [pyproject.toml1-280](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L1-L280) [README.md1-161](https://github.com/docling-project/docling/blob/f7244a43/README.md#L1-L161) [mkdocs.yml54-162](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L54-L162)\n\n---\n\n## Output Architecture\n\nThe output subsystem is organized around the `DoclingDocument` as the central unified representation. All processed documents, regardless of their input format or processing pipeline, converge to this common structure before being exported or integrated with external systems.\n\n### Export Flow Diagram\n\n```\n```\n\n**Description**: This diagram illustrates how all processing pipelines converge on `DoclingDocument`, which serves as the single source for exports, chunking, and framework integrations. The export methods are direct serialization functions on the document object, while chunking produces `DocChunk` objects that can be fed into AI frameworks. Framework integrations can consume either the full `DoclingDocument` or chunked segments depending on the use case.\n\nSources: [README.md34-43](https://github.com/docling-project/docling/blob/f7244a43/README.md#L34-L43) [mkdocs.yml100-128](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L100-L128) [pyproject.toml47](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L47-L47)\n\n---\n\n## Export Formats Overview\n\nDocling provides four primary export formats, each accessed through methods on the `DoclingDocument` instance:",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 942,
      "character_count": 3805,
      "created_at": "2025-10-16T17:42:17.689892",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 2,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "| Format       | Method                 | Primary Use Case                            | Output Type |\n| ------------ | ---------------------- | ------------------------------------------- | ----------- |\n| **Markdown** | `export_to_markdown()` | Human-readable text, LLM input              | `str`       |\n| **JSON**     | `export_to_json()`     | Lossless serialization, programmatic access | `str`       |\n| **HTML**     | `export_to_html()`     | Web display, visual rendering               | `str`       |\n| **DOCTAGS**  | `export_to_doctags()`  | Structured markup, VLM training             | `str`       |\n\n### Basic Export Example\n\n```\n```\n\nEach export method supports format-specific options for controlling output behavior. For example, `export_to_markdown()` supports `image_mode` to control embedded image handling, and `export_to_json()` supports `indent` for pretty-printing.\n\n**DOCTAGS Format**: A specialized structured markup format designed for vision-language model training and structured document representation. DOCTAGS uses XML-like tags to encode document structure hierarchically (e.g., `<document>`, `<page>`, `<section>`, `<table>`). This format is the preferred output for VLM pipelines that generate structured representations directly.\n\nSources: [README.md35](https://github.com/docling-project/docling/blob/f7244a43/README.md#L35-L35) [docs/index.md27](https://github.com/docling-project/docling/blob/f7244a43/docs/index.md#L27-L27) [docs/usage/index.md10-20](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/index.md#L10-L20)\n\n---\n\n## Document Chunking Overview\n\nChunking breaks `DoclingDocument` instances into smaller `DocChunk` segments suitable for retrieval-augmented generation (RAG) systems and vector databases. Docling leverages the `docling-core` library's `HybridChunker`, which implements hierarchical and hybrid chunking strategies.\n\n### Chunking Workflow\n\n```\n```\n\n**Description**: The chunking process transforms a `DoclingDocument` into a list of `DocChunk` objects. Each chunk contains the text content, metadata about the source document items (paragraphs, tables, etc.), and hierarchical path information (headings leading to the chunk). This metadata enables context-aware retrieval.\n\n### Chunking Strategies\n\n1. **Hierarchical Chunking**: Respects document structure (sections, subsections) and preserves heading context\n2. **Hybrid Chunking**: Combines hierarchical structure with token/character limits to ensure chunks fit within model context windows\n3. **Token-Based Splitting**: Uses tokenizers to enforce maximum chunk sizes while respecting document boundaries\n\nThe chunker configuration allows control over:\n\n- Maximum chunk size (tokens or characters)\n- Overlap between consecutive chunks\n- Heading level depth for context preservation\n- Tokenizer selection (for transformer models)\n\nSources: [pyproject.toml47](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L47-L47) [mkdocs.yml100-103](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L100-L103)\n\n---\n\n## Framework Integration Architecture\n\nDocling provides native integrations with popular AI development frameworks, enabling seamless incorporation into RAG pipelines, agentic workflows, and document processing applications.\n\n### Integration Landscape Diagram\n\n```\n```\n\n**Description**: Docling integrates with the AI ecosystem at multiple levels. Document loaders/readers provide framework-specific adapters for LangChain, LlamaIndex, and Haystack. These frameworks then connect to vector databases for retrieval. Separately, agentic frameworks like MCP, CrewAI, and Bee Agent consume `DoclingDocument` directly for agent-based workflows.\n\nSources: [mkdocs.yml130-155](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L130-L155) [README.md109-113](https://github.com/docling-project/docling/blob/f7244a43/README.md#L109-L113)\n\n---\n\n## Integration Patterns\n\n### Pattern 1: Direct Framework Integration\n\nFrameworks like LangChain and LlamaIndex provide native loaders/readers that accept `DoclingDocument` objects:\n\n```\n```\n\nThese loaders handle the conversion from `DoclingDocument` (or `DocChunk`) to framework-native document representations.\n\n### Pattern 2: MCP Server for Agents\n\nThe Model Context Protocol (MCP) integration enables any MCP-compatible agent to access Docling's document processing capabilities as a service:\n\n```\n```\n\nThis configuration (placed in `claude_desktop_config.json` or `mcp.json` for LM Studio) exposes Docling as an MCP tool that agents can invoke for document conversion tasks.\n\n### Pattern 3: Vector Database Ingestion",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 1017,
      "character_count": 4651,
      "created_at": "2025-10-16T17:42:17.702300",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 3,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "Chunked documents can be embedded and stored in vector databases for semantic search:\n\n```\n```\n\nSources: [docs/usage/mcp.md1-31](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/mcp.md#L1-L31) [mkdocs.yml106-127](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L106-L127) [README.md37-42](https://github.com/docling-project/docling/blob/f7244a43/README.md#L37-L42)\n\n---\n\n## Export Method Reference\n\nAll export methods are instance methods on the `DoclingDocument` class. They serialize the unified document representation into format-specific string outputs:\n\n```\n```\n\n**Description**: The `DoclingDocument` Pydantic model provides four export methods, each with format-specific options. Common options include `image_mode` for controlling image handling (placeholders, embedded data, or references), `strict_text` for enforcing plain text output, and `indent` for JSON pretty-printing.\n\n### Export Method Signatures\n\n```\n```\n\nThese methods are implemented in the `docling-core` library, which `DoclingDocument` inherits from. The actual method implementations handle traversal of the document's hierarchical structure and serialization to each format.\n\nSources: [docs/usage/index.md10-20](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/index.md#L10-L20) [README.md77](https://github.com/docling-project/docling/blob/f7244a43/README.md#L77-L77)\n\n---\n\n## Chunking Configuration\n\nThe chunking subsystem uses `HybridChunker` from `docling-core`, configurable through initialization parameters:\n\n| Parameter                   | Type   | Default        | Description                       |\n| --------------------------- | ------ | -------------- | --------------------------------- |\n| `max_tokens`                | `int`  | 512            | Maximum tokens per chunk          |\n| `tokenizer`                 | `str`  | \"cl100k\\_base\" | Tokenizer for counting (tiktoken) |\n| `include_heading_hierarchy` | `bool` | `True`         | Add heading context to chunks     |\n| `overlap`                   | `int`  | 0              | Token overlap between chunks      |\n\n### Chunking Method Flow\n\n```\n```\n\n**Description**: The `HybridChunker.chunk()` method traverses the `DoclingDocument.body` items (paragraphs, tables, lists, etc.) and segments them into chunks respecting token limits. Each chunk is enriched with metadata including the hierarchical path (sequence of headings leading to the chunk) and references to source document items.\n\nSources: [pyproject.toml47](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L47-L47) [mkdocs.yml100-103](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L100-L103)\n\n---\n\n## Integration Dependencies\n\nFramework integrations are provided through optional dependency groups and separate integration packages:\n\n### Core Dependencies\n\n```\n```\n\n### Optional Integration Dependencies\n\n```\n```\n\n### Framework Integration Packages\n\nThe integrations are maintained as separate packages:\n\n- **LangChain**: `langchain-docling` package provides `DoclingLoader` and `DoclingPDFLoader`\n- **LlamaIndex**: `llama-index-readers-docling` provides `DoclingReader`\n- **Haystack**: `haystack-docling` provides `DoclingConverter`\n- **MCP**: `docling-mcp` provides the MCP server implementation\n\nThis separation allows framework integrations to evolve independently from Docling core.\n\nSources: [pyproject.toml45-148](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L45-L148) [mkdocs.yml130-155](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L130-L155)\n\n---\n\n## Use Case: RAG Pipeline\n\nA typical RAG pipeline using Docling follows this pattern:\n\n```\n```\n\n**Description**: The complete RAG workflow starts with document conversion to `DoclingDocument`, followed by chunking into `DocChunk` objects. Chunks are embedded and stored in a vector database. At query time, relevant chunks are retrieved via similarity search and provided as context to an LLM for answer generation.\n\n### Code Example Structure\n\n```\n```\n\nSources: [mkdocs.yml106-127](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L106-L127) [pyproject.toml144-148](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L144-L148)\n\n---\n\n## MCP Server Architecture",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 1017,
      "character_count": 4316,
      "created_at": "2025-10-16T17:42:17.715139",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 4,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "The MCP (Model Context Protocol) server provides a standardized interface for AI agents to access Docling's document conversion capabilities:\n\n```\n```\n\n**Description**: The MCP server (`docling-mcp-server`) runs as a separate process and communicates with MCP clients via JSON-RPC over standard input/output. Clients (like Claude Desktop or LM Studio) can invoke Docling document conversion as a tool, passing document paths or URLs and receiving structured `DoclingDocument` representations in response.\n\n### MCP Configuration Example\n\n```\n```\n\nThis configuration launches the MCP server using `uvx` (the uv package runner), which handles dependency installation and execution. The server then registers itself with the MCP client, making Docling tools available to the agent.\n\nSources: [docs/usage/mcp.md1-31](https://github.com/docling-project/docling/blob/f7244a43/docs/usage/mcp.md#L1-L31) [README.md41](https://github.com/docling-project/docling/blob/f7244a43/README.md#L41-L41)\n\n---\n\n## Export Format Comparison\n\nDifferent export formats serve different downstream use cases:\n\n| Format       | Structure Preservation       | Human Readable      | Lossless                | Primary Consumers          |\n| ------------ | ---------------------------- | ------------------- | ----------------------- | -------------------------- |\n| **Markdown** | ⭐⭐⭐ Heading hierarchy, lists | ⭐⭐⭐ Highly readable | ❌ No (styling lost)     | LLMs, humans, static sites |\n| **JSON**     | ⭐⭐⭐ Full provenance          | ⭐ Programmatic      | ✅ Yes (complete)        | Applications, archival     |\n| **HTML**     | ⭐⭐ Visual structure          | ⭐⭐ Web rendering    | ❌ No (formatting focus) | Web browsers, displays     |\n| **DOCTAGS**  | ⭐⭐⭐ Semantic tags            | ⭐⭐ Structured text  | ⭐⭐ Partial              | VLMs, structured ML        |\n\n### Format Selection Guide\n\n**Use Markdown when:**\n\n- Providing context to language models\n- Creating human-readable documentation\n- Generating static websites or wikis\n\n**Use JSON when:**\n\n- Preserving complete document structure for later processing\n- Building document databases or archives\n- Implementing document version control\n\n**Use HTML when:**\n\n- Rendering documents in web applications\n- Creating interactive document viewers\n- Generating print-ready outputs\n\n**Use DOCTAGS when:**\n\n- Training or fine-tuning vision-language models\n- Creating structured datasets for ML\n- Preserving semantic document structure with minimal tokens\n\nSources: [README.md35](https://github.com/docling-project/docling/blob/f7244a43/README.md#L35-L35) [docs/index.md27](https://github.com/docling-project/docling/blob/f7244a43/docs/index.md#L27-L27)\n\n---\n\n## Summary\n\nDocling's output and integration capabilities center around the `DoclingDocument` unified representation:\n\n1. **Export**: Four serialization formats (`export_to_markdown()`, `export_to_json()`, `export_to_html()`, `export_to_doctags()`) provide format-specific outputs for different use cases\n\n2. **Chunking**: The `HybridChunker` from `docling-core` segments documents into `DocChunk` objects with preserved hierarchical context for RAG systems\n\n3. **Integration**: Native support for LangChain, LlamaIndex, Haystack via dedicated loader packages, plus MCP server for agent frameworks\n\nAll export and integration paths preserve the document's hierarchical structure and provenance metadata, enabling downstream systems to leverage Docling's advanced document understanding capabilities.\n\nSources: [README.md28-43](https://github.com/docling-project/docling/blob/f7244a43/README.md#L28-L43) [pyproject.toml45-148](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml#L45-L148) [mkdocs.yml54-162](https://github.com/docling-project/docling/blob/f7244a43/mkdocs.yml#L54-L162)\n\nDismiss\n\nRefresh this wiki\n\nThis wiki was recently refreshed. Please wait 4 days to refresh again.\n\n### On this page",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 897,
      "character_count": 3903,
      "created_at": "2025-10-16T17:42:17.724395",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 5,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [Output and Integration](#output-and-integration.md)\n- [Purpose and Scope](#purpose-and-scope.md)\n- [Output Architecture](#output-architecture.md)\n- [Export Flow Diagram](#export-flow-diagram.md)\n- [Export Formats Overview](#export-formats-overview.md)\n- [Basic Export Example](#basic-export-example.md)\n- [Document Chunking Overview](#document-chunking-overview.md)\n- [Chunking Workflow](#chunking-workflow.md)\n- [Chunking Strategies](#chunking-strategies.md)\n- [Framework Integration Architecture](#framework-integration-architecture.md)\n- [Integration Landscape Diagram](#integration-landscape-diagram.md)\n- [Integration Patterns](#integration-patterns.md)\n- [Pattern 1: Direct Framework Integration](#pattern-1-direct-framework-integration.md)\n- [Pattern 2: MCP Server for Agents](#pattern-2-mcp-server-for-agents.md)\n- [Pattern 3: Vector Database Ingestion](#pattern-3-vector-database-ingestion.md)\n- [Export Method Reference](#export-method-reference.md)\n- [Export Method Signatures](#export-method-signatures.md)\n- [Chunking Configuration](#chunking-configuration.md)\n- [Chunking Method Flow](#chunking-method-flow.md)\n- [Integration Dependencies](#integration-dependencies.md)\n- [Core Dependencies](#core-dependencies.md)\n- [Optional Integration Dependencies](#optional-integration-dependencies.md)\n- [Framework Integration Packages](#framework-integration-packages.md)\n- [Use Case: RAG Pipeline](#use-case-rag-pipeline.md)\n- [Code Example Structure](#code-example-structure.md)\n- [MCP Server Architecture](#mcp-server-architecture.md)\n- [MCP Configuration Example](#mcp-configuration-example.md)\n- [Export Format Comparison](#export-format-comparison.md)\n- [Format Selection Guide](#format-selection-guide.md)\n- [Summary](#summary.md)",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 419,
      "character_count": 1745,
      "created_at": "2025-10-16T17:42:17.724610",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 6,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_8-output-and-integration.md",
      "collection_context": "Docling"
    }
  }
]
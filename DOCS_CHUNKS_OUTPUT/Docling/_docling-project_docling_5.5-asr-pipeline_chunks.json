[
  {
    "text": "ASR Pipeline | docling-project/docling | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[docling-project/docling](https://github.com/docling-project/docling \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 12 October 2025 ([f7244a](https://github.com/docling-project/docling/commits/f7244a43))",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 115,
      "character_count": 413,
      "created_at": "2025-10-16T17:42:17.345515",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 0,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [Overview](docling-project/docling/1-overview.md)\n- [Installation](docling-project/docling/1.1-installation.md)\n- [Quick Start](docling-project/docling/1.2-quick-start.md)\n- [Core Architecture](docling-project/docling/2-core-architecture.md)\n- [Document Conversion Flow](docling-project/docling/2.1-document-conversion-flow.md)\n- [DoclingDocument Data Model](docling-project/docling/2.2-doclingdocument-data-model.md)\n- [Configuration and Pipeline Options](docling-project/docling/2.3-configuration-and-pipeline-options.md)\n- [Format Detection and Routing](docling-project/docling/2.4-format-detection-and-routing.md)\n- [Document Backends](docling-project/docling/3-document-backends.md)\n- [PDF Processing Backends](docling-project/docling/3.1-pdf-processing-backends.md)\n- [Office Document Backends](docling-project/docling/3.2-office-document-backends.md)\n- [Web and Markup Backends](docling-project/docling/3.3-web-and-markup-backends.md)\n- [AI/ML Models](docling-project/docling/4-aiml-models.md)\n- [OCR Models](docling-project/docling/4.1-ocr-models.md)\n- [Layout and Table Structure Models](docling-project/docling/4.2-layout-and-table-structure-models.md)\n- [Vision Language Models](docling-project/docling/4.3-vision-language-models.md)\n- [Inline VLM Models](docling-project/docling/4.3.1-inline-vlm-models.md)\n- [API-Based VLM Models](docling-project/docling/4.3.2-api-based-vlm-models.md)\n- [Enrichment Models](docling-project/docling/4.4-enrichment-models.md)\n- [Processing Pipelines](docling-project/docling/5-processing-pipelines.md)\n- [Standard PDF Pipeline](docling-project/docling/5.1-standard-pdf-pipeline.md)\n- [Threaded PDF Pipeline](docling-project/docling/5.2-threaded-pdf-pipeline.md)\n- [VLM Pipeline](docling-project/docling/5.3-vlm-pipeline.md)\n- [Extraction Pipeline](docling-project/docling/5.4-extraction-pipeline.md)\n- [ASR Pipeline](docling-project/docling/5.5-asr-pipeline.md)\n- [Base Pipeline Architecture](docling-project/docling/5.6-base-pipeline-architecture.md)\n- [Command Line Interface](docling-project/docling/6-command-line-interface.md)\n- [Document Conversion CLI](docling-project/docling/6.1-document-conversion-cli.md)\n- [Model Management CLI](docling-project/docling/6.2-model-management-cli.md)\n- [Python SDK](docling-project/docling/7-python-sdk.md)\n- [DocumentConverter API](docling-project/docling/7.1-documentconverter-api.md)\n- [DocumentExtractor API](docling-project/docling/7.2-documentextractor-api.md)\n- [Usage Examples](docling-project/docling/7.3-usage-examples.md)\n- [Output and Integration](docling-project/docling/8-output-and-integration.md)\n- [Export Formats](docling-project/docling/8.1-export-formats.md)\n- [Document Chunking](docling-project/docling/8.2-document-chunking.md)\n- [Framework Integrations](docling-project/docling/8.3-framework-integrations.md)\n- [Development and Testing](docling-project/docling/9-development-and-testing.md)\n- [Testing Framework](docling-project/docling/9.1-testing-framework.md)\n- [Ground Truth Data](docling-project/docling/9.2-ground-truth-data.md)\n- [CI/CD and Development Workflow](docling-project/docling/9.3-cicd-and-development-workflow.md)\n- [Deployment](docling-project/docling/10-deployment.md)\n- [Docker Deployment](docling-project/docling/10.1-docker-deployment.md)\n- [Model Artifacts Management](docling-project/docling/10.2-model-artifacts-management.md)\n\nMenu\n\n# ASR Pipeline\n\nRelevant source files",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 927,
      "character_count": 3411,
      "created_at": "2025-10-16T17:42:17.348584",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 1,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "- [.github/SECURITY.md](https://github.com/docling-project/docling/blob/f7244a43/.github/SECURITY.md)\n- [CHANGELOG.md](https://github.com/docling-project/docling/blob/f7244a43/CHANGELOG.md)\n- [CITATION.cff](https://github.com/docling-project/docling/blob/f7244a43/CITATION.cff)\n- [docling/datamodel/extraction.py](https://github.com/docling-project/docling/blob/f7244a43/docling/datamodel/extraction.py)\n- [docling/document\\_extractor.py](https://github.com/docling-project/docling/blob/f7244a43/docling/document_extractor.py)\n- [docling/models/vlm\\_models\\_inline/nuextract\\_transformers\\_model.py](https://github.com/docling-project/docling/blob/f7244a43/docling/models/vlm_models_inline/nuextract_transformers_model.py)\n- [docling/pipeline/asr\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py)\n- [docling/pipeline/base\\_extraction\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/base_extraction_pipeline.py)\n- [docling/pipeline/base\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/base_pipeline.py)\n- [docling/pipeline/extraction\\_vlm\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/extraction_vlm_pipeline.py)\n- [docling/pipeline/simple\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/simple_pipeline.py)\n- [docling/pipeline/threaded\\_standard\\_pdf\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/threaded_standard_pdf_pipeline.py)\n- [docling/pipeline/vlm\\_pipeline.py](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py)\n- [pyproject.toml](https://github.com/docling-project/docling/blob/f7244a43/pyproject.toml)\n- [uv.lock](https://github.com/docling-project/docling/blob/f7244a43/uv.lock)\n\nThe ASR (Automatic Speech Recognition) Pipeline provides audio transcription capabilities within Docling, converting audio files into text-based `DoclingDocument` representations. This pipeline uses OpenAI's Whisper models to transcribe speech and generates structured output with optional timestamps and word-level segmentation.\n\nFor information about other pipeline types, see:\n\n- Standard PDF processing: [Standard PDF Pipeline](docling-project/docling/5.1-standard-pdf-pipeline.md)\n- Vision-based document processing: [VLM Pipeline](docling-project/docling/5.3-vlm-pipeline.md)\n- Structured data extraction: [Extraction Pipeline](docling-project/docling/5.4-extraction-pipeline.md)\n\n## Overview\n\nThe ASR Pipeline differs fundamentally from other Docling pipelines in several ways:\n\n1. **No page-based processing**: Audio files are not paginated, so the pipeline inherits directly from `BasePipeline` rather than `PaginatedPipeline`\n2. **Backend architecture**: Uses `NoOpBackend` since audio files don't require document parsing like PDFs\n3. **Output format**: Produces text-based `DoclingDocument` with conversation items containing transcribed text and optional timing information\n4. **Model dependency**: Requires the `openai-whisper` package (installable via `pip install openai-whisper` or `uv sync --extra asr`)\n\nSources: [docling/pipeline/asr\\_pipeline.py1-270](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L1-L270)\n\n## Architecture\n\n```\n```\n\n**Figure 1: ASR Pipeline Component Architecture**\n\nThe ASR Pipeline follows a streamlined architecture compared to document processing pipelines:\n\n- **NoOpBackend** provides access to the audio file path or stream without parsing\n- **\\_NativeWhisperModel** handles the actual transcription using Whisper\n- **\\_ConversationItem** structures represent transcribed segments with metadata\n- Final output is a `DoclingDocument` populated with `TextItem` elements\n\nSources: [docling/pipeline/asr\\_pipeline.py1-50](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L1-L50) [docling/pipeline/asr\\_pipeline.py232-270](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L232-L270)\n\n## Pipeline Initialization",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 1023,
      "character_count": 4167,
      "created_at": "2025-10-16T17:42:17.354635",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 2,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "### Class Hierarchy\n\n```\n```\n\n**Figure 2: ASR Pipeline Class Hierarchy**\n\nThe `AsrPipeline` class inherits directly from `BasePipeline` (not `PaginatedPipeline`) because audio files are not paginated.\n\nSources: [docling/pipeline/asr\\_pipeline.py232-270](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L232-L270) [docling/pipeline/base\\_pipeline.py43-133](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/base_pipeline.py#L43-L133)\n\n### Initialization Process\n\nThe pipeline is initialized in `AsrPipeline.__init__()`:\n\n| Component          | Purpose                                   | Configuration Source          |\n| ------------------ | ----------------------------------------- | ----------------------------- |\n| `pipeline_options` | Contains ASR model configuration          | `AsrPipelineOptions`          |\n| `keep_backend`     | Set to `True` to retain backend reference | Fixed value                   |\n| `_model`           | Whisper transcription model wrapper       | `_NativeWhisperModel`         |\n| `artifacts_path`   | Model download/cache location             | Inherited from `BasePipeline` |\n\nThe initialization delegates model setup to `_NativeWhisperModel`:\n\n```\nAsrPipeline.__init__()\n  ├── super().__init__(pipeline_options)\n  │   └── Sets artifacts_path from options or settings\n  ├── self.keep_backend = True\n  └── self._model = _NativeWhisperModel(...)\n      ├── Import whisper package\n      ├── Set device (CPU/CUDA/MPS) based on accelerator_options\n      ├── Load Whisper model with name from asr_options.repo_id\n      └── Configure transcription parameters (verbose, timestamps, word_timestamps)\n```\n\nSources: [docling/pipeline/asr\\_pipeline.py233-251](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L233-L251) [docling/pipeline/asr\\_pipeline.py99-149](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L99-L149)\n\n## Audio Processing Flow\n\n```\n```\n\n**Figure 3: ASR Pipeline Execution Sequence**\n\nSources: [docling/pipeline/asr\\_pipeline.py260-265](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L260-L265) [docling/pipeline/asr\\_pipeline.py150-230](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L150-L230)\n\n### Step-by-Step Processing\n\n1. **Pipeline Entry** ([asr\\_pipeline.py260-265](https://github.com/docling-project/docling/blob/f7244a43/asr_pipeline.py#L260-L265)):\n\n- `AsrPipeline._build_document()` is called by the base pipeline's `execute()` method\n   - Delegates immediately to `_NativeWhisperModel.run()`\n\n2. **Input Handling** ([asr\\_pipeline.py150-169](https://github.com/docling-project/docling/blob/f7244a43/asr_pipeline.py#L150-L169)):\n\n- Accesses `path_or_stream` from the `NoOpBackend`\n   - For `BytesIO` inputs, creates a temporary file (Whisper requires file paths)\n   - For `Path` inputs, uses the path directly\n\n3. **Transcription** ([asr\\_pipeline.py171-189](https://github.com/docling-project/docling/blob/f7244a43/asr_pipeline.py#L171-L189)):\n\n- Calls `_NativeWhisperModel.transcribe()` which invokes the Whisper model\n   - Whisper returns segments with text, start time, end time, and optionally word-level timestamps\n\n4. **Document Assembly** ([asr\\_pipeline.py174-188](https://github.com/docling-project/docling/blob/f7244a43/asr_pipeline.py#L174-L188)):\n\n- Creates a `DoclingDocument` with proper `DocumentOrigin` metadata\n   - Iterates through conversation items\n   - Each item is added as a `TextItem` with `DocItemLabel.TEXT`\n\n5. **Cleanup** ([asr\\_pipeline.py197-205](https://github.com/docling-project/docling/blob/f7244a43/asr_pipeline.py#L197-L205)):\n\n- Removes temporary files if created from `BytesIO` input\n\nSources: [docling/pipeline/asr\\_pipeline.py150-230](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L150-L230)\n\n## Whisper Model Integration",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 1015,
      "character_count": 3997,
      "created_at": "2025-10-16T17:42:17.362756",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 3,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "### Model Wrapper: \\_NativeWhisperModel\n\nThe `_NativeWhisperModel` class encapsulates Whisper model loading and inference:\n\n| Property          | Type          | Purpose                       |\n| ----------------- | ------------- | ----------------------------- |\n| `enabled`         | `bool`        | Whether model is active       |\n| `device`          | `str`         | Compute device (cpu/cuda/mps) |\n| `model`           | Whisper model | Loaded Whisper model instance |\n| `max_tokens`      | `int`         | Maximum tokens per generation |\n| `temperature`     | `float`       | Sampling temperature          |\n| `verbose`         | `bool`        | Enable Whisper logging        |\n| `timestamps`      | `bool`        | Include segment timestamps    |\n| `word_timestamps` | `bool`        | Include word-level timestamps |\n\n### Model Loading Logic\n\n```\n```\n\n**Figure 4: Whisper Model Loading Flow**\n\nSources: [docling/pipeline/asr\\_pipeline.py99-149](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L99-L149)\n\n### Device Selection\n\nThe model automatically selects the appropriate device using `decide_device()`:\n\n1. Checks `accelerator_options.device` setting\n2. Validates against `asr_options.supported_devices`\n3. Falls back to CPU if CUDA/MPS unavailable\n4. Logs the selected device for debugging\n\nSources: [docling/pipeline/asr\\_pipeline.py126-130](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L126-L130)\n\n### Transcription Output Structure\n\nThe `transcribe()` method returns a list of `_ConversationItem` objects:\n\n```\n```\n\nEach conversation item can be formatted as:\n\n```\n[time: 0.0-5.2] [speaker:speaker-1] Transcribed text goes here\n```\n\nSources: [docling/pipeline/asr\\_pipeline.py50-97](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L50-L97) [docling/pipeline/asr\\_pipeline.py207-229](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L207-L229)\n\n## Configuration Options\n\n### AsrPipelineOptions\n\nThe `AsrPipelineOptions` class (defined in the options module, referenced in the code) configures the ASR pipeline:\n\n```\n```\n\n### InlineAsrNativeWhisperOptions\n\nModel-specific configuration for native Whisper:\n\n| Option              | Type        | Default                 | Purpose                                              |\n| ------------------- | ----------- | ----------------------- | ---------------------------------------------------- |\n| `repo_id`           | `str`       | e.g., \"base\"            | Whisper model variant (tiny/base/small/medium/large) |\n| `max_new_tokens`    | `int`       | -                       | Maximum tokens to generate                           |\n| `temperature`       | `float`     | -                       | Sampling temperature                                 |\n| `verbose`           | `bool`      | `False`                 | Enable detailed logging                              |\n| `timestamps`        | `bool`      | `True`                  | Include segment timestamps                           |\n| `word_timestamps`   | `bool`      | `False`                 | Include word-level timestamps                        |\n| `supported_devices` | `list[str]` | \\[\"cuda\", \"cpu\", \"mps\"] | Allowed compute devices                              |\n\nSources: [docling/pipeline/asr\\_pipeline.py105-148](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L105-L148)\n\n### Default Options\n\n```\n```\n\nThis provides default configuration when no options are explicitly specified.\n\nSources: [docling/pipeline/asr\\_pipeline.py256-258](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L256-L258)\n\n## Backend Integration\n\n### NoOpBackend Usage\n\nThe ASR pipeline uses `NoOpBackend` which provides minimal functionality:\n\n```\n```\n\n**Figure 5: NoOpBackend Role**\n\nThe backend's role is limited to:\n\n1. Storing the `path_or_stream` reference\n2. Providing file metadata (name, size, etc.)\n3. No parsing or structure extraction (unlike PDF backends)\n\nThe `is_backend_supported()` method validates this:\n\n```\n```",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 957,
      "character_count": 4185,
      "created_at": "2025-10-16T17:42:17.376201",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 4,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "Sources: [docling/pipeline/asr\\_pipeline.py268-269](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L268-L269) [docling/backend/noop\\_backend.py1-20](https://github.com/docling-project/docling/blob/f7244a43/docling/backend/noop_backend.py#L1-L20) (referenced but not shown)\n\n### Input Handling: Path vs BytesIO\n\nThe pipeline handles two input types:\n\n| Input Type | Handling                  | Cleanup Required         |\n| ---------- | ------------------------- | ------------------------ |\n| `Path`     | Used directly by Whisper  | No                       |\n| `BytesIO`  | Written to temporary file | Yes (in `finally` block) |\n\n**Temporary File Creation**:\n\n```\n```\n\nThis approach is necessary because the Whisper library requires file paths for audio processing.\n\nSources: [docling/pipeline/asr\\_pipeline.py154-169](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L154-L169)\n\n## Output Format\n\n### DoclingDocument Structure\n\nThe ASR pipeline creates a simple `DoclingDocument` structure:\n\n```\n```\n\n**Figure 6: ASR Output Document Structure**\n\nUnlike PDF documents, ASR output:\n\n- Has no page structure\n- No layout elements (headings, tables, figures)\n- Only text items with optional timestamps\n- No bounding boxes or provenance information\n\nSources: [docling/pipeline/asr\\_pipeline.py174-188](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L174-L188)\n\n### Text Formatting\n\nEach conversation item is formatted using `_ConversationItem.to_string()`:\n\n```\n```\n\nExample output:\n\n```\n[time: 0.0-5.234] This is the first transcribed segment\n[time: 5.234-10.512] This is the second segment with more text\n[time: 10.512-15.801] And this is the third segment\n```\n\nSources: [docling/pipeline/asr\\_pipeline.py86-96](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L86-L96)\n\n## Error Handling\n\n### Exception Management\n\n```\n```\n\n**Figure 7: ASR Error Handling Flow**\n\nError handling includes:\n\n1. **Import errors**: Caught during initialization if `openai-whisper` not installed\n2. **Transcription errors**: Logged and set `status = FAILURE`\n3. **Cleanup guarantees**: Temporary files deleted in `finally` block\n4. **Graceful degradation**: Failed conversions return `ConversionResult` with `FAILURE` status\n\nSources: [docling/pipeline/asr\\_pipeline.py171-205](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L171-L205)\n\n### Status Determination\n\n```\n```\n\nThe ASR pipeline uses a simple status determination: if `_build_document()` completes without raising an exception, the status is `SUCCESS`. Unlike PDF pipelines, there's no concept of partial success (no page-level validation).\n\nSources: [docling/pipeline/asr\\_pipeline.py252-254](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L252-L254)\n\n## Usage Example\n\n```\n```\n\n## Integration with DocumentConverter\n\nThe ASR pipeline is automatically selected by `DocumentConverter` when processing audio formats:\n\n```\n```\n\n**Figure 8: ASR Pipeline Selection in DocumentConverter**\n\nThe format-to-pipeline mapping is configured in `DocumentConverter.format_to_options`:\n\n- Audio formats (MP3, WAV, etc.) → `AsrPipeline`\n- Uses `AudioBackend` or `NoOpBackend` for file access\n- Pipeline options can be customized per format\n\nSources: [docling/pipeline/asr\\_pipeline.py232-270](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L232-L270) [docling/document\\_converter.py1-500](https://github.com/docling-project/docling/blob/f7244a43/docling/document_converter.py#L1-L500) (referenced but not shown in detail)\n\n## Key Differences from Other Pipelines",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 939,
      "character_count": 3781,
      "created_at": "2025-10-16T17:42:17.388699",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 5,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "collection_context": "Docling"
    }
  },
  {
    "text": "| Aspect           | ASR Pipeline       | PDF Pipelines         | VLM Pipeline          |\n| ---------------- | ------------------ | --------------------- | --------------------- |\n| Base class       | `BasePipeline`     | `PaginatedPipeline`   | `PaginatedPipeline`   |\n| Backend type     | `NoOpBackend`      | `PdfDocumentBackend`  | `PdfDocumentBackend`  |\n| Processing unit  | Entire audio file  | Individual pages      | Individual pages      |\n| Primary model    | Whisper (external) | Layout, Table, OCR    | Vision-Language Model |\n| Output structure | Sequential text    | Hierarchical document | Structured document   |\n| Temporal data    | Timestamps         | Page numbers          | Page numbers          |\n\nSources: [docling/pipeline/asr\\_pipeline.py232-270](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/asr_pipeline.py#L232-L270) [docling/pipeline/base\\_pipeline.py184-320](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/base_pipeline.py#L184-L320) [docling/pipeline/vlm\\_pipeline.py50-389](https://github.com/docling-project/docling/blob/f7244a43/docling/pipeline/vlm_pipeline.py#L50-L389)\n\nDismiss\n\nRefresh this wiki\n\nThis wiki was recently refreshed. Please wait 4 days to refresh again.\n\n### On this page\n\n- [ASR Pipeline](#asr-pipeline.md)\n- [Overview](#overview.md)\n- [Architecture](#architecture.md)\n- [Pipeline Initialization](#pipeline-initialization.md)\n- [Class Hierarchy](#class-hierarchy.md)\n- [Initialization Process](#initialization-process.md)\n- [Audio Processing Flow](#audio-processing-flow.md)\n- [Step-by-Step Processing](#step-by-step-processing.md)\n- [Whisper Model Integration](#whisper-model-integration.md)\n- [Model Wrapper: \\_NativeWhisperModel](#model-wrapper-_nativewhispermodel.md)\n- [Model Loading Logic](#model-loading-logic.md)\n- [Device Selection](#device-selection.md)\n- [Transcription Output Structure](#transcription-output-structure.md)\n- [Configuration Options](#configuration-options.md)\n- [AsrPipelineOptions](#asrpipelineoptions.md)\n- [InlineAsrNativeWhisperOptions](#inlineasrnativewhisperoptions.md)\n- [Default Options](#default-options.md)\n- [Backend Integration](#backend-integration.md)\n- [NoOpBackend Usage](#noopbackend-usage.md)\n- [Input Handling: Path vs BytesIO](#input-handling-path-vs-bytesio.md)\n- [Output Format](#output-format.md)\n- [DoclingDocument Structure](#doclingdocument-structure.md)\n- [Text Formatting](#text-formatting.md)\n- [Error Handling](#error-handling.md)\n- [Exception Management](#exception-management.md)\n- [Status Determination](#status-determination.md)\n- [Usage Example](#usage-example.md)\n- [Integration with DocumentConverter](#integration-with-documentconverter.md)\n- [Key Differences from Other Pipelines](#key-differences-from-other-pipelines.md)",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "input_type": "docling",
      "chunking_strategy": "hybrid_adaptive",
      "token_count": 691,
      "character_count": 2798,
      "created_at": "2025-10-16T17:42:17.390514",
      "parent_context": null,
      "semantic_type": "docling",
      "collection_name": "Docling",
      "subfolder_name": null,
      "collection_strategy": "hybrid_adaptive",
      "chunk_index_in_file": 6,
      "file_relative_path": "Docs\\Docling\\_docling-project_docling_5.5-asr-pipeline.md",
      "collection_context": "Docling"
    }
  }
]
[
  {
    "text": "Medical Image Search with Vision Transformers | qdrant/examples | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[qdrant/examples](https://github.com/qdrant/examples \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 26 June 2025 ([b3c4b2](https://github.com/qdrant/examples/commits/b3c4b28f))\n\n- [Overview](qdrant/examples/1-overview.md)\n- [Getting Started with Qdrant](qdrant/examples/2-getting-started-with-qdrant.md)\n- [Text Data Applications](qdrant/examples/3-text-data-applications.md)\n- [Code Search with Dual Embeddings](qdrant/examples/3.1-code-search-with-dual-embeddings.md)\n- [Extractive Question Answering](qdrant/examples/3.2-extractive-question-answering.md)\n- [Movie Recommendations with Sparse Vectors](qdrant/examples/3.3-movie-recommendations-with-sparse-vectors.md)\n- [Image Data Applications](qdrant/examples/4-image-data-applications.md)\n- [E-commerce Reverse Image Search](qdrant/examples/4.1-e-commerce-reverse-image-search.md)\n- [Medical Image Search with Vision Transformers](qdrant/examples/4.2-medical-image-search-with-vision-transformers.md)\n- [Audio Data Applications](qdrant/examples/5-audio-data-applications.md)\n- [Music Recommendation Engine](qdrant/examples/5.1-music-recommendation-engine.md)\n- [Advanced RAG Systems](qdrant/examples/6-advanced-rag-systems.md)\n- [Multivector RAG with DSPy](qdrant/examples/6.1-multivector-rag-with-dspy.md)\n- [Graph-Enhanced RAG with Neo4j](qdrant/examples/6.2-graph-enhanced-rag-with-neo4j.md)\n- [PDF Retrieval at Scale](qdrant/examples/6.3-pdf-retrieval-at-scale.md)\n- [Agentic Systems with CrewAI](qdrant/examples/7-agentic-systems-with-crewai.md)\n- [Meeting Analysis with Agentic RAG](qdrant/examples/7.1-meeting-analysis-with-agentic-rag.md)\n- [Additional Use Cases](qdrant/examples/8-additional-use-cases.md)\n- [Self-Query Systems with LangChain](qdrant/examples/8.1-self-query-systems-with-langchain.md)\n- [Development Environment Setup](qdrant/examples/8.2-development-environment-setup.md)\n\nMenu\n\n# Medical Image Search with Vision Transformers\n\nRelevant source files\n\n- [qdrant\\_101\\_image\\_data/04\\_qdrant\\_101\\_cv.ipynb](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/04_qdrant_101_cv.ipynb)\n- [qdrant\\_101\\_image\\_data/README.md](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md)\n\n## Purpose and Scope\n\nThis document describes the medical image search system that enables healthcare professionals to find similar skin lesion images using semantic search powered by Vision Transformers and Qdrant vector database. The system processes medical images to extract visual embeddings and provides similarity-based retrieval with advanced filtering capabilities for demographic and diagnostic criteria.\n\nFor general image search applications in e-commerce contexts, see [E-commerce Reverse Image Search](qdrant/examples/4.1-e-commerce-reverse-image-search.md). For foundational Qdrant concepts, see [Getting Started with Qdrant](qdrant/examples/2-getting-started-with-qdrant.md).\n\n## System Architecture Overview\n\nThe medical image search system combines computer vision models with vector database technology to enable semantic similarity search across dermatological images.\n\n### Core System Components\n\n```\n```\n\nSources: [qdrant\\_101\\_image\\_data/README.md1-984](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L1-L984)\n\n### Data Flow Pipeline\n\n```\n```",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4.2-medical-image-search-with-vision-transformers.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 932,
      "character_count": 3540,
      "created_at": "2025-10-16T17:42:29.491401",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_examples",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "Qdrant\\qdrant_examples\\_qdrant_examples_4.2-medical-image-search-with-vision-transformers.md",
      "collection_context": "Qdrant/qdrant_examples"
    }
  },
  {
    "text": "Sources: [qdrant\\_101\\_image\\_data/README.md295-398](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L295-L398) [qdrant\\_101\\_image\\_data/README.md453-520](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L453-L520)\n\n## Vision Transformer Implementation\n\nThe system utilizes Facebook's DINO Vision Transformer model for extracting meaningful visual features from medical images.\n\n### Model Configuration\n\n| Component         | Specification                                               |\n| ----------------- | ----------------------------------------------------------- |\n| Processor         | `ViTImageProcessor.from_pretrained('facebook/dino-vits16')` |\n| Model             | `ViTModel.from_pretrained('facebook/dino-vits16')`          |\n| Input Size        | 224x224 pixels (3 channels)                                 |\n| Output Dimensions | 384-dimensional embeddings                                  |\n| Patch Processing  | 197 patches per image                                       |\n| Pooling Method    | Mean pooling across patches                                 |\n\nThe embedding extraction process transforms raw medical images into dense vector representations that capture visual similarities relevant for diagnostic comparison.\n\nSources: [qdrant\\_101\\_image\\_data/README.md203-207](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L203-L207) [qdrant\\_101\\_image\\_data/README.md295-302](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L295-L302)\n\n### Dataset Structure\n\nThe system processes a comprehensive skin lesion dataset with the following metadata schema:\n\n```\n```\n\nSources: [qdrant\\_101\\_image\\_data/README.md23-34](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L23-L34) [qdrant\\_101\\_image\\_data/README.md332-360](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L332-L360)\n\n## Qdrant Vector Database Integration\n\nThe system leverages Qdrant for efficient similarity search and metadata filtering across medical image embeddings.\n\n### Collection Configuration\n\n```\n```\n\nSources: [qdrant\\_101\\_image\\_data/README.md95-100](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L95-L100) [qdrant\\_101\\_image\\_data/README.md379-398](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L379-L398)\n\n## Advanced Search Capabilities\n\nThe system provides sophisticated search functionality tailored for medical diagnostic applications.\n\n### Filter Types and Use Cases\n\n| Filter Type | Purpose                             | Example Implementation                                                     |\n| ----------- | ----------------------------------- | -------------------------------------------------------------------------- |\n| Demographic | Age/gender-based filtering          | `FieldCondition(key=\"sex\", match=MatchValue(value=\"female\"))`              |\n| Diagnostic  | Disease category filtering          | `FieldCondition(key=\"dx\", match=MatchExcept(except=[\"melanoma\"]))`         |\n| Anatomical  | Body location filtering             | `FieldCondition(key=\"localization\", match=MatchAny(any=[\"face\", \"neck\"]))` |\n| ID-based    | Specific sample inclusion/exclusion | `HasIdCondition(has_id=range_list)`                                        |\n| Score-based | Similarity threshold filtering      | `score_threshold=0.92`                                                     |\n\n### Search Query Patterns\n\n```\n```\n\nSources: [qdrant\\_101\\_image\\_data/README.md484-520](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L484-L520) [qdrant\\_101\\_image\\_data/README.md632-704](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L632-L704) [qdrant\\_101\\_image\\_data/README.md872-900](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L872-L900)\n\n## Streamlit User Interface\n\nThe system includes a web-based interface that enables medical professionals to upload images and retrieve similar cases from the database.\n\n### Application Components\n\n```\n```",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4.2-medical-image-search-with-vision-transformers.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 986,
      "character_count": 4215,
      "created_at": "2025-10-16T17:42:29.505781",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_examples",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "Qdrant\\qdrant_examples\\_qdrant_examples_4.2-medical-image-search-with-vision-transformers.md",
      "collection_context": "Qdrant/qdrant_examples"
    }
  },
  {
    "text": "Sources: [qdrant\\_101\\_image\\_data/README.md928-964](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L928-L964)\n\n## Implementation Details\n\n### Key Functions and Methods\n\n| Function                     | Purpose                                   | Location                                                                                                                                |\n| ---------------------------- | ----------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- |\n| `get_embeddings(batch)`      | Extract ViT embeddings from image batches | [qdrant\\_101\\_image\\_data/README.md296-302](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L296-L302) |\n| `see_images(results, top_k)` | Visualize search results with metadata    | [qdrant\\_101\\_image\\_data/README.md532-548](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L532-L548) |\n| `client.search()`            | Execute similarity search with filters    | [qdrant\\_101\\_image\\_data/README.md454-458](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L454-L458) |\n| `client.search_batch()`      | Process multiple search requests          | [qdrant\\_101\\_image\\_data/README.md896-900](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L896-L900) |\n\n### Performance Considerations\n\nThe system processes 9,577 medical images with the following specifications:\n\n- Batch processing: 16 images per batch for embedding extraction\n- Storage efficiency: 384-dimensional vectors with cosine similarity\n- Upsert batching: 1,000 vectors per database transaction\n- Query performance: Filtered search across demographic and diagnostic criteria\n\nSources: [qdrant\\_101\\_image\\_data/README.md306-307](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L306-L307) [qdrant\\_101\\_image\\_data/README.md380-398](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_image_data/README.md#L380-L398)\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh\n\n### On this page\n\n- [Medical Image Search with Vision Transformers](#medical-image-search-with-vision-transformers.md)\n- [Purpose and Scope](#purpose-and-scope.md)\n- [System Architecture Overview](#system-architecture-overview.md)\n- [Core System Components](#core-system-components.md)\n- [Data Flow Pipeline](#data-flow-pipeline.md)\n- [Vision Transformer Implementation](#vision-transformer-implementation.md)\n- [Model Configuration](#model-configuration.md)\n- [Dataset Structure](#dataset-structure.md)\n- [Qdrant Vector Database Integration](#qdrant-vector-database-integration.md)\n- [Collection Configuration](#collection-configuration.md)\n- [Advanced Search Capabilities](#advanced-search-capabilities.md)\n- [Filter Types and Use Cases](#filter-types-and-use-cases.md)\n- [Search Query Patterns](#search-query-patterns.md)\n- [Streamlit User Interface](#streamlit-user-interface.md)\n- [Application Components](#application-components.md)\n- [Implementation Details](#implementation-details.md)\n- [Key Functions and Methods](#key-functions-and-methods.md)\n- [Performance Considerations](#performance-considerations.md)",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_4.2-medical-image-search-with-vision-transformers.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 777,
      "character_count": 3329,
      "created_at": "2025-10-16T17:42:29.509783",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_examples",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "Qdrant\\qdrant_examples\\_qdrant_examples_4.2-medical-image-search-with-vision-transformers.md",
      "collection_context": "Qdrant/qdrant_examples"
    }
  }
]
[
  {
    "text": "Text Data Applications | qdrant/examples | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[qdrant/examples](https://github.com/qdrant/examples \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 26 June 2025 ([b3c4b2](https://github.com/qdrant/examples/commits/b3c4b28f))\n\n- [Overview](qdrant/examples/1-overview.md)\n- [Getting Started with Qdrant](qdrant/examples/2-getting-started-with-qdrant.md)\n- [Text Data Applications](qdrant/examples/3-text-data-applications.md)\n- [Code Search with Dual Embeddings](qdrant/examples/3.1-code-search-with-dual-embeddings.md)\n- [Extractive Question Answering](qdrant/examples/3.2-extractive-question-answering.md)\n- [Movie Recommendations with Sparse Vectors](qdrant/examples/3.3-movie-recommendations-with-sparse-vectors.md)\n- [Image Data Applications](qdrant/examples/4-image-data-applications.md)\n- [E-commerce Reverse Image Search](qdrant/examples/4.1-e-commerce-reverse-image-search.md)\n- [Medical Image Search with Vision Transformers](qdrant/examples/4.2-medical-image-search-with-vision-transformers.md)\n- [Audio Data Applications](qdrant/examples/5-audio-data-applications.md)\n- [Music Recommendation Engine](qdrant/examples/5.1-music-recommendation-engine.md)\n- [Advanced RAG Systems](qdrant/examples/6-advanced-rag-systems.md)\n- [Multivector RAG with DSPy](qdrant/examples/6.1-multivector-rag-with-dspy.md)\n- [Graph-Enhanced RAG with Neo4j](qdrant/examples/6.2-graph-enhanced-rag-with-neo4j.md)\n- [PDF Retrieval at Scale](qdrant/examples/6.3-pdf-retrieval-at-scale.md)\n- [Agentic Systems with CrewAI](qdrant/examples/7-agentic-systems-with-crewai.md)\n- [Meeting Analysis with Agentic RAG](qdrant/examples/7.1-meeting-analysis-with-agentic-rag.md)\n- [Additional Use Cases](qdrant/examples/8-additional-use-cases.md)\n- [Self-Query Systems with LangChain](qdrant/examples/8.1-self-query-systems-with-langchain.md)\n- [Development Environment Setup](qdrant/examples/8.2-development-environment-setup.md)\n\nMenu\n\n# Text Data Applications\n\nRelevant source files\n\n- [README.md](https://github.com/qdrant/examples/blob/b3c4b28f/README.md)\n- [code-search/code-search.ipynb](https://github.com/qdrant/examples/blob/b3c4b28f/code-search/code-search.ipynb)\n- [qdrant\\_101\\_audio\\_data/03\\_qdrant\\_101\\_audio.ipynb](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_audio_data/03_qdrant_101_audio.ipynb)\n- [qdrant\\_101\\_audio\\_data/README.md](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_audio_data/README.md)\n- [qdrant\\_101\\_text\\_data/README.md](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_text_data/README.md)\n- [qdrant\\_101\\_text\\_data/qdrant\\_and\\_text\\_data\\_files/qdrant\\_and\\_text\\_data\\_25\\_0.png](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_text_data/qdrant_and_text_data_files/qdrant_and_text_data_25_0.png)\n- [qdrant\\_101\\_text\\_data/qdrant\\_and\\_text\\_data\\_files/qdrant\\_and\\_text\\_data\\_28\\_0.png](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_text_data/qdrant_and_text_data_files/qdrant_and_text_data_28_0.png)\n- [sparse-vectors-movies-reco/recommend-movies.ipynb](https://github.com/qdrant/examples/blob/b3c4b28f/sparse-vectors-movies-reco/recommend-movies.ipynb)",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_3-text-data-applications.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1011,
      "character_count": 3303,
      "created_at": "2025-10-16T17:42:29.330453",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_examples",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "Qdrant\\qdrant_examples\\_qdrant_examples_3-text-data-applications.md",
      "collection_context": "Qdrant/qdrant_examples"
    }
  },
  {
    "text": "This page covers text processing, embedding generation, and various text-based search and recommendation systems using Qdrant. It demonstrates how to transform textual data into vector representations and build semantic search capabilities for different domains including news articles, code repositories, and collaborative filtering systems.\n\nFor audio data applications, see [Audio Data Applications](qdrant/examples/5-audio-data-applications.md). For advanced RAG implementations that combine text processing with generation, see [Advanced RAG Systems](qdrant/examples/6-advanced-rag-systems.md).\n\n## Core Text Processing Pipeline\n\nThe foundation of text applications involves transforming raw text into numerical vector representations that capture semantic meaning. This process enables similarity search and recommendation systems.\n\n```\n```\n\n**Text Processing Pipeline Architecture**\n\nSources: [qdrant\\_101\\_text\\_data/README.md1-100](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_text_data/README.md#L1-L100) [code-search/code-search.ipynb1-50](https://github.com/qdrant/examples/blob/b3c4b28f/code-search/code-search.ipynb#L1-L50) [sparse-vectors-movies-reco/recommend-movies.ipynb1-50](https://github.com/qdrant/examples/blob/b3c4b28f/sparse-vectors-movies-reco/recommend-movies.ipynb#L1-L50)\n\n## Embedding Generation Approaches\n\n### Dense Text Embeddings\n\nThe primary approach uses transformer models to generate dense vector representations. The `embed_text` function demonstrates the core embedding pipeline:\n\n```\n```\n\n**Dense Embedding Generation Flow**\n\nThe `mean_pooling` function handles attention-weighted averaging to convert token-level embeddings to sentence-level representations:\n\nSources: [qdrant\\_101\\_text\\_data/README.md378-415](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_text_data/README.md#L378-L415)\n\n### Code-Specific Text Processing\n\nFor code search applications, the `textify` function normalizes code structures into human-readable descriptions:\n\n```\n```\n\n**Code Search Dual Embedding Architecture**\n\nSources: [code-search/code-search.ipynb125-191](https://github.com/qdrant/examples/blob/b3c4b28f/code-search/code-search.ipynb#L125-L191) [code-search/code-search.ipynb333-349](https://github.com/qdrant/examples/blob/b3c4b28f/code-search/code-search.ipynb#L333-L349)\n\n### Sparse Vector Representations\n\nFor collaborative filtering, user preferences are encoded as sparse vectors where indices represent items and values represent ratings:\n\nSources: [sparse-vectors-movies-reco/recommend-movies.ipynb417-429](https://github.com/qdrant/examples/blob/b3c4b28f/sparse-vectors-movies-reco/recommend-movies.ipynb#L417-L429)\n\n## Qdrant Collection Management\n\n### Collection Configuration\n\nDifferent text applications require specific collection configurations based on the embedding approach:\n\n| Application           | Vector Config             | Distance Metric | Dimensions |\n| --------------------- | ------------------------- | --------------- | ---------- |\n| News Articles         | Dense only                | Cosine          | 768        |\n| Code Search           | Named vectors (text/code) | Cosine          | 384/768    |\n| Movie Recommendations | Sparse vectors only       | Dot Product     | Dynamic    |\n\n### Data Upload Patterns\n\nThe `upsert` operation loads embeddings with structured payloads:\n\n```\n```\n\n**Qdrant Data Upload Flow**\n\nSources: [qdrant\\_101\\_text\\_data/README.md574-583](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_text_data/README.md#L574-L583) [code-search/code-search.ipynb387-414](https://github.com/qdrant/examples/blob/b3c4b28f/code-search/code-search.ipynb#L387-L414)\n\n## Search and Recommendation Systems\n\n### Semantic Search Implementation\n\nThe search functionality uses vector similarity to find relevant documents:\n\n```\n```\n\n**Semantic Search Architecture**\n\nSources: [qdrant\\_101\\_text\\_data/README.md680-690](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_text_data/README.md#L680-L690)\n\n### Recommendation API Usage\n\nThe recommendation system finds similar items using positive and negative examples:\n\n```\n```\n\n**Recommendation System Flow**\n\nSources: [qdrant\\_101\\_text\\_data/README.md726-750](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_text_data/README.md#L726-L750)\n\n### Code Search Query Processing",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_3-text-data-applications.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1019,
      "character_count": 4352,
      "created_at": "2025-10-16T17:42:29.342025",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_examples",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "Qdrant\\qdrant_examples\\_qdrant_examples_3-text-data-applications.md",
      "collection_context": "Qdrant/qdrant_examples"
    }
  },
  {
    "text": "Code search supports both natural language and code-specific queries using named vectors:\n\nSources: [code-search/code-search.ipynb504-518](https://github.com/qdrant/examples/blob/b3c4b28f/code-search/code-search.ipynb#L504-L518) [code-search/code-search.ipynb554-568](https://github.com/qdrant/examples/blob/b3c4b28f/code-search/code-search.ipynb#L554-L568)\n\n## Advanced Text Applications\n\n### Collaborative Filtering with Sparse Vectors\n\nMovie recommendation uses sparse vectors where each dimension represents a movie and values represent normalized ratings. The `user_sparse_vectors` structure efficiently encodes user preferences:\n\n```\n```\n\n**Collaborative Filtering Architecture**\n\nSources: [sparse-vectors-movies-reco/recommend-movies.ipynb403-409](https://github.com/qdrant/examples/blob/b3c4b28f/sparse-vectors-movies-reco/recommend-movies.ipynb#L403-L409) [sparse-vectors-movies-reco/recommend-movies.ipynb420-429](https://github.com/qdrant/examples/blob/b3c4b28f/sparse-vectors-movies-reco/recommend-movies.ipynb#L420-L429) [sparse-vectors-movies-reco/recommend-movies.ipynb527-535](https://github.com/qdrant/examples/blob/b3c4b28f/sparse-vectors-movies-reco/recommend-movies.ipynb#L527-L535)\n\n### Multi-Model Code Search\n\nThe code search system demonstrates how to combine different embedding approaches for comprehensive search capabilities. The `points` structure uses named vectors to store both text and code representations simultaneously.\n\nSources: [code-search/code-search.ipynb387-398](https://github.com/qdrant/examples/blob/b3c4b28f/code-search/code-search.ipynb#L387-L398)\n\n## Implementation Examples\n\n### Basic Text Collection Setup\n\n```\n```\n\n### Named Vector Configuration\n\n```\n```\n\n### Sparse Vector Setup\n\n```\n```\n\nSources: [qdrant\\_101\\_text\\_data/README.md539-544](https://github.com/qdrant/examples/blob/b3c4b28f/qdrant_101_text_data/README.md#L539-L544) [code-search/code-search.ipynb336-349](https://github.com/qdrant/examples/blob/b3c4b28f/code-search/code-search.ipynb#L336-L349) [sparse-vectors-movies-reco/recommend-movies.ipynb463-469](https://github.com/qdrant/examples/blob/b3c4b28f/sparse-vectors-movies-reco/recommend-movies.ipynb#L463-L469)\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh\n\n### On this page\n\n- [Text Data Applications](#text-data-applications.md)\n- [Core Text Processing Pipeline](#core-text-processing-pipeline.md)\n- [Embedding Generation Approaches](#embedding-generation-approaches.md)\n- [Dense Text Embeddings](#dense-text-embeddings.md)\n- [Code-Specific Text Processing](#code-specific-text-processing.md)\n- [Sparse Vector Representations](#sparse-vector-representations.md)\n- [Qdrant Collection Management](#qdrant-collection-management.md)\n- [Collection Configuration](#collection-configuration.md)\n- [Data Upload Patterns](#data-upload-patterns.md)\n- [Search and Recommendation Systems](#search-and-recommendation-systems.md)\n- [Semantic Search Implementation](#semantic-search-implementation.md)\n- [Recommendation API Usage](#recommendation-api-usage.md)\n- [Code Search Query Processing](#code-search-query-processing.md)\n- [Advanced Text Applications](#advanced-text-applications.md)\n- [Collaborative Filtering with Sparse Vectors](#collaborative-filtering-with-sparse-vectors.md)\n- [Multi-Model Code Search](#multi-model-code-search.md)\n- [Implementation Examples](#implementation-examples.md)\n- [Basic Text Collection Setup](#basic-text-collection-setup.md)\n- [Named Vector Configuration](#named-vector-configuration.md)\n- [Sparse Vector Setup](#sparse-vector-setup.md)",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_examples\\_qdrant_examples_3-text-data-applications.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 893,
      "character_count": 3542,
      "created_at": "2025-10-16T17:42:29.346052",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_examples",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "Qdrant\\qdrant_examples\\_qdrant_examples_3-text-data-applications.md",
      "collection_context": "Qdrant/qdrant_examples"
    }
  }
]
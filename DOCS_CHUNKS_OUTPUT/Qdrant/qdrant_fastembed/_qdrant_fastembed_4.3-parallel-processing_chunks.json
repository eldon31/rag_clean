[
  {
    "text": "Parallel Processing | qdrant/fastembed | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[qdrant/fastembed](https://github.com/qdrant/fastembed \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 20 April 2025 ([b78564](https://github.com/qdrant/fastembed/commits/b785640b))\n\n- [Overview](qdrant/fastembed/1-overview.md)\n- [Installation and Setup](qdrant/fastembed/2-installation-and-setup.md)\n- [Core Embedding Classes](qdrant/fastembed/3-core-embedding-classes.md)\n- [TextEmbedding](qdrant/fastembed/3.1-textembedding.md)\n- [SparseTextEmbedding](qdrant/fastembed/3.2-sparsetextembedding.md)\n- [LateInteractionTextEmbedding](qdrant/fastembed/3.3-lateinteractiontextembedding.md)\n- [ImageEmbedding](qdrant/fastembed/3.4-imageembedding.md)\n- [LateInteractionMultimodalEmbedding](qdrant/fastembed/3.5-lateinteractionmultimodalembedding.md)\n- [TextCrossEncoder](qdrant/fastembed/3.6-textcrossencoder.md)\n- [Architecture](qdrant/fastembed/4-architecture.md)\n- [Model Management](qdrant/fastembed/4.1-model-management.md)\n- [ONNX Runtime Integration](qdrant/fastembed/4.2-onnx-runtime-integration.md)\n- [Parallel Processing](qdrant/fastembed/4.3-parallel-processing.md)\n- [Implementation Details](qdrant/fastembed/5-implementation-details.md)\n- [Dense Text Embeddings](qdrant/fastembed/5.1-dense-text-embeddings.md)\n- [Sparse Text Embeddings](qdrant/fastembed/5.2-sparse-text-embeddings.md)\n- [Late Interaction Models](qdrant/fastembed/5.3-late-interaction-models.md)\n- [Multimodal Models](qdrant/fastembed/5.4-multimodal-models.md)\n- [Supported Models](qdrant/fastembed/6-supported-models.md)\n- [Usage Examples](qdrant/fastembed/7-usage-examples.md)\n- [Basic Text Embedding](qdrant/fastembed/7.1-basic-text-embedding.md)\n- [Sparse and Hybrid Search](qdrant/fastembed/7.2-sparse-and-hybrid-search.md)\n- [ColBERT and Late Interaction](qdrant/fastembed/7.3-colbert-and-late-interaction.md)\n- [Image Embedding](qdrant/fastembed/7.4-image-embedding.md)\n- [Performance Optimization](qdrant/fastembed/8-performance-optimization.md)\n- [Integration with Qdrant](qdrant/fastembed/9-integration-with-qdrant.md)\n- [Development Guide](qdrant/fastembed/10-development-guide.md)\n\nMenu\n\n# Parallel Processing\n\nRelevant source files\n\n- [fastembed/common/onnx\\_model.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py)\n- [fastembed/parallel\\_processor.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py)\n- [fastembed/rerank/cross\\_encoder/onnx\\_text\\_model.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/rerank/cross_encoder/onnx_text_model.py)\n- [fastembed/text/onnx\\_embedding.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py)\n\nFastEmbed provides a robust parallel processing system that enables efficient generation of embeddings for large datasets by distributing workloads across multiple CPU cores or GPU devices. This system significantly improves throughput when processing large batches of documents or images.\n\nFor information about the general architecture of FastEmbed, see [Architecture](qdrant/fastembed/4-architecture.md), and for details on ONNX integration, see [ONNX Runtime Integration](qdrant/fastembed/4.2-onnx-runtime-integration.md).\n\n## Parallel Processing Architecture\n\nFastEmbed's parallel processing is implemented through a worker pool architecture that manages multiple processes, each running its own instance of an embedding model. The core of this system is the `ParallelWorkerPool` class, which handles process creation, workload distribution, and result collection.\n\n```\n```",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.3-parallel-processing.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 987,
      "character_count": 3726,
      "created_at": "2025-10-16T17:42:30.126129",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.3-parallel-processing.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "Sources: [fastembed/parallel\\_processor.py91-253](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L91-L253) [fastembed/text/onnx\\_embedding.py260-292](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L260-L292)\n\n## Worker Interface and Implementation\n\nThe parallel processing system defines a `Worker` interface that all worker implementations must adhere to. Each embedding type in FastEmbed has its own worker implementation that handles the specific requirements for that type of embedding.\n\n```\n```\n\nSources: [fastembed/parallel\\_processor.py26-32](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L26-L32) [fastembed/common/onnx\\_model.py114-136](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L114-L136) [fastembed/text/onnx\\_embedding.py328-340](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L328-L340) [fastembed/rerank/cross\\_encoder/onnx\\_text\\_model.py148-169](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/rerank/cross_encoder/onnx_text_model.py#L148-L169)\n\n## Parallel Processing Flow\n\nWhen parallel processing is enabled, the following sequence of operations occurs:\n\n```\n```\n\nThe system uses two queues to manage this workflow:\n\n1. **Input Queue**: Sends batches of documents to worker processes\n2. **Output Queue**: Receives processed embeddings from worker processes\n\nThe `ParallelWorkerPool` class provides two mapping methods:\n\n- `semi_ordered_map()`: Returns results as soon as they are available (potentially out of order)\n- `ordered_map()`: Ensures results are returned in the same order as inputs\n\nSources: [fastembed/parallel\\_processor.py142-209](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L142-L209)\n\n## Enabling Parallel Processing\n\nTo utilize parallel processing in FastEmbed, you can set the `parallel` parameter when calling the `embed()` method:\n\n```\n```\n\nThe `parallel` parameter accepts the following values:\n\n- `None`: Disable parallel processing (default)\n- `0`: Use all available CPU cores\n- `n` (where n > 0): Use n worker processes\n\nThis parameter is available in all embedding classes in FastEmbed, including `TextEmbedding`, `SparseTextEmbedding`, `LateInteractionTextEmbedding`, `ImageEmbedding`, and `TextCrossEncoder`.\n\nSources: [fastembed/text/onnx\\_embedding.py260-292](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L260-L292)\n\n## GPU Support and Device Assignment\n\nFastEmbed's parallel processing system includes robust GPU support, allowing distribution of worker processes across multiple GPUs:\n\n```\n```\n\nTo utilize GPU acceleration with parallel processing, you can configure the embedding model as follows:\n\n```\n```\n\nIn this configuration:\n\n- The `cuda=True` parameter enables GPU acceleration\n- The `device_ids=[0, 1]` parameter specifies which GPUs to use\n- The `parallel=4` parameter creates 4 worker processes\n- Worker processes are assigned to GPUs in a round-robin fashion\n\nSources: [fastembed/parallel\\_processor.py120-126](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L120-L126) [fastembed/text/onnx\\_embedding.py200-246](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L200-L246)\n\n## Implementation Details\n\n### Worker Process Management\n\nThe `ParallelWorkerPool` class manages worker processes through several key methods:\n\n1. `start()`: Initializes worker processes and communication queues\n2. `ordered_map()`: Maps input items to worker processes and returns results in order\n3. `semi_ordered_map()`: Similar to `ordered_map()` but may return results out of order\n4. `check_worker_health()`: Monitors worker processes for failures\n5. `join_or_terminate()`: Handles emergency shutdown of worker processes\n6. `join()`: Waits for all worker processes to complete\n\nThe system includes robust error handling to detect and manage failures in worker processes, including timeouts for detecting hanging processes.\n\nSources: [fastembed/parallel\\_processor.py92-253](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L92-L253)\n\n### Worker Communication\n\nCommunication between the main process and worker processes occurs through multiprocessing queues:",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.3-parallel-processing.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1017,
      "character_count": 4370,
      "created_at": "2025-10-16T17:42:30.135005",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.3-parallel-processing.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "| Component     | Purpose                                                                       |\n| ------------- | ----------------------------------------------------------------------------- |\n| Input Queue   | Sends batches of documents to worker processes                                |\n| Output Queue  | Receives processed embeddings from worker processes                           |\n| Queue Signals | Special markers like `stop`, `confirm`, and `error` that control process flow |\n\nThe system uses a producer-consumer pattern where the main process produces items for the input queue and consumes results from the output queue, while worker processes do the opposite.\n\nSources: [fastembed/parallel\\_processor.py20-24](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L20-L24) [fastembed/parallel\\_processor.py35-89](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L35-L89)\n\n### Worker Process Creation\n\nWhen creating worker processes, FastEmbed handles several important considerations:\n\n1. **Start Method**: Uses `forkserver` (if available) or `spawn` to create new processes\n2. **Device Assignment**: Assigns GPU devices to workers in a round-robin fashion\n3. **Model Loading**: Each worker loads its own instance of the model\n4. **Synchronization**: Uses a shared counter to track active workers\n\nThis approach ensures that each worker process has its own isolated environment with access to the necessary resources.\n\nSources: [fastembed/rerank/cross\\_encoder/onnx\\_text\\_model.py117-118](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/rerank/cross_encoder/onnx_text_model.py#L117-L118) [fastembed/parallel\\_processor.py92-110](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L92-L110)\n\n## Performance Considerations\n\nWhen using parallel processing in FastEmbed, consider the following factors to optimize performance:\n\n- **Number of Workers**: Start with a number equal to your CPU cores or GPU count and adjust based on performance\n- **Batch Size**: Larger batch sizes typically improve throughput but increase memory usage\n- **GPU Memory**: Each worker loads a separate model instance, so ensure your GPUs have sufficient memory\n- **Process Creation Overhead**: There's an initial overhead to creating worker processes, so parallel processing is most beneficial for larger datasets\n- **Lazy Loading**: Consider using `lazy_load=True` when creating models with parallel processing to avoid loading the model multiple times\n\nTable of performance impacts:\n\n| Configuration        | Best For                                     | Considerations                         |\n| -------------------- | -------------------------------------------- | -------------------------------------- |\n| Single Process       | Small datasets, low latency requirements     | Limited throughput                     |\n| Multiple CPU Workers | Medium-sized datasets, no GPU available      | Higher throughput, increased CPU usage |\n| Multiple GPU Workers | Large datasets, high throughput requirements | Highest performance, requires GPU(s)   |\n\nSources: [fastembed/text/onnx\\_embedding.py199-257](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L199-L257)\n\n## Conclusion\n\nFastEmbed's parallel processing system provides a powerful mechanism for scaling embedding generation across multiple CPU cores or GPU devices. By distributing workloads and managing worker processes effectively, it achieves significant performance improvements for large datasets while maintaining a simple, consistent API.\n\nFor information on model management and caching, see [Model Management](qdrant/fastembed/4.1-model-management.md), or for details on how to use specific embedding types, refer to [Core Embedding Classes](qdrant/fastembed/3-core-embedding-classes.md).\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh\n\n### On this page\n\n- [Parallel Processing](#parallel-processing.md)\n- [Parallel Processing Architecture](#parallel-processing-architecture.md)\n- [Worker Interface and Implementation](#worker-interface-and-implementation.md)\n- [Parallel Processing Flow](#parallel-processing-flow.md)\n- [Enabling Parallel Processing](#enabling-parallel-processing.md)\n- [GPU Support and Device Assignment](#gpu-support-and-device-assignment.md)\n- [Implementation Details](#implementation-details.md)\n- [Worker Process Management](#worker-process-management.md)\n- [Worker Communication](#worker-communication.md)\n- [Worker Process Creation](#worker-process-creation.md)\n- [Performance Considerations](#performance-considerations.md)\n- [Conclusion](#conclusion.md)",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.3-parallel-processing.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 916,
      "character_count": 4684,
      "created_at": "2025-10-16T17:42:30.140141",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_4.3-parallel-processing.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  }
]
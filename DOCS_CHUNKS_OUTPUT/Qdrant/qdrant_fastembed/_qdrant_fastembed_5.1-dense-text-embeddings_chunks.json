[
  {
    "text": "Dense Text Embeddings | qdrant/fastembed | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[qdrant/fastembed](https://github.com/qdrant/fastembed \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 20 April 2025 ([b78564](https://github.com/qdrant/fastembed/commits/b785640b))\n\n- [Overview](qdrant/fastembed/1-overview.md)\n- [Installation and Setup](qdrant/fastembed/2-installation-and-setup.md)\n- [Core Embedding Classes](qdrant/fastembed/3-core-embedding-classes.md)\n- [TextEmbedding](qdrant/fastembed/3.1-textembedding.md)\n- [SparseTextEmbedding](qdrant/fastembed/3.2-sparsetextembedding.md)\n- [LateInteractionTextEmbedding](qdrant/fastembed/3.3-lateinteractiontextembedding.md)\n- [ImageEmbedding](qdrant/fastembed/3.4-imageembedding.md)\n- [LateInteractionMultimodalEmbedding](qdrant/fastembed/3.5-lateinteractionmultimodalembedding.md)\n- [TextCrossEncoder](qdrant/fastembed/3.6-textcrossencoder.md)\n- [Architecture](qdrant/fastembed/4-architecture.md)\n- [Model Management](qdrant/fastembed/4.1-model-management.md)\n- [ONNX Runtime Integration](qdrant/fastembed/4.2-onnx-runtime-integration.md)\n- [Parallel Processing](qdrant/fastembed/4.3-parallel-processing.md)\n- [Implementation Details](qdrant/fastembed/5-implementation-details.md)\n- [Dense Text Embeddings](qdrant/fastembed/5.1-dense-text-embeddings.md)\n- [Sparse Text Embeddings](qdrant/fastembed/5.2-sparse-text-embeddings.md)\n- [Late Interaction Models](qdrant/fastembed/5.3-late-interaction-models.md)\n- [Multimodal Models](qdrant/fastembed/5.4-multimodal-models.md)\n- [Supported Models](qdrant/fastembed/6-supported-models.md)\n- [Usage Examples](qdrant/fastembed/7-usage-examples.md)\n- [Basic Text Embedding](qdrant/fastembed/7.1-basic-text-embedding.md)\n- [Sparse and Hybrid Search](qdrant/fastembed/7.2-sparse-and-hybrid-search.md)\n- [ColBERT and Late Interaction](qdrant/fastembed/7.3-colbert-and-late-interaction.md)\n- [Image Embedding](qdrant/fastembed/7.4-image-embedding.md)\n- [Performance Optimization](qdrant/fastembed/8-performance-optimization.md)\n- [Integration with Qdrant](qdrant/fastembed/9-integration-with-qdrant.md)\n- [Development Guide](qdrant/fastembed/10-development-guide.md)\n\nMenu\n\n# Dense Text Embeddings\n\nRelevant source files\n\n- [fastembed/text/clip\\_embedding.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/clip_embedding.py)\n- [fastembed/text/onnx\\_embedding.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py)\n- [fastembed/text/pooled\\_embedding.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_embedding.py)\n- [fastembed/text/pooled\\_normalized\\_embedding.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_normalized_embedding.py)\n\nDense text embeddings are fixed-size vector representations of text that capture semantic meaning in a continuous vector space. In FastEmbed, dense text embeddings are implemented through several specialized classes that leverage ONNX Runtime for high-performance inference. This page details the implementation of dense text embedding models in the FastEmbed library.\n\nFor information about sparse text embeddings, see [Sparse Text Embeddings](qdrant/fastembed/5.2-sparse-text-embeddings.md). For late interaction models, see [Late Interaction Models](qdrant/fastembed/5.3-late-interaction-models.md).\n\n## Architecture Overview\n\nFastEmbed implements dense text embeddings through a hierarchy of specialized classes, each handling different embedding strategies and post-processing techniques.\n\n```\n```",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.1-dense-text-embeddings.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 972,
      "character_count": 3655,
      "created_at": "2025-10-16T17:42:30.169459",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.1-dense-text-embeddings.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "Sources: [fastembed/text/onnx\\_embedding.py186-326](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L186-L326) [fastembed/text/pooled\\_embedding.py93-120](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_embedding.py#L93-L120) [fastembed/text/pooled\\_normalized\\_embedding.py127-147](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_normalized_embedding.py#L127-L147) [fastembed/text/clip\\_embedding.py24-40](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/clip_embedding.py#L24-L40)\n\n## Core Implementation Classes\n\nThe FastEmbed library implements dense text embeddings through four primary classes, each catering to different embedding strategies and post-processing techniques.\n\n### OnnxTextEmbedding\n\n`OnnxTextEmbedding` serves as the foundational class for ONNX-based text embeddings. It provides the base implementation for model loading, inference, and embedding generation.\n\nKey features:\n\n- Leverages ONNX Runtime for optimized inference\n- Supports parallel processing with multiple workers\n- Handles model downloading and caching\n- Implements a flexible post-processing pipeline\n\nThis class supports models like BGE, Snowflake Arctic, and MXBai embeddings.\n\nSources: [fastembed/text/onnx\\_embedding.py186-326](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L186-L326)\n\n### PooledEmbedding\n\n`PooledEmbedding` extends `OnnxTextEmbedding` and implements mean pooling for models that produce token-level embeddings. Mean pooling aggregates token embeddings weighted by attention mask values.\n\nKey features:\n\n- Implements mean pooling across token dimensions\n- Preserves semantic information from all tokens\n- Returns non-normalized embeddings\n\nThis class supports models like Nomic Embed, multilingual sentence transformers, and E5 models.\n\nSources: [fastembed/text/pooled\\_embedding.py93-120](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_embedding.py#L93-L120)\n\n### PooledNormalizedEmbedding\n\n`PooledNormalizedEmbedding` extends `PooledEmbedding` and adds L2 normalization to the pooled embeddings. Normalization ensures all embedding vectors have the same magnitude, which is particularly useful for cosine similarity comparisons.\n\nKey features:\n\n- Applies mean pooling like its parent class\n- Adds L2 normalization to the embeddings\n- Optimized for cosine similarity use cases\n\nThis class supports models like MiniLM, Jina Embeddings V2, and GTE models.\n\nSources: [fastembed/text/pooled\\_normalized\\_embedding.py127-147](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_normalized_embedding.py#L127-L147)\n\n### CLIPOnnxEmbedding\n\n`CLIPOnnxEmbedding` extends `OnnxTextEmbedding` and is specialized for CLIP text encoder models. It handles the unique output format of CLIP models without additional pooling.\n\nKey features:\n\n- Specialized for CLIP text encoders\n- Works with multimodal embedding spaces\n- Compatible with corresponding image encoders\n\nThis class specifically supports the CLIP ViT-B-32 text encoder.\n\nSources: [fastembed/text/clip\\_embedding.py24-40](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/clip_embedding.py#L24-L40)\n\n## Embedding Process Flow\n\nThe process of generating dense text embeddings involves several steps, from input preprocessing to the final vector representation.\n\n```\n```\n\nSources: [fastembed/text/onnx\\_embedding.py260-294](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L260-L294) [fastembed/text/onnx\\_embedding.py306-315](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L306-L315) [fastembed/text/pooled\\_embedding.py113-119](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_embedding.py#L113-L119) [fastembed/text/pooled\\_normalized\\_embedding.py141-147](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_normalized_embedding.py#L141-L147) [fastembed/text/clip\\_embedding.py38-39](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/clip_embedding.py#L38-L39)\n\n## Post-Processing Techniques\n\nThe different embedding classes implement various post-processing techniques:",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.1-dense-text-embeddings.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 993,
      "character_count": 4250,
      "created_at": "2025-10-16T17:42:30.177461",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.1-dense-text-embeddings.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "1. **CLS Token Extraction**: `OnnxTextEmbedding` extracts the first token (CLS) embedding for models that encode sentence meaning in this special token.\n\n```\n```\n\n2. **Mean Pooling**: `PooledEmbedding` applies mean pooling across token embeddings, weighted by the attention mask.\n\n```\n```\n\n3. **Normalized Pooling**: `PooledNormalizedEmbedding` applies mean pooling followed by L2 normalization.\n\n```\n```\n\n4. **CLIP Processing**: `CLIPOnnxEmbedding` passes through the model output directly as it's already in the desired format.\n\nSources: [fastembed/text/onnx\\_embedding.py306-315](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L306-L315) [fastembed/text/pooled\\_embedding.py99-102](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_embedding.py#L99-L102) [fastembed/text/pooled\\_normalized\\_embedding.py141-147](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_normalized_embedding.py#L141-L147) [fastembed/text/clip\\_embedding.py38-39](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/clip_embedding.py#L38-L39)\n\n## Supported Models\n\nFastEmbed supports a wide range of dense text embedding models across different implementations:\n\n### OnnxTextEmbedding Models\n\n| Model                               | Dimension | Language | Context Length | License    |\n| ----------------------------------- | --------- | -------- | -------------- | ---------- |\n| BAAI/bge-small-en-v1.5              | 384       | English  | 512            | MIT        |\n| BAAI/bge-base-en-v1.5               | 768       | English  | 512            | MIT        |\n| BAAI/bge-large-en-v1.5              | 1024      | English  | 512            | MIT        |\n| BAAI/bge-small-zh-v1.5              | 512       | Chinese  | 512            | MIT        |\n| mixedbread-ai/mxbai-embed-large-v1  | 1024      | English  | 512            | Apache-2.0 |\n| snowflake/snowflake-arctic-embed-\\* | 384-1024  | English  | 512-2048       | Apache-2.0 |\n| jinaai/jina-clip-v1                 | 768       | English  | -              | Apache-2.0 |\n\n### PooledEmbedding Models\n\n| Model                                            | Dimension | Language                   | Context Length | License    |\n| ------------------------------------------------ | --------- | -------------------------- | -------------- | ---------- |\n| nomic-ai/nomic-embed-text-v1.5                   | 768       | English                    | 8192           | Apache-2.0 |\n| sentence-transformers/paraphrase-multilingual-\\* | 384-768   | Multilingual (\\~50 langs)  | 384-512        | Apache-2.0 |\n| intfloat/multilingual-e5-large                   | 1024      | Multilingual (\\~100 langs) | 512            | MIT        |\n\n### PooledNormalizedEmbedding Models\n\n| Model                                  | Dimension | Language          | Context Length | License    |\n| -------------------------------------- | --------- | ----------------- | -------------- | ---------- |\n| sentence-transformers/all-MiniLM-L6-v2 | 384       | English           | 256            | Apache-2.0 |\n| jinaai/jina-embeddings-v2-base-en      | 768       | English           | 8192           | Apache-2.0 |\n| jinaai/jina-embeddings-v2-small-en     | 512       | English           | 8192           | Apache-2.0 |\n| jinaai/jina-embeddings-v2-base-\\*      | 768       | Various languages | 8192           | Apache-2.0 |\n| thenlper/gte-base                      | 768       | English           | 512            | MIT        |\n| thenlper/gte-large                     | 1024      | English           | 512            | MIT        |\n\n### CLIPOnnxEmbedding Models\n\n| Model                     | Dimension | Language | Context Length | License |\n| ------------------------- | --------- | -------- | -------------- | ------- |\n| Qdrant/clip-ViT-B-32-text | 512       | English  | 77             | MIT     |",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.1-dense-text-embeddings.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 970,
      "character_count": 3898,
      "created_at": "2025-10-16T17:42:30.182543",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.1-dense-text-embeddings.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "Sources: [fastembed/text/onnx\\_embedding.py10-183](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L10-L183) [fastembed/text/pooled\\_embedding.py12-90](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_embedding.py#L12-L90) [fastembed/text/pooled\\_normalized\\_embedding.py11-124](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_normalized_embedding.py#L11-L124) [fastembed/text/clip\\_embedding.py8-21](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/clip_embedding.py#L8-L21)\n\n## Model Selection Guide\n\nWhen choosing a dense text embedding model, consider the following factors:\n\n```\n```\n\nSources: [fastembed/text/onnx\\_embedding.py10-183](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/onnx_embedding.py#L10-L183) [fastembed/text/pooled\\_embedding.py12-90](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_embedding.py#L12-L90) [fastembed/text/pooled\\_normalized\\_embedding.py11-124](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/pooled_normalized_embedding.py#L11-L124)\n\n## Integration with FastEmbed API\n\nThe dense text embedding classes are accessible through the main `TextEmbedding` class, which serves as the public API for all dense text embedding functionality in FastEmbed.\n\n```\n```\n\nInternally, `TextEmbedding` instantiates the appropriate implementation class (e.g., `OnnxTextEmbedding`, `PooledEmbedding`, etc.) based on the specified model name.\n\nFor more examples and detailed usage, see [Basic Text Embedding](qdrant/fastembed/7.1-basic-text-embedding.md).\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh\n\n### On this page\n\n- [Dense Text Embeddings](#dense-text-embeddings.md)\n- [Architecture Overview](#architecture-overview.md)\n- [Core Implementation Classes](#core-implementation-classes.md)\n- [OnnxTextEmbedding](#onnxtextembedding.md)\n- [PooledEmbedding](#pooledembedding.md)\n- [PooledNormalizedEmbedding](#poolednormalizedembedding.md)\n- [CLIPOnnxEmbedding](#cliponnxembedding.md)\n- [Embedding Process Flow](#embedding-process-flow.md)\n- [Post-Processing Techniques](#post-processing-techniques.md)\n- [Supported Models](#supported-models.md)\n- [OnnxTextEmbedding Models](#onnxtextembedding-models.md)\n- [PooledEmbedding Models](#pooledembedding-models.md)\n- [PooledNormalizedEmbedding Models](#poolednormalizedembedding-models.md)\n- [CLIPOnnxEmbedding Models](#cliponnxembedding-models.md)\n- [Model Selection Guide](#model-selection-guide.md)\n- [Integration with FastEmbed API](#integration-with-fastembed-api.md)",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.1-dense-text-embeddings.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 679,
      "character_count": 2597,
      "created_at": "2025-10-16T17:42:30.185145",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 3,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.1-dense-text-embeddings.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  }
]
[
  {
    "text": "Image Embedding | qdrant/fastembed | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[qdrant/fastembed](https://github.com/qdrant/fastembed \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 20 April 2025 ([b78564](https://github.com/qdrant/fastembed/commits/b785640b))\n\n- [Overview](qdrant/fastembed/1-overview.md)\n- [Installation and Setup](qdrant/fastembed/2-installation-and-setup.md)\n- [Core Embedding Classes](qdrant/fastembed/3-core-embedding-classes.md)\n- [TextEmbedding](qdrant/fastembed/3.1-textembedding.md)\n- [SparseTextEmbedding](qdrant/fastembed/3.2-sparsetextembedding.md)\n- [LateInteractionTextEmbedding](qdrant/fastembed/3.3-lateinteractiontextembedding.md)\n- [ImageEmbedding](qdrant/fastembed/3.4-imageembedding.md)\n- [LateInteractionMultimodalEmbedding](qdrant/fastembed/3.5-lateinteractionmultimodalembedding.md)\n- [TextCrossEncoder](qdrant/fastembed/3.6-textcrossencoder.md)\n- [Architecture](qdrant/fastembed/4-architecture.md)\n- [Model Management](qdrant/fastembed/4.1-model-management.md)\n- [ONNX Runtime Integration](qdrant/fastembed/4.2-onnx-runtime-integration.md)\n- [Parallel Processing](qdrant/fastembed/4.3-parallel-processing.md)\n- [Implementation Details](qdrant/fastembed/5-implementation-details.md)\n- [Dense Text Embeddings](qdrant/fastembed/5.1-dense-text-embeddings.md)\n- [Sparse Text Embeddings](qdrant/fastembed/5.2-sparse-text-embeddings.md)\n- [Late Interaction Models](qdrant/fastembed/5.3-late-interaction-models.md)\n- [Multimodal Models](qdrant/fastembed/5.4-multimodal-models.md)\n- [Supported Models](qdrant/fastembed/6-supported-models.md)\n- [Usage Examples](qdrant/fastembed/7-usage-examples.md)\n- [Basic Text Embedding](qdrant/fastembed/7.1-basic-text-embedding.md)\n- [Sparse and Hybrid Search](qdrant/fastembed/7.2-sparse-and-hybrid-search.md)\n- [ColBERT and Late Interaction](qdrant/fastembed/7.3-colbert-and-late-interaction.md)\n- [Image Embedding](qdrant/fastembed/7.4-image-embedding.md)\n- [Performance Optimization](qdrant/fastembed/8-performance-optimization.md)\n- [Integration with Qdrant](qdrant/fastembed/9-integration-with-qdrant.md)\n- [Development Guide](qdrant/fastembed/10-development-guide.md)\n\nMenu\n\n# Image Embedding\n\nRelevant source files\n\n- [README.md](https://github.com/qdrant/fastembed/blob/b785640b/README.md)\n- [docs/examples/FastEmbed\\_GPU.ipynb](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_GPU.ipynb)\n- [fastembed/image/onnx\\_embedding.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/image/onnx_embedding.py)\n\nThis page documents the image embedding capabilities of the FastEmbed library. FastEmbed provides efficient mechanisms for generating vector representations (embeddings) from images using optimized ONNX models. For text embedding functionality, see [TextEmbedding](qdrant/fastembed/3.1-textembedding.md), and for multimodal embedding, see [LateInteractionMultimodalEmbedding](qdrant/fastembed/3.5-lateinteractionmultimodalembedding.md).\n\n## Overview\n\nThe `ImageEmbedding` class is a high-level interface for generating embeddings from images. It leverages ONNX Runtime for efficient inference and supports various vision models. Image embeddings can be used for image search, similarity comparison, and as input to multimodal systems.\n\n```\n```\n\nSources: [fastembed/image/onnx\\_embedding.py62-65](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/image/onnx_embedding.py#L62-L65)\n\n## Supported Models\n\nFastEmbed supports several vision models for image embedding, each with different characteristics, dimensions, and applications:",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7.4-image-embedding.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 998,
      "character_count": 3684,
      "created_at": "2025-10-16T17:42:30.375350",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7.4-image-embedding.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "| Model Name                  | Dimensions | Type       | Year | Description                                  |\n| --------------------------- | ---------- | ---------- | ---- | -------------------------------------------- |\n| Qdrant/clip-ViT-B-32-vision | 512        | Multimodal | 2021 | Image embeddings from CLIP model             |\n| Qdrant/resnet50-onnx        | 2048       | Unimodal   | 2016 | Image-only embeddings using ResNet50         |\n| Qdrant/Unicom-ViT-B-16      | 768        | Multimodal | 2023 | Detailed image embeddings, higher resolution |\n| Qdrant/Unicom-ViT-B-32      | 512        | Multimodal | 2023 | Efficient image embeddings                   |\n| jinaai/jina-clip-v1         | 768        | Multimodal | 2024 | Recent multimodal embedding model            |\n\n```\n```\n\nSources: [fastembed/image/onnx\\_embedding.py13-59](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/image/onnx_embedding.py#L13-L59)\n\n## Image Embedding Process\n\nThe image embedding process in FastEmbed follows several steps from input to embedding generation:\n\n```\n```\n\nSources: [fastembed/image/onnx\\_embedding.py148-181](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/image/onnx_embedding.py#L148-L181)\n\n## Basic Usage\n\nYou can generate image embeddings with just a few lines of code:\n\n```\n```\n\nThe `embed()` method returns a generator that yields numpy arrays, which can be converted to a list as shown above.\n\nSources: [README.md137-155](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L137-L155)\n\n## Configuration Options\n\nThe `ImageEmbedding` class provides several configuration options:\n\n```\n```\n\nKey parameters include:\n\n- `model_name`: Name of the model to use (required)\n- `cache_dir`: Directory to store downloaded models (optional)\n- `threads`: Number of threads for inference (optional)\n- `providers`: ONNX Runtime execution providers (optional)\n- `cuda`: Whether to use CUDA for inference (optional)\n- `device_ids`: List of device IDs for parallel processing (optional)\n- `lazy_load`: Whether to defer model loading until needed (optional)\n\nThe `embed()` method also accepts parameters:\n\n- `images`: Images to embed (required)\n- `batch_size`: Number of images to process at once (default: 16)\n- `parallel`: Number of worker processes for parallelization (optional)\n\nSources: [fastembed/image/onnx\\_embedding.py63-96](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/image/onnx_embedding.py#L63-L96) [fastembed/image/onnx\\_embedding.py148-166](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/image/onnx_embedding.py#L148-L166)\n\n## GPU Acceleration\n\nFor faster image embedding, FastEmbed supports GPU acceleration through ONNX Runtime:\n\n1. Install with GPU support:\n\n```\n   ```\n\n2. Specify CUDA execution provider:\n\n```\n   ```\n\nGPU acceleration can significantly improve performance, especially for large batches of images.\n\nSources: [README.md210-230](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L210-L230) [docs/examples/FastEmbed\\_GPU.ipynb1-193](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_GPU.ipynb#L1-L193)\n\n## Integration with Qdrant\n\nFastEmbed's image embedding can be easily integrated with Qdrant vector database:\n\n```\n```\n\nSources: [README.md232-281](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L232-L281)\n\n## Implementation Details\n\nThe `OnnxImageEmbedding` class inherits from both `ImageEmbeddingBase` and `OnnxImageModel[NumpyArray]`. It manages model downloading, caching, and inference operations. The actual embedding generation is delegated to ONNX Runtime, which provides efficient execution on both CPU and GPU.\n\nFor parallel processing, the class utilizes `OnnxImageEmbeddingWorker`, which initializes separate model instances in worker processes to handle embedding generation in parallel.\n\nThe embedding vectors are normalized after model inference to ensure they have unit length, which is important for cosine similarity calculations in vector search.\n\nSources: [fastembed/image/onnx\\_embedding.py62-198](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/image/onnx_embedding.py#L62-L198)\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh\n\n### On this page",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7.4-image-embedding.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1004,
      "character_count": 4223,
      "created_at": "2025-10-16T17:42:30.387329",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7.4-image-embedding.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "- [Image Embedding](#image-embedding.md)\n- [Overview](#overview.md)\n- [Supported Models](#supported-models.md)\n- [Image Embedding Process](#image-embedding-process.md)\n- [Basic Usage](#basic-usage.md)\n- [Configuration Options](#configuration-options.md)\n- [GPU Acceleration](#gpu-acceleration.md)\n- [Integration with Qdrant](#integration-with-qdrant.md)\n- [Implementation Details](#implementation-details.md)",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7.4-image-embedding.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 105,
      "character_count": 408,
      "created_at": "2025-10-16T17:42:30.387390",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_7.4-image-embedding.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  }
]
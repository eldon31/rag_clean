[
  {
    "text": "LateInteractionMultimodalEmbedding | qdrant/fastembed | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[qdrant/fastembed](https://github.com/qdrant/fastembed \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 20 April 2025 ([b78564](https://github.com/qdrant/fastembed/commits/b785640b))\n\n- [Overview](qdrant/fastembed/1-overview.md)\n- [Installation and Setup](qdrant/fastembed/2-installation-and-setup.md)\n- [Core Embedding Classes](qdrant/fastembed/3-core-embedding-classes.md)\n- [TextEmbedding](qdrant/fastembed/3.1-textembedding.md)\n- [SparseTextEmbedding](qdrant/fastembed/3.2-sparsetextembedding.md)\n- [LateInteractionTextEmbedding](qdrant/fastembed/3.3-lateinteractiontextembedding.md)\n- [ImageEmbedding](qdrant/fastembed/3.4-imageembedding.md)\n- [LateInteractionMultimodalEmbedding](qdrant/fastembed/3.5-lateinteractionmultimodalembedding.md)\n- [TextCrossEncoder](qdrant/fastembed/3.6-textcrossencoder.md)\n- [Architecture](qdrant/fastembed/4-architecture.md)\n- [Model Management](qdrant/fastembed/4.1-model-management.md)\n- [ONNX Runtime Integration](qdrant/fastembed/4.2-onnx-runtime-integration.md)\n- [Parallel Processing](qdrant/fastembed/4.3-parallel-processing.md)\n- [Implementation Details](qdrant/fastembed/5-implementation-details.md)\n- [Dense Text Embeddings](qdrant/fastembed/5.1-dense-text-embeddings.md)\n- [Sparse Text Embeddings](qdrant/fastembed/5.2-sparse-text-embeddings.md)\n- [Late Interaction Models](qdrant/fastembed/5.3-late-interaction-models.md)\n- [Multimodal Models](qdrant/fastembed/5.4-multimodal-models.md)\n- [Supported Models](qdrant/fastembed/6-supported-models.md)\n- [Usage Examples](qdrant/fastembed/7-usage-examples.md)\n- [Basic Text Embedding](qdrant/fastembed/7.1-basic-text-embedding.md)\n- [Sparse and Hybrid Search](qdrant/fastembed/7.2-sparse-and-hybrid-search.md)\n- [ColBERT and Late Interaction](qdrant/fastembed/7.3-colbert-and-late-interaction.md)\n- [Image Embedding](qdrant/fastembed/7.4-image-embedding.md)\n- [Performance Optimization](qdrant/fastembed/8-performance-optimization.md)\n- [Integration with Qdrant](qdrant/fastembed/9-integration-with-qdrant.md)\n- [Development Guide](qdrant/fastembed/10-development-guide.md)\n\nMenu\n\n# LateInteractionMultimodalEmbedding\n\nRelevant source files\n\n- [fastembed/\\_\\_init\\_\\_.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/__init__.py)\n- [fastembed/late\\_interaction\\_multimodal/colpali.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/colpali.py)\n- [fastembed/late\\_interaction\\_multimodal/late\\_interaction\\_multimodal\\_embedding.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/late_interaction_multimodal_embedding.py)\n- [fastembed/late\\_interaction\\_multimodal/late\\_interaction\\_multimodal\\_embedding\\_base.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/late_interaction_multimodal_embedding_base.py)\n- [fastembed/late\\_interaction\\_multimodal/onnx\\_multimodal\\_model.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/onnx_multimodal_model.py)\n- [tests/test\\_late\\_interaction\\_multimodal.py](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_late_interaction_multimodal.py)\n\n## Purpose and Overview",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.5-lateinteractionmultimodalembedding.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 980,
      "character_count": 3415,
      "created_at": "2025-10-16T17:42:30.024061",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.5-lateinteractionmultimodalembedding.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "The `LateInteractionMultimodalEmbedding` class provides a unified interface for generating and working with late interaction embeddings across multiple modalities (specifically text and images). Late interaction embedding models produce token-level embeddings rather than single dense vectors, enabling more precise matching between queries and documents. The multimodal capability allows for cross-modal retrieval applications like searching images with text queries or vice versa.\n\nFor text-only late interaction embeddings, see [LateInteractionTextEmbedding](qdrant/fastembed/3.3-lateinteractiontextembedding.md).\n\nSources: [fastembed/late\\_interaction\\_multimodal/late\\_interaction\\_multimodal\\_embedding.py1-131](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/late_interaction_multimodal_embedding.py#L1-L131) [fastembed/late\\_interaction\\_multimodal/late\\_interaction\\_multimodal\\_embedding\\_base.py1-68](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/late_interaction_multimodal_embedding_base.py#L1-L68)\n\n## Architecture\n\nThe `LateInteractionMultimodalEmbedding` system is designed with a factory pattern that delegates to specialized implementations based on the selected model. Currently, the system supports the ColPali model, but the architecture allows for easy extension with additional multimodal late interaction models.\n\n```\n```\n\nSources: [fastembed/late\\_interaction\\_multimodal/late\\_interaction\\_multimodal\\_embedding.py14-16](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/late_interaction_multimodal_embedding.py#L14-L16) [fastembed/late\\_interaction\\_multimodal/colpali.py34-131](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/colpali.py#L34-L131) [fastembed/late\\_interaction\\_multimodal/onnx\\_multimodal\\_model.py20-83](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/onnx_multimodal_model.py#L20-L83)\n\n## Embedding Process Flow\n\nThe late interaction multimodal embedding process uses specialized token-level encoders for both text and images, combining the power of late interaction with multimodal capabilities.\n\n```\n```\n\nSources: [fastembed/late\\_interaction\\_multimodal/late\\_interaction\\_multimodal\\_embedding.py86-130](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/late_interaction_multimodal_embedding.py#L86-L130) [fastembed/late\\_interaction\\_multimodal/onnx\\_multimodal\\_model.py86-223](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/onnx_multimodal_model.py#L86-L223)\n\n## Supported Models\n\nCurrently, the `LateInteractionMultimodalEmbedding` class supports the following model:\n\n| Model                    | Dimensions | Description                                                                            | License | Size   |\n| ------------------------ | ---------- | -------------------------------------------------------------------------------------- | ------- | ------ |\n| Qdrant/colpali-v1.3-fp16 | 128        | Text embeddings, Multimodal (text & image), English, 50 tokens query length truncation | MIT     | 6.5 GB |\n\nThe ColPali model is designed for late interaction retrieval between text and images, enabling efficient cross-modal search capabilities.\n\nSources: [fastembed/late\\_interaction\\_multimodal/colpali.py20-31](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/colpali.py#L20-L31)\n\n## Implementation Details\n\n### ColPali\n\nThe ColPali implementation uses an ONNX-optimized model architecture that captures token-level embeddings for both text and images. It has several important components:\n\n1. **Text Processing**:\n\n- Adds specific prefix and tokens to text queries\n   - Tokenizes text with a specialized tokenizer\n   - Preprocesses tokenized text for ONNX inference\n\n2. **Image Processing**:\n\n- Uses a standardized image preprocessor\n   - Converts images to the expected format (3x448x448)\n   - Adds placeholders for text when processing images\n\n3. **Model Output**:\n\n- Token-level embeddings rather than a single vector\n   - Preserves contextual information for more precise matching\n\nSources: [fastembed/late\\_interaction\\_multimodal/colpali.py34-190](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/colpali.py#L34-L190)\n\n### Parallel Processing Support",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.5-lateinteractionmultimodalembedding.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1020,
      "character_count": 4483,
      "created_at": "2025-10-16T17:42:30.031256",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.5-lateinteractionmultimodalembedding.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "The system supports parallel processing for both text and image embedding to improve throughput when dealing with large datasets:\n\n```\n```\n\nSources: [fastembed/late\\_interaction\\_multimodal/onnx\\_multimodal\\_model.py113-223](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/onnx_multimodal_model.py#L113-L223) [fastembed/late\\_interaction\\_multimodal/colpali.py275-300](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/colpali.py#L275-L300)\n\n## Usage\n\n### Initializing the Embedder\n\n```\n```\n\nSources: [fastembed/late\\_interaction\\_multimodal/late\\_interaction\\_multimodal\\_embedding.py54-84](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/late_interaction_multimodal_embedding.py#L54-L84)\n\n### Embedding Text\n\n```\n```\n\nSources: [fastembed/late\\_interaction\\_multimodal/late\\_interaction\\_multimodal\\_embedding.py86-107](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/late_interaction_multimodal_embedding.py#L86-L107)\n\n### Embedding Images\n\n```\n```\n\nSources: [fastembed/late\\_interaction\\_multimodal/late\\_interaction\\_multimodal\\_embedding.py109-130](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/late_interaction_multimodal_embedding.py#L109-L130) [tests/test\\_late\\_interaction\\_multimodal.py40-45](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_late_interaction_multimodal.py#L40-L45)\n\n## Key Parameters\n\n| Parameter    | Description                                        | Default                 |\n| ------------ | -------------------------------------------------- | ----------------------- |\n| `model_name` | The name of the multimodal model to use            | Required                |\n| `cache_dir`  | Directory to cache downloaded models               | System temp directory   |\n| `threads`    | Number of threads for single ONNX session          | None (auto)             |\n| `cuda`       | Whether to use CUDA for inference                  | False                   |\n| `device_ids` | List of device IDs for parallel processing         | None                    |\n| `lazy_load`  | Whether to load the model on demand                | False                   |\n| `batch_size` | Number of items to process together                | 256 (text), 16 (images) |\n| `parallel`   | Number of worker processes for parallel processing | None                    |\n\nSources: [fastembed/late\\_interaction\\_multimodal/late\\_interaction\\_multimodal\\_embedding.py54-84](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/late_interaction_multimodal_embedding.py#L54-L84) [fastembed/late\\_interaction\\_multimodal/colpali.py46-78](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/colpali.py#L46-L78)\n\n## Notes on Token-Level Embeddings\n\nUnlike traditional dense embeddings that produce a single vector per input, late interaction models like ColPali produce token-level embeddings. This means:\n\n1. Each token in the text or image gets its own embedding vector\n2. The output shape is (batch\\_size, sequence\\_length, embedding\\_dimension)\n3. These token-level embeddings enable more fine-grained matching between queries and documents\n\nFor multimodal late interaction, this token-level approach allows precise matching between text tokens and image regions, enabling more accurate cross-modal retrieval.\n\nSources: [fastembed/late\\_interaction\\_multimodal/colpali.py129-160](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/colpali.py#L129-L160)\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh\n\n### On this page",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.5-lateinteractionmultimodalembedding.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 886,
      "character_count": 3741,
      "created_at": "2025-10-16T17:42:30.036442",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.5-lateinteractionmultimodalembedding.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "- [LateInteractionMultimodalEmbedding](#lateinteractionmultimodalembedding.md)\n- [Purpose and Overview](#purpose-and-overview.md)\n- [Architecture](#architecture.md)\n- [Embedding Process Flow](#embedding-process-flow.md)\n- [Supported Models](#supported-models.md)\n- [Implementation Details](#implementation-details.md)\n- [ColPali](#colpali.md)\n- [Parallel Processing Support](#parallel-processing-support.md)\n- [Usage](#usage.md)\n- [Initializing the Embedder](#initializing-the-embedder.md)\n- [Embedding Text](#embedding-text.md)\n- [Embedding Images](#embedding-images.md)\n- [Key Parameters](#key-parameters.md)\n- [Notes on Token-Level Embeddings](#notes-on-token-level-embeddings.md)",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.5-lateinteractionmultimodalembedding.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 176,
      "character_count": 683,
      "created_at": "2025-10-16T17:42:30.036518",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 3,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3.5-lateinteractionmultimodalembedding.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  }
]
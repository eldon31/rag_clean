[
  {
    "text": "Core Embedding Classes | qdrant/fastembed | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[qdrant/fastembed](https://github.com/qdrant/fastembed \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 20 April 2025 ([b78564](https://github.com/qdrant/fastembed/commits/b785640b))\n\n- [Overview](qdrant/fastembed/1-overview.md)\n- [Installation and Setup](qdrant/fastembed/2-installation-and-setup.md)\n- [Core Embedding Classes](qdrant/fastembed/3-core-embedding-classes.md)\n- [TextEmbedding](qdrant/fastembed/3.1-textembedding.md)\n- [SparseTextEmbedding](qdrant/fastembed/3.2-sparsetextembedding.md)\n- [LateInteractionTextEmbedding](qdrant/fastembed/3.3-lateinteractiontextembedding.md)\n- [ImageEmbedding](qdrant/fastembed/3.4-imageembedding.md)\n- [LateInteractionMultimodalEmbedding](qdrant/fastembed/3.5-lateinteractionmultimodalembedding.md)\n- [TextCrossEncoder](qdrant/fastembed/3.6-textcrossencoder.md)\n- [Architecture](qdrant/fastembed/4-architecture.md)\n- [Model Management](qdrant/fastembed/4.1-model-management.md)\n- [ONNX Runtime Integration](qdrant/fastembed/4.2-onnx-runtime-integration.md)\n- [Parallel Processing](qdrant/fastembed/4.3-parallel-processing.md)\n- [Implementation Details](qdrant/fastembed/5-implementation-details.md)\n- [Dense Text Embeddings](qdrant/fastembed/5.1-dense-text-embeddings.md)\n- [Sparse Text Embeddings](qdrant/fastembed/5.2-sparse-text-embeddings.md)\n- [Late Interaction Models](qdrant/fastembed/5.3-late-interaction-models.md)\n- [Multimodal Models](qdrant/fastembed/5.4-multimodal-models.md)\n- [Supported Models](qdrant/fastembed/6-supported-models.md)\n- [Usage Examples](qdrant/fastembed/7-usage-examples.md)\n- [Basic Text Embedding](qdrant/fastembed/7.1-basic-text-embedding.md)\n- [Sparse and Hybrid Search](qdrant/fastembed/7.2-sparse-and-hybrid-search.md)\n- [ColBERT and Late Interaction](qdrant/fastembed/7.3-colbert-and-late-interaction.md)\n- [Image Embedding](qdrant/fastembed/7.4-image-embedding.md)\n- [Performance Optimization](qdrant/fastembed/8-performance-optimization.md)\n- [Integration with Qdrant](qdrant/fastembed/9-integration-with-qdrant.md)\n- [Development Guide](qdrant/fastembed/10-development-guide.md)\n\nMenu\n\n# Core Embedding Classes\n\nRelevant source files\n\n- [NOTICE](https://github.com/qdrant/fastembed/blob/b785640b/NOTICE)\n- [README.md](https://github.com/qdrant/fastembed/blob/b785640b/README.md)\n- [docs/examples/FastEmbed\\_GPU.ipynb](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_GPU.ipynb)\n- [docs/examples/Supported\\_Models.ipynb](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Supported_Models.ipynb)\n- [fastembed/embedding.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/embedding.py)\n- [fastembed/late\\_interaction\\_multimodal/\\_\\_init\\_\\_.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/__init__.py)\n\nThis page provides an overview of the main embedding classes in FastEmbed, which serve as primary interfaces for generating embeddings from different types of data. Each class is designed for a specific embedding strategy, offering a balance of simplicity and performance through ONNX Runtime integration.\n\nFor detailed information about how to use each class with specific examples, see [Usage Examples](qdrant/fastembed/7-usage-examples.md).\n\n## Class Hierarchy\n\nThe FastEmbed library is built around a hierarchical architecture of embedding classes, providing specialized functionality for different embedding strategies and data types.\n\n```\n```",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3-core-embedding-classes.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 997,
      "character_count": 3644,
      "created_at": "2025-10-16T17:42:29.896477",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3-core-embedding-classes.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "Sources: [fastembed/embedding.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/embedding.py)\n\n## Overview of Core Classes\n\nThe core embedding classes in FastEmbed can be categorized based on the type of embeddings they generate and the modalities they support:\n\n| Class                              | Embedding Type   | Input Type    | Primary Use Cases                             |\n| ---------------------------------- | ---------------- | ------------- | --------------------------------------------- |\n| TextEmbedding                      | Dense            | Text          | Semantic search, document retrieval           |\n| SparseTextEmbedding                | Sparse           | Text          | Lexical search, hybrid search                 |\n| LateInteractionTextEmbedding       | Token-level      | Text          | Precise text matching, complex queries        |\n| ImageEmbedding                     | Dense            | Images        | Image search, visual similarity               |\n| LateInteractionMultimodalEmbedding | Token-level      | Text & Images | Cross-modal search, visual question answering |\n| TextCrossEncoder                   | Relevance scores | Text pairs    | Result reranking, relevance judgment          |\n\nSources: [README.md49-156](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L49-L156)\n\n## Dense Text Embeddings with TextEmbedding\n\nThe `TextEmbedding` class is the primary interface for generating dense vector representations of text. It creates fixed-length vectors that capture semantic meaning.\n\n```\n```\n\n### Key Features\n\n- Supports various embedding models with different dimensions and language capabilities\n- Automatically handles model downloading and caching\n- Provides parallel processing capabilities for handling large datasets\n- Supports GPU acceleration through ONNX Runtime\n\n### Basic Usage Example\n\n```\n```\n\nFor detailed usage examples, see [Basic Text Embedding](qdrant/fastembed/7.1-basic-text-embedding.md).\n\nSources: [README.md29-47](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L29-L47) [docs/examples/Supported\\_Models.ipynb56-129](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Supported_Models.ipynb#L56-L129)\n\n## Sparse Text Embeddings with SparseTextEmbedding\n\nThe `SparseTextEmbedding` class generates sparse vector representations where most values are zero, making them efficient for large vocabularies and well-suited for lexical matching.\n\n```\n```\n\n### Key Features\n\n- Returns sparse embeddings as pairs of indices (token IDs) and values (weights)\n- Supports both neural sparse models (SPLADE) and statistical approaches (BM25)\n- Complements dense embeddings for hybrid search scenarios\n- Some models (BM25, BM42) require IDF statistics for optimal performance\n\n### Basic Usage Example\n\n```\n```\n\nFor detailed usage examples, see [Sparse and Hybrid Search](qdrant/fastembed/7.2-sparse-and-hybrid-search.md).\n\nSources: [README.md85-99](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L85-L99) [docs/examples/Supported\\_Models.ipynb370-413](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Supported_Models.ipynb#L370-L413)\n\n## Late Interaction Text Embeddings with LateInteractionTextEmbedding\n\nThe `LateInteractionTextEmbedding` class implements the ColBERT approach, which creates token-level embeddings to enable fine-grained matching between queries and documents.\n\n```\n```\n\n### Key Features\n\n- Generates a sequence of embeddings for each token rather than a single vector\n- Allows for more precise matching by comparing individual token representations\n- Maintains context through token-level embeddings\n- Typically used with specialized retrieval approaches\n\n### Basic Usage Example\n\n```\n```\n\nFor detailed usage examples, see [ColBERT and Late Interaction](qdrant/fastembed/7.3-colbert-and-late-interaction.md).\n\nSources: [README.md117-136](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L117-L136) [docs/examples/Supported\\_Models.ipynb492-600](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Supported_Models.ipynb#L492-L600)\n\n## Image Embeddings with ImageEmbedding\n\nThe `ImageEmbedding` class generates vector representations of images, allowing for image similarity search and visual retrieval.\n\n```\n```\n\n### Key Features\n\n- Supports loading images from file paths or PIL Image objects\n- Automatically handles image preprocessing (resizing, normalization)\n- Integrates with vision-language models like CLIP\n- Returns fixed-length vector representations of images\n\n### Basic Usage Example\n\n```\n```\n\nFor detailed usage examples, see [Image Embedding](qdrant/fastembed/7.4-image-embedding.md).",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3-core-embedding-classes.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1002,
      "character_count": 4684,
      "created_at": "2025-10-16T17:42:29.909907",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3-core-embedding-classes.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "Sources: [README.md138-155](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L138-L155) [docs/examples/Supported\\_Models.ipynb603-714](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Supported_Models.ipynb#L603-L714)\n\n## Multimodal Embeddings with LateInteractionMultimodalEmbedding\n\nThe `LateInteractionMultimodalEmbedding` class enables cross-modal retrieval through models that can embed both text and images in a compatible latent space.\n\n```\n```\n\n### Key Features\n\n- Supports both text and image inputs through separate embedding methods\n- Uses late interaction approach similar to ColBERT\n- Primarily implements the ColPali model for multimodal retrieval\n- Enables complex queries involving both textual and visual elements\n\n### Basic Usage Example\n\n```\n```\n\nSources: [README.md157-176](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L157-L176) [NOTICE16-19](https://github.com/qdrant/fastembed/blob/b785640b/NOTICE#L16-L19) [fastembed/late\\_interaction\\_multimodal/\\_\\_init\\_\\_.py1-5](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/late_interaction_multimodal/__init__.py#L1-L5)\n\n## Text Cross-Encoder with TextCrossEncoder\n\nThe `TextCrossEncoder` class implements cross-encoder models for reranking search results by directly scoring the relevance of query-document pairs.\n\n```\n```\n\n### Key Features\n\n- Returns relevance scores for query-document pairs instead of embeddings\n- Designed specifically for reranking results after initial retrieval\n- More accurate but computationally expensive compared to embedding similarity\n- Efficient implementation through ONNX Runtime\n\n### Basic Usage Example\n\n```\n```\n\nSources: [README.md178-208](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L178-L208) [docs/examples/Supported\\_Models.ipynb717-836](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Supported_Models.ipynb#L717-L836)\n\n## GPU Acceleration\n\nAll the core embedding classes support GPU acceleration through ONNX Runtime's CUDA execution provider, which can significantly improve performance, especially for batch processing.\n\n### Enabling GPU Support\n\nTo use GPU acceleration:\n\n1. Install the GPU-enabled version of FastEmbed:\n\n```\n   ```\n\n2. Specify the CUDA execution provider when initializing the embedding model:\n\n```\n   ```\n\nFor detailed GPU setup instructions and troubleshooting, see [FastEmbed GPU](qdrant/fastembed/8-performance-optimization.md).\n\nSources: [README.md210-230](https://github.com/qdrant/fastembed/blob/b785640b/README.md#L210-L230) [docs/examples/FastEmbed\\_GPU.ipynb1-42](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_GPU.ipynb#L1-L42) [docs/examples/FastEmbed\\_GPU.ipynb90-108](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_GPU.ipynb#L90-L108)\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh\n\n### On this page",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3-core-embedding-classes.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 713,
      "character_count": 2887,
      "created_at": "2025-10-16T17:42:29.916532",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3-core-embedding-classes.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "- [Core Embedding Classes](#core-embedding-classes.md)\n- [Class Hierarchy](#class-hierarchy.md)\n- [Overview of Core Classes](#overview-of-core-classes.md)\n- [Dense Text Embeddings with TextEmbedding](#dense-text-embeddings-with-textembedding.md)\n- [Key Features](#key-features.md)\n- [Basic Usage Example](#basic-usage-example.md)\n- [Sparse Text Embeddings with SparseTextEmbedding](#sparse-text-embeddings-with-sparsetextembedding.md)\n- [Key Features](#key-features-1.md)\n- [Basic Usage Example](#basic-usage-example-1.md)\n- [Late Interaction Text Embeddings with LateInteractionTextEmbedding](#late-interaction-text-embeddings-with-lateinteractiontextembedding.md)\n- [Key Features](#key-features-2.md)\n- [Basic Usage Example](#basic-usage-example-2.md)\n- [Image Embeddings with ImageEmbedding](#image-embeddings-with-imageembedding.md)\n- [Key Features](#key-features-3.md)\n- [Basic Usage Example](#basic-usage-example-3.md)\n- [Multimodal Embeddings with LateInteractionMultimodalEmbedding](#multimodal-embeddings-with-lateinteractionmultimodalembedding.md)\n- [Key Features](#key-features-4.md)\n- [Basic Usage Example](#basic-usage-example-4.md)\n- [Text Cross-Encoder with TextCrossEncoder](#text-cross-encoder-with-textcrossencoder.md)\n- [Key Features](#key-features-5.md)\n- [Basic Usage Example](#basic-usage-example-5.md)\n- [GPU Acceleration](#gpu-acceleration.md)\n- [Enabling GPU Support](#enabling-gpu-support.md)",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3-core-embedding-classes.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 390,
      "character_count": 1418,
      "created_at": "2025-10-16T17:42:29.916734",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 3,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_3-core-embedding-classes.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  }
]
[
  {
    "text": "Sparse Text Embeddings | qdrant/fastembed | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[qdrant/fastembed](https://github.com/qdrant/fastembed \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 20 April 2025 ([b78564](https://github.com/qdrant/fastembed/commits/b785640b))\n\n- [Overview](qdrant/fastembed/1-overview.md)\n- [Installation and Setup](qdrant/fastembed/2-installation-and-setup.md)\n- [Core Embedding Classes](qdrant/fastembed/3-core-embedding-classes.md)\n- [TextEmbedding](qdrant/fastembed/3.1-textembedding.md)\n- [SparseTextEmbedding](qdrant/fastembed/3.2-sparsetextembedding.md)\n- [LateInteractionTextEmbedding](qdrant/fastembed/3.3-lateinteractiontextembedding.md)\n- [ImageEmbedding](qdrant/fastembed/3.4-imageembedding.md)\n- [LateInteractionMultimodalEmbedding](qdrant/fastembed/3.5-lateinteractionmultimodalembedding.md)\n- [TextCrossEncoder](qdrant/fastembed/3.6-textcrossencoder.md)\n- [Architecture](qdrant/fastembed/4-architecture.md)\n- [Model Management](qdrant/fastembed/4.1-model-management.md)\n- [ONNX Runtime Integration](qdrant/fastembed/4.2-onnx-runtime-integration.md)\n- [Parallel Processing](qdrant/fastembed/4.3-parallel-processing.md)\n- [Implementation Details](qdrant/fastembed/5-implementation-details.md)\n- [Dense Text Embeddings](qdrant/fastembed/5.1-dense-text-embeddings.md)\n- [Sparse Text Embeddings](qdrant/fastembed/5.2-sparse-text-embeddings.md)\n- [Late Interaction Models](qdrant/fastembed/5.3-late-interaction-models.md)\n- [Multimodal Models](qdrant/fastembed/5.4-multimodal-models.md)\n- [Supported Models](qdrant/fastembed/6-supported-models.md)\n- [Usage Examples](qdrant/fastembed/7-usage-examples.md)\n- [Basic Text Embedding](qdrant/fastembed/7.1-basic-text-embedding.md)\n- [Sparse and Hybrid Search](qdrant/fastembed/7.2-sparse-and-hybrid-search.md)\n- [ColBERT and Late Interaction](qdrant/fastembed/7.3-colbert-and-late-interaction.md)\n- [Image Embedding](qdrant/fastembed/7.4-image-embedding.md)\n- [Performance Optimization](qdrant/fastembed/8-performance-optimization.md)\n- [Integration with Qdrant](qdrant/fastembed/9-integration-with-qdrant.md)\n- [Development Guide](qdrant/fastembed/10-development-guide.md)\n\nMenu\n\n# Sparse Text Embeddings\n\nRelevant source files\n\n- [fastembed/sparse/bm25.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm25.py)\n- [fastembed/sparse/bm42.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm42.py)\n- [fastembed/sparse/sparse\\_text\\_embedding.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/sparse_text_embedding.py)\n- [fastembed/sparse/splade\\_pp.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/splade_pp.py)\n\nThis document explains the implementation and usage of sparse text embeddings in FastEmbed. Sparse embeddings represent text as high-dimensional vectors where most dimensions are zero, making them storage-efficient and well-suited for certain retrieval tasks. For information about dense text embeddings, see [Dense Text Embeddings](qdrant/fastembed/5.1-dense-text-embeddings.md).\n\n## Introduction to Sparse Embeddings\n\nSparse embeddings differ from dense embeddings in several key ways:\n\n- **Representation**: Sparse vectors have most dimensions set to zero, with only a small subset containing non-zero values\n- **Dimensionality**: Often much higher dimensional than dense embeddings (tens of thousands vs hundreds)\n- **Interpretability**: Each non-zero dimension typically corresponds to a specific token/word\n- **Storage**: More efficient to store as (index, value) pairs rather than full vectors\n- **Matching**: Often use similarity measures like BM25 rather than cosine distance",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.2-sparse-text-embeddings.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1019,
      "character_count": 3787,
      "created_at": "2025-10-16T17:42:30.191317",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.2-sparse-text-embeddings.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "FastEmbed implements three distinct approaches to sparse embeddings:\n\n```\n```\n\nSources: [fastembed/sparse/sparse\\_text\\_embedding.py16-17](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/sparse_text_embedding.py#L16-L17) [fastembed/sparse/sparse\\_embedding\\_base.py7-9](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/sparse_embedding_base.py#L7-L9)\n\n## Core Architecture\n\nThe `SparseTextEmbedding` class serves as the main entry point for generating sparse embeddings. It maintains a registry of implementation classes and delegates to the appropriate implementation based on the provided model name.\n\n```\n```\n\nSources: [fastembed/sparse/sparse\\_text\\_embedding.py16-18](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/sparse_text_embedding.py#L16-L18) [fastembed/sparse/splade\\_pp.py36](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/splade_pp.py#L36-L36) [fastembed/sparse/bm25.py61](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm25.py#L61-L61) [fastembed/sparse/bm42.py39](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm42.py#L39-L39)\n\n## Implemented Models\n\nFastEmbed offers three sparse embedding implementations with different characteristics:\n\n### 1. SpladePP\n\nSPLADE++ (SParse Lexical AnD Expansion) uses a transformer model to generate sparse embeddings that capture contextual meaning. It applies a log operation on ReLU-activated outputs to emphasize important tokens.\n\nKey features:\n\n- Neural-based approach using transformer models\n- Learns weights through contextual understanding of text\n- Creates high-quality sparse representations\n- Requires an ONNX model for inference\n\nImplementation highlights:\n\n```\n```\n\nSources: [fastembed/sparse/splade\\_pp.py36-52](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/splade_pp.py#L36-L52)\n\n### 2. BM25\n\nBM25 (Best Matching 25) is a classic information retrieval algorithm implemented as sparse embeddings. It evaluates token importance based on term frequency and document length.\n\nKey features:\n\n- Traditional bag-of-words IR approach\n- Applies stemming and stopword removal\n- Language-aware with support for 18 languages\n- Requires no model weights (lightweight)\n\nThe BM25 formula used is:\n\n```\nscore(q, d) = SUM[ IDF(q_i) * (f(q_i, d) * (k + 1)) / (f(q_i, d) + k * (1 - b + b * (|d| / avg_len))) ]\n```\n\nImplementation highlights:\n\n```\n```\n\nSources: [fastembed/sparse/bm25.py61-266](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm25.py#L61-L266) [fastembed/sparse/bm25.py25-44](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm25.py#L25-L44)\n\n### 3. BM42\n\nBM42 is an extension of BM25 that addresses limitations with short documents by using transformer attention weights instead of token counts.\n\nKey features:\n\n- Hybrid approach combining BM25 with neural attention\n- Better handles short documents and rare tokens\n- Applies stemming and stopword removal\n- Named \"42\" as a reference to \"The Hitchhiker's Guide to the Galaxy\"\n\nImplementation highlights:\n\n```\n```\n\nSources: [fastembed/sparse/bm42.py39-218](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm42.py#L39-L218)\n\n## Embedding Process Flow\n\nThe process of generating sparse embeddings differs between the three implementations, but follows a general pattern:\n\n```\n```\n\nSources: [fastembed/sparse/splade\\_pp.py37-52](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/splade_pp.py#L37-L52) [fastembed/sparse/bm25.py251-262](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm25.py#L251-L262) [fastembed/sparse/bm42.py220-250](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm42.py#L220-L250)\n\n## Model Comparison",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.2-sparse-text-embeddings.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 998,
      "character_count": 3784,
      "created_at": "2025-10-16T17:42:30.200625",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.2-sparse-text-embeddings.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "| Feature          | SpladePP                         | BM25                          | BM42                     |\n| ---------------- | -------------------------------- | ----------------------------- | ------------------------ |\n| Approach         | Neural (Transformer)             | Statistical                   | Hybrid                   |\n| Model Size       | \\~532 MB                         | None (rule-based)             | \\~90 MB                  |\n| Strengths        | High quality for semantic search | Works well for keyword search | Good for short documents |\n| Token Importance | Learned weights                  | Term frequency                | Attention weights        |\n| Language Support | English                          | 18 languages                  | English                  |\n| IDF Requirement  | Yes                              | Yes                           | Yes                      |\n| Preprocessing    | Minimal                          | Stemming, stopwords           | Stemming, stopwords      |\n\nSources: [fastembed/sparse/splade\\_pp.py14-33](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/splade_pp.py#L14-L33) [fastembed/sparse/bm25.py25-58](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm25.py#L25-L58) [fastembed/sparse/bm42.py20-36](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm42.py#L20-L36)\n\n## Usage\n\nThe `SparseTextEmbedding` class provides a unified interface for all sparse embedding implementations:\n\n```\n```\n\nSources: [fastembed/sparse/sparse\\_text\\_embedding.py52-129](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/sparse_text_embedding.py#L52-L129)\n\n## IDF Requirement\n\nAll sparse embedding models in FastEmbed are designed to be used with inverse document frequency (IDF) weighting applied during search. When used with Qdrant vector database, this requires setting `\"modifier\": \"idf\"` in the sparse vector index configuration.\n\nIDF weights terms based on their rarity across the entire corpus, giving more importance to uncommon terms:\n\n```\nIDF(term) = log(N / df(term))\n```\n\nWhere N is the total number of documents and df(term) is the number of documents containing the term.\n\nSources: [fastembed/sparse/bm25.py65-66](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm25.py#L65-L66) [fastembed/sparse/bm42.py52-53](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm42.py#L52-L53)\n\n## Implementation Details\n\n### SparseEmbedding Structure\n\nAll sparse embedding implementations produce objects of type `SparseEmbedding`, which contains:\n\n- `indices`: An array of token IDs (integers)\n- `values`: An array of weights corresponding to each token ID\n\nThis representation is compact and efficient for vector databases like Qdrant.\n\n### Model Selection\n\nThe `SparseTextEmbedding` class automatically selects the appropriate implementation based on the model name:\n\n```\n```\n\nSources: [fastembed/sparse/sparse\\_text\\_embedding.py73-91](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/sparse_text_embedding.py#L73-L91)\n\n### Parallel Processing\n\nAll sparse embedding implementations support parallel processing for faster document embedding. The `parallel` parameter in the `embed` method controls this behavior:\n\n- `None`: Uses single-process embedding with ONNX threading\n- `0`: Uses all available CPU cores\n- `> 1`: Uses the specified number of worker processes\n\nSources: [fastembed/sparse/splade\\_pp.py135-167](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/splade_pp.py#L135-L167) [fastembed/sparse/bm25.py156-198](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm25.py#L156-L198) [fastembed/sparse/bm42.py270-302](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/sparse/bm42.py#L270-L302)\n\n## Common Use Cases\n\n1. **Hybrid Search**: Combining sparse and dense embeddings for both keyword and semantic matching\n2. **Exact Keyword Matching**: When precise term matching is required\n3. **Specialized Domain Search**: When specific terminology must be precisely matched\n4. **Long Document Search**: Sparse embeddings can better handle specific terms in very long documents\n\nFor hybrid search examples, see [Sparse and Hybrid Search](qdrant/fastembed/7.2-sparse-and-hybrid-search.md).\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh\n\n### On this page",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.2-sparse-text-embeddings.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1004,
      "character_count": 4398,
      "created_at": "2025-10-16T17:42:30.212163",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.2-sparse-text-embeddings.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  },
  {
    "text": "- [Sparse Text Embeddings](#sparse-text-embeddings.md)\n- [Introduction to Sparse Embeddings](#introduction-to-sparse-embeddings.md)\n- [Core Architecture](#core-architecture.md)\n- [Implemented Models](#implemented-models.md)\n- [1. SpladePP](#1-spladepp.md)\n- [2. BM25](#2-bm25.md)\n- [3. BM42](#3-bm42.md)\n- [Embedding Process Flow](#embedding-process-flow.md)\n- [Model Comparison](#model-comparison.md)\n- [Usage](#usage.md)\n- [IDF Requirement](#idf-requirement.md)\n- [Implementation Details](#implementation-details.md)\n- [SparseEmbedding Structure](#sparseembedding-structure.md)\n- [Model Selection](#model-selection.md)\n- [Parallel Processing](#parallel-processing.md)\n- [Common Use Cases](#common-use-cases.md)",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.2-sparse-text-embeddings.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 202,
      "character_count": 712,
      "created_at": "2025-10-16T17:42:30.212280",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_fastembed",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 3,
      "file_relative_path": "Qdrant\\qdrant_fastembed\\_qdrant_fastembed_5.2-sparse-text-embeddings.md",
      "collection_context": "Qdrant/qdrant_fastembed"
    }
  }
]
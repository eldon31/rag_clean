[
  {
    "text": "Apache Spark - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 928,
      "character_count": 3487,
      "created_at": "2025-10-16T17:42:24.068491",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 968,
      "character_count": 3625,
      "created_at": "2025-10-16T17:42:24.071321",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 965,
      "character_count": 3819,
      "created_at": "2025-10-16T17:42:24.076264",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 978,
      "character_count": 3651,
      "created_at": "2025-10-16T17:42:24.078054",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 3,
      "file_relative_path": "qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- [Data management](https://qdrant.tech/documentation/data-management/)\n-\n- Apache Spark\n\n# Apache Spark\n\n[Spark](https://spark.apache.org/) is a distributed computing framework designed for big data processing and analytics. The [Qdrant-Spark connector](https://github.com/qdrant/qdrant-spark) enables Qdrant to be a storage destination in Spark.\n\n## Installation\n\nTo integrate the connector into your Spark environment, get the JAR file from one of the sources listed below.\n\n- GitHub Releases",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 994,
      "character_count": 3998,
      "created_at": "2025-10-16T17:42:24.083214",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 4,
      "file_relative_path": "qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "The packaged `jar` file with all the required dependencies can be found [here](https://github.com/qdrant/qdrant-spark/releases).\n\n- Building from Source\n\nTo build the `jar` from source, you need [JDK@8](https://www.azul.com/downloads/#zulu) and [Maven](https://maven.apache.org/) installed. Once the requirements have been satisfied, run the following command in the [project root](https://github.com/qdrant/qdrant-spark).\n\n```bash\nmvn package -DskipTests\n```\n\nThe JAR file will be written into the `target` directory by default.\n\n- Maven Central\n\nFind the project on Maven Central [here](https://central.sonatype.com/artifact/io.qdrant/spark).\n\n## Usage\n\n### Creating a Spark session with Qdrant support\n\n```python\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.config(\n        \"spark.jars\",\n        \"path/to/file/spark-VERSION.jar\",  # Specify the path to the downloaded JAR file\n    )\n    .master(\"local[*]\")\n    .appName(\"qdrant\")\n    .getOrCreate()\n```\n\n```scala\nimport org.apache.spark.sql.SparkSession\n\nval spark = SparkSession.builder\n  .config(\"spark.jars\", \"path/to/file/spark-VERSION.jar\") // Specify the path to the downloaded JAR file\n  .master(\"local[*]\")\n  .appName(\"qdrant\")\n  .getOrCreate()\n```\n\n```java\nimport org.apache.spark.sql.SparkSession;\n\npublic class QdrantSparkJavaExample {\n    public static void main(String[] args) {\n        SparkSession spark = SparkSession.builder()\n                .config(\"spark.jars\", \"path/to/file/spark-VERSION.jar\") // Specify the path to the downloaded JAR file\n                .master(\"local[*]\")\n                .appName(\"qdrant\")\n                .getOrCreate(); \n    }\n}\n```\n\n### Loading data\n\nBefore loading the data using this connector, a collection has to be [created](https://qdrant.tech/documentation/concepts/collections/#create-a-collection) in advance with the appropriate vector dimensions and configurations.\n\nThe connector supports ingesting multiple named/unnamed, dense/sparse vectors.\n\n*Click each to expand.*\n\n**Unnamed/Default vector**\n\n```python\n  <pyspark.sql.DataFrame>\n   .write\n   .format(\"io.qdrant.spark.Qdrant\")\n   .option(\"qdrant_url\", <QDRANT_GRPC_URL>)\n   .option(\"collection_name\", <QDRANT_COLLECTION_NAME>)\n   .option(\"embedding_field\", <EMBEDDING_FIELD_NAME>)  # Expected to be a field of type ArrayType(FloatType)\n   .option(\"schema\", <pyspark.sql.DataFrame>.schema.json())\n   .mode(\"append\")\n   .save()\n```\n\n**Named vector**\n\n```python\n  <pyspark.sql.DataFrame>\n   .write\n   .format(\"io.qdrant.spark.Qdrant\")\n   .option(\"qdrant_url\", <QDRANT_GRPC_URL>)\n   .option(\"collection_name\", <QDRANT_COLLECTION_NAME>)\n   .option(\"embedding_field\", <EMBEDDING_FIELD_NAME>)  # Expected to be a field of type ArrayType(FloatType)\n   .option(\"vector_name\", <VECTOR_NAME>)\n   .option(\"schema\", <pyspark.sql.DataFrame>.schema.json())\n   .mode(\"append\")\n   .save()\n```\n\n> #### NOTE\n>\n> The `embedding_field` and `vector_name` options are maintained for backward compatibility. It is recommended to use `vector_fields` and `vector_names` for named vectors as shown below.\n\n**Multiple named vectors**\n\n```python\n  <pyspark.sql.DataFrame>\n   .write\n   .format(\"io.qdrant.spark.Qdrant\")\n   .option(\"qdrant_url\", \"<QDRANT_GRPC_URL>\")\n   .option(\"collection_name\", \"<QDRANT_COLLECTION_NAME>\")\n   .option(\"vector_fields\", \"<COLUMN_NAME>,<ANOTHER_COLUMN_NAME>\")\n   .option(\"vector_names\", \"<VECTOR_NAME>,<ANOTHER_VECTOR_NAME>\")\n   .option(\"schema\", <pyspark.sql.DataFrame>.schema.json())\n   .mode(\"append\")\n   .save()\n```\n\n**Sparse vectors**",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 911,
      "character_count": 3529,
      "created_at": "2025-10-16T17:42:24.089555",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 5,
      "file_relative_path": "qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "```python\n  <pyspark.sql.DataFrame>\n   .write\n   .format(\"io.qdrant.spark.Qdrant\")\n   .option(\"qdrant_url\", \"<QDRANT_GRPC_URL>\")\n   .option(\"collection_name\", \"<QDRANT_COLLECTION_NAME>\")\n   .option(\"sparse_vector_value_fields\", \"<COLUMN_NAME>\")\n   .option(\"sparse_vector_index_fields\", \"<COLUMN_NAME>\")\n   .option(\"sparse_vector_names\", \"<SPARSE_VECTOR_NAME>\")\n   .option(\"schema\", <pyspark.sql.DataFrame>.schema.json())\n   .mode(\"append\")\n   .save()\n```\n\n**Multiple sparse vectors**\n\n```python\n  <pyspark.sql.DataFrame>\n   .write\n   .format(\"io.qdrant.spark.Qdrant\")\n   .option(\"qdrant_url\", \"<QDRANT_GRPC_URL>\")\n   .option(\"collection_name\", \"<QDRANT_COLLECTION_NAME>\")\n   .option(\"sparse_vector_value_fields\", \"<COLUMN_NAME>,<ANOTHER_COLUMN_NAME>\")\n   .option(\"sparse_vector_index_fields\", \"<COLUMN_NAME>,<ANOTHER_COLUMN_NAME>\")\n   .option(\"sparse_vector_names\", \"<SPARSE_VECTOR_NAME>,<ANOTHER_SPARSE_VECTOR_NAME>\")\n   .option(\"schema\", <pyspark.sql.DataFrame>.schema.json())\n   .mode(\"append\")\n   .save()\n```\n\n**Combination of named dense and sparse vectors**\n\n```python\n  <pyspark.sql.DataFrame>\n   .write\n   .format(\"io.qdrant.spark.Qdrant\")\n   .option(\"qdrant_url\", \"<QDRANT_GRPC_URL>\")\n   .option(\"collection_name\", \"<QDRANT_COLLECTION_NAME>\")\n   .option(\"vector_fields\", \"<COLUMN_NAME>,<ANOTHER_COLUMN_NAME>\")\n   .option(\"vector_names\", \"<VECTOR_NAME>,<ANOTHER_VECTOR_NAME>\")\n   .option(\"sparse_vector_value_fields\", \"<COLUMN_NAME>,<ANOTHER_COLUMN_NAME>\")\n   .option(\"sparse_vector_index_fields\", \"<COLUMN_NAME>,<ANOTHER_COLUMN_NAME>\")\n   .option(\"sparse_vector_names\", \"<SPARSE_VECTOR_NAME>,<ANOTHER_SPARSE_VECTOR_NAME>\")\n   .option(\"schema\", <pyspark.sql.DataFrame>.schema.json())\n   .mode(\"append\")\n   .save()\n```\n\n**Multi-vectors**\n\n```python\n  <pyspark.sql.DataFrame>\n   .write\n   .format(\"io.qdrant.spark.Qdrant\")\n   .option(\"qdrant_url\", \"<QDRANT_GRPC_URL>\")\n   .option(\"collection_name\", \"<QDRANT_COLLECTION_NAME>\")\n   .option(\"multi_vector_fields\", \"<COLUMN_NAME>\")\n   .option(\"multi_vector_names\", \"<MULTI_VECTOR_NAME>\")\n   .option(\"schema\", <pyspark.sql.DataFrame>.schema.json())\n   .mode(\"append\")\n   .save()\n```\n\n**Multiple Multi-vectors**\n\n```python\n  <pyspark.sql.DataFrame>\n   .write\n   .format(\"io.qdrant.spark.Qdrant\")\n   .option(\"qdrant_url\", \"<QDRANT_GRPC_URL>\")\n   .option(\"collection_name\", \"<QDRANT_COLLECTION_NAME>\")\n   .option(\"multi_vector_fields\", \"<COLUMN_NAME>,<ANOTHER_COLUMN_NAME>\")\n   .option(\"multi_vector_names\", \"<MULTI_VECTOR_NAME>,<ANOTHER_MULTI_VECTOR_NAME>\")\n   .option(\"schema\", <pyspark.sql.DataFrame>.schema.json())\n   .mode(\"append\")\n   .save()\n```\n\n**No vectors - Entire dataframe is stored as payload**\n\n```python\n  <pyspark.sql.DataFrame>\n   .write\n   .format(\"io.qdrant.spark.Qdrant\")\n   .option(\"qdrant_url\", \"<QDRANT_GRPC_URL>\")\n   .option(\"collection_name\", \"<QDRANT_COLLECTION_NAME>\")\n   .option(\"schema\", <pyspark.sql.DataFrame>.schema.json())\n   .mode(\"append\")\n   .save()\n```\n\n## Databricks\n\nCheck out our [example](https://qdrant.tech/documentation/send-data/databricks/) of using the Spark connector with Databricks.\n\nYou can use the `qdrant-spark` connector as a library in [Databricks](https://www.databricks.com/).\n\n- Go to the `Libraries` section in your Databricks cluster dashboard.\n- Select `Install New` to open the library installation modal.\n- Search for `io.qdrant:spark:VERSION` in the Maven packages and click `Install`.\n\n## Datatype support\n\nThe appropriate Spark data types are mapped to the Qdrant payload based on the provided `schema`.\n\n## Options and Spark types",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 963,
      "character_count": 3546,
      "created_at": "2025-10-16T17:42:24.096825",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 6,
      "file_relative_path": "qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "| Option                       | Description                                                                          | Column DataType                   | Required |\n| ---------------------------- | ------------------------------------------------------------------------------------ | --------------------------------- | -------- |\n| `qdrant_url`                 | gRPC URL of the Qdrant instance. Eg: <http://localhost:6334>                         | -                                 | ✅        |\n| `collection_name`            | Name of the collection to write data into                                            | -                                 | ✅        |\n| `schema`                     | JSON string of the dataframe schema                                                  | -                                 | ✅        |\n| `embedding_field`            | Name of the column holding the embeddings (Deprecated - Use `vector_fields` instead) | `ArrayType(FloatType)`            | ❌        |\n| `id_field`                   | Name of the column holding the point IDs. Default: Random UUID                       | `StringType` or `IntegerType`     | ❌        |\n| `batch_size`                 | Max size of the upload batch. Default: 64                                            | -                                 | ❌        |\n| `retries`                    | Number of upload retries. Default: 3                                                 | -                                 | ❌        |\n| `api_key`                    | Qdrant API key for authentication                                                    | -                                 | ❌        |\n| `vector_name`                | Name of the vector in the collection.                                                | -                                 | ❌        |\n| `vector_fields`              | Comma-separated names of columns holding the vectors.                                | `ArrayType(FloatType)`            | ❌        |\n| `vector_names`               | Comma-separated names of vectors in the collection.                                  | -                                 | ❌        |\n| `sparse_vector_index_fields` | Comma-separated names of columns holding the sparse vector indices.                  | `ArrayType(IntegerType)`          | ❌        |\n| `sparse_vector_value_fields` | Comma-separated names of columns holding the sparse vector values.                   | `ArrayType(FloatType)`            | ❌        |\n| `sparse_vector_names`        | Comma-separated names of the sparse vectors in the collection.                       | -                                 | ❌        |\n| `multi_vector_fields`        | Comma-separated names of columns holding the multi-vector values.                    | `ArrayType(ArrayType(FloatType))` | ❌        |\n| `multi_vector_names`         | Comma-separated names of the multi-vectors in the collection.                        | -                                 | ❌        |\n| `shard_key_selector`         | Comma-separated names of custom shard keys to use during upsert.                     | -                                 | ❌        |\n| `wait`                       | Wait for each batch upsert to complete. `true` or `false`. Defaults to `true`.       | -                                 | ❌        |\n\nFor more information, be sure to check out the [Qdrant-Spark GitHub repository](https://github.com/qdrant/qdrant-spark). The Apache Spark guide is available [here](https://spark.apache.org/docs/latest/quick-start.html). Happy data processing!\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! 🙏\n\nWe are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/data-management/spark.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Apache Spark](#apache-spark.md)\n\n- [Installation](#installation.md)\n\n- [Usage](#usage.md)\n\n- [Creating a Spark session with Qdrant support](#creating-a-spark-session-with-qdrant-support.md)\n    - [Loading data](#loading-data.md)\n\n- [Databricks](#databricks.md)\n\n- [Datatype support](#datatype-support.md)\n\n- [Options and Spark types](#options-and-spark-types.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/data-management/spark.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
    "metadata": {
      "chunk_id": 7,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 941,
      "character_count": 4775,
      "created_at": "2025-10-16T17:42:24.106980",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 7,
      "file_relative_path": "qdrant_documentation\\documentation_data-management_spark\\_documentation_data-management_spark_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  }
]
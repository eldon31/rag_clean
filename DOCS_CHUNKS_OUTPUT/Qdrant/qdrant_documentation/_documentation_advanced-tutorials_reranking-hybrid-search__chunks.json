[
  {
    "text": "Reranking in Hybrid Search - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Getting Started\n\n[What is Qdrant?](https://qdrant.tech/documentation/overview/)\n\n- [Understanding Vector Search in Qdrant](https://qdrant.tech/documentation/overview/vector-search/)\n\n[Local Quickstart](https://qdrant.tech/documentation/quickstart/)\n\n[API & SDKs](https://qdrant.tech/documentation/interfaces/)\n\n[Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)\n\n### User Manual\n\n[Concepts](https://qdrant.tech/documentation/concepts/)\n\n- [Collections](https://qdrant.tech/documentation/concepts/collections/)\n- [Points](https://qdrant.tech/documentation/concepts/points/)\n- [Vectors](https://qdrant.tech/documentation/concepts/vectors/)\n- [Payload](https://qdrant.tech/documentation/concepts/payload/)\n- [Search](https://qdrant.tech/documentation/concepts/search/)\n- [Explore](https://qdrant.tech/documentation/concepts/explore/)\n- [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/)\n- [Filtering](https://qdrant.tech/documentation/concepts/filtering/)\n- [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/)\n- [Storage](https://qdrant.tech/documentation/concepts/storage/)\n- [Indexing](https://qdrant.tech/documentation/concepts/indexing/)\n- [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)\n\n[Guides](https://qdrant.tech/documentation/guides/installation/)\n\n- [Installation](https://qdrant.tech/documentation/guides/installation/)\n- [Administration](https://qdrant.tech/documentation/guides/administration/)\n- [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/)\n- [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/)\n- [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/)\n- [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)\n- [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)\n- [Quantization](https://qdrant.tech/documentation/guides/quantization/)\n- [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/)\n- [Configuration](https://qdrant.tech/documentation/guides/configuration/)\n- [Security](https://qdrant.tech/documentation/guides/security/)\n- [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/)\n- [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)\n\n### Ecosystem\n\n[FastEmbed](https://qdrant.tech/documentation/fastembed/)\n\n- [Quickstart](https://qdrant.tech/documentation/fastembed/fastembed-quickstart/)\n- [FastEmbed & Qdrant](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/)\n- [Working with miniCOIL](https://qdrant.tech/documentation/fastembed/fastembed-minicoil/)\n- [Working with SPLADE](https://qdrant.tech/documentation/fastembed/fastembed-splade/)\n- [Working with ColBERT](https://qdrant.tech/documentation/fastembed/fastembed-colbert/)\n- [Reranking with FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-rerankers/)\n\n[Qdrant MCP Server](https://github.com/qdrant/mcp-server-qdrant)\n\n### Tutorials\n\n[Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 969,
      "character_count": 3794,
      "created_at": "2025-10-16T17:42:21.214031",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)\n- [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)\n- [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)\n- [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)\n\n[Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)\n\n- [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/)\n- [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/)\n- [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)\n- [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)\n- [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)\n\n[Using the Database](https://qdrant.tech/documentation/database-tutorials/)\n\n- [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)\n- [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)\n- [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)\n- [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)\n- [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/)\n- [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/)\n- [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)\n\n### Support\n\n[FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n\n- [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n- [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)\n\n[Release Notes](https://github.com/qdrant/qdrant/releases)\n\n### Getting Started\n\n[What is Qdrant?](https://qdrant.tech/documentation/overview/)\n\n- [Understanding Vector Search in Qdrant](https://qdrant.tech/documentation/overview/vector-search/)\n\n[Local Quickstart](https://qdrant.tech/documentation/quickstart/)\n\n[API & SDKs](https://qdrant.tech/documentation/interfaces/)\n\n[Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)\n\n### User Manual\n\n[Concepts](https://qdrant.tech/documentation/concepts/)\n\n- [Collections](https://qdrant.tech/documentation/concepts/collections/)\n- [Points](https://qdrant.tech/documentation/concepts/points/)\n- [Vectors](https://qdrant.tech/documentation/concepts/vectors/)\n- [Payload](https://qdrant.tech/documentation/concepts/payload/)\n- [Search](https://qdrant.tech/documentation/concepts/search/)\n- [Explore](https://qdrant.tech/documentation/concepts/explore/)\n- [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/)\n- [Filtering](https://qdrant.tech/documentation/concepts/filtering/)\n- [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/)\n- [Storage](https://qdrant.tech/documentation/concepts/storage/)\n- [Indexing](https://qdrant.tech/documentation/concepts/indexing/)\n- [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)\n\n[Guides](https://qdrant.tech/documentation/guides/installation/)",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 852,
      "character_count": 3535,
      "created_at": "2025-10-16T17:42:21.218271",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Installation](https://qdrant.tech/documentation/guides/installation/)\n- [Administration](https://qdrant.tech/documentation/guides/administration/)\n- [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/)\n- [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/)\n- [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/)\n- [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)\n- [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)\n- [Quantization](https://qdrant.tech/documentation/guides/quantization/)\n- [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/)\n- [Configuration](https://qdrant.tech/documentation/guides/configuration/)\n- [Security](https://qdrant.tech/documentation/guides/security/)\n- [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/)\n- [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)\n\n### Ecosystem\n\n[FastEmbed](https://qdrant.tech/documentation/fastembed/)\n\n- [Quickstart](https://qdrant.tech/documentation/fastembed/fastembed-quickstart/)\n- [FastEmbed & Qdrant](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/)\n- [Working with miniCOIL](https://qdrant.tech/documentation/fastembed/fastembed-minicoil/)\n- [Working with SPLADE](https://qdrant.tech/documentation/fastembed/fastembed-splade/)\n- [Working with ColBERT](https://qdrant.tech/documentation/fastembed/fastembed-colbert/)\n- [Reranking with FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-rerankers/)\n\n[Qdrant MCP Server](https://github.com/qdrant/mcp-server-qdrant)\n\n### Tutorials\n\n[Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)\n\n- [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)\n- [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)\n- [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)\n- [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)\n\n[Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)\n\n- [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/)\n- [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/)\n- [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)\n- [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)\n- [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)\n\n[Using the Database](https://qdrant.tech/documentation/database-tutorials/)\n\n- [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)\n- [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)\n- [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)\n- [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)\n- [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/)\n- [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/)\n- [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)\n\n### Support\n\n[FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n\n- [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n- [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)\n\n[Release Notes](https://github.com/qdrant/qdrant/releases)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- [Advanced tutorials](https://qdrant.tech/documentation/advanced-tutorials/)\n-\n- Reranking in Hybrid Search\n\n# Reranking Hybrid Search Results with Qdrant Vector Database",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1021,
      "character_count": 4227,
      "created_at": "2025-10-16T17:42:21.222793",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "Hybrid search combines dense and sparse retrieval to deliver precise and comprehensive results. By adding reranking with ColBERT, you can further refine search outputs for maximum relevance.\n\nIn this guide, we’ll show you how to implement hybrid search with reranking in Qdrant, leveraging dense, sparse, and late interaction embeddings to create an efficient, high-accuracy search system. Let’s get started!\n\n## Overview\n\nLet’s start by breaking down the architecture:\n\nProcessing Dense, Sparse, and Late Interaction Embeddings in Vector Databases (VDB)\n\n### Ingestion Stage\n\nHere’s how we’re going to set up the advanced hybrid search. The process is similar to what we did earlier but with a few powerful additions:\n\n1. **Documents**: Just like before, we start with the raw input—our set of documents that need to be indexed for search.\n2. **Dense Embeddings**: We’ll generate dense embeddings for each document, just like in the basic search. These embeddings capture the deeper, semantic meanings behind the text.\n3. **Sparse Embeddings**: This is where it gets interesting. Alongside dense embeddings, we’ll create sparse embeddings using more traditional, keyword-based methods. Specifically, we’ll use BM25, a probabilistic retrieval model. BM25 ranks documents based on how relevant their terms are to a given query, taking into account how often terms appear, document length, and how common the term is across all documents. It’s perfect for keyword-heavy searches.\n4. **Late Interaction Embeddings**: Now, we add the magic of ColBERT. ColBERT uses a two-stage approach. First, it generates contextualized embeddings for both queries and documents using BERT, and then it performs late interaction—matching those embeddings efficiently using a dot product to fine-tune relevance. This step allows for deeper, contextual understanding, making sure you get the most precise results.\n5. **Vector Database**: All of these embeddings—dense, sparse, and late interaction—are stored in a vector database like Qdrant. This allows you to efficiently search, retrieve, and rerank your documents based on multiple layers of relevance.\n\nQuery Retrieval and Reranking Process in Search Systems\n\n### Retrieval Stage\n\nNow, let’s talk about how we’re going to pull the best results once the user submits a query:\n\n1. **User’s Query**: The user enters a query, and that query is transformed into multiple types of embeddings. We’re talking about representations that capture both the deeper meaning (dense) and specific keywords (sparse).\n2. **Embeddings**: The query gets converted into various embeddings—some for understanding the semantics (dense embeddings) and others for focusing on keyword matches (sparse embeddings).\n3. **Hybrid Search**: Our hybrid search uses both dense and sparse embeddings to find the most relevant documents. The dense embeddings ensure we capture the overall meaning of the query, while sparse embeddings make sure we don’t miss out on those key, important terms.\n4. **Rerank**: Once we’ve got a set of documents, the final step is reranking. This is where late interaction embeddings come into play, giving you results that are not only relevant but tuned to your query by prioritizing the documents that truly meet the user’s intent.\n\n## Implementation\n\nLet’s see it in action in this section.\n\n### Additional Setup\n\nThis time around, we’re using FastEmbed—a lightweight Python library designed for generating embeddings, and it supports popular text models right out of the box. First things first, you’ll need to install it:\n\n```python\npip install fastembed\n```\n\n---\n\nHere are the models we’ll be pulling from FastEmbed:\n\n```python\nfrom fastembed import TextEmbedding, LateInteractionTextEmbedding, SparseTextEmbedding \n```\n\n---\n\n### Ingestion\n\nAs before, we’ll convert our documents into embeddings, but thanks to FastEmbed, the process is even more straightforward because all the models you need are conveniently available in one location.\n\n### Embeddings\n\nFirst, let’s load the models we need:\n\n```python\ndense_embedding_model = TextEmbedding(\"sentence-transformers/all-MiniLM-L6-v2\")\nbm25_embedding_model = SparseTextEmbedding(\"Qdrant/bm25\")\nlate_interaction_embedding_model = LateInteractionTextEmbedding(\"colbert-ir/colbertv2.0\")\n```\n\n---\n\nNow, let’s convert our documents into embeddings:\n\n```python\ndense_embeddings = list(dense_embedding_model.embed(doc for doc in documents))\nbm25_embeddings = list(bm25_embedding_model.embed(doc for doc in documents))\nlate_interaction_embeddings = list(late_interaction_embedding_model.embed(doc for doc in documents))\n```\n\n---\n\nSince we’re dealing with multiple types of embeddings (dense, sparse, and late interaction), we’ll need to store them in a collection that supports a multi-vector setup. The previous collection we created won’t work here, so we’ll create a new one designed specifically for handling these different types of embeddings.\n\n### Create Collection",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1016,
      "character_count": 4950,
      "created_at": "2025-10-16T17:42:21.230880",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 3,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "Now, we’re setting up a new collection in Qdrant for our hybrid search with the right configurations to handle all the different vector types we’re working with.\n\nHere’s how you do it:\n\n```python\nfrom qdrant_client.models import Distance, VectorParams, models\n\nclient.create_collection(\n    \"hybrid-search\",\n    vectors_config={\n        \"all-MiniLM-L6-v2\": models.VectorParams(\n            size=len(dense_embeddings[0]),\n            distance=models.Distance.COSINE,\n        ),\n        \"colbertv2.0\": models.VectorParams(\n            size=len(late_interaction_embeddings[0][0]),\n            distance=models.Distance.COSINE,\n            multivector_config=models.MultiVectorConfig(\n                comparator=models.MultiVectorComparator.MAX_SIM,\n            ),\n            hnsw_config=models.HnswConfigDiff(m=0)  #  Disable HNSW for reranking\n        ),\n    },\n    sparse_vectors_config={\n        \"bm25\": models.SparseVectorParams(modifier=models.Modifier.IDF\n        )\n    }\n)\n```\n\n---\n\nWhat’s happening here? We’re creating a collection called “hybrid-search”, and we’re configuring it to handle:\n\n- **Dense embeddings** from the model all-MiniLM-L6-v2 using cosine distance for comparisons.\n- **Late interaction embeddings** from colbertv2.0, also using cosine distance, but with a multivector configuration to use the maximum similarity comparator. Note that we set `m=0` in the `colbertv2.0` vector to prevent indexing since it’s not needed for reranking.\n- **Sparse embeddings** from BM25 for keyword-based searches. They use `dot_product` for similarity calculation.\n\nThis setup ensures that all the different types of vectors are stored and compared correctly for your hybrid search.\n\n### Upsert Data\n\nNext, we need to insert the documents along with their multiple embeddings into the **hybrid-search** collection:\n\n```python\nfrom qdrant_client.models import PointStruct\npoints = []\nfor idx, (dense_embedding, bm25_embedding, late_interaction_embedding, doc) in enumerate(zip(dense_embeddings, bm25_embeddings, late_interaction_embeddings, documents)):\n  \n    point = PointStruct(\n        id=idx,\n        vector={\n            \"all-MiniLM-L6-v2\": dense_embedding,\n            \"bm25\": bm25_embedding.as_object(),\n            \"colbertv2.0\": late_interaction_embedding,\n        },\n        payload={\"document\": doc}\n    )\n    points.append(point)\n\noperation_info = client.upsert(\n    collection_name=\"hybrid-search\",\n    points=points\n)\n```\n\nCheck how points can be uploaded with builtin Fastembed integration.\n\nUpload with implicit embeddings computation\n\n```python\nfrom qdrant_client.models import PointStruct\npoints = []\n\nfor idx, doc in enumerate(documents):\n    point = PointStruct(\n        id=idx,\n        vector={\n            \"all-MiniLM-L6-v2\": models.Document(text=doc, model=\"sentence-transformers/all-MiniLM-L6-v2\"),\n            \"bm25\": models.Document(text=doc, model=\"Qdrant/bm25\"),\n            \"colbertv2.0\": models.Document(text=doc, model=\"colbert-ir/colbertv2.0\"),\n        },\n        payload={\"document\": doc}\n    )\n    points.append(point)\n\noperation_info = client.upsert(\n    collection_name=\"hybrid-search\",\n    points=points\n)\n```\n\n---\n\nThis code pulls everything together by creating a list of **PointStruct** objects, each containing the embeddings and corresponding documents.\n\nFor each document, it adds:\n\n- **Dense embeddings** for the deep, semantic meaning.\n- **BM25 embeddings** for powerful keyword-based search.\n- **ColBERT embeddings** for precise contextual interactions.\n\nOnce that’s done, the points are uploaded into our **“hybrid-search”** collection using the upsert method, ensuring everything’s in place.\n\n### Retrieval\n\nFor retrieval, it’s time to convert the user’s query into the required embeddings. Here’s how you can do it:\n\n```python\ndense_vectors = next(dense_embedding_model.query_embed(query))\nsparse_vectors = next(bm25_embedding_model.query_embed(query))\nlate_vectors = next(late_interaction_embedding_model.query_embed(query))\n```\n\n---\n\nThe real magic of hybrid search lies in the **prefetch** parameter. This lets you run multiple sub-queries in one go, combining the power of dense and sparse embeddings. Here’s how to set it up, after which we execute the hybrid search:\n\n```python\nprefetch = [\n        models.Prefetch(\n            query=dense_vectors,\n            using=\"all-MiniLM-L6-v2\",\n            limit=20,\n        ),\n        models.Prefetch(\n            query=models.SparseVector(**sparse_vectors.as_object()),\n            using=\"bm25\",\n            limit=20,\n        ),\n    ]\n```\n\n---",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1017,
      "character_count": 4550,
      "created_at": "2025-10-16T17:42:21.239873",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 4,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "This code kicks off a hybrid search by running two sub-queries:\n\n- One using dense embeddings from “all-MiniLM-L6-v2” to capture the semantic meaning of the query.\n- The other using sparse embeddings from BM25 for strong keyword matching.\n\nEach sub-query is limited to 20 results. These sub-queries are bundled together using the prefetch parameter, allowing them to run in parallel.\n\n### Rerank\n\nNow that we’ve got our initial hybrid search results, it’s time to rerank them using late interaction embeddings for maximum precision. Here’s how you can do it:\n\n```python\nresults = client.query_points(\n         \"hybrid-search\",\n        prefetch=prefetch,\n        query=late_vectors,\n        using=\"colbertv2.0\",\n        with_payload=True,\n        limit=10,\n)\n```\n\nCheck how queries can be made with builtin Fastembed integration.\n\nQuery points with implicit embeddings computation\n\n```python\nprefetch = [\n        models.Prefetch(\n            query=models.Document(text=query, model=\"sentence-transformers/all-MiniLM-L6-v2\"),\n            using=\"all-MiniLM-L6-v2\",\n            limit=20,\n        ),\n        models.Prefetch(\n            query=models.Document(text=query, model=\"Qdrant/bm25\"),\n            using=\"bm25\",\n            limit=20,\n        ),\n    ]\nresults = client.query_points(\n         \"hybrid-search\",\n        prefetch=prefetch,\n        query=models.Document(text=query, model=\"colbert-ir/colbertv2.0\"),\n        using=\"colbertv2.0\",\n        with_payload=True,\n        limit=10,\n)\n```\n\n---\n\nLet’s look at how the positions change after applying reranking. Notice how some documents shift in rank based on their relevance according to the late interaction embeddings.\n\n|   | **Document**                                                                                                                                                                                                                                                                             | **First Query Rank** | **Second Query Rank** | **Rank Change** |\n| - | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------- | --------------------- | --------------- |\n|   | In machine learning, feature scaling is the process of normalizing the range of independent variables or features. The goal is to ensure that all features contribute equally to the model, especially in algorithms like SVM or k-nearest neighbors where distance calculations matter. | 1                    | 1                     | No Change       |\n|   | Feature scaling is commonly used in data preprocessing to ensure that features are on the same scale. This is particularly important for gradient descent-based algorithms where features with larger scales could disproportionately impact the cost function.                          | 2                    | 6                     | Moved Down      |\n|   | Unsupervised learning algorithms, such as clustering methods, may benefit from feature scaling, which ensures that features with larger numerical ranges don’t dominate the learning process.                                                                                            | 3                    | 4                     | Moved Down      |\n|   | Data preprocessing steps, including feature scaling, can significantly impact the performance of machine learning models, making it a crucial part of the modeling pipeline.                                                                                                             | 5                    | 2                     | Moved Up        |\n\nGreat! We’ve now explored how reranking works and successfully implemented it.\n\n## Best Practices in Reranking\n\nReranking can dramatically improve the relevance of search results, especially when combined with hybrid search. Here are some best practices to keep in mind:\n\n- **Implement Hybrid Reranking**: Blend keyword-based (sparse) and vector-based (dense) search results for a more comprehensive ranking system.\n- **Continuous Testing and Monitoring**: Regularly evaluate your reranking models to avoid overfitting and make timely adjustments to maintain performance.\n- **Balance Relevance and Latency**: Reranking can be computationally expensive, so aim for a balance between relevance and speed. Therefore, the first step is to retrieve the relevant documents and then use reranking on it.\n\n## Conclusion\n\nReranking is a powerful tool that boosts the relevance of search results, especially when combined with hybrid search methods. While it can add some latency due to its complexity, applying it to a smaller, pre-filtered subset of results ensures both speed and relevance.\n\nQdrant offers an easy-to-use API to get started with your own search engine, so if you’re ready to dive in, sign up for free at [Qdrant Cloud](https://qdrant.tech/) and start building\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! 🙏\n\nWe are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/advanced-tutorials/reranking-hybrid-search.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Reranking Hybrid Search Results with Qdrant Vector Database](#reranking-hybrid-search-results-with-qdrant-vector-database.md)",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1020,
      "character_count": 5568,
      "created_at": "2025-10-16T17:42:21.249372",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 5,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Overview](#overview.md)\n\n- [Ingestion Stage](#ingestion-stage.md)\n    - [Retrieval Stage](#retrieval-stage.md)\n\n- [Implementation](#implementation.md)\n\n- [Additional Setup](#additional-setup.md)\n    - [Ingestion](#ingestion.md)\n    - [Embeddings](#embeddings.md)\n    - [Create Collection](#create-collection.md)\n    - [Upsert Data](#upsert-data.md)\n    - [Retrieval](#retrieval.md)\n    - [Rerank](#rerank.md)\n\n- [Best Practices in Reranking](#best-practices-in-reranking.md)\n\n- [Conclusion](#conclusion.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/advanced-tutorials/reranking-hybrid-search.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 289,
      "character_count": 1006,
      "created_at": "2025-10-16T17:42:21.250286",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 6,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  }
]
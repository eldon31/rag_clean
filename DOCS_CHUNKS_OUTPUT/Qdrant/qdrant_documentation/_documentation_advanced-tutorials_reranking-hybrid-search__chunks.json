[
  {
    "text": "Reranking in Hybrid Search - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Getting Started\n\n[What is Qdrant?](https://qdrant.tech/documentation/overview/)\n\n- [Understanding Vector Search in Qdrant](https://qdrant.tech/documentation/overview/vector-search/)\n\n[Local Quickstart](https://qdrant.tech/documentation/quickstart/)\n\n[API & SDKs](https://qdrant.tech/documentation/interfaces/)\n\n[Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)\n\n### User Manual\n\n[Concepts](https://qdrant.tech/documentation/concepts/)\n\n- [Collections](https://qdrant.tech/documentation/concepts/collections/)\n- [Points](https://qdrant.tech/documentation/concepts/points/)\n- [Vectors](https://qdrant.tech/documentation/concepts/vectors/)\n- [Payload](https://qdrant.tech/documentation/concepts/payload/)\n- [Search](https://qdrant.tech/documentation/concepts/search/)\n- [Explore](https://qdrant.tech/documentation/concepts/explore/)\n- [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/)\n- [Filtering](https://qdrant.tech/documentation/concepts/filtering/)\n- [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/)\n- [Storage](https://qdrant.tech/documentation/concepts/storage/)\n- [Indexing](https://qdrant.tech/documentation/concepts/indexing/)\n- [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)\n\n[Guides](https://qdrant.tech/documentation/guides/installation/)\n\n- [Installation](https://qdrant.tech/documentation/guides/installation/)\n- [Administration](https://qdrant.tech/documentation/guides/administration/)\n- [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/)\n- [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/)\n- [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/)\n- [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)\n- [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)\n- [Quantization](https://qdrant.tech/documentation/guides/quantization/)\n- [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/)\n- [Configuration](https://qdrant.tech/documentation/guides/configuration/)\n- [Security](https://qdrant.tech/documentation/guides/security/)\n- [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/)\n- [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)\n\n### Ecosystem\n\n[FastEmbed](https://qdrant.tech/documentation/fastembed/)\n\n- [Quickstart](https://qdrant.tech/documentation/fastembed/fastembed-quickstart/)\n- [FastEmbed & Qdrant](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/)\n- [Working with miniCOIL](https://qdrant.tech/documentation/fastembed/fastembed-minicoil/)\n- [Working with SPLADE](https://qdrant.tech/documentation/fastembed/fastembed-splade/)\n- [Working with ColBERT](https://qdrant.tech/documentation/fastembed/fastembed-colbert/)\n- [Reranking with FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-rerankers/)\n\n[Qdrant MCP Server](https://github.com/qdrant/mcp-server-qdrant)\n\n### Tutorials\n\n[Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 969,
      "character_count": 3794,
      "created_at": "2025-10-16T17:42:21.214031",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)\n- [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)\n- [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)\n- [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)\n\n[Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)\n\n- [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/)\n- [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/)\n- [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)\n- [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)\n- [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)\n\n[Using the Database](https://qdrant.tech/documentation/database-tutorials/)\n\n- [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)\n- [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)\n- [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)\n- [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)\n- [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/)\n- [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/)\n- [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)\n\n### Support\n\n[FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n\n- [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n- [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)\n\n[Release Notes](https://github.com/qdrant/qdrant/releases)\n\n### Getting Started\n\n[What is Qdrant?](https://qdrant.tech/documentation/overview/)\n\n- [Understanding Vector Search in Qdrant](https://qdrant.tech/documentation/overview/vector-search/)\n\n[Local Quickstart](https://qdrant.tech/documentation/quickstart/)\n\n[API & SDKs](https://qdrant.tech/documentation/interfaces/)\n\n[Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)\n\n### User Manual\n\n[Concepts](https://qdrant.tech/documentation/concepts/)\n\n- [Collections](https://qdrant.tech/documentation/concepts/collections/)\n- [Points](https://qdrant.tech/documentation/concepts/points/)\n- [Vectors](https://qdrant.tech/documentation/concepts/vectors/)\n- [Payload](https://qdrant.tech/documentation/concepts/payload/)\n- [Search](https://qdrant.tech/documentation/concepts/search/)\n- [Explore](https://qdrant.tech/documentation/concepts/explore/)\n- [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/)\n- [Filtering](https://qdrant.tech/documentation/concepts/filtering/)\n- [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/)\n- [Storage](https://qdrant.tech/documentation/concepts/storage/)\n- [Indexing](https://qdrant.tech/documentation/concepts/indexing/)\n- [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)\n\n[Guides](https://qdrant.tech/documentation/guides/installation/)",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 852,
      "character_count": 3535,
      "created_at": "2025-10-16T17:42:21.218271",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Installation](https://qdrant.tech/documentation/guides/installation/)\n- [Administration](https://qdrant.tech/documentation/guides/administration/)\n- [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/)\n- [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/)\n- [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/)\n- [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)\n- [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)\n- [Quantization](https://qdrant.tech/documentation/guides/quantization/)\n- [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/)\n- [Configuration](https://qdrant.tech/documentation/guides/configuration/)\n- [Security](https://qdrant.tech/documentation/guides/security/)\n- [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/)\n- [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)\n\n### Ecosystem\n\n[FastEmbed](https://qdrant.tech/documentation/fastembed/)\n\n- [Quickstart](https://qdrant.tech/documentation/fastembed/fastembed-quickstart/)\n- [FastEmbed & Qdrant](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/)\n- [Working with miniCOIL](https://qdrant.tech/documentation/fastembed/fastembed-minicoil/)\n- [Working with SPLADE](https://qdrant.tech/documentation/fastembed/fastembed-splade/)\n- [Working with ColBERT](https://qdrant.tech/documentation/fastembed/fastembed-colbert/)\n- [Reranking with FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-rerankers/)\n\n[Qdrant MCP Server](https://github.com/qdrant/mcp-server-qdrant)\n\n### Tutorials\n\n[Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)\n\n- [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)\n- [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)\n- [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)\n- [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)\n\n[Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)\n\n- [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/)\n- [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/)\n- [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)\n- [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)\n- [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)\n\n[Using the Database](https://qdrant.tech/documentation/database-tutorials/)\n\n- [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)\n- [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)\n- [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)\n- [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)\n- [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/)\n- [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/)\n- [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)\n\n### Support\n\n[FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n\n- [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n- [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)\n\n[Release Notes](https://github.com/qdrant/qdrant/releases)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- [Advanced tutorials](https://qdrant.tech/documentation/advanced-tutorials/)\n-\n- Reranking in Hybrid Search\n\n# Reranking Hybrid Search Results with Qdrant Vector Database",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1021,
      "character_count": 4227,
      "created_at": "2025-10-16T17:42:21.222793",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "Hybrid search combines dense and sparse retrieval to deliver precise and comprehensive results. By adding reranking with ColBERT, you can further refine search outputs for maximum relevance.\n\nIn this guide, we‚Äôll show you how to implement hybrid search with reranking in Qdrant, leveraging dense, sparse, and late interaction embeddings to create an efficient, high-accuracy search system. Let‚Äôs get started!\n\n## Overview\n\nLet‚Äôs start by breaking down the architecture:\n\nProcessing Dense, Sparse, and Late Interaction Embeddings in Vector Databases (VDB)\n\n### Ingestion Stage\n\nHere‚Äôs how we‚Äôre going to set up the advanced hybrid search. The process is similar to what we did earlier but with a few powerful additions:\n\n1. **Documents**: Just like before, we start with the raw input‚Äîour set of documents that need to be indexed for search.\n2. **Dense Embeddings**: We‚Äôll generate dense embeddings for each document, just like in the basic search. These embeddings capture the deeper, semantic meanings behind the text.\n3. **Sparse Embeddings**: This is where it gets interesting. Alongside dense embeddings, we‚Äôll create sparse embeddings using more traditional, keyword-based methods. Specifically, we‚Äôll use BM25, a probabilistic retrieval model. BM25 ranks documents based on how relevant their terms are to a given query, taking into account how often terms appear, document length, and how common the term is across all documents. It‚Äôs perfect for keyword-heavy searches.\n4. **Late Interaction Embeddings**: Now, we add the magic of ColBERT. ColBERT uses a two-stage approach. First, it generates contextualized embeddings for both queries and documents using BERT, and then it performs late interaction‚Äîmatching those embeddings efficiently using a dot product to fine-tune relevance. This step allows for deeper, contextual understanding, making sure you get the most precise results.\n5. **Vector Database**: All of these embeddings‚Äîdense, sparse, and late interaction‚Äîare stored in a vector database like Qdrant. This allows you to efficiently search, retrieve, and rerank your documents based on multiple layers of relevance.\n\nQuery Retrieval and Reranking Process in Search Systems\n\n### Retrieval Stage\n\nNow, let‚Äôs talk about how we‚Äôre going to pull the best results once the user submits a query:\n\n1. **User‚Äôs Query**: The user enters a query, and that query is transformed into multiple types of embeddings. We‚Äôre talking about representations that capture both the deeper meaning (dense) and specific keywords (sparse).\n2. **Embeddings**: The query gets converted into various embeddings‚Äîsome for understanding the semantics (dense embeddings) and others for focusing on keyword matches (sparse embeddings).\n3. **Hybrid Search**: Our hybrid search uses both dense and sparse embeddings to find the most relevant documents. The dense embeddings ensure we capture the overall meaning of the query, while sparse embeddings make sure we don‚Äôt miss out on those key, important terms.\n4. **Rerank**: Once we‚Äôve got a set of documents, the final step is reranking. This is where late interaction embeddings come into play, giving you results that are not only relevant but tuned to your query by prioritizing the documents that truly meet the user‚Äôs intent.\n\n## Implementation\n\nLet‚Äôs see it in action in this section.\n\n### Additional Setup\n\nThis time around, we‚Äôre using FastEmbed‚Äîa lightweight Python library designed for generating embeddings, and it supports popular text models right out of the box. First things first, you‚Äôll need to install it:\n\n```python\npip install fastembed\n```\n\n---\n\nHere are the models we‚Äôll be pulling from FastEmbed:\n\n```python\nfrom fastembed import TextEmbedding, LateInteractionTextEmbedding, SparseTextEmbedding \n```\n\n---\n\n### Ingestion\n\nAs before, we‚Äôll convert our documents into embeddings, but thanks to FastEmbed, the process is even more straightforward because all the models you need are conveniently available in one location.\n\n### Embeddings\n\nFirst, let‚Äôs load the models we need:\n\n```python\ndense_embedding_model = TextEmbedding(\"sentence-transformers/all-MiniLM-L6-v2\")\nbm25_embedding_model = SparseTextEmbedding(\"Qdrant/bm25\")\nlate_interaction_embedding_model = LateInteractionTextEmbedding(\"colbert-ir/colbertv2.0\")\n```\n\n---\n\nNow, let‚Äôs convert our documents into embeddings:\n\n```python\ndense_embeddings = list(dense_embedding_model.embed(doc for doc in documents))\nbm25_embeddings = list(bm25_embedding_model.embed(doc for doc in documents))\nlate_interaction_embeddings = list(late_interaction_embedding_model.embed(doc for doc in documents))\n```\n\n---\n\nSince we‚Äôre dealing with multiple types of embeddings (dense, sparse, and late interaction), we‚Äôll need to store them in a collection that supports a multi-vector setup. The previous collection we created won‚Äôt work here, so we‚Äôll create a new one designed specifically for handling these different types of embeddings.\n\n### Create Collection",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1016,
      "character_count": 4950,
      "created_at": "2025-10-16T17:42:21.230880",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 3,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "Now, we‚Äôre setting up a new collection in Qdrant for our hybrid search with the right configurations to handle all the different vector types we‚Äôre working with.\n\nHere‚Äôs how you do it:\n\n```python\nfrom qdrant_client.models import Distance, VectorParams, models\n\nclient.create_collection(\n    \"hybrid-search\",\n    vectors_config={\n        \"all-MiniLM-L6-v2\": models.VectorParams(\n            size=len(dense_embeddings[0]),\n            distance=models.Distance.COSINE,\n        ),\n        \"colbertv2.0\": models.VectorParams(\n            size=len(late_interaction_embeddings[0][0]),\n            distance=models.Distance.COSINE,\n            multivector_config=models.MultiVectorConfig(\n                comparator=models.MultiVectorComparator.MAX_SIM,\n            ),\n            hnsw_config=models.HnswConfigDiff(m=0)  #  Disable HNSW for reranking\n        ),\n    },\n    sparse_vectors_config={\n        \"bm25\": models.SparseVectorParams(modifier=models.Modifier.IDF\n        )\n    }\n)\n```\n\n---\n\nWhat‚Äôs happening here? We‚Äôre creating a collection called ‚Äúhybrid-search‚Äù, and we‚Äôre configuring it to handle:\n\n- **Dense embeddings** from the model all-MiniLM-L6-v2 using cosine distance for comparisons.\n- **Late interaction embeddings** from colbertv2.0, also using cosine distance, but with a multivector configuration to use the maximum similarity comparator. Note that we set `m=0` in the `colbertv2.0` vector to prevent indexing since it‚Äôs not needed for reranking.\n- **Sparse embeddings** from BM25 for keyword-based searches. They use `dot_product` for similarity calculation.\n\nThis setup ensures that all the different types of vectors are stored and compared correctly for your hybrid search.\n\n### Upsert Data\n\nNext, we need to insert the documents along with their multiple embeddings into the **hybrid-search** collection:\n\n```python\nfrom qdrant_client.models import PointStruct\npoints = []\nfor idx, (dense_embedding, bm25_embedding, late_interaction_embedding, doc) in enumerate(zip(dense_embeddings, bm25_embeddings, late_interaction_embeddings, documents)):\n  \n    point = PointStruct(\n        id=idx,\n        vector={\n            \"all-MiniLM-L6-v2\": dense_embedding,\n            \"bm25\": bm25_embedding.as_object(),\n            \"colbertv2.0\": late_interaction_embedding,\n        },\n        payload={\"document\": doc}\n    )\n    points.append(point)\n\noperation_info = client.upsert(\n    collection_name=\"hybrid-search\",\n    points=points\n)\n```\n\nCheck how points can be uploaded with builtin Fastembed integration.\n\nUpload with implicit embeddings computation\n\n```python\nfrom qdrant_client.models import PointStruct\npoints = []\n\nfor idx, doc in enumerate(documents):\n    point = PointStruct(\n        id=idx,\n        vector={\n            \"all-MiniLM-L6-v2\": models.Document(text=doc, model=\"sentence-transformers/all-MiniLM-L6-v2\"),\n            \"bm25\": models.Document(text=doc, model=\"Qdrant/bm25\"),\n            \"colbertv2.0\": models.Document(text=doc, model=\"colbert-ir/colbertv2.0\"),\n        },\n        payload={\"document\": doc}\n    )\n    points.append(point)\n\noperation_info = client.upsert(\n    collection_name=\"hybrid-search\",\n    points=points\n)\n```\n\n---\n\nThis code pulls everything together by creating a list of **PointStruct** objects, each containing the embeddings and corresponding documents.\n\nFor each document, it adds:\n\n- **Dense embeddings** for the deep, semantic meaning.\n- **BM25 embeddings** for powerful keyword-based search.\n- **ColBERT embeddings** for precise contextual interactions.\n\nOnce that‚Äôs done, the points are uploaded into our **‚Äúhybrid-search‚Äù** collection using the upsert method, ensuring everything‚Äôs in place.\n\n### Retrieval\n\nFor retrieval, it‚Äôs time to convert the user‚Äôs query into the required embeddings. Here‚Äôs how you can do it:\n\n```python\ndense_vectors = next(dense_embedding_model.query_embed(query))\nsparse_vectors = next(bm25_embedding_model.query_embed(query))\nlate_vectors = next(late_interaction_embedding_model.query_embed(query))\n```\n\n---\n\nThe real magic of hybrid search lies in the **prefetch** parameter. This lets you run multiple sub-queries in one go, combining the power of dense and sparse embeddings. Here‚Äôs how to set it up, after which we execute the hybrid search:\n\n```python\nprefetch = [\n        models.Prefetch(\n            query=dense_vectors,\n            using=\"all-MiniLM-L6-v2\",\n            limit=20,\n        ),\n        models.Prefetch(\n            query=models.SparseVector(**sparse_vectors.as_object()),\n            using=\"bm25\",\n            limit=20,\n        ),\n    ]\n```\n\n---",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1017,
      "character_count": 4550,
      "created_at": "2025-10-16T17:42:21.239873",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 4,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "This code kicks off a hybrid search by running two sub-queries:\n\n- One using dense embeddings from ‚Äúall-MiniLM-L6-v2‚Äù to capture the semantic meaning of the query.\n- The other using sparse embeddings from BM25 for strong keyword matching.\n\nEach sub-query is limited to 20 results. These sub-queries are bundled together using the prefetch parameter, allowing them to run in parallel.\n\n### Rerank\n\nNow that we‚Äôve got our initial hybrid search results, it‚Äôs time to rerank them using late interaction embeddings for maximum precision. Here‚Äôs how you can do it:\n\n```python\nresults = client.query_points(\n         \"hybrid-search\",\n        prefetch=prefetch,\n        query=late_vectors,\n        using=\"colbertv2.0\",\n        with_payload=True,\n        limit=10,\n)\n```\n\nCheck how queries can be made with builtin Fastembed integration.\n\nQuery points with implicit embeddings computation\n\n```python\nprefetch = [\n        models.Prefetch(\n            query=models.Document(text=query, model=\"sentence-transformers/all-MiniLM-L6-v2\"),\n            using=\"all-MiniLM-L6-v2\",\n            limit=20,\n        ),\n        models.Prefetch(\n            query=models.Document(text=query, model=\"Qdrant/bm25\"),\n            using=\"bm25\",\n            limit=20,\n        ),\n    ]\nresults = client.query_points(\n         \"hybrid-search\",\n        prefetch=prefetch,\n        query=models.Document(text=query, model=\"colbert-ir/colbertv2.0\"),\n        using=\"colbertv2.0\",\n        with_payload=True,\n        limit=10,\n)\n```\n\n---\n\nLet‚Äôs look at how the positions change after applying reranking. Notice how some documents shift in rank based on their relevance according to the late interaction embeddings.\n\n|   | **Document**                                                                                                                                                                                                                                                                             | **First Query Rank** | **Second Query Rank** | **Rank Change** |\n| - | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------- | --------------------- | --------------- |\n|   | In machine learning, feature scaling is the process of normalizing the range of independent variables or features. The goal is to ensure that all features contribute equally to the model, especially in algorithms like SVM or k-nearest neighbors where distance calculations matter. | 1                    | 1                     | No Change       |\n|   | Feature scaling is commonly used in data preprocessing to ensure that features are on the same scale. This is particularly important for gradient descent-based algorithms where features with larger scales could disproportionately impact the cost function.                          | 2                    | 6                     | Moved Down      |\n|   | Unsupervised learning algorithms, such as clustering methods, may benefit from feature scaling, which ensures that features with larger numerical ranges don‚Äôt dominate the learning process.                                                                                            | 3                    | 4                     | Moved Down      |\n|   | Data preprocessing steps, including feature scaling, can significantly impact the performance of machine learning models, making it a crucial part of the modeling pipeline.                                                                                                             | 5                    | 2                     | Moved Up        |\n\nGreat! We‚Äôve now explored how reranking works and successfully implemented it.\n\n## Best Practices in Reranking\n\nReranking can dramatically improve the relevance of search results, especially when combined with hybrid search. Here are some best practices to keep in mind:\n\n- **Implement Hybrid Reranking**: Blend keyword-based (sparse) and vector-based (dense) search results for a more comprehensive ranking system.\n- **Continuous Testing and Monitoring**: Regularly evaluate your reranking models to avoid overfitting and make timely adjustments to maintain performance.\n- **Balance Relevance and Latency**: Reranking can be computationally expensive, so aim for a balance between relevance and speed. Therefore, the first step is to retrieve the relevant documents and then use reranking on it.\n\n## Conclusion\n\nReranking is a powerful tool that boosts the relevance of search results, especially when combined with hybrid search methods. While it can add some latency due to its complexity, applying it to a smaller, pre-filtered subset of results ensures both speed and relevance.\n\nQdrant offers an easy-to-use API to get started with your own search engine, so if you‚Äôre ready to dive in, sign up for free at [Qdrant Cloud](https://qdrant.tech/) and start building\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! üôè\n\nWe are sorry to hear that. üòî You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/advanced-tutorials/reranking-hybrid-search.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Reranking Hybrid Search Results with Qdrant Vector Database](#reranking-hybrid-search-results-with-qdrant-vector-database.md)",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1020,
      "character_count": 5568,
      "created_at": "2025-10-16T17:42:21.249372",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 5,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Overview](#overview.md)\n\n- [Ingestion Stage](#ingestion-stage.md)\n    - [Retrieval Stage](#retrieval-stage.md)\n\n- [Implementation](#implementation.md)\n\n- [Additional Setup](#additional-setup.md)\n    - [Ingestion](#ingestion.md)\n    - [Embeddings](#embeddings.md)\n    - [Create Collection](#create-collection.md)\n    - [Upsert Data](#upsert-data.md)\n    - [Retrieval](#retrieval.md)\n    - [Rerank](#rerank.md)\n\n- [Best Practices in Reranking](#best-practices-in-reranking.md)\n\n- [Conclusion](#conclusion.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/advanced-tutorials/reranking-hybrid-search.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n¬© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 289,
      "character_count": 1006,
      "created_at": "2025-10-16T17:42:21.250286",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 6,
      "file_relative_path": "qdrant_documentation\\documentation_advanced-tutorials_reranking-hybrid-search\\_documentation_advanced-tutorials_reranking-hybrid-search_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  }
]
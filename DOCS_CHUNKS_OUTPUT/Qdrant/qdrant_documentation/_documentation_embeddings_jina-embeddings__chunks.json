[
  {
    "text": "Jina Embeddings - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 930,
      "character_count": 3490,
      "created_at": "2025-10-16T17:42:24.617891",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 968,
      "character_count": 3625,
      "created_at": "2025-10-16T17:42:24.620901",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 965,
      "character_count": 3819,
      "created_at": "2025-10-16T17:42:24.626315",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 978,
      "character_count": 3651,
      "created_at": "2025-10-16T17:42:24.628222",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 3,
      "file_relative_path": "qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- [Embeddings](https://qdrant.tech/documentation/embeddings/)\n-\n- Jina Embeddings\n\n# Jina Embeddings\n\nQdrant is compatible with [Jina AI](https://jina.ai/) embeddings. You can get a free trial key from [Jina Embeddings](https://jina.ai/embeddings/) to get embeddings.\n\nQdrant users can receive a 10% discount on Jina AI APIs by using the code **QDRANT**.\n\n## Technical Summary",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 988,
      "character_count": 3879,
      "created_at": "2025-10-16T17:42:24.633307",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 4,
      "file_relative_path": "qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "| Model                      | Dimension                                    | Language                         | MRL (matryoshka) | Context                |\n| -------------------------- | -------------------------------------------- | -------------------------------- | ---------------- | ---------------------- |\n| **jina-embeddings-v4**     | **2048 (single-vector), 128 (multi-vector)** | **Multilingual (30+)**           | **Yes**          | **32768 + Text/Image** |\n| jina-clip-v2               | 1024                                         | Multilingual (100+, focus on 30) | Yes              | Text/Image             |\n| jina-embeddings-v3         | 1024                                         | Multilingual (89 languages)      | Yes              | 8192                   |\n| jina-embeddings-v2-base-en | 768                                          | English                          | No               | 8192                   |\n| jina-embeddings-v2-base-de | 768                                          | German & English                 | No               | 8192                   |\n| jina-embeddings-v2-base-es | 768                                          | Spanish & English                | No               | 8192                   |\n| jina-embeddings-v2-base-zh | 768                                          | Chinese & English                | No               | 8192                   |\n\n> Jina recommends using `jina-embeddings-v4` for all tasks.\n\nOn top of the backbone, `jina-embeddings-v4` has been trained with 5 task-specific adapters for different embedding uses. Include `task` in your request to optimize your downstream application:\n\n- **retrieval.query**: Used to encode user queries or questions in retrieval tasks.\n- **retrieval.passage**: Used to encode large documents in retrieval tasks at indexing time.\n- **code.query**: Used to encode user queries or questions in code related retrieval tasks.\n- **code.passage**: Used to encode large documents in code related retrieval tasks at indexing time.\n- **text-matching**: Used to encode text for similarity matching, such as measuring similarity between two sentences.\n\nSimilarly, `jina-embeddings-v3` has been trained with 5 task-specific adapters for different embedding uses. Include `task` in your request to optimize your downstream application:\n\n- **retrieval.query**: Used to encode user queries or questions in retrieval tasks.\n- **retrieval.passage**: Used to encode large documents in retrieval tasks at indexing time.\n- **classification**: Used to encode text for text classification tasks.\n- **text-matching**: Used to encode text for similarity matching, such as measuring similarity between two sentences.\n- **separation**: Used for clustering or reranking tasks.\n\n`jina-embeddings-v4`, `jina-embeddings-v3` and `jina-clip-v2` support **Matryoshka Representation Learning**, allowing users to control the embedding dimension with minimal performance loss. Include `dimensions` in your request to select the desired dimension. By default, **dimensions** is set to 2048 (`jina-embeddings-v4`) or 1024 (`jina-embeddings-v3` and `jina-clip-v2`), and a number between 256 and 2048 is recommended. You can reference the table below for hints on dimension vs. performance for the `jina-embeddings-v3` model. Similar results hold for the others.\n\n| Dimension                                | 32    | 64    | 128   | 256   | 512   | 768  | 1024  |\n| ---------------------------------------- | ----- | ----- | ----- | ----- | ----- | ---- | ----- |\n| Average Retrieval Performance (nDCG\\@10) | 52.54 | 58.54 | 61.64 | 62.72 | 63.16 | 63.3 | 63.35 |\n\n`jina-embeddings-v4` and `jina-embeddings-v3` supports [Late Chunking](https://jina.ai/news/late-chunking-in-long-context-embedding-models/), the technique to leverage the model’s long-context capabilities for generating contextual chunk embeddings. Include `late_chunking=True` in your request to enable contextual chunked representation. When set to true, Jina AI API will concatenate all sentences in the input field and feed them as a single string to the model. Internally, the model embeds this long concatenated string and then performs late chunking, returning a list of embeddings that matches the size of the input list.\n\n## Example\n\n### Text-to-Text Retrieval\n\nThe code below demonstrates how to use `jina-embeddings-v4` with Qdrant:\n\n```python\nimport requests\n\nimport qdrant_client\nfrom qdrant_client.models import Distance, VectorParams, Batch",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 986,
      "character_count": 4499,
      "created_at": "2025-10-16T17:42:24.640167",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 5,
      "file_relative_path": "qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "# Provide Jina API key and choose one of the available models.\nJINA_API_KEY = \"jina_xxxxxxxxxxx\"\nMODEL = \"jina-embeddings-v4\"\nDIMENSIONS = 2048 # Or choose your desired output vector dimensionality.\nTASK = 'retrieval.passage' # For indexing, or set to retrieval.query for querying\n\n# Get embeddings from the API\nurl = \"https://api.jina.ai/v1/embeddings\"\n\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {JINA_API_KEY}\",\n}\n\ndata = {\n    \"input\": [\"Your text string goes here\", \"You can send multiple texts\"],\n    \"model\": MODEL,\n    \"dimensions\": DIMENSIONS,\n    \"task\": TASK,\n    \"late_chunking\": True,\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nembeddings = [d[\"embedding\"] for d in response.json()[\"data\"]]\n\n# Index the embeddings into Qdrant\nclient = qdrant_client.QdrantClient(\":memory:\")\nclient.create_collection(\n    collection_name=\"MyCollection\",\n    vectors_config=VectorParams(size= DIMENSIONS, distance=Distance.DOT),\n)\n\nqdrant_client.upsert(\n    collection_name=\"MyCollection\",\n    points=Batch(\n        ids=list(range(len(embeddings))),\n        vectors=embeddings,\n    ),\n)\n```\n\n### Text-to-Image Retrieval\n\nThe code below demonstrates how to use `jina-embeddings-v4` with Qdrant:\n\n```python\nimport requests\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.models import Distance, VectorParams, PointStruct\n\n# Provide your Jina API key and choose the model.\nJINA_API_KEY = \"jina_xxxxxxxxxxx\"\nMODEL = \"jina-embeddings-v4\"\nDIMENSIONS = 2048  # Set the desired output vector dimensionality.\n\n# Define the inputs\ntext_input = \"A blue cat\"\nimage_url = \"https://i.pinimg.com/600x315/21/48/7e/21487e8e0970dd366dafaed6ab25d8d8.jpg\"\n\n# Get embeddings from the Jina API\nurl = \"https://api.jina.ai/v1/embeddings\"\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {JINA_API_KEY}\",\n}\ndata = {\n    \"input\": [\n        {\"text\": text_input},\n        {\"image\": image_url},\n    ],\n    \"model\": MODEL,\n    \"dimensions\": DIMENSIONS,\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nresponse_data = response.json()[\"data\"]\n\n# The model doesn't differentiate between images and text, so we extract output based on the input order.\ntext_embedding = response_data[0][\"embedding\"]\nimage_embedding = response_data[1][\"embedding\"]\n\n# Initialize Qdrant client\nclient = QdrantClient(url=\"http://localhost:6333/\")\n\n# Create a collection with named vectors\ncollection_name = \"MyCollection\"\nclient.recreate_collection(\n    collection_name=collection_name,\n    vectors_config={\n        \"text_vector\": VectorParams(size=DIMENSIONS, distance=Distance.DOT),\n        \"image_vector\": VectorParams(size=DIMENSIONS, distance=Distance.DOT),\n    },\n)\n\nclient.upsert(\n    collection_name=collection_name,\n    points=[\n        PointStruct(\n            id=0,\n            vector={\n                \"text_vector\": text_embedding,\n                \"image_vector\": image_embedding,\n            }\n        )\n    ],\n)\n\n# Now let's query the collection\nsearch_query = \"A purple cat\"\n\n# Get the embedding for the search query from the Jina API\nurl = \"https://api.jina.ai/v1/embeddings\"\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {JINA_API_KEY}\",\n}\ndata = {\n    \"input\": [{\"text\": search_query}],\n    \"model\": MODEL,\n    \"dimensions\": DIMENSIONS,\n    # \"task\": \"retrieval.query\" # Uncomment this line for text-to-text retrieval tasks\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nquery_embedding = response.json()[\"data\"][0][\"embedding\"]\n\nsearch_results = client.query_points(\n    collection_name=collection_name,\n    query=query_embedding,\n    using=\"image_vector\",\n    limit=5\n).points\n\nfor result in search_results:\n    print(f\"ID: {result.id}, Score: {result.score}\")\n```\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! 🙏",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 964,
      "character_count": 3858,
      "created_at": "2025-10-16T17:42:24.648942",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 6,
      "file_relative_path": "qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "We are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/embeddings/jina-embeddings.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Jina Embeddings](#jina-embeddings.md)\n\n- [Technical Summary](#technical-summary.md)\n\n- [Example](#example.md)\n\n- [Text-to-Text Retrieval](#text-to-text-retrieval.md)\n    - [Text-to-Image Retrieval](#text-to-image-retrieval.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/embeddings/jina-embeddings.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
    "metadata": {
      "chunk_id": 7,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 276,
      "character_count": 995,
      "created_at": "2025-10-16T17:42:24.649925",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 7,
      "file_relative_path": "qdrant_documentation\\documentation_embeddings_jina-embeddings\\_documentation_embeddings_jina-embeddings_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  }
]
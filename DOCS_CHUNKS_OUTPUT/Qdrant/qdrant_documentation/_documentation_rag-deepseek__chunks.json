[
  {
    "text": "5 Minute RAG with Qdrant and DeepSeek - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 937,
      "character_count": 3512,
      "created_at": "2025-10-16T17:42:28.831955",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 968,
      "character_count": 3625,
      "created_at": "2025-10-16T17:42:28.834753",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 965,
      "character_count": 3819,
      "created_at": "2025-10-16T17:42:28.838774",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 978,
      "character_count": 3651,
      "created_at": "2025-10-16T17:42:28.840206",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 3,
      "file_relative_path": "qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- 5 Minute RAG with Qdrant and DeepSeek\n\n# 5 Minute RAG with Qdrant and DeepSeek\n\n| Time: 5 min | Level: Beginner | Output: [GitHub](https://github.com/qdrant/examples/blob/master/rag-with-qdrant-deepseek/deepseek-qdrant.ipynb) |   |\n| ----------- | --------------- | --------------------------------------------------------------------------------------------------------------- | - |",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 973,
      "character_count": 3888,
      "created_at": "2025-10-16T17:42:28.843366",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 4,
      "file_relative_path": "qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "This tutorial demonstrates how to build a **Retrieval-Augmented Generation (RAG)** pipeline using Qdrant as a vector storage solution and DeepSeek for semantic query enrichment. RAG pipelines enhance Large Language Model (LLM) responses by providing contextually relevant data.\n\n## Overview\n\nIn this tutorial, we will:\n\n1. Take sample text and turn it into vectors with FastEmbed.\n2. Send the vectors to a Qdrant collection.\n3. Connect Qdrant and DeepSeek into a minimal RAG pipeline.\n4. Ask DeepSeek different questions and test answer accuracy.\n5. Enrich DeepSeek prompts with content retrieved from Qdrant.\n6. Evaluate answer accuracy before and after.\n\n#### Architecture:\n\n---\n\n## Prerequisites\n\nEnsure you have the following:\n\n- Python environment (3.9+)\n- Access to [Qdrant Cloud](https://qdrant.tech)\n- A DeepSeek API key from [DeepSeek Platform](https://platform.deepseek.com/api_keys)\n\n## Setup Qdrant\n\n```python\npip install \"qdrant-client[fastembed]>=1.14.1\"\n```\n\n[Qdrant](https://qdrant.tech) will act as a knowledge base providing the context information for the prompts we‚Äôll be sending to the LLM.\n\nYou can get a free-forever Qdrant cloud instance at <http://cloud.qdrant.io>. Learn about setting up your instance from the [Quickstart](https://qdrant.tech/documentation/quickstart-cloud/).\n\n```python\nQDRANT_URL = \"https://xyz-example.eu-central.aws.cloud.qdrant.io:6333\"\nQDRANT_API_KEY = \"<your-api-key>\"\n```\n\n### Instantiating Qdrant Client\n\n```python\nfrom qdrant_client import QdrantClient, models\n\nclient = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n```\n\n### Building the knowledge base\n\nQdrant will use vector embeddings of our facts to enrich the original prompt with some context. Thus, we need to store the vector embeddings and the facts used to generate them.\n\nWe‚Äôll be using the [bge-base-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5) model via [FastEmbed](https://github.com/qdrant/fastembed/) - A lightweight, fast, Python library for embeddings generation.\n\nThe Qdrant client provides a handy integration with FastEmbed that makes building a knowledge base very straighforward.\n\nFirst, we need to create a collection, so Qdrant would know what vectors it will be dealing with, and then, we just pass our raw documents wrapped into `models.Document` to compute and upload the embeddings.\n\n```python\ncollection_name = \"knowledge_base\"\nmodel_name = \"BAAI/bge-small-en-v1.5\"\nclient.create_collection(\n    collection_name=collection_name,\n    vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE)\n)\n```",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 627,
      "character_count": 2569,
      "created_at": "2025-10-16T17:42:28.846997",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 5,
      "file_relative_path": "qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "```python\ndocuments = [\n    \"Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\",\n    \"Docker helps developers build, share, and run applications anywhere ‚Äî without tedious environment configuration or management.\",\n    \"PyTorch is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing.\",\n    \"MySQL is an open-source relational database management system (RDBMS). A relational database organizes data into one or more data tables in which data may be related to each other; these relations help structure the data. SQL is a language that programmers use to create, modify and extract data from the relational database, as well as control user access to the database.\",\n    \"NGINX is a free, open-source, high-performance HTTP server and reverse proxy, as well as an IMAP/POP3 proxy server. NGINX is known for its high performance, stability, rich feature set, simple configuration, and low resource consumption.\",\n    \"FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\",\n    \"SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.\",\n    \"The cron command-line utility is a job scheduler on Unix-like operating systems. Users who set up and maintain software environments use cron to schedule jobs (commands or shell scripts), also known as cron jobs, to run periodically at fixed times, dates, or intervals.\",\n]\nclient.upsert(\n    collection_name=collection_name,\n    points=[\n        models.PointStruct(\n            id=idx,\n            vector=models.Document(text=document, model=model_name),\n            payload={\"document\": document},\n        )\n        for idx, document in enumerate(documents)\n    ],\n)\n```\n\n## Setup DeepSeek\n\nRAG changes the way we interact with Large Language Models. We‚Äôre converting a knowledge-oriented task, in which the model may create a counterfactual answer, into a language-oriented task. The latter expects the model to extract meaningful information and generate an answer. LLMs, when implemented correctly, are supposed to be carrying out language-oriented tasks.\n\nThe task starts with the original prompt sent by the user. The same prompt is then vectorized and used as a search query for the most relevant facts. Those facts are combined with the original prompt to build a longer prompt containing more information.\n\nBut let‚Äôs start simply by asking our question directly.\n\n```python\nprompt = \"\"\"\nWhat tools should I need to use to build a web service using vector embeddings for search?\n\"\"\"\n```\n\nUsing the Deepseek API requires providing the API key. You can obtain it from the [DeepSeek platform](https://platform.deepseek.com/api_keys).\n\nNow we can finally call the completion API.\n\n```python\nimport requests\nimport json\n\n# Fill the environmental variable with your own Deepseek API key\n# See: https://platform.deepseek.com/api_keys\nAPI_KEY = \"<YOUR_DEEPSEEK_KEY>\"\n\nHEADERS = {\n    \"Authorization\": f\"Bearer {API_KEY}\",\n    \"Content-Type\": \"application/json\",\n}\n\ndef query_deepseek(prompt):\n    data = {\n        \"model\": \"deepseek-chat\",\n        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n        \"stream\": False,\n    }\n\nresponse = requests.post(\n        \"https://api.deepseek.com/chat/completions\", headers=HEADERS, data=json.dumps(data)\n    )\n\nif response.ok:\n        result = response.json()\n        return result[\"choices\"][0][\"message\"][\"content\"]\n    else:\n        raise Exception(f\"Error {response.status_code}: {response.text}\")\n```\n\nand also the query\n\n```python\nquery_deepseek(prompt)\n```\n\nThe response is:",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 876,
      "character_count": 4215,
      "created_at": "2025-10-16T17:42:28.853403",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 6,
      "file_relative_path": "qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "```bash\n\"Building a web service that uses vector embeddings for search involves several components, including data processing, embedding generation, storage, search, and serving the service via an API. Below is a list of tools and technologies you can use for each step:\\n\\n---\\n\\n### 1. **Data Processing**\\n   - **Python**: For general data preprocessing and scripting.\\n   - **Pandas**: For handling tabular data.\\n   - **NumPy**: For numerical operations.\\n   - **NLTK/Spacy**: For text preprocessing (tokenization, stemming, etc.).\\n   - **LLM models**: For generating embeddings if you're using pre-trained models.\\n\\n---\\n\\n### 2. **Embedding Generation**\\n   - **Pre-trained Models**:\\n     - Embeddings (e.g., `text-embedding-ada-002`).\\n     - Hugging Face Transformers (e.g., `Sentence-BERT`, `all-MiniLM-L6-v2`).\\n     - Google's Universal Sentence Encoder.\\n   - **Custom Models**:\\n     - TensorFlow/PyTorch: For training custom embedding models.\\n   - **Libraries**:\\n     - `sentence-transformers`: For generating sentence embeddings.\\n     - `transformers`: For using Hugging Face models.\\n\\n---\\n\\n### 3. **Vector Storage**\\n   - **Vector Databases**:\\n     - Pinecone: Managed vector database for similarity search.\\n     - Weaviate: Open-source vector search engine.\\n     - Milvus: Open-source vector database.\\n     - FAISS (Facebook AI Similarity Search): Library for efficient similarity search.\\n     - Qdrant: Open-source vector search engine.\\n     - Redis with RedisAI: For storing and querying vectors.\\n   - **Traditional Databases with Vector Support**:\\n     - PostgreSQL with pgvector extension.\\n     - Elasticsearch with dense vector support.\\n\\n---\\n\\n### 4. **Search and Retrieval**\\n   - **Similarity Search Algorithms**:\\n     - Cosine similarity, Euclidean distance, or dot product for comparing vectors.\\n   - **Libraries**:\\n     - FAISS: For fast nearest-neighbor search.\\n     - Annoy (Approximate Nearest Neighbors Oh Yeah): For approximate nearest neighbor search.\\n   - **Vector Databases**: Most vector databases (e.g., Pinecone, Weaviate) come with built-in search capabilities.\\n\\n---\\n\\n### 5. **Web Service Framework**\\n   - **Backend Frameworks**:\\n     - Flask/Django/FastAPI (Python): For building RESTful APIs.\\n     - Node.js/Express: If you prefer JavaScript.\\n   - **API Documentation**:\\n     - Swagger/OpenAPI: For documenting your API.\\n   - **Authentication**:\\n     - OAuth2, JWT: For securing your API.\\n\\n---\\n\\n### 6. **Deployment**\\n   - **Containerization**:\\n     - Docker: For packaging your application.\\n   - **Orchestration**:\\n     - Kubernetes: For managing containers at scale.\\n   - **Cloud Platforms**:\\n     - AWS (EC2, Lambda, S3).\\n     - Google Cloud (Compute Engine, Cloud Functions).\\n     - Azure (App Service, Functions).\\n   - **Serverless**:\\n     - AWS Lambda, Google Cloud Functions, or Vercel for serverless deployment.\\n\\n---\\n\\n### 7. **Monitoring and Logging**\\n   - **Monitoring**:\\n     - Prometheus + Grafana: For monitoring performance.\\n   - **Logging**:\\n     - ELK Stack (Elasticsearch, Logstash, Kibana).\\n     - Fluentd.\\n   - **Error Tracking**:\\n     - Sentry.\\n\\n---\\n\\n### 8. **Frontend (Optional)**\\n   - **Frontend Frameworks**:\\n     - React, Vue.js, or Angular: For building a user interface.\\n   - **Libraries**:\\n     - Axios: For making API calls from the frontend.\\n\\n---\\n\\n### Example Workflow\\n1. Preprocess your data (e.g., clean text, tokenize).\\n2. Generate embeddings using a pre-trained model (e.g., Hugging Face).\\n3. Store embeddings in a vector database (e.g., Pinecone or FAISS).\\n4. Build a REST API using FastAPI or Flask to handle search queries.\\n5. Deploy the service using Docker and Kubernetes or a serverless platform.\\n6. Monitor and scale the service as needed.\\n\\n---\\n\\n### Example Tools Stack\\n- **Embedding Generation**: Hugging Face `sentence-transformers`.\\n- **Vector Storage**: Pinecone or FAISS.\\n- **Web Framework**: FastAPI.\\n- **Deployment**: Docker + AWS/GCP.\\n\\nBy combining these tools, you can build a scalable and efficient web service for vector embedding-based search.\"\n```",
    "metadata": {
      "chunk_id": 7,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1086,
      "character_count": 4130,
      "created_at": "2025-10-16T17:42:28.854609",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 7,
      "file_relative_path": "qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "### Extending the prompt\n\nEven though the original answer sounds credible, it didn‚Äôt answer our question correctly. Instead, it gave us a generic description of an application stack. To improve the results, enriching the original prompt with the descriptions of the tools available seems like one of the possibilities. Let‚Äôs use a semantic knowledge base to augment the prompt with the descriptions of different technologies!\n\n```python\nresults = client.query_points(\n    collection_name=collection_name,\n    query=models.Document(text=prompt, model=model_name),\n    limit=3,\n)\nresults\n```\n\nHere is the response:\n\n```bash\nQueryResponse(points=[\n    ScoredPoint(id=0, version=0, score=0.67437416, payload={'document': 'Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!'}, vector=None, shard_key=None, order_value=None), \n    ScoredPoint(id=6, version=0, score=0.63144326, payload={'document': 'SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.'}, vector=None, shard_key=None, order_value=None), \n    ScoredPoint(id=5, version=0, score=0.6064749, payload={'document': 'FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.'}, vector=None, shard_key=None, order_value=None)\n])\n```\n\nWe used the original prompt to perform a semantic search over the set of tool descriptions. Now we can use these descriptions to augment the prompt and create more context.\n\n```python\ncontext = \"\\n\".join(r.payload['document'] for r in results.points)\ncontext\n```\n\nThe response is:\n\n```bash\n'Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\\nFastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\\nPyTorch is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing.'\n```\n\nFinally, let‚Äôs build a metaprompt, the combination of the assumed role of the LLM, the original question, and the results from our semantic search that will force our LLM to use the provided context.\n\nBy doing this, we effectively convert the knowledge-oriented task into a language task and hopefully reduce the chances of hallucinations. It also should make the response sound more relevant.\n\n```python\nmetaprompt = f\"\"\"\nYou are a software architect. \nAnswer the following question using the provided context. \nIf you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n\nQuestion: {prompt.strip()}\n\nContext: \n{context.strip()}\n\nAnswer:\n\"\"\"\n\n# Look at the full metaprompt\nprint(metaprompt)\n```\n\n**Response:**\n\n```bash\nYou are a software architect. \nAnswer the following question using the provided context. \nIf you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n    \nQuestion: What tools should I need to use to build a web service using vector embeddings for search?\n    \nContext: \nQdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\nFastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\nPyTorch is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing.\n    \nAnswer:\n```\n\nOur current prompt is much longer, and we also used a couple of strategies to make the responses even better:\n\n1. The LLM has the role of software architect.\n2. We provide more context to answer the question.\n3. If the context contains no meaningful information, the model shouldn‚Äôt make up an answer.\n\nLet‚Äôs find out if that works as expected.\n\n**Question:**",
    "metadata": {
      "chunk_id": 8,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1022,
      "character_count": 4726,
      "created_at": "2025-10-16T17:42:28.861761",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 8,
      "file_relative_path": "qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "```python\nquery_deepseek(metaprompt)\n```\n\n**Answer:**\n\n```bash\n'To build a web service using vector embeddings for search, you can use the following tools:\\n\\n1. **Qdrant**: As a vector database and similarity search engine, Qdrant will handle the storage and retrieval of high-dimensional vectors. It provides an API service for searching and matching vectors, making it ideal for applications that require vector-based search functionality.\\n\\n2. **FastAPI**: This web framework is perfect for building the API layer of your web service. It is fast, easy to use, and based on Python type hints, which makes it a great choice for developing the backend of your service. FastAPI will allow you to expose endpoints that interact with Qdrant for vector search operations.\\n\\n3. **PyTorch**: If you need to generate vector embeddings from your data (e.g., text, images), PyTorch can be used to create and train neural network models that produce these embeddings. PyTorch is a powerful machine learning framework that supports a wide range of applications, including natural language processing and computer vision.\\n\\n### Summary:\\n- **Qdrant** for vector storage and search.\\n- **FastAPI** for building the web service API.\\n- **PyTorch** for generating vector embeddings (if needed).\\n\\nThese tools together provide a robust stack for building a web service that leverages vector embeddings for search functionality.'\n```\n\n### Testing out the RAG pipeline\n\nBy leveraging the semantic context we provided our model is doing a better job answering the question. Let‚Äôs enclose the RAG as a function, so we can call it more easily for different prompts.\n\n```python\ndef rag(question: str, n_points: int = 3) -> str:\n    results = client.query_points(\n        collection_name=collection_name,\n        query=models.Document(text=question, model=model_name),\n        limit=n_points,\n    )\n\ncontext = \"\\n\".join(r.payload[\"document\"] for r in results.points)\n\nmetaprompt = f\"\"\"\n    You are a software architect. \n    Answer the following question using the provided context. \n    If you can't find the answer, do not pretend you know it, but only answer \"I don't know\".\n\nQuestion: {question.strip()}\n\nContext: \n    {context.strip()}\n\nAnswer:\n    \"\"\"\n\nreturn query_deepseek(metaprompt)\n```\n\nNow it‚Äôs easier to ask a broad range of questions.\n\n**Question:**\n\n```python\nrag(\"What can the stack for a web api look like?\")\n```\n\n**Answer:**\n\n```bash\n'The stack for a web API can include the following components based on the provided context:\\n\\n1. **Web Framework**: FastAPI can be used as the web framework for building the API. It is modern, fast, and leverages Python type hints for better development and performance.\\n\\n2. **Reverse Proxy/Web Server**: NGINX can be used as a reverse proxy or web server to handle incoming HTTP requests, load balancing, and serving static content. It is known for its high performance and low resource consumption.\\n\\n3. **Containerization**: Docker can be used to containerize the application, making it easier to build, share, and run the API consistently across different environments without worrying about configuration issues.\\n\\nThis stack provides a robust, scalable, and efficient setup for building and deploying a web API.'\n```\n\n**Question:**\n\n```python\nrag(\"Where is the nearest grocery store?\")\n```\n\n**Answer:**\n\n```bash\n\"I don't know. The provided context does not contain any information about the location of the nearest grocery store.\"\n```\n\nOur model can now:\n\n1. Take advantage of the knowledge in our vector datastore.\n2. Answer, based on the provided context, that it can not provide an answer.\n\nWe have just shown a useful mechanism to mitigate the risks of hallucinations in Large Language Models.\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! üôè\n\nWe are sorry to hear that. üòî You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/rag-deepseek.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [5 Minute RAG with Qdrant and DeepSeek](#5-minute-rag-with-qdrant-and-deepseek.md)\n\n- [Overview](#overview.md)\n    -\n\n- [Prerequisites](#prerequisites.md)\n\n- [Setup Qdrant](#setup-qdrant.md)\n\n- [Instantiating Qdrant Client](#instantiating-qdrant-client.md)\n    - [Building the knowledge base](#building-the-knowledge-base.md)\n\n- [Setup DeepSeek](#setup-deepseek.md)",
    "metadata": {
      "chunk_id": 9,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1020,
      "character_count": 4452,
      "created_at": "2025-10-16T17:42:28.871284",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 9,
      "file_relative_path": "qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Extending the prompt](#extending-the-prompt.md)\n    - [Testing out the RAG pipeline](#testing-out-the-rag-pipeline.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/rag-deepseek.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n¬© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
    "metadata": {
      "chunk_id": 10,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 165,
      "character_count": 588,
      "created_at": "2025-10-16T17:42:28.871580",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 10,
      "file_relative_path": "qdrant_documentation\\documentation_rag-deepseek\\_documentation_rag-deepseek_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  }
]
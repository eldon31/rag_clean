[
  {
    "text": "Practice Datasets - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 929,
      "character_count": 3492,
      "created_at": "2025-10-16T17:42:24.436909",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 968,
      "character_count": 3625,
      "created_at": "2025-10-16T17:42:24.439885",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 965,
      "character_count": 3819,
      "created_at": "2025-10-16T17:42:24.444934",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 978,
      "character_count": 3651,
      "created_at": "2025-10-16T17:42:24.446971",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 3,
      "file_relative_path": "qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- Practice Datasets\n\n# Common Datasets in Snapshot Format\n\nYou may find that creating embeddings from datasets is a very resource-intensive task. If you need a practice dataset, feel free to pick one of the ready-made snapshots on this page. These snapshots contain pre-computed vectors that you can easily import into your Qdrant instance.\n\n## Available datasets\n\nOur snapshots are usually generated from publicly available datasets, which are often used for non-commercial or academic purposes. The following datasets are currently available. Please click on a dataset name to see its detailed description.",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 998,
      "character_count": 4111,
      "created_at": "2025-10-16T17:42:24.452110",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 4,
      "file_relative_path": "qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "| Dataset                                       | Model                                                                       | Vector size | Documents | Size   | Qdrant snapshot                                                                                          | HF Hub                                                                                 |\n| --------------------------------------------- | --------------------------------------------------------------------------- | ----------- | --------- | ------ | -------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |\n| [Arxiv.org titles](#arxivorg-titles.md)       | [InstructorXL](https://huggingface.co/hkunlp/instructor-xl)                 | 768         | 2.3M      | 7.1 GB | [Download](https://snapshots.qdrant.io/arxiv_titles-3083016565637815127-2023-05-29-13-56-22.snapshot)    | [Open](https://huggingface.co/datasets/Qdrant/arxiv-titles-instructorxl-embeddings)    |\n| [Arxiv.org abstracts](#arxivorg-abstracts.md) | [InstructorXL](https://huggingface.co/hkunlp/instructor-xl)                 | 768         | 2.3M      | 8.4 GB | [Download](https://snapshots.qdrant.io/arxiv_abstracts-3083016565637815127-2023-06-02-07-26-29.snapshot) | [Open](https://huggingface.co/datasets/Qdrant/arxiv-abstracts-instructorxl-embeddings) |\n| [Wolt food](#wolt-food.md)                    | [clip-ViT-B-32](https://huggingface.co/sentence-transformers/clip-ViT-B-32) | 512         | 1.7M      | 7.9 GB | [Download](https://snapshots.qdrant.io/wolt-clip-ViT-B-32-2446808438011867-2023-12-14-15-55-26.snapshot) | [Open](https://huggingface.co/datasets/Qdrant/wolt-food-clip-ViT-B-32-embeddings)      |\n\nOnce you download a snapshot, you need to [restore it](https://qdrant.tech/documentation/concepts/snapshots/#restore-snapshot) using the Qdrant CLI upon startup or through the API.\n\n## Qdrant on Hugging Face\n\n[](https://huggingface.co/Qdrant)\n\n[Hugging Face](https://huggingface.co/) provides a platform for sharing and using ML models and datasets. [Qdrant](https://huggingface.co/Qdrant) is one of the organizations there! We aim to provide you with datasets containing neural embeddings that you can use to practice with Qdrant and build your applications based on semantic search. **Please let us know if you’d like to see a specific dataset!**\n\nIf you are not familiar with [Hugging Face datasets](https://huggingface.co/docs/datasets/index), or would like to know how to combine it with Qdrant, please refer to the [tutorial](https://qdrant.tech/documentation/tutorials/huggingface-datasets/).\n\n## Arxiv.org\n\n[Arxiv.org](https://arxiv.org) is a highly-regarded open-access repository of electronic preprints in multiple fields. Operated by Cornell University, arXiv allows researchers to share their findings with the scientific community and receive feedback before they undergo peer review for formal publication. Its archives host millions of scholarly articles, making it an invaluable resource for those looking to explore the cutting edge of scientific research. With a high frequency of daily submissions from scientists around the world, arXiv forms a comprehensive, evolving dataset that is ripe for mining, analysis, and the development of future innovations.\n\nArxiv.org snapshots were created using precomputed embeddings exposed by [the Alexandria Index](https://alex.macrocosm.so/download).\n\n### Arxiv.org titles\n\nThis dataset contains embeddings generated from the paper titles only. Each vector has a payload with the title used to create it, along with the DOI (Digital Object Identifier).\n\n```json\n{\n    \"title\": \"Nash Social Welfare for Indivisible Items under Separable, Piecewise-Linear Concave Utilities\",\n    \"DOI\": \"1612.05191\"\n}\n```\n\nThe embeddings generated with InstructorXL model have been generated using the following instruction:\n\n> Represent the Research Paper title for retrieval; Input:\n\nThe following code snippet shows how to generate embeddings using the InstructorXL model:\n\n```python\nfrom InstructorEmbedding import INSTRUCTOR\n\nmodel = INSTRUCTOR(\"hkunlp/instructor-xl\")\nsentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\ninstruction = \"Represent the Research Paper title for retrieval; Input:\"\nembeddings = model.encode([[instruction, sentence]])\n```\n\nThe snapshot of the dataset might be downloaded [here](https://snapshots.qdrant.io/arxiv_titles-3083016565637815127-2023-05-29-13-56-22.snapshot).\n\n#### Importing the dataset",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1023,
      "character_count": 4597,
      "created_at": "2025-10-16T17:42:24.460631",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 5,
      "file_relative_path": "qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "The easiest way to use the provided dataset is to recover it via the API by passing the URL as a location. It works also in [Qdrant Cloud](https://cloud.qdrant.io/). The following code snippet shows how to create a new collection and fill it with the snapshot data:\n\n```http\nPUT /collections/{collection_name}/snapshots/recover\n{\n  \"location\": \"https://snapshots.qdrant.io/arxiv_titles-3083016565637815127-2023-05-29-13-56-22.snapshot\"\n}\n```\n\n### Arxiv.org abstracts\n\nThis dataset contains embeddings generated from the paper abstracts. Each vector has a payload with the abstract used to create it, along with the DOI (Digital Object Identifier).\n\n```json\n{\n    \"abstract\": \"Recently Cole and Gkatzelis gave the first constant factor approximation\\nalgorithm for the problem of allocating indivisible items to agents, under\\nadditive valuations, so as to maximize the Nash Social Welfare. We give\\nconstant factor algorithms for a substantial generalization of their problem --\\nto the case of separable, piecewise-linear concave utility functions. We give\\ntwo such algorithms, the first using market equilibria and the second using the\\ntheory of stable polynomials.\\n  In AGT, there is a paucity of methods for the design of mechanisms for the\\nallocation of indivisible goods and the result of Cole and Gkatzelis seemed to\\nbe taking a major step towards filling this gap. Our result can be seen as\\nanother step in this direction.\\n\",\n    \"DOI\": \"1612.05191\"\n}\n```\n\nThe embeddings generated with InstructorXL model have been generated using the following instruction:\n\n> Represent the Research Paper abstract for retrieval; Input:\n\nThe following code snippet shows how to generate embeddings using the InstructorXL model:\n\n```python\nfrom InstructorEmbedding import INSTRUCTOR\n\nmodel = INSTRUCTOR(\"hkunlp/instructor-xl\")\nsentence = \"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train.\"\ninstruction = \"Represent the Research Paper abstract for retrieval; Input:\"\nembeddings = model.encode([[instruction, sentence]])\n```\n\nThe snapshot of the dataset might be downloaded [here](https://snapshots.qdrant.io/arxiv_abstracts-3083016565637815127-2023-06-02-07-26-29.snapshot).\n\n#### Importing the dataset\n\nThe easiest way to use the provided dataset is to recover it via the API by passing the URL as a location. It works also in [Qdrant Cloud](https://cloud.qdrant.io/). The following code snippet shows how to create a new collection and fill it with the snapshot data:\n\n```http\nPUT /collections/{collection_name}/snapshots/recover\n{\n  \"location\": \"https://snapshots.qdrant.io/arxiv_abstracts-3083016565637815127-2023-06-02-07-26-29.snapshot\"\n}\n```\n\n## Wolt food\n\nOur [Food Discovery demo](https://food-discovery.qdrant.tech/) relies on the dataset of food images from the Wolt app. Each point in the collection represents a dish with a single image. The image is represented as a vector of 512 float numbers. There is also a JSON payload attached to each point, which looks similar to this:",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 783,
      "character_count": 3502,
      "created_at": "2025-10-16T17:42:24.464774",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 6,
      "file_relative_path": "qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "```json\n{\n    \"cafe\": {\n        \"address\": \"VGX7+6R2 Vecchia Napoli, Valletta\",\n        \"categories\": [\"italian\", \"pasta\", \"pizza\", \"burgers\", \"mediterranean\"],\n        \"location\": {\"lat\": 35.8980154, \"lon\": 14.5145106},\n        \"menu_id\": \"610936a4ee8ea7a56f4a372a\",\n        \"name\": \"Vecchia Napoli Is-Suq Tal-Belt\",\n        \"rating\": 9,\n        \"slug\": \"vecchia-napoli-skyparks-suq-tal-belt\"\n    },\n    \"description\": \"Tomato sauce, mozzarella fior di latte, crispy guanciale, Pecorino Romano cheese and a hint of chilli\",\n    \"image\": \"https://wolt-menu-images-cdn.wolt.com/menu-images/610936a4ee8ea7a56f4a372a/005dfeb2-e734-11ec-b667-ced7a78a5abd_l_amatriciana_pizza_joel_gueller1.jpeg\",\n    \"name\": \"L'Amatriciana\"\n}\n```\n\nThe embeddings generated with clip-ViT-B-32 model have been generated using the following code snippet:\n\n```python\nfrom PIL import Image\nfrom sentence_transformers import SentenceTransformer\n\nimage_path = \"5dbfd216-5cce-11eb-8122-de94874ad1c8_ns_takeaway_seelachs_ei_baguette.jpeg\"\n\nmodel = SentenceTransformer(\"clip-ViT-B-32\")\nembedding = model.encode(Image.open(image_path))\n```\n\nThe snapshot of the dataset might be downloaded [here](https://snapshots.qdrant.io/wolt-clip-ViT-B-32-2446808438011867-2023-12-14-15-55-26.snapshot).\n\n#### Importing the dataset\n\nThe easiest way to use the provided dataset is to recover it via the API by passing the URL as a location. It works also in [Qdrant Cloud](https://cloud.qdrant.io/). The following code snippet shows how to create a new collection and fill it with the snapshot data:\n\n```http\nPUT /collections/{collection_name}/snapshots/recover\n{\n  \"location\": \"https://snapshots.qdrant.io/wolt-clip-ViT-B-32-2446808438011867-2023-12-14-15-55-26.snapshot\"\n}\n```\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! 🙏\n\nWe are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/datasets.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Common Datasets in Snapshot Format](#common-datasets-in-snapshot-format.md)\n\n- [Available datasets](#available-datasets.md)\n\n- [Qdrant on Hugging Face](#qdrant-on-hugging-face.md)\n\n- [Arxiv.org](#arxivorg.md)\n\n- [Arxiv.org titles](#arxivorg-titles.md)\n    - [Arxiv.org abstracts](#arxivorg-abstracts.md)\n\n- [Wolt food](#wolt-food.md)\n    -\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/datasets.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
    "metadata": {
      "chunk_id": 7,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 866,
      "character_count": 2875,
      "created_at": "2025-10-16T17:42:24.472208",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 7,
      "file_relative_path": "qdrant_documentation\\documentation_datasets\\_documentation_datasets_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  }
]
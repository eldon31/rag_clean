[
  {
    "text": "Agentic RAG Discord Bot with CAMEL-AI - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)",
    "metadata": {
      "chunk_id": 0,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 938,
      "character_count": 3512,
      "created_at": "2025-10-16T17:42:21.295070",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 0,
      "file_relative_path": "qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)",
    "metadata": {
      "chunk_id": 1,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 968,
      "character_count": 3625,
      "created_at": "2025-10-16T17:42:21.298139",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 1,
      "file_relative_path": "qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)",
    "metadata": {
      "chunk_id": 2,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 965,
      "character_count": 3819,
      "created_at": "2025-10-16T17:42:21.303275",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 2,
      "file_relative_path": "qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)",
    "metadata": {
      "chunk_id": 3,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 978,
      "character_count": 3651,
      "created_at": "2025-10-16T17:42:21.305110",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 3,
      "file_relative_path": "qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- Agentic RAG Discord Bot with CAMEL-AI\n\n# Agentic RAG Discord ChatBot with Qdrant, CAMEL-AI, & OpenAI\n\n| Time: 45 min | Level: Intermediate | [](https://colab.research.google.com/drive/1Ymqzm6ySoyVOekY7fteQBCFCXYiYyHxw#scrollTo=QQZXwzqmNfaS) |   |\n| ------------ | ------------------- | --------------------------------------------------------------------------------------------------- | - |",
    "metadata": {
      "chunk_id": 4,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 996,
      "character_count": 3896,
      "created_at": "2025-10-16T17:42:21.309527",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 4,
      "file_relative_path": "qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "Unlike traditional RAG techniques, which passively retrieve context and generate responses, **agentic RAG** involves active decision-making and multi-step reasoning by the chatbot. Instead of just fetching data, the chatbot makes decisions, dynamically interacts with various data sources, and adapts based on context, giving it a much more dynamic and intelligent approach.\n\nIn this tutorial, we’ll develop a fully functional chatbot using Qdrant, [CAMEL-AI](https://www.camel-ai.org/), and [OpenAI](https://openai.com/).\n\nLet’s get started!\n\n---\n\n## Workflow Overview\n\nBelow is a high-level look at our Agentic RAG workflow:\n\n| Step                                        | Description                                                                                                 |\n| ------------------------------------------- | ----------------------------------------------------------------------------------------------------------- |\n| **1. Environment Setup**                    | Install required libraries (`camel-ai`, `qdrant-client`, `discord.py`) and set up the Python environment.   |\n| **2. Set Up the OpenAI Embedding Instance** | Create an OpenAI account, generate an API key, and configure the embedding model.                           |\n| **3. Configure the Qdrant Client**          | Sign up for Qdrant Cloud, create a cluster, configure `QdrantStorage`, and set up the API connection.       |\n| **4. Scrape and Process Data**              | Use `VectorRetriever` to scrape Qdrant documentation, chunk text, and store embeddings in Qdrant.           |\n| **5. Set Up the CAMEL-AI ChatAgent**        | Instantiate a CAMEL-AI `ChatAgent` with OpenAI models for multi-step reasoning and context-aware responses. |\n| **6. Create and Configure the Discord Bot** | Register a new bot in the Discord Developer Portal, invite it to a server, and enable permissions.          |\n| **7. Build the Discord Bot**                | Integrate Discord.py with CAMEL-AI and Qdrant to retrieve context and generate intelligent responses.       |\n| **8. Test the Bot**                         | Run the bot in a live Discord server and verify that it provides relevant, context-rich answers.            |\n\n## Architecture Diagram\n\nBelow is the architecture diagram representing the workflow and interactions of the chatbot:\n\nThe workflow starts by **scraping, chunking, and upserting** content from URLs using the `vector_retriever.process()` method, which generates embeddings with the **OpenAI embedding instance**. These embeddings, along with their metadata, are then indexed and stored in **Qdrant** via the `QdrantStorage` class.\n\nWhen a user sends a query through the **Discord bot**, it is processed by `vector_retriever.query()`, which first embeds the query using **OpenAI Embeddings** and then retrieves the most relevant matches from Qdrant via `QdrantStorage`. The retrieved context (e.g., relevant documentation snippets) is then passed to an **OpenAI-powered Qdrant Agent** under **CAMEL-AI**, which generates a final, context-aware response.\n\nThe Qdrant Agent processes the retrieved vectors using the `GPT_4O_MINI` language model, producing a response that is contextually relevant to the user’s query. This response is then sent back to the user through the **Discord bot**, completing the flow.\n\n---\n\n## **Step 1: Environment Setup**\n\nBefore diving into the implementation, here’s a high-level overview of the stack we’ll use:\n\n| **Component**   | **Purpose**                                                                               |\n| --------------- | ----------------------------------------------------------------------------------------- |\n| **Qdrant**      | Vector database for storing and querying document embeddings.                             |\n| **OpenAI**      | Embedding and language model for generating vector representations and chatbot responses. |\n| **CAMEL-AI**    | Framework for managing dialogue flow, retrieval, and AI agent interactions.               |\n| **Discord API** | Platform for deploying and interacting with the chatbot.                                  |\n\n### Install Dependencies\n\nWe’ll install CAMEL-AI, which includes all necessary dependencies:\n\n```python\n!pip install camel-ai[all]==0.2.17\n```\n\n---\n\n## **Step 2: Set Up the OpenAI Embedding Instance**\n\n1. **Create an OpenAI Account**: Go to [OpenAI](https://platform.openai.com/signup) and sign up for an account if you don’t already have one.\n\n2. **Generate an API Key**:\n\n- After logging in, click on your profile icon in the top-right corner and select **API keys**.\n\n- Click **Create new secret key**.\n\n- Copy the generated API key and store it securely. You won’t be able to see it again.\n\nHere’s how to set up the OpenAI client in your code:\n\nCreate a `.env` file in your project directory and add your API key:\n\n```bash\nOPENAI_API_KEY=<your_openai_api_key>\n```",
    "metadata": {
      "chunk_id": 5,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1021,
      "character_count": 4890,
      "created_at": "2025-10-16T17:42:21.320108",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 5,
      "file_relative_path": "qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "Make sure to replace `<your_openai_api_key>` with your actual API key.\n\nNow, start the OpenAI Client\n\n```python\nimport openai\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nopenai_client = openai.Client(\n    api_key=os.getenv(\"OPENAI_API_KEY\")\n)\n```\n\nTo set up the embedding instance, we will use text embedding 3 large:\n\n```python\nfrom camel.embeddings import OpenAIEmbedding\nfrom camel.types import EmbeddingModelType\n\nembedding_instance = OpenAIEmbedding(model_type=EmbeddingModelType.TEXT_EMBEDDING_3_LARGE)\n```\n\n## **Step 3: Configure the Qdrant Client**\n\nFor this tutorial, we will be using the **Qdrant Cloud Free Tier**. Here’s how to set it up:\n\n1. **Create an Account**: Sign up for a Qdrant Cloud account at [Qdrant Cloud](https://cloud.qdrant.io).\n\n2. **Create a Cluster**:\n\n- Navigate to the **Overview** section.\n   - Follow the onboarding instructions under **Create First Cluster** to set up your cluster.\n   - When you create the cluster, you will receive an **API Key**. Copy and securely store it, as you will need it later.\n\n3. **Wait for the Cluster to Provision**:\n\n- Your new cluster will appear under the **Clusters** section.\n\nAfter obtaining your Qdrant Cloud details, add to your `.env` file:\n\n```bash\nQDRANT_CLOUD_URL=<your-qdrant-cloud-url>\nQDRANT_CLOUD_API_KEY=<your-api-key>\n```\n\n### Configure the QdrantStorage\n\nThe `QdrantStorage` will deal with connecting with the Qdrant Client for all necessary operations to your collection.\n\n```python\nfrom camel.retrievers import VectorRetriever\n\n# Define collection name\ncollection_name = \"qdrant-agent\"\n\nstorage_instance = QdrantStorage(\n    vector_dim=embedding_instance.get_output_dim(),\n    url_and_api_key=(\n        qdrant_cloud_url,\n        qdrant_api_key,\n    ),\n    collection_name=collection_name,\n)\n```\n\nMake sure to update the `<your-qdrant-cloud-url>` and `<your-api-key>` fields.\n\n---\n\n## **Step 4: Scrape and Process Data**\n\nWe’ll use CamelAI `VectorRetriever` library to help us to It processes content from a file or URL, divides it into chunks, and stores the embeddings in the specified Qdrant collection.\n\n```python\nfrom camel.retrievers import VectorRetriever\n\nvector_retriever = VectorRetriever(embedding_model=embedding_instance,\n                                   storage=storage_instance)\n\nqdrant_urls = [\n    \"https://qdrant.tech/documentation/overview\",\n    \"https://qdrant.tech/documentation/guides/installation\",\n    \"https://qdrant.tech/documentation/concepts/filtering\",\n    \"https://qdrant.tech/documentation/concepts/indexing\",\n    \"https://qdrant.tech/documentation/guides/distributed_deployment\",\n    \"https://qdrant.tech/documentation/guides/quantization\"\n    # Add more URLs as needed\n]\n\nfor qdrant_url in qdrant_urls:\n  vector_retriever.process(\n      content=qdrant_url,\n  )\n```\n\n---\n\n## **Step 5: Setup the CAMEL-AI ChatAgent Instance**\n\nDefine the OpenAI model and create a CAMEL-AI ChatAgent instance.\n\n```python\nfrom camel.configs import ChatGPTConfig\nfrom camel.models import ModelFactory\nfrom camel.types import ModelPlatformType, ModelType\nfrom camel.agents import ChatAgent\n\n# Create a ChatGPT configuration\nconfig = ChatGPTConfig(temperature=0.2).as_dict()\n\n# Create an OpenAI model using the configuration\nopenai_model = ModelFactory.create(\n    model_platform=ModelPlatformType.OPENAI,\n    model_type=ModelType.GPT_4O_MINI,\n    model_config_dict=config,\n)\n\nassistant_sys_msg = \"\"\"You are a helpful assistant to answer question,\n         I will give you the Original Query and Retrieved Context,\n        answer the Original Query based on the Retrieved Context,\n        if you can't answer the question just say I don't know.\"\"\"\n\nqdrant_agent = ChatAgent(system_message=assistant_sys_msg, model=openai_model)\n```\n\n---\n\n## **Step 6: Create and Configure the Discord Bot**\n\nNow let’s bring the bot to life! It will serve as the interface through which users can interact with the agentic RAG system you’ve built.\n\n### Create a New Discord Bot\n\n1. Go to the [Discord Developer Portal](https://discord.com/developers/applications) and log in with your Discord account.\n\n2. Click on the **New Application** button.\n\n3. Give your application a name and click **Create**.",
    "metadata": {
      "chunk_id": 6,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 1018,
      "character_count": 4195,
      "created_at": "2025-10-16T17:42:21.330321",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 6,
      "file_relative_path": "qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "4. Navigate to the **Bot** tab on the left sidebar and click **Add Bot**.\n\n5. Once the bot is created, click **Reset Token** under the **Token** section to generate a new bot token. Copy this token securely as you will need it later.\n\n### Invite the Bot to Your Server\n\n1. Go to the **OAuth2** tab and then to the **URL Generator** section.\n\n2. Under **Scopes**, select **bot**.\n\n3. Under **Bot Permissions**, select the necessary permissions:\n\n- Send Messages\n\n- Read Message History\n\n4. Copy the generated URL and paste it into your browser.\n\n5. Select the server where you want to invite the bot and click **Authorize**.\n\n### Grant the Bot Permissions\n\n1. Go back to the **Bot** tab.\n\n2. Enable the following under **Privileged Gateway Intents**:\n\n- Server Members Intent\n\n- Message Content Intent\n\nNow, the bot is ready to be integrated with your code.\n\n## **Step 7: Build the Discord Bot**\n\nAdd to your `.env` file:\n\n```bash\nDISCORD_BOT_TOKEN=<your-discord-bot-token>\n```\n\nWe’ll use `discord.py` to create a simple Discord bot that interacts with users and retrieves context from Qdrant before responding.\n\n```python\nfrom camel.bots import DiscordApp\nimport nest_asyncio\nimport discord\n\nnest_asyncio.apply()\ndiscord_q_bot = DiscordApp(token=os.getenv(\"DISCORD_BOT_TOKEN\"))\n\n@discord_q_bot.client.event # triggers when a message is sent in the channel\nasync def on_message(message: discord.Message):\n    if message.author == discord_q_bot.client.user:\n        return\n\nif message.type != discord.MessageType.default:\n        return\n\nif message.author.bot:\n        return\n    user_input = message.content\n\nretrieved_info = vector_retriever.query(\n        query=user_input, top_k=10, similarity_threshold=0.6\n    )\n\nuser_msg = str(retrieved_info)\n    assistant_response = qdrant_agent.step(user_msg)\n    response_content = assistant_response.msgs[0].content\n\nif len(response_content) > 2000: # discord message length limit\n        for chunk in [response_content[i:i+2000] for i in range(0, len(response_content), 2000)]:\n            await message.channel.send(chunk)\n    else:\n        await message.channel.send(response_content)\n\ndiscord_q_bot.run()\n```\n\n---\n\n## **Step 9: Test the Bot**\n\n1. Invite your bot to your Discord server using the OAuth2 URL from the Discord Developer Portal.\n\n2. Run the notebook.\n\n3. Start chatting with the bot in your Discord server. It will retrieve context from Qdrant and provide relevant answers based on your queries.\n\n---\n\n## Conclusion\n\nNice work! You’ve built an agentic RAG-powered Discord bot that retrieves relevant information with Qdrant, generates smart responses with OpenAI, and handles multi-step reasoning using CAMEL-AI. Here’s a quick recap:\n\n- **Smart Knowledge Retrieval:** Your chatbot can now pull relevant info from large datasets using Qdrant’s vector search.\n\n- **Autonomous Reasoning with CAMEL-AI:** Enables multi-step reasoning instead of just regurgitating text.\n\n- **Live Discord Deployment:** You launched the chatbot on Discord, making it interactive and ready to help real users.\n\nOne of the biggest advantages of CAMEL-AI is the abstraction it provides, allowing you to focus on designing intelligent interactions rather than worrying about low-level implementation details.\n\nYou’re now well-equipped to tackle more complex real-world problems that require scalable, autonomous knowledge systems.\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! 🙏\n\nWe are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/agentic-rag-camelai-discord.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Agentic RAG Discord ChatBot with Qdrant, CAMEL-AI, & OpenAI](#agentic-rag-discord-chatbot-with-qdrant-camel-ai--openai.md)\n\n- [Workflow Overview](#workflow-overview.md)\n\n- [Architecture Diagram](#architecture-diagram.md)\n\n- [**Step 1: Environment Setup**](#step-1-environment-setup.md)\n    - [Install Dependencies](#install-dependencies.md)\n\n- [**Step 2: Set Up the OpenAI Embedding Instance**](#step-2-set-up-the-openai-embedding-instance.md)",
    "metadata": {
      "chunk_id": 7,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 980,
      "character_count": 4168,
      "created_at": "2025-10-16T17:42:21.342375",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 7,
      "file_relative_path": "qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  },
  {
    "text": "- [**Step 3: Configure the Qdrant Client**](#step-3-configure-the-qdrant-client.md)\n    - [Configure the QdrantStorage](#configure-the-qdrantstorage.md)\n\n- [**Step 4: Scrape and Process Data**](#step-4-scrape-and-process-data.md)\n\n- [**Step 5: Setup the CAMEL-AI ChatAgent Instance**](#step-5-setup-the-camel-ai-chatagent-instance.md)\n\n- [**Step 6: Create and Configure the Discord Bot**](#step-6-create-and-configure-the-discord-bot.md)\n\n- [Create a New Discord Bot](#create-a-new-discord-bot.md)\n    - [Invite the Bot to Your Server](#invite-the-bot-to-your-server.md)\n    - [Grant the Bot Permissions](#grant-the-bot-permissions.md)\n\n- [**Step 7: Build the Discord Bot**](#step-7-build-the-discord-bot.md)\n\n- [**Step 9: Test the Bot**](#step-9-test-the-bot.md)\n\n- [Conclusion](#conclusion.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/agentic-rag-camelai-discord.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
    "metadata": {
      "chunk_id": 8,
      "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\Qdrant\\qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "input_type": "qdrant",
      "chunking_strategy": "platform_documentation",
      "token_count": 375,
      "character_count": 1277,
      "created_at": "2025-10-16T17:42:21.343849",
      "parent_context": null,
      "semantic_type": "qdrant",
      "collection_name": "Qdrant",
      "subfolder_name": "qdrant_documentation",
      "collection_strategy": "platform_documentation",
      "chunk_index_in_file": 8,
      "file_relative_path": "qdrant_documentation\\documentation_agentic-rag-camelai-discord\\_documentation_agentic-rag-camelai-discord_.md",
      "collection_context": "Qdrant/qdrant_documentation"
    }
  }
]
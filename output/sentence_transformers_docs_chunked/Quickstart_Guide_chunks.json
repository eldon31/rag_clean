[
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Quickstart_Guide.md:chunk:0",
    "content": "This guide provides essential examples for getting started with the three core model types in sentence-transformers: **SentenceTransformer** for dense embeddings, **SparseEncoder** for sparse embeddings, and **CrossEncoder** for reranking. Each model type serves different use cases in natural language processing and information retrieval systems.\n\nFor installation instructions, see [Installation & Setup](#2). For detailed training information, see [Training](#3). For comprehensive usage documentation, see the specific model sections: [SentenceTransformer Models](#5.1), [SparseEncoder Models](#5.2), and [CrossEncoder Models](#5.3).\n\n## Core Model Types Overview\n\nThe sentence-transformers library provides three main model architectures that complement each other in modern NLP workflows:\n\n```mermaid\ngraph TB\n    subgraph \"Core Classes\"\n        ST[\"SentenceTransformer<br/>sentence_transformers/SentenceTransformer.py\"]\n        SE[\"SparseEncoder<br/>sentence_transformers/sparse_encoder/SparseEncoder.py\"]",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Quickstart_Guide.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Quickstart_Guide.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "token_count": 200,
      "char_count": 1013,
      "start_char": 0,
      "end_char": 1014
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Quickstart_Guide.md:chunk:1",
    "content": "nsformer.py\"]\n        SE[\"SparseEncoder<br/>sentence_transformers/sparse_encoder/SparseEncoder.py\"]\n        CE[\"CrossEncoder<br/>sentence_transformers/cross_encoder/CrossEncoder.py\"]\n    end\n    \n    subgraph \"Output Types\"\n        ST --> Dense[\"Dense Vectors<br/>[batch_size, embedding_dim]\"]\n        SE --> Sparse[\"Sparse Vectors<br/>[batch_size, vocab_size]\"]\n        CE --> Scores[\"Similarity Scores<br/>[batch_size] or [batch_size, num_labels]\"]\n    end\n    \n    subgraph \"Primary Use Cases\"\n        Dense --> SemanticSearch[\"Semantic Search<br/>Clustering<br/>Similarity\"]\n        Sparse --> LexicalSearch[\"Neural Lexical Search<br/>Hybrid Retrieval\"]\n        Scores --> Reranking[\"Reranking<br/>Classification\"]\n    end\n```\n\n**Sources:** [sentence_transformers/SentenceTransformer.py:61](), [sentence_transformers/sparse_encoder/SparseEncoder.py:27](), [sentence_transformers/cross_encoder/CrossEncoder.py:48](), [README.md:15-17]()\n\n## SentenceTransformer: Dense Embeddings",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Quickstart_Guide.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Quickstart_Guide.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "token_count": 243,
      "char_count": 981,
      "start_char": 914,
      "end_char": 1897
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Quickstart_Guide.md:chunk:2",
    "content": "cross_encoder/CrossEncoder.py:48](), [README.md:15-17]()\n\n## SentenceTransformer: Dense Embeddings\n\n`SentenceTransformer` models encode text into fixed-size dense vector representations, ideal for semantic similarity tasks and vector databases.\n\n### Basic Usage\n\n```python\nfrom sentence_transformers import SentenceTransformer\n\n# Load a pre-trained model\nmodel = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n# Encode sentences into dense vectors\nsentences = [\n    \"The weather is lovely today.\",\n    \"It's so sunny outside!\",\n    \"He drove to the stadium.\",\n]\nembeddings = model.encode(sentences)\nprint(embeddings.shape)\n# (3, 384)\n\n# Calculate similarity scores\nsimilarities = model.similarity(embeddings, embeddings)\nprint(similarities)\n# tensor([[1.0000, 0.6660, 0.1046],\n#         [0.6660, 1.0000, 0.1411],\n#         [0.1046, 0.1411, 1.0000]])\n```\n\n### Specialized Encoding Methods\n\nFor information retrieval tasks, use task-specific encoding methods:\n\n```python",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Quickstart_Guide.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Quickstart_Guide.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "token_count": 267,
      "char_count": 962,
      "start_char": 1797,
      "end_char": 2821
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Quickstart_Guide.md:chunk:3",
    "content": "-specific encoding methods:\n\n```python",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Quickstart_Guide.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Quickstart_Guide.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "token_count": 6,
      "char_count": 38,
      "start_char": 2721,
      "end_char": 3745
    }
  }
]
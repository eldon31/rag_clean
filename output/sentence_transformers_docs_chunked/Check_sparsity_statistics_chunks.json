[
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Check_sparsity_statistics.md:chunk:0",
    "content": "stats = SparseEncoder.sparsity(sparse_embeddings)\nprint(f\"Sparsity: {stats['sparsity_ratio']:.2%}\")\n```\n\n```python\n# CrossEncoder - Pairwise scoring and ranking\nfrom sentence_transformers import CrossEncoder\n\nmodel = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L6-v2\")\n\n# Predict similarity scores\nquery = \"What is machine learning?\"\npassages = [\"ML is a subset of AI\", \"Weather prediction models\"]\nscores = model.predict([(query, passage) for passage in passages])\n\n# Rank passages by relevance\nranked_results = model.rank(query, passages, return_documents=True)\n```\n\n### Model Organization and Naming\n\n| Model Source | Loading Pattern | Example |\n|---|---|---|\n| Official sentence-transformers | Direct name | `SentenceTransformer(\"all-mpnet-base-v2\")` |\n| Community models | Full path | `SentenceTransformer(\"BAAI/bge-large-en\")` |\n| Organization-specific | Org/model format | `SparseEncoder(\"naver/splade-cocondenser-ensembledistil\")` |\n\n**Sources:** [README.md:58-167](), [index.",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Check_sparsity_statistics.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Check_sparsity_statistics.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "token_count": 247,
      "char_count": 984,
      "start_char": 0,
      "end_char": 984
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Check_sparsity_statistics.md:chunk:1",
    "content": "rseEncoder(\"naver/splade-cocondenser-ensembledistil\")` |\n\n**Sources:** [README.md:58-167](), [index.rst:37-132](), [docs/sentence_transformer/pretrained_models.md:16-27]()\n\n## Model Versioning and Evolution\n\nThe library maintains version histories for major model series to track improvements over time:\n\n```mermaid\ngraph TD\n    subgraph \"MSMARCO Evolution\"\n        V1[\"v1: Initial Models<br/>MultipleNegativesRankingLoss<br/>In-batch negatives\"]\n        V2[\"v2: Improved Training<br/>Better hard negatives<br/>Performance gains\"]\n        V3[\"v3: Cross-Encoder Mining<br/>electra-base cross-encoder<br/>Hard negative mining\"]\n        V5[\"v5: Normalized + MarginMSE<br/>normalized_embeddings<br/>MarginMSE loss\"]\n    end\n    \n    V1 --> V2\n    V2 --> V3\n    V3 --> V5\n    \n    subgraph \"Performance Trends\"\n        P1[\"MRR@10: ~23\"]\n        P2[\"MRR@10: ~29\"] \n        P3[\"MRR@10: ~33\"]\n        P5[\"MRR@10: ~37\"]\n    end\n    \n    V1 --> P1\n    V2 --> P2\n    V3 --> P3\n    V5 --> P5\n```",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Check_sparsity_statistics.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Check_sparsity_statistics.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "token_count": 318,
      "char_count": 983,
      "start_char": 884,
      "end_char": 1869
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Check_sparsity_statistics.md:chunk:2",
    "content": "P5[\"MRR@10: ~37\"]\n    end\n    \n    V1 --> P1\n    V2 --> P2\n    V3 --> P3\n    V5 --> P5\n```\n\n**Sources:** [docs/pretrained-models/msmarco-v1.md:10-11](), [docs/pretrained-models/msmarco-v3.md:53-58](), [docs/pretrained-models/msmarco-v5.md:53-65]()\n\nEach version incorporates training improvements, better negative sampling strategies, and architectural refinements that progressively enhance model performance on downstream tasks.\n\n# SentenceTransformer Models\n\n\n\n\nThis page provides a comprehensive guide to pretrained SentenceTransformer models for dense text embeddings. SentenceTransformer models encode text into fixed-size vector representations that capture semantic meaning, enabling applications like semantic search, clustering, and similarity comparison.\n\nFor sparse embedding models, see [SparseEncoder Models](#5.2). For pairwise scoring models, see [CrossEncoder Models](#5.3). For MSMARCO-specific models, see [MSMARCO Models](#5.4).\n\n## Model Architecture Overview",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Check_sparsity_statistics.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Check_sparsity_statistics.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "token_count": 238,
      "char_count": 980,
      "start_char": 1769,
      "end_char": 2759
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Check_sparsity_statistics.md:chunk:3",
    "content": "s](#5.3). For MSMARCO-specific models, see [MSMARCO Models](#5.4).\n\n## Model Architecture Overview\n\nSentenceTransformer models generate dense embeddings by combining transformer layers with pooling mechanisms:\n\n```mermaid\ngraph LR\n    subgraph \"SentenceTransformer Architecture\"\n        Input[\"Input Text\"] --> Tokenizer[\"AutoTokenizer\"]\n        Tokenizer --> Transformer[\"Transformer Module\"]\n        Transformer --> Pooling[\"Pooling Module\"]\n        Pooling --> Normalize[\"Normalize (Optional)\"]\n        Normalize --> Output[\"Dense Embeddings\"]\n    end\n    \n    subgraph \"Core Components\"\n        ST[\"SentenceTransformer\"] --> TF[\"sentence_transformers.models.Transformer\"]\n        ST --> PL[\"sentence_transformers.models.Pooling\"]\n        ST --> NM[\"sentence_transformers.models.Normalize\"]\n    end\n```\n\nThe `SentenceTransformer` class in [sentence_transformers/SentenceTransformer.py:61-163]() serves as the main interface, orchestrating sequential modules to transform text into embeddings.",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Check_sparsity_statistics.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Check_sparsity_statistics.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "token_count": 205,
      "char_count": 995,
      "start_char": 2659,
      "end_char": 3656
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Check_sparsity_statistics.md:chunk:4",
    "content": "serves as the main interface, orchestrating sequential modules to transform text into embeddings.\n\nSources: [sentence_transformers/SentenceTransformer.py:61-163](), [sentence_transformers/models/Transformer.py](), [sentence_transformers/models/Pooling.py]()\n\n## Model Categories\n\n### General Purpose Models\n\n**All-series Models**: Trained on diverse datasets (1B+ training pairs) for broad applicability.\n\n| Model | Dimensions | Speed (GPU/CPU) | Performance | Use Case |\n|-------|------------|-----------------|-------------|----------|\n| `all-mpnet-base-v2` | 768 | 2,800 / 170 | 67.97 | Best quality |\n| `all-MiniLM-L6-v2` | 384 | 14,200 / 750 | 64.82 | Balanced speed/quality |\n| `all-MiniLM-L12-v2` | 384 | 7,500 / 400 | 66.01 | Higher quality MiniLM |\n\n**Paraphrase Models**: Optimized for sentence similarity and paraphrase detection.\n\n| Model | Base Architecture | Training Data | Performance |\n|-------|------------------|---------------|-------------|",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Check_sparsity_statistics.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Check_sparsity_statistics.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "token_count": 274,
      "char_count": 961,
      "start_char": 3556,
      "end_char": 4519
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Check_sparsity_statistics.md:chunk:5",
    "content": "itecture | Training Data | Performance |\n|-------|------------------|---------------|-------------|\n| `paraphrase-mpnet-base-v2` | MPNet | Multi-domain paraphrases | 67.97 |\n| `paraphrase-MiniLM-L6-v2` | MiniLM | Efficient paraphrase model | 64.82 |\n| `paraphrase-distilroberta-base-v2` | DistilRoBERTa | RoBERTa-based paraphrase | 66.27 |\n\nSources: [docs/_static/html/models_en_sentence_embeddings.html:342-355](), [docs/sentence_transformer/pretrained_models.md:41-49]()\n\n### Semantic Search Models\n\nSpecialized for query-document retrieval tasks:\n\n```mermaid\ngraph TB\n    subgraph \"Multi-QA Models\"\n        MQ1[\"multi-qa-mpnet-base-cos-v1<br/>57.46 performance<br/>4,000 qps\"]\n        MQ2[\"multi-qa-distilbert-cos-v1<br/>52.83 performance<br/>7,000 qps\"] \n        MQ3[\"multi-qa-MiniLM-L6-cos-v1<br/>51.83 performance<br/>18,000 qps\"]\n    end\n    \n    subgraph \"MSMARCO Models\"\n        MS1[\"msmarco-bert-base-dot-v5<br/>38.08 MRR@10<br/>4,000 qps\"]\n        MS2[\"msmarco-distilbert-dot-v5<br/>37.25 MRR@10<br/>7,000 qps\"]",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Check_sparsity_statistics.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Check_sparsity_statistics.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "token_count": 361,
      "char_count": 1022,
      "start_char": 4419,
      "end_char": 5442
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Check_sparsity_statistics.md:chunk:6",
    "content": "8.08 MRR@10<br/>4,000 qps\"]\n        MS2[\"msmarco-distilbert-dot-v5<br/>37.25 MRR@10<br/>7,000 qps\"]\n        MS3[\"msmarco-distilbert-cos-v5<br/>33.79 MRR@10<br/>7,000 qps\"]\n    end\n    \n    subgraph \"Usage Patterns\"\n        Query[\"encode_query()\"] --> MQ1\n        Documents[\"encode_document()\"] --> MQ1\n        MQ1 --> Similarity[\"similarity()\"]\n    end\n```\n\n**Multi-QA Models** are trained on 215M+ question-answer pairs from diverse sources. **MSMARCO Models** are trained on Bing search queries with web passages.\n\nSources: [docs/sentence_transformer/pretrained_models.md:84-124](), [docs/pretrained-models/msmarco-v5.md:29-44]()\n\n### Multilingual Models\n\nSupport 50+ languages with aligned vector spaces:\n\n| Model | Languages | Architecture | Use Case |\n|-------|-----------|--------------|----------|\n| `distiluse-base-multilingual-cased-v2` | 50+ | DistilUSE | General multilingual |\n| `paraphrase-multilingual-mpnet-base-v2` | 50+ | MPNet | High-quality multilingual |",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Check_sparsity_statistics.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Check_sparsity_statistics.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "token_count": 307,
      "char_count": 974,
      "start_char": 5342,
      "end_char": 6317
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Check_sparsity_statistics.md:chunk:7",
    "content": "ultilingual |\n| `paraphrase-multilingual-mpnet-base-v2` | 50+ | MPNet | High-quality multilingual |\n| `LaBSE` | 109 | BERT | Bitext mining/translation |\n\nSources: [docs/sentence_transformer/pretrained_models.md:128-144]()\n\n## Model Selection Guide\n\n```mermaid\nflowchart TD\n    Start[\"Model Selection\"] --> Task{\"Task Type?\"}\n    \n    Task -->|\"General Purpose\"| Speed{\"Speed vs Quality?\"}\n    Task -->|\"Semantic Search\"| Domain{\"Domain?\"}\n    Task -->|\"Multilingual\"| Languages{\"Language Count?\"}\n    \n    Speed -->|\"Best Quality\"| MPNet[\"all-mpnet-base-v2\"]\n    Speed -->|\"Balanced\"| MiniLM6[\"all-MiniLM-L6-v2\"]\n    Speed -->|\"Fastest\"| MiniLM3[\"paraphrase-MiniLM-L3-v2\"]\n    \n    Domain -->|\"Web Search\"| MSMARCO[\"msmarco-distilbert-dot-v5\"]\n    Domain -->|\"QA Diverse\"| MultiQA[\"multi-qa-mpnet-base-cos-v1\"]\n    Domain -->|\"Scientific\"| Specter[\"allenai-specter\"]\n    \n    Languages -->|\"15 Major\"| DistilUSE1[\"distiluse-base-multilingual-cased-v1\"]",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Check_sparsity_statistics.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Check_sparsity_statistics.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "token_count": 287,
      "char_count": 952,
      "start_char": 6217,
      "end_char": 7170
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Check_sparsity_statistics.md:chunk:8",
    "content": "nai-specter\"]\n    \n    Languages -->|\"15 Major\"| DistilUSE1[\"distiluse-base-multilingual-cased-v1\"]\n    Languages -->|\"50+\"| DistilUSE2[\"distiluse-base-multilingual-cased-v2\"]\n    Languages -->|\"Translation\"| LaBSE[\"LaBSE\"]\n```\n\n### Performance Considerations\n\n**Embedding Dimensions**: Higher dimensions generally provide better quality but require more storage and compute:\n- 384-dim: Efficient for most applications\n- 768-dim: Better quality for complex tasks\n- 1024-dim: Highest quality for specialized domains\n\n**Normalization**: Models with normalized embeddings enable efficient dot-product similarity:\n- Normalized: Use `util.dot_score()` for fastest similarity\n- Non-normalized: Use `util.cos_sim()` for cosine similarity\n\nSources: [docs/_static/html/models_en_sentence_embeddings.html:184-202](), [sentence_transformers/SentenceTransformer.py:139-163]()\n\n## Loading and Usage Patterns\n\n### Basic Model Loading\n\n```python\nfrom sentence_transformers import SentenceTransformer",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Check_sparsity_statistics.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Check_sparsity_statistics.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "token_count": 239,
      "char_count": 984,
      "start_char": 7070,
      "end_char": 8094
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Check_sparsity_statistics.md:chunk:9",
    "content": "python\nfrom sentence_transformers import SentenceTransformer",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Check_sparsity_statistics.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Check_sparsity_statistics.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "token_count": 9,
      "char_count": 60,
      "start_char": 7994,
      "end_char": 9018
    }
  }
]
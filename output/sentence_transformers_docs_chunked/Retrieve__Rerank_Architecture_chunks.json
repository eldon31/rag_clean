[
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md:chunk:0",
    "content": "This document explains the two-stage retrieval architecture that combines bi-encoders (`SentenceTransformer`) for efficient retrieval with cross-encoders (`CrossEncoder`) for high-precision reranking. This approach balances computational efficiency with ranking quality by leveraging the strengths of both model types.\n\nFor information about individual model types, see [SentenceTransformer Models](#5.1) and [CrossEncoder Models](#5.3). For basic semantic search implementations, see [Semantic Search](#6.1).\n\n## Architecture Overview\n\nThe retrieve & rerank architecture consists of two sequential stages that process user queries against a document corpus:\n\n```mermaid\ngraph TB\n    subgraph \"Input\"\n        Query[\"User Query\"]\n        Corpus[\"Document Corpus\"]\n    end\n    \n    subgraph \"Stage 1: Retrieval\"\n        ST[\"SentenceTransformer<br/>(Bi-Encoder)\"]\n        QueryEmb[\"Query Embedding\"]\n        DocEmbs[\"Document Embeddings<br/>(Pre-computed)\"]\n        VectorSearch[\"Vector Similarity Search\"]",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Retrieve__Rerank_Architecture.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "token_count": 208,
      "char_count": 1003,
      "start_char": 0,
      "end_char": 1004
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md:chunk:1",
    "content": "DocEmbs[\"Document Embeddings<br/>(Pre-computed)\"]\n        VectorSearch[\"Vector Similarity Search\"]\n        TopK[\"Top-K Candidates<br/>(e.g., k=100)\"]\n    end\n    \n    subgraph \"Stage 2: Reranking\" \n        CE[\"CrossEncoder\"]\n        Pairs[\"Query-Document Pairs\"]\n        Scores[\"Relevance Scores\"]\n        FinalRank[\"Final Ranking<br/>(e.g., top-10)\"]\n    end\n    \n    Query --> ST\n    ST --> QueryEmb\n    Corpus --> DocEmbs\n    QueryEmb --> VectorSearch\n    DocEmbs --> VectorSearch\n    VectorSearch --> TopK\n    \n    Query --> Pairs\n    TopK --> Pairs\n    Pairs --> CE\n    CE --> Scores\n    Scores --> FinalRank\n```\n\n**Two-Stage Retrieve & Rerank Pipeline**\n\nThis architecture optimizes the trade-off between efficiency and quality. The `SentenceTransformer` handles the computationally expensive task of searching through millions of documents efficiently, while the `CrossEncoder` provides more accurate scoring for a smaller set of candidates.\n\nSources: [docs/pretrained-models/msmarco-v3.",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Retrieve__Rerank_Architecture.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "token_count": 249,
      "char_count": 994,
      "start_char": 904,
      "end_char": 1899
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md:chunk:2",
    "content": "more accurate scoring for a smaller set of candidates.\n\nSources: [docs/pretrained-models/msmarco-v3.md:54-58](), [docs/cross_encoder/pretrained_models.md:44](), [docs/pretrained-models/ce-msmarco.md:36-48]()\n\n## Retrieval Stage: SentenceTransformer\n\nThe first stage uses a `SentenceTransformer` model to encode queries and documents into dense vector embeddings. This bi-encoder approach processes queries and documents independently, enabling efficient pre-computation and fast similarity search.\n\n```mermaid\ngraph LR\n    subgraph \"SentenceTransformer Models\"\n        MiniLM[\"msmarco-MiniLM-L6-v3\"]\n        DistilBERT[\"msmarco-distilbert-base-v3\"] \n        RoBERTa[\"msmarco-roberta-base-v3\"]\n    end\n    \n    subgraph \"Encoding Process\"\n        QueryEncode[\"model.encode(query)\"]\n        DocEncode[\"model.encode(documents)\"]\n        CosineSim[\"util.cos_sim()\"]\n        DotProduct[\"util.dot_score()\"]\n    end\n    \n    subgraph \"Similarity Functions\"\n        CosineModels[\"Cosine Similarity Models\"]",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Retrieve__Rerank_Architecture.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "token_count": 246,
      "char_count": 998,
      "start_char": 1799,
      "end_char": 2798
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md:chunk:3",
    "content": "]\n    end\n    \n    subgraph \"Similarity Functions\"\n        CosineModels[\"Cosine Similarity Models\"]\n        DotProdModels[\"Dot Product Models\"]\n    end\n    \n    MiniLM --> CosineModels\n    DistilBERT --> CosineModels\n    RoBERTa --> CosineModels\n    \n    CosineModels --> CosineSim\n    DotProdModels --> DotProduct\n    \n    QueryEncode --> CosineSim\n    DocEncode --> CosineSim\n```\n\n**SentenceTransformer Retrieval Components**\n\n### Model Selection for Retrieval\n\nThe choice of retrieval model depends on similarity function and performance requirements:\n\n| Model | NDCG@10 (TREC DL 19) | MRR@10 (MS Marco Dev) | Similarity Function |\n|-------|---------------------|----------------------|-------------------|\n| `msmarco-MiniLM-L6-v3` | 67.46 | 32.27 | Cosine |\n| `msmarco-distilbert-base-v3` | 69.02 | 33.13 | Cosine |\n| `msmarco-distilbert-base-v4` | 70.24 | 33.79 | Cosine |\n| `msmarco-distilbert-base-dot-prod-v3` | 68.42 | 33.04 | Dot Product |",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Retrieve__Rerank_Architecture.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "token_count": 292,
      "char_count": 949,
      "start_char": 2698,
      "end_char": 3649
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md:chunk:4",
    "content": "| 70.24 | 33.79 | Cosine |\n| `msmarco-distilbert-base-dot-prod-v3` | 68.42 | 33.04 | Dot Product |\n\nModels tuned for cosine similarity prefer shorter passages, while dot-product models prefer longer passages.\n\nSources: [docs/pretrained-models/msmarco-v3.md:27-48](), [docs/pretrained-models/msmarco-v3.md:6-16]()\n\n## Reranking Stage: CrossEncoder\n\nThe second stage uses a `CrossEncoder` model to perform joint encoding of query-document pairs, producing more accurate relevance scores for the top-k candidates from the retrieval stage.\n\n```mermaid\ngraph TB\n    subgraph \"CrossEncoder Models\"\n        TinyBERT[\"cross-encoder/ms-marco-TinyBERT-L2-v2\"]\n        MiniLMSmall[\"cross-encoder/ms-marco-MiniLM-L2-v2\"]\n        MiniLMBase[\"cross-encoder/ms-marco-MiniLM-L6-v2\"]\n        Electra[\"cross-encoder/ms-marco-electra-base\"]\n    end\n    \n    subgraph \"Reranking Process\"\n        Pairs[\"(query, document) pairs\"]\n        CrossEncode[\"model.predict(pairs)\"]\n        Sigmoid[\"torch.nn.Sigmoid()\"]",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Retrieve__Rerank_Architecture.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "token_count": 281,
      "char_count": 990,
      "start_char": 3549,
      "end_char": 4540
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md:chunk:5",
    "content": "document) pairs\"]\n        CrossEncode[\"model.predict(pairs)\"]\n        Sigmoid[\"torch.nn.Sigmoid()\"]\n        RelevanceScores[\"Relevance Scores 0-1\"]\n        Ranking[\"Final Ranking\"]\n    end\n    \n    subgraph \"Performance Metrics\"\n        Speed[\"Processing Speed<br/>(docs/sec)\"]\n        Quality[\"Ranking Quality<br/>(NDCG@10)\"]\n    end\n    \n    TinyBERT --> Speed\n    MiniLMBase --> Quality\n    \n    Pairs --> CrossEncode\n    CrossEncode --> Sigmoid\n    Sigmoid --> RelevanceScores\n    RelevanceScores --> Ranking\n```\n\n**CrossEncoder Reranking Pipeline**\n\n### Model Selection for Reranking\n\nCrossEncoder models provide different speed-quality trade-offs:\n\n| Model | NDCG@10 (TREC DL 19) | MRR@10 (MS Marco Dev) | Docs/Sec |\n|-------|---------------------|----------------------|----------|\n| `cross-encoder/ms-marco-TinyBERT-L2-v2` | 69.84 | 32.56 | 9000 |\n| `cross-encoder/ms-marco-MiniLM-L6-v2` | 74.30 | 39.01 | 1800 |\n| `cross-encoder/ms-marco-MiniLM-L12-v2` | 74.31 | 39.02 | 960 |",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Retrieve__Rerank_Architecture.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "token_count": 310,
      "char_count": 985,
      "start_char": 4440,
      "end_char": 5426
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md:chunk:6",
    "content": "LM-L6-v2` | 74.30 | 39.01 | 1800 |\n| `cross-encoder/ms-marco-MiniLM-L12-v2` | 74.31 | 39.02 | 960 |\n| `cross-encoder/ms-marco-electra-base` | 71.99 | 36.41 | 340 |\n\nThe `cross-encoder/ms-marco-MiniLM-L6-v2` model provides the best balance of quality and speed for most applications.\n\nSources: [docs/cross_encoder/pretrained_models.md:35-43](), [docs/pretrained-models/ce-msmarco.md:41-53]()\n\n## Training Data Integration\n\nThe MSMARCO v3 models demonstrate how retrieve & rerank architectures are used during training to improve model quality:\n\n```mermaid\ngraph TD\n    subgraph \"Training Pipeline\"\n        V2Models[\"MSMARCO v2 Models\"]\n        BiEncoder[\"Bi-Encoder Retrieval\"]\n        CrossEncoderScore[\"Cross-Encoder Scoring\"]\n        HardNegatives[\"Hard Negatives\"]\n        V3Training[\"V3 Model Training\"]\n    end\n    \n    subgraph \"Hard Negative Mining\"\n        HighBiScore[\"High Bi-Encoder Score\"]\n        LowCrossScore[\"Low Cross-Encoder Score\"]\n        SaveNegative[\"Save as Hard Negative\"]\n    end",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Retrieve__Rerank_Architecture.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "token_count": 303,
      "char_count": 1004,
      "start_char": 5326,
      "end_char": 6336
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md:chunk:7",
    "content": "LowCrossScore[\"Low Cross-Encoder Score\"]\n        SaveNegative[\"Save as Hard Negative\"]\n    end\n    \n    V2Models --> BiEncoder\n    BiEncoder --> CrossEncoderScore\n    CrossEncoderScore --> HighBiScore\n    CrossEncoderScore --> LowCrossScore\n    HighBiScore --> SaveNegative\n    LowCrossScore --> SaveNegative\n    SaveNegative --> HardNegatives\n    HardNegatives --> V3Training\n```\n\n**Hard Negative Mining in MSMARCO v3 Training**\n\nThis process identifies passages that receive high scores from the bi-encoder but low scores from the (more accurate) cross-encoder, creating challenging training examples that improve model quality.\n\nSources: [docs/pretrained-models/msmarco-v3.md:53-58]()\n\n## Performance Characteristics\n\nThe retrieve & rerank architecture provides several performance advantages:\n\n### Computational Efficiency\n- **Pre-computation**: Document embeddings are computed once and stored\n- **Fast Retrieval**: Vector similarity search scales to millions of documents",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Retrieve__Rerank_Architecture.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "token_count": 208,
      "char_count": 977,
      "start_char": 6236,
      "end_char": 7216
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md:chunk:8",
    "content": "ed once and stored\n- **Fast Retrieval**: Vector similarity search scales to millions of documents  \n- **Selective Reranking**: Only top-k candidates require expensive cross-encoder processing\n\n### Quality Improvements\n- **Broader Recall**: Bi-encoders capture semantic similarity across large corpora\n- **Precise Ranking**: Cross-encoders provide accurate relevance scoring for final results\n- **Hard Negative Training**: Improved training data quality through cross-encoder feedback\n\n### Typical Configuration\n- **Retrieval**: Return top-100 to top-1000 candidates\n- **Reranking**: Score and return top-10 to top-20 final results\n- **Latency**: ~10-50ms for retrieval + ~50-200ms for reranking\n\nSources: [docs/pretrained-models/msmarco-v3.md:27-50](), [docs/cross_encoder/pretrained_models.md:35-43]()\n\n## Implementation Considerations\n\n### Model Compatibility\nBoth retrieval and reranking models should be trained on similar datasets (e.g., MSMARCO) to ensure consistent relevance understanding.\n\n### Activation Functions",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Retrieve__Rerank_Architecture.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "token_count": 246,
      "char_count": 1023,
      "start_char": 7116,
      "end_char": 8140
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md:chunk:9",
    "content": "ar datasets (e.g., MSMARCO) to ensure consistent relevance understanding.\n\n### Activation Functions\nCrossEncoder models may require specific activation functions: `activation_fn=torch.nn.Sigmoid()` ensures scores are normalized between 0 and 1.\n\n### Similarity Functions\nEnsure consistency between training and inference similarity functions (cosine vs. dot product) for optimal performance.\n\nSources: [docs/cross_encoder/pretrained_models.md:17-33](), [docs/pretrained-models/msmarco-v3.md:46-47]()",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Retrieve__Rerank_Architecture.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Retrieve__Rerank_Architecture.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "token_count": 111,
      "char_count": 499,
      "start_char": 8040,
      "end_char": 9064
    }
  }
]
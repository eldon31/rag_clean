[
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\..._populate_matrices_....md:chunk:0",
    "content": "loss = self.cross_entropy_loss(logits_matrix, labels_matrix.softmax(dim=1))\n```\n\nSources: [sentence_transformers/cross_encoder/losses/ListNetLoss.py:10-198]()\n\n### Position-Aware ListMLE\n\nThe `PListMLELoss` and `ListMLELoss` implement maximum likelihood estimation for permutations with optional position-aware weighting:\n\n```python\n# Core PListMLE computation from PListMLELoss.forward()\nscores = sorted_logits.exp()\ncumsum_scores = torch.flip(torch.cumsum(torch.flip(scores, [1]), 1), [1])\nlog_probs = sorted_logits - torch.log(cumsum_scores + self.eps)\n\nif self.lambda_weight is not None:\n    lambda_weight = self.lambda_weight(mask)\n    log_probs = log_probs * lambda_weight\n```\n\nSources: [sentence_transformers/cross_encoder/losses/PListMLELoss.py:45-295](), [sentence_transformers/cross_encoder/losses/ListMLELoss.py:9-127]()\n\n## Common Implementation Patterns\n\nAll learning-to-rank losses share several implementation patterns:\n\n### Mini-Batch Processing",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "..._populate_matrices_....md",
      "file_extension": ".md",
      "chunk_index": 0,
      "token_count": 234,
      "char_count": 961,
      "start_char": 0,
      "end_char": 963
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\..._populate_matrices_....md:chunk:1",
    "content": "rns\n\nAll learning-to-rank losses share several implementation patterns:\n\n### Mini-Batch Processing\n\nLarge document lists are processed in mini-batches to manage memory usage:\n\n```python\nmini_batch_size = self.mini_batch_size or batch_size\nif mini_batch_size <= 0:\n    mini_batch_size = len(pairs)\n\nfor i in range(0, len(pairs), mini_batch_size):\n    mini_batch_pairs = pairs[i : i + mini_batch_size]\n    # Process mini-batch...\n```\n\n### Padding Handling\n\nVariable document counts per query are handled using padding and masking:\n\n```python\n# Create padded matrices\nlogits_matrix = torch.full((batch_size, max_docs), -1e16, device=self.model.device)\nlabels_matrix = torch.full_like(logits_matrix, float(\"-inf\"))\n\n# Place valid logits and labels\ndoc_indices = torch.cat([torch.arange(len(docs)) for docs in docs_list], dim=0)\nbatch_indices = torch.repeat_interleave(torch.arange(batch_size), torch.tensor(docs_per_query))\nlogits_matrix[batch_indices, doc_indices] = logits\n```",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "..._populate_matrices_....md",
      "file_extension": ".md",
      "chunk_index": 1,
      "token_count": 227,
      "char_count": 974,
      "start_char": 863,
      "end_char": 1839
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\..._populate_matrices_....md:chunk:2",
    "content": "(batch_size), torch.tensor(docs_per_query))\nlogits_matrix[batch_indices, doc_indices] = logits\n```\n\nSources: [sentence_transformers/cross_encoder/losses/LambdaLoss.py:247-287](), [sentence_transformers/cross_encoder/losses/ListNetLoss.py:132-176]()\n\n## Configuration and Usage\n\n### Basic Usage Pattern\n\n```python\nfrom sentence_transformers.cross_encoder import CrossEncoder, CrossEncoderTrainer, losses\nfrom datasets import Dataset\n\nmodel = CrossEncoder(\"microsoft/mpnet-base\")\ntrain_dataset = Dataset.from_dict({\n    \"query\": [\"What are pandas?\", \"What is the capital of France?\"],\n    \"docs\": [\n        [\"Pandas are a kind of bear.\", \"Pandas are kind of like fish.\"],\n        [\"The capital of France is Paris.\", \"Paris is quite large.\"],\n    ],\n    \"labels\": [[1, 0], [1, 0]],\n})",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\..._populate_matrices_....md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "..._populate_matrices_....md",
      "file_extension": ".md",
      "chunk_index": 2,
      "token_count": 205,
      "char_count": 781,
      "start_char": 1739,
      "end_char": 2763
    }
  }
]
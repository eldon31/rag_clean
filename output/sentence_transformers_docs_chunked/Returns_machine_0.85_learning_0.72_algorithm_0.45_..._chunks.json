[
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Returns_machine_0.85_learning_0.72_algorithm_0.45_....md:chunk:0",
    "content": "```\n\n**Sources:** [sentence_transformers/sparse_encoder/SparseEncoder.py:27-180](), [sentence_transformers/sparse_encoder/models/MLMTransformer.py](), [sentence_transformers/sparse_encoder/models/SpladePooling.py](), [tests/sparse_encoder/test_sparse_encoder.py:15-169]()\n\n## CrossEncoder\n\nThe `CrossEncoder` architecture differs fundamentally from the other two by taking pairs of texts as input and producing similarity scores rather than individual embeddings.\n\n### CrossEncoder Pipeline\n\n```mermaid\ngraph TB\n    subgraph \"CrossEncoder Architecture\"\n        Pairs[\"Text Pairs<br/>[(query, document), ...]\"]\n        TokenizerCE[\"AutoTokenizer<br/>Joint encoding\"]\n        ModelCE[\"AutoModelForSequenceClassification\"]\n        Activation[\"Activation Function<br/>(Sigmoid/Identity)\"]\n        ScoresOut[\"Similarity Scores\"]\n    end\n    \n    subgraph \"Key Methods\"\n        Predict[\"predict()<br/>Score pairs\"]\n        Rank[\"rank()<br/>Rank documents\"]\n    end\n    \n    Pairs --> TokenizerCE\n    TokenizerCE --> ModelCE",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Returns_machine_0.85_learning_0.72_algorithm_0.45_....md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Returns_machine_0.85_learning_0.72_algorithm_0.45_....md",
      "file_extension": ".md",
      "chunk_index": 0,
      "token_count": 235,
      "char_count": 1017,
      "start_char": 0,
      "end_char": 1018
    }
  },
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Returns_machine_0.85_learning_0.72_algorithm_0.45_....md:chunk:1",
    "content": "ank[\"rank()<br/>Rank documents\"]\n    end\n    \n    Pairs --> TokenizerCE\n    TokenizerCE --> ModelCE\n    ModelCE --> Activation\n    Activation --> ScoresOut\n    \n    ScoresOut --> Predict\n    ScoresOut --> Rank\n```\n\n### Architecture Characteristics\n\n- **No Individual Embeddings**: Cannot encode single texts independently\n- **Joint Processing**: Both texts processed together through transformer layers\n- **Classification Head**: Uses sequence classification architecture\n- **Configurable Labels**: Supports regression (`num_labels=1`) or multi-class classification\n- **Higher Accuracy**: Generally more accurate than bi-encoder approaches for pairwise tasks\n\n### Usage in Retrieve-Rerank Pipeline\n\n```python",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Returns_machine_0.85_learning_0.72_algorithm_0.45_....md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Returns_machine_0.85_learning_0.72_algorithm_0.45_....md",
      "file_extension": ".md",
      "chunk_index": 1,
      "token_count": 141,
      "char_count": 708,
      "start_char": 918,
      "end_char": 1942
    }
  }
]
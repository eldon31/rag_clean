[
  {
    "chunk_id": "sentence_transformers_docs:UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md:chunk:0",
    "content": "cosine_similarity = util.cos_sim(query_embedding, passage_embedding)\ndot_product_similarity = util.dot_score(query_embedding, passage_embedding)\n\nprint(\"Cosine similarity:\", cosine_similarity)\n```\n\n### Cross-Encoder Model Usage\n\n```python\nfrom sentence_transformers import CrossEncoder\nimport torch\n\n# Load cross-encoder with sigmoid activation for 0-1 scores\nmodel = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L6-v2\", activation_fn=torch.nn.Sigmoid())\n\n# Score query-passage pairs\nscores = model.predict([\n    (\"How big is London\", \"London has 9,787,426 inhabitants at the 2011 census\"),\n    (\"How big is London\", \"London is well known for its museums\")\n])\n# Returns array([0.9998173, 0.01312432], dtype=float32)\n```\n\n### Batch Processing for Production\n\n```python",
    "metadata": {
      "source_file": "UKPLab\\sentence-transformers\\Calculate_similarity_choose_based_on_model_optimization.md",
      "source_collection": "sentence_transformers_docs",
      "subdirectory": "UKPLab",
      "filename": "Calculate_similarity_choose_based_on_model_optimization.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "token_count": 199,
      "char_count": 766,
      "start_char": 0,
      "end_char": 1024
    }
  }
]
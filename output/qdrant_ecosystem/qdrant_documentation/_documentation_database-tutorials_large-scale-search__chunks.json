{
  "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
  "source_repo": "qdrant_documentation",
  "total_chunks": 15,
  "chunks": [
    {
      "content": "Large Scale Search - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Getting Started\n\n[What is Qdrant?](https://qdrant.tech/documentation/overview/)\n\n- [Understanding Vector Search in Qdrant](https://qdrant.tech/documentation/overview/vector-search/)\n\n[Local Quickstart](https://qdrant.tech/documentation/quickstart/)\n\n[API & SDKs](https://qdrant.tech/documentation/interfaces/)\n\n[Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)\n\n### User Manual\n\n[Concepts](https://qdrant.tech/documentation/concepts/)\n\n- [Collections](https://qdrant.tech/documentation/concepts/collections/)\n- [Points](https://qdrant.tech/documentation/concepts/points/)\n- [Vectors](https://qdrant.tech/documentation/concepts/vectors/)\n- [Payload](https://qdrant.tech/documentation/concepts/payload/)\n- [Search](https://qdrant.tech/documentation/concepts/search/)\n- [Explore](https://qdrant.tech/documentation/concepts/explore/)\n- [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/)\n- [Filtering](https://qdrant.tech/documentation/concepts/filtering/)\n- [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/)\n- [Storage](https://qdrant.tech/documentation/concepts/storage/)\n- [Indexing](https://qdrant.tech/documentation/concepts/indexing/)\n- [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)\n\n[Guides](https://qdrant.tech/documentation/guides/installation/)\n\n- [Installation](https://qdrant.",
      "index": 0,
      "token_count": 528,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 0,
      "end_char": 2029
    },
    {
      "content": "[Guides](https://qdrant.tech/documentation/guides/installation/)\n\n- [Installation](https://qdrant.tech/documentation/guides/installation/)\n- [Administration](https://qdrant.tech/documentation/guides/administration/)\n- [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/)\n- [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/)\n- [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/)\n- [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)\n- [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)\n- [Quantization](https://qdrant.tech/documentation/guides/quantization/)\n- [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/)\n- [Configuration](https://qdrant.tech/documentation/guides/configuration/)\n- [Security](https://qdrant.tech/documentation/guides/security/)\n- [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/)\n- [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)\n\n### Ecosystem\n\n[FastEmbed](https://qdrant.tech/documentation/fastembed/)\n\n- [Quickstart](https://qdrant.tech/documentation/fastembed/fastembed-quickstart/)\n- [FastEmbed & Qdrant](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/)\n- [Working with miniCOIL](https://qdrant.tech/documentation/fastembed/fastembed-minicoil/)\n- [Working with SPLADE](https://qdrant.tech/documentation/fastembed/fastembed-splade/)\n- [Working with ColBERT](https://qdrant.tech/documentation/fastembed/fastembed-colbert/)\n- [Reranking with FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-rerankers/)\n\n[Qdrant MCP Server](https://github.com/qdrant/mcp-server-qdrant)\n\n### Tutorials\n\n[Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)\n\n- [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)\n- [Build a Neural Search Service](https://qdrant.",
      "index": 1,
      "token_count": 507,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 1929,
      "end_char": 3933
    },
    {
      "content": "ocumentation/beginner-tutorials/search-beginners/)\n- [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)\n- [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)\n- [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)\n\n[Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)\n\n- [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/)\n- [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/)\n- [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)\n- [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)\n- [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)\n\n[Using the Database](https://qdrant.tech/documentation/database-tutorials/)\n\n- [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)\n- [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)\n- [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)\n- [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)\n- [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/)\n- [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/)\n- [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)\n\n### Support\n\n[FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n\n- [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)",
      "index": 2,
      "token_count": 472,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 3833,
      "end_char": 5848
    },
    {
      "content": "fundamentals/)\n\n- [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n- [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)\n\n[Release Notes](https://github.com/qdrant/qdrant/releases)\n\n### Getting Started\n\n[What is Qdrant?](https://qdrant.tech/documentation/overview/)\n\n- [Understanding Vector Search in Qdrant](https://qdrant.tech/documentation/overview/vector-search/)\n\n[Local Quickstart](https://qdrant.tech/documentation/quickstart/)\n\n[API & SDKs](https://qdrant.tech/documentation/interfaces/)\n\n[Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)\n\n### User Manual\n\n[Concepts](https://qdrant.tech/documentation/concepts/)\n\n- [Collections](https://qdrant.tech/documentation/concepts/collections/)\n- [Points](https://qdrant.tech/documentation/concepts/points/)\n- [Vectors](https://qdrant.tech/documentation/concepts/vectors/)\n- [Payload](https://qdrant.tech/documentation/concepts/payload/)\n- [Search](https://qdrant.tech/documentation/concepts/search/)\n- [Explore](https://qdrant.tech/documentation/concepts/explore/)\n- [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/)\n- [Filtering](https://qdrant.tech/documentation/concepts/filtering/)\n- [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/)\n- [Storage](https://qdrant.tech/documentation/concepts/storage/)\n- [Indexing](https://qdrant.tech/documentation/concepts/indexing/)\n- [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)\n\n[Guides](https://qdrant.tech/documentation/guides/installation/)\n\n- [Installation](https://qdrant.tech/documentation/guides/installation/)\n- [Administration](https://qdrant.tech/documentation/guides/administration/)\n- [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/)\n- [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/)\n- [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/)\n- [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)",
      "index": 3,
      "token_count": 514,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 5748,
      "end_char": 7796
    },
    {
      "content": "n/guides/optimize/)\n- [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)\n- [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)\n- [Quantization](https://qdrant.tech/documentation/guides/quantization/)\n- [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/)\n- [Configuration](https://qdrant.tech/documentation/guides/configuration/)\n- [Security](https://qdrant.tech/documentation/guides/security/)\n- [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/)\n- [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)\n\n### Ecosystem\n\n[FastEmbed](https://qdrant.tech/documentation/fastembed/)\n\n- [Quickstart](https://qdrant.tech/documentation/fastembed/fastembed-quickstart/)\n- [FastEmbed & Qdrant](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/)\n- [Working with miniCOIL](https://qdrant.tech/documentation/fastembed/fastembed-minicoil/)\n- [Working with SPLADE](https://qdrant.tech/documentation/fastembed/fastembed-splade/)\n- [Working with ColBERT](https://qdrant.tech/documentation/fastembed/fastembed-colbert/)\n- [Reranking with FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-rerankers/)\n\n[Qdrant MCP Server](https://github.com/qdrant/mcp-server-qdrant)\n\n### Tutorials\n\n[Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)\n\n- [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)\n- [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)\n- [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)\n- [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)\n\n[Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)\n\n- [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.",
      "index": 4,
      "token_count": 501,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 7696,
      "end_char": 9693
    },
    {
      "content": "nced-tutorials/)\n\n- [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/)\n- [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/)\n- [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)\n- [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)\n- [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)\n\n[Using the Database](https://qdrant.tech/documentation/database-tutorials/)\n\n- [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)\n- [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)\n- [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)\n- [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)\n- [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/)\n- [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/)\n- [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)\n\n### Support\n\n[FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n\n- [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n- [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)\n\n[Release Notes](https://github.com/qdrant/qdrant/releases)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- [Database tutorials](https://qdrant.tech/documentation/database-tutorials/)\n-\n- Large Scale Search\n\n# Upload and Search Large collections cost-efficiently\n\n| Time: 2 days | Level: Advanced |   |   |\n| ------------ | --------------- | - | - |",
      "index": 5,
      "token_count": 480,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 9593,
      "end_char": 11626
    },
    {
      "content": "efficiently\n\n| Time: 2 days | Level: Advanced |   |   |\n| ------------ | --------------- | - | - |\n\nIn this tutorial, we will describe an approach to upload, index, and search a large volume of data cost-efficiently, on an example of the real-world dataset [LAION-400M](https://laion.ai/blog/laion-400-open-dataset/).\n\nThe goal of this tutorial is to demonstrate what minimal amount of resources is required to index and search a large dataset, while still maintaining a reasonable search latency and accuracy.\n\nAll relevant code snippets are available in the [GitHub repository](https://github.com/qdrant/laion-400m-benchmark).\n\nThe recommended Qdrant version for this tutorial is `v1.13.5` and higher.\n\n## Dataset\n\nThe dataset we will use is [LAION-400M](https://laion.ai/blog/laion-400-open-dataset/), a collection of approximately 400 million vectors obtained from images extracted from a Common Crawl dataset. Each vector is 512-dimensional and generated using a [CLIP](https://openai.com/blog/clip/) model.\n\nVectors are associated with a number of metadata fields, such as `url`, `caption`, `LICENSE`, etc.\n\nThe overall payload size is approximately 200 GB, and the vectors are 400 GB.\n\nDataset doesn't store images themselves, and only contain URLs to the image origin. By the time of writing, some of the URLs are already unavailable.\n\nThe dataset is available in the form of 409 chunks, each containing approximately 1M vectors. We will use the following [python script](https://github.com/qdrant/laion-400m-benchmark/blob/master/upload.py) to upload dataset chunks one by one.\n\n## Hardware\n\nAfter some initial experiments, we figured out a minimal hardware configuration for the task:\n\n- 8 CPU cores\n- 64Gb RAM\n- 650Gb Disk space\n\nHardware configuration\n\nThis configuration is enough to index and explore the dataset in a single-user mode; latency is reasonable enough to build interactive graphs and navigate in the dashboard.\n\nNaturally, you might need more CPU cores and RAM for production-grade configurations.",
      "index": 6,
      "token_count": 483,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 11526,
      "end_char": 13552
    },
    {
      "content": "dashboard.\n\nNaturally, you might need more CPU cores and RAM for production-grade configurations.\n\nIt is important to ensure high network bandwidth for this experiment so you are running the client and server in the same region.\n\n## Uploading and Indexing\n\nWe will use the following [python script](https://github.com/qdrant/laion-400m-benchmark/blob/master/upload.py) to upload dataset chunks one by one.\n\n```bash\nexport QDRANT_URL=\"https://xxxx-xxxx.xxxx.cloud.qdrant.io\"\nexport QDRANT_API_KEY=\"xxxx-xxxx-xxxx-xxxx\"\n\npython upload.py\n```\n\nThis script will download chunks of the LAION dataset one by one and upload them to Qdrant. Intermediate data is not persisted on disk, so the script doesn’t require much disk space on the client side.\n\nLet’s take a look at the collection configuration we used:\n\n```python\nclient.create_collection(\n        QDRANT_COLLECTION_NAME,\n        vectors_config=models.VectorParams(\n            size=512, # CLIP model output size\n            distance=models.Distance.COSINE, # CLIP model uses cosine distance\n            datatype=models.Datatype.FLOAT16, # We only need 16 bits for float, otherwise disk usage would be 800Gb instead of 400Gb\n            on_disk=True # We don't need original vectors in RAM\n        ),\n        # Even though CLIP vectors don't work well with binary quantization, out of the box,\n        # we can rely on query-time oversampling to get more accurate results\n        quantization_config=models.BinaryQuantization(\n            binary=models.BinaryQuantizationConfig(\n                always_ram=True,\n            )\n        ),\n        optimizers_config=models.OptimizersConfigDiff(\n            # Bigger size of segments are desired for faster search\n            # However it might be slower for indexing\n            max_segment_size=5_000_000, \n        ),\n        # Having larger M value is desirable for higher accuracy,\n        # but in our case we care more about memory usage\n        # We could still achieve reasonable accuracy even with M=6 + oversampling",
      "index": 7,
      "token_count": 449,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 13452,
      "end_char": 15475
    },
    {
      "content": "bout memory usage\n        # We could still achieve reasonable accuracy even with M=6 + oversampling\n        hnsw_config=models.HnswConfigDiff(\n            m=6, # decrease M for lower memory usage\n            on_disk=False\n        ),\n    )\n```\n\nThere are a few important points to note:\n\n- We use `FLOAT16` datatype for vectors, which allows us to store vectors in half the size compared to `FLOAT32`. There are no significant accuracy losses for this dataset.\n- We use `BinaryQuantization` with `always_ram=True` to enable query-time oversampling. This allows us to get an accurate and resource-efficient search, even though 512d CLIP vectors don’t work well with binary quantization out of the box.\n- We use `HnswConfig` with `m=6` to reduce memory usage. We will look deeper into memory usage in the next section.\n\nGoal of this configuration is to ensure that prefetch component of the search never needs to load data from disk, and at least a minimal version of vectors and vector index is always in RAM. The second stage of the search can explicitly determine how many times we can afford to load data from a disk.\n\nIn our experiment, the upload process was going at 5000 points per second. The indexation process was going in parallel with the upload and was happening at the rate of approximately 4000 points per second.\n\nUpload and indexation process\n\n## Memory Usage\n\nAfter the upload and indexation process is finished, let’s take a detailed look at the memory usage of the Qdrant server.\n\nMemory usage\n\nOn the high level, memory usage consists of 3 components:\n\n- System memory - 8.34Gb - this is memory reserved for internal systems and OS, it doesn’t depend on the dataset size.\n- Data memory - 39.27Gb - this is a resident memory of qdrant process, it can’t be evicter and qdrant process will crash if it exceeds the limit.\n- Cache memory - 14.54Gb - this is a disk cache qdrant uses. It is necessary for fast search but can be evicted if needed.\n\nThe most interest for us is Data and Cache memory.",
      "index": 8,
      "token_count": 470,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 15375,
      "end_char": 17386
    },
    {
      "content": "ry for fast search but can be evicted if needed.\n\nThe most interest for us is Data and Cache memory. Let’s look what exactly is stored in these components.\n\nIn our scenario, Qdrant uses memory to store the following components:\n\n- Storing vectors\n- Storing vector index\n- Storing information about IDs and versions of points\n\nPlease note, that payload indexes are out of scope for this tutorial. If you are using payload indexes in your collection, you might need to adjust the estimations accordingly.\n\n### Size of vectors\n\nIn our scenario, we store only quantized vectors in RAM, so it is relatively easy to calculate the required size:\n\n```text\n400_000_000 * 512d / 8 bits / 1024 (Kb) / 1024 (Mb) / 1024 (Gb) = 23.84Gb\n```\n\n### Size of vector index\n\nVector index is a bit more complicated, as it is not a simple matrix.\n\nInternally, it is stored as a list of connections in a graph, and each connection is a 4-byte integer.\n\nThe number of connections is defined by the `M` parameter of the HNSW index, and in our case, it is `6` on the high level and `2 x M` on level 0.\n\nThis gives us the following estimation:\n\n```text\n400_000_000 * (6 * 2) * 4 bytes / 1024 (Kb) / 1024 (Mb) / 1024 (Gb) = 17.881Gb\n```\n\nIn practice the size of index is a bit smaller due to the [compression](https://qdrant.tech/blog/qdrant-1.13.x/#hnsw-graph-compression) we implemented in Qdrant v1.13.0, but it is still a good estimation.\n\nThe HNSW index in Qdrant is stored as a mmap, and it can be evicted from RAM if needed. So, the memory consumption of HNSW falls under the category of `Cache memory`.\n\n### Size of IDs and versions\n\nQdrant must store additional information about each point, such as ID and version. This information is needed on each request, so it is very important to keep it in RAM for fast access.\n\nLet’s take a look at Qdrant internals to understand how much memory is required for this information.\n\n```rust\n\n// This is s simplified version of the IdTracker struct\n// It omits all optimizations and small details,",
      "index": 9,
      "token_count": 557,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 17286,
      "end_char": 19302
    },
    {
      "content": "is is s simplified version of the IdTracker struct\n// It omits all optimizations and small details,\n// but gives a good estimation of memory usage\nIdTracker {\n    // Mapping of internal id to version (u64), compressed to 4 bytes\n    // Required for versioning and conflict resolution between segments\n    internal_to_version, // 400M x 4 = 1.5Gb\n\n    // Mapping of external id to internal id, 4 bytes per point.\n    // Required to determine original point ID after search inside the segment\n    internal_to_external: Vec<u128>, // 400M x 16 = 6.4Gb\n\n    // Mapping of external id to internal id. For numeric ids it uses 8 bytes,\n    //  UUIDs are stored as 16 bytes.\n    // Required to determine sequential point ID inside the segment\n    external_to_internal: Vec<u64, u32>, // 400M x (8 + 4) = 4.5Gb\n}\n```\n\nIn the v1.13.5 we introduced a [significant optimization](https://github.com/qdrant/qdrant/pull/6023) to reduce the memory usage of `IdTracker` by approximately 2 times. So the total memory usage of `IdTracker` in our case is approximately `12.4Gb`.\n\nSo total expected RAM usage of Qdrant server in our case is approximately `23.84Gb + 17.881Gb + 12.4Gb = 54.121Gb`, which is very close to the actual memory usage we observed: `39.27Gb + 14.54Gb = 53.81Gb`.\n\nWe had to apply some simplifications to the estimations, but they are good enough to understand the memory usage of the Qdrant server.\n\n## Search\n\nAfter the dataset is uploaded and indexed, we can start searching for similar vectors.\n\nWe can start by exploring the dataset in Web-UI. So you can get an intuition into the search performance, not just table numbers.\n\nWeb-UI Bear image\n\nWeb-UI similar Bear image\n\nWeb-UI default requests do not use oversampling, but the observable results are still good enough to see the resemblance between images.\n\n### Ground truth data\n\nHowever, to estimate the search performance more accurately, we need to compare search results with the ground truth.",
      "index": 10,
      "token_count": 522,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 19202,
      "end_char": 21160
    },
    {
      "content": "ate the search performance more accurately, we need to compare search results with the ground truth. Unfortunately, the LAION dataset doesn’t contain usable ground truth, so we had to generate it ourselves.\n\nTo do this, we need to perform a full-scan search for each vector in the dataset and store the results in a separate file. Unfortunately, this process is very time-consuming and requires a lot of resources, so we had to limit the number of queries to 100, we provide a ready-to-use [ground truth file](https://github.com/qdrant/laion-400m-benchmark/blob/master/expected.py) and the [script](https://github.com/qdrant/laion-400m-benchmark/blob/master/full_scan.py) to generate it (requires 512Gb RAM machine and about 20 hours of execution time).\n\nOur ground truth file contains 100 queries, each with 50 results. The first 100 vectors of the dataset itself were used to generate queries.\n\nNote, that this dataset contain a significant amount of exact duplicates, so ordering of the results might be different in different runs.\n\n### Search Query\n\nTo precisely control the amount of oversampling, we will use the following search query:\n\n```python\n\nlimit = 50\nrescore_limit = 1000 # oversampling factor is 20\n\nquery = vectors[query_id] # One of existing vectors\n\nresponse = client.query_points(\n        collection_name=QDRANT_COLLECTION_NAME,\n        query=query,\n        limit=limit,\n        # Go to disk \n        search_params=models.SearchParams(\n            quantization=models.QuantizationSearchParams(\n                rescore=True,\n            ),\n        ),\n        # Prefetch is performed using only in-RAM data,\n        # so querying even large amount of data is fast\n        prefetch=models.Prefetch(\n            query=query,\n            limit=rescore_limit,\n            params=models.SearchParams(\n                quantization=models.QuantizationSearchParams(\n                    # Avoid rescoring in prefetch\n                    # We should do it explicitly on the second stage\n                    rescore=False,",
      "index": 11,
      "token_count": 440,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 21060,
      "end_char": 23091
    },
    {
      "content": "# We should do it explicitly on the second stage\n                    rescore=False,\n                ),\n            )\n        )\n    )\n```\n\nAs you can see, this query contains two stages:\n\n- First stage is a prefetch, which is performed using only in-RAM data. It is very fast and allows us to get a large amount of candidates.\n- The second stage is a rescore, which is performed with full-size vectors stored on disks.\n\nBy using 2-stage search we can precisely control the amount of data loaded from disk and ensure the balance between search speed and accuracy.\n\nYou can find the complete code of the search process in the [eval.py](https://github.com/qdrant/laion-400m-benchmark/blob/master/eval.py)\n\n## Performance tweak\n\nOne important performance tweak we found useful for this dataset is to enable [Async IO](https://qdrant.tech/articles/io_uring) in Qdrant.\n\nBy default, Qdrant uses synchronous IO, which is good for in-memory datasets but can be a bottleneck when we want to read a lot of data from a disk.\n\nAsync IO (implemented with `io_uring`) allows to send parallel requests to the disk and saturate the disk bandwidth.\n\nThis is exactly what we are looking for when performing large-scale re-scoring with original vectors.\n\nInstead of reading vectors one by one and waiting for the disk response 1000 times, we can send 1000 requests to the disk and wait for all of them to complete. This allows us to saturate the disk bandwidth and get faster results.\n\nTo enable Async IO in Qdrant, you need to set the following environment variable:\n\n```bash\nQDRANT__STORAGE__PERFORMANCE__ASYNC_SCORER=true\n```\n\nOr set parameter in config file:\n\n```yaml\nstorage:\n  performance:\n    async_scorer: true\n```\n\nIn Qdrant Managed cloud Async IO can be enabled via `Advanced optimizations` section in cluster `Configuration` tab.\n\nAsync IO configuration in Cloud\n\n## Running search requests\n\nOnce all the preparations are done, we can run the search requests and evaluate the results.",
      "index": 12,
      "token_count": 445,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 22991,
      "end_char": 24984
    },
    {
      "content": "ests\n\nOnce all the preparations are done, we can run the search requests and evaluate the results.\n\nYou can find the full code of the search process in the [eval.py](https://github.com/qdrant/laion-400m-benchmark/blob/master/eval.py)\n\nThis script will run 100 search requests with configured oversampling factor and compare the results with the ground truth.\n\n```bash\npython eval.py --rescore_limit 1000\n```\n\nIn our request we achieved the following results:\n\n| Rescore Limit | Precision\\@50 | Time per request |\n| ------------- | ------------- | ---------------- |\n| 1000          | 75.2%         | 0.7s             |\n| 5000          | 81.0%         | 2.2s             |\n\nAdditional experiments with `m=16` demonstrated that we can achieve `85%` precision with `rescore_limit=1000`, but they would require slightly more memory.\n\nLog of search evaluation\n\n## Conclusion\n\nIn this tutorial we demonstrated how to upload, index and search a large dataset in Qdrant cost-efficiently. Binary quantization can be applied even on 512d vectors, if combined with query-time oversampling.\n\nQdrant allows to precisely control where each part of storage is located, which allows to achieve a good balance between search speed and memory usage.\n\n### Potential improvements\n\nIn this experiment, we investigated in detail which parts of the storage are responsible for memory usage and how to control them.\n\nOne especially interesting part is the `VectorIndex` component, which is responsible for storing the graph of connections between vectors.\n\nIn our further research, we will investigate the possibility of making HNSW more disk-friendly so it can be offloaded to disk without significant performance losses.\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! 🙏\n\nWe are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/database-tutorials/large-scale-search.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.",
      "index": 13,
      "token_count": 472,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 24884,
      "end_char": 26933
    },
    {
      "content": "ge on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Upload and Search Large collections cost-efficiently](#upload-and-search-large-collections-cost-efficiently.md)\n\n  - [Dataset](#dataset.md)\n\n  - [Hardware](#hardware.md)\n\n  - [Uploading and Indexing](#uploading-and-indexing.md)\n\n  - [Memory Usage](#memory-usage.md)\n\n    - [Size of vectors](#size-of-vectors.md)\n    - [Size of vector index](#size-of-vector-index.md)\n    - [Size of IDs and versions](#size-of-ids-and-versions.md)\n\n  - [Search](#search.md)\n\n    - [Ground truth data](#ground-truth-data.md)\n    - [Search Query](#search-query.md)\n\n  - [Performance tweak](#performance-tweak.md)\n\n  - [Running search requests](#running-search-requests.md)\n\n  - [Conclusion](#conclusion.md)\n    - [Potential improvements](#potential-improvements.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/database-tutorials/large-scale-search.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
      "index": 14,
      "token_count": 366,
      "metadata": {
        "title": "_documentation_database-tutorials_large-scale-search_",
        "source": "qdrant_documentation\\documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_database-tutorials_large-scale-search",
        "category": "database-tutorials",
        "file_path": "documentation_database-tutorials_large-scale-search\\_documentation_database-tutorials_large-scale-search_.md",
        "file_name": "_documentation_database-tutorials_large-scale-search_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:30.550193",
        "total_chunks": 15
      },
      "start_char": 26833,
      "end_char": 28881
    }
  ]
}
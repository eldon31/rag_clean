{
  "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
  "source_repo": "qdrant_documentation",
  "total_chunks": 18,
  "chunks": [
    {
      "content": "Simple Agentic RAG System - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)",
      "index": 0,
      "token_count": 549,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 0,
      "end_char": 2037
    },
    {
      "content": "ata-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.",
      "index": 1,
      "token_count": 535,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 1937,
      "end_char": 3946
    },
    {
      "content": "ai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.",
      "index": 2,
      "token_count": 551,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 3846,
      "end_char": 5880
    },
    {
      "content": "VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.",
      "index": 3,
      "token_count": 531,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 5780,
      "end_char": 7802
    },
    {
      "content": "drant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.",
      "index": 4,
      "token_count": 498,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 7702,
      "end_char": 9704
    },
    {
      "content": ".tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)",
      "index": 5,
      "token_count": 536,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 9604,
      "end_char": 11644
    },
    {
      "content": "h/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)",
      "index": 6,
      "token_count": 542,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 11544,
      "end_char": 13578
    },
    {
      "content": "entation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.",
      "index": 7,
      "token_count": 554,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 13478,
      "end_char": 15521
    },
    {
      "content": "PT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.",
      "index": 8,
      "token_count": 504,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 15421,
      "end_char": 17424
    },
    {
      "content": "les/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- Simple Agentic RAG System\n\n# Agentic RAG With CrewAI & Qdrant Vector Database\n\n| Time: 45 min | Level: Beginner | Output: [GitHub](https://github.com/qdrant/examples/tree/master/agentic_rag_zoom_crewai) |   |\n| ------------ | --------------- | ---------------------------------------------------------------------------------------- | - |\n\nBy combining the power of Qdrant for vector search and CrewAI for orchestrating modular agents, you can build systems that don’t just answer questions but analyze, interpret, and act.\n\nTraditional RAG systems focus on fetching data and generating responses, but they lack the ability to reason deeply or handle multi-step processes.\n\nIn this tutorial, we’ll walk you through building an Agentic RAG system step by step. By the end, you’ll have a working framework for storing data in a Qdrant Vector Database and extracting insights using CrewAI agents in conjunction with Vector Search over your data.\n\nWe already built this app for you. [Clone this repository](https://github.com/qdrant/examples/tree/master/agentic_rag_zoom_crewai) and follow along with the tutorial.\n\n## What You’ll Build\n\nIn this hands-on tutorial, we’ll create a system that:\n\n1.",
      "index": 9,
      "token_count": 439,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 17324,
      "end_char": 19300
    },
    {
      "content": "with the tutorial.\n\n## What You’ll Build\n\nIn this hands-on tutorial, we’ll create a system that:\n\n1. Uses Qdrant to store and retrieve meeting transcripts as vector embeddings\n2. Leverages CrewAI agents to analyze and summarize meeting data\n3. Presents insights in a simple Streamlit interface for easy interaction\n\nThis project demonstrates how to build a Vector Search powered Agentic workflow to extract insights from meeting recordings. By combining Qdrant’s vector search capabilities with CrewAI agents, users can search through and analyze their own meeting content.\n\nThe application first converts the meeting transcript into vector embeddings and stores them in a Qdrant vector database. It then uses CrewAI agents to query the vector database and extract insights from the meeting content. Finally, it uses Anthropic Claude to generate natural language responses to user queries based on the extracted insights from the vector database.\n\n### How Does It Work?\n\nWhen you interact with the system, here’s what happens behind the scenes:\n\nFirst the user submits a query to the system. In this example, we want to find out the average length of Marketing meetings. Since one of the data points from the meetings is the duration of the meeting, the agent can calculate the average duration of the meetings by averaging the duration of all meetings with the keyword “Marketing” in the topic or content.\n\nNext, the agent used the `search_meetings` tool to search the Qdrant vector database for the most semantically similar meeting points. We asked about Marketing meetings, so the agent searched the database with the search meeting tool for all meetings with the keyword “Marketing” in the topic or content.\n\nNext, the agent used the `calculator` tool to find the average duration of the meetings.\n\nFinally, the agent used the `Information Synthesizer` tool to synthesize the analysis and present it in a natural language format.\n\nThe user sees the final output in a chat-like interface.",
      "index": 10,
      "token_count": 389,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 19200,
      "end_char": 21194
    },
    {
      "content": "present it in a natural language format.\n\nThe user sees the final output in a chat-like interface.\n\nThe user can then continue to interact with the system by asking more questions.\n\n### Architecture\n\nThe system is built on three main components:\n\n- **Qdrant Vector Database**: Stores meeting transcripts and summaries as vector embeddings, enabling semantic search\n- **CrewAI Framework**: Coordinates AI agents that handle different aspects of meeting analysis\n- **Anthropic Claude**: Provides natural language understanding and response generation\n\n1. **Data Processing Pipeline**\n\n   - Processes meeting transcripts and metadata\n   - Creates embeddings with SentenceTransformer\n   - Manages Qdrant collection and data upload\n\n2. **AI Agent System**\n\n   - Implements CrewAI agent logic\n   - Handles vector search integration\n   - Processes queries with Claude\n\n3. **User Interface**\n\n   - Provides chat-like web interface\n   - Shows real-time processing feedback\n   - Maintains conversation history\n\n---\n\n## Getting Started\n\n1. **Get API Credentials for Qdrant**:\n\n   - Sign up for an account at [Qdrant Cloud](https://cloud.qdrant.io/signup).\n   - Create a new cluster and copy the **Cluster URL** (format: <https://xxx.gcp.cloud.qdrant.io>).\n   - Go to **Data Access Control** and generate an **API key**.\n\n2. **Get API Credentials for AI Services**:\n\n   - Get an API key from [Anthropic](https://www.anthropic.com/)\n   - Get an API key from [OpenAI](https://platform.openai.com/)\n\n---\n\n## Setup\n\n1. **Clone the Repository**:\n\n```bash\ngit clone https://github.com/qdrant/examples.git\ncd agentic_rag_zoom_crewai\n```\n\n2. **Create and Activate a Python Virtual Environment with Python 3.10 for compatibility**:\n\n```bash\npython3.10 -m venv venv\nsource venv/bin/activate  # Windows: venv\\Scripts\\activate\n```\n\n3. **Install Dependencies**:\n\n```bash\npip install -r requirements.txt\n```\n\n4. **Configure Environment Variables**: Create a `.env.local` file with:\n\n```bash\nopenai_api_key=your_openai_key_here\nanthropic_api_key=your_anthropic_key_here",
      "index": 11,
      "token_count": 483,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 21094,
      "end_char": 23137
    },
    {
      "content": "` file with:\n\n```bash\nopenai_api_key=your_openai_key_here\nanthropic_api_key=your_anthropic_key_here\nqdrant_url=your_qdrant_url_here\nqdrant_api_key=your_qdrant_api_key_here\n```\n\n---\n\n## Usage\n\n### 1. Process Meeting Data\n\nThe [`data_loader.py`](https://github.com/qdrant/examples/blob/master/agentic_rag_zoom_crewai/vector/data_loader.py) script processes meeting data and stores it in Qdrant:\n\n```bash\npython vector/data_loader.py\n```\n\nAfter this script has run, you should see a new collection in your Qdrant Cloud account called `zoom_recordings`. This collection contains the vector embeddings of the meeting transcripts. The points in the collection contain the original meeting data, including the topic, content, and summary.\n\n### 2. Launch the Interface\n\nThe [`streamlit_app.py`](https://github.com/qdrant/examples/blob/master/agentic_rag_zoom_crewai/vector/streamlit_app.py) is located in the `vector` folder. To launch it, run:\n\n```bash\nstreamlit run vector/streamlit_app.py\n```\n\nWhen you run this script, you will be able to interact with the system through a chat-like interface. Ask questions about the meeting content, and the system will use the AI agents to find the most relevant information and present it in a natural language format.\n\n### The Data Pipeline\n\nAt the heart of our system is the data processing pipeline:\n\n```python\nclass MeetingData:\n    def _initialize(self):\n        self.data_dir = Path(__file__).parent.parent / 'data'\n        self.meetings = self._load_meetings()\n        \n        self.qdrant_client = QdrantClient(\n            url=os.getenv('qdrant_url'),\n            api_key=os.getenv('qdrant_api_key')\n        )\n        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n```\n\nThe singleton pattern in data\\_loader.py is implemented through a MeetingData class that uses Python’s **new** and **init** methods. The class maintains a private \\_instance variable to track if an instance exists, and a \\_initialized flag to ensure the initialization code only runs once.",
      "index": 12,
      "token_count": 470,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 23037,
      "end_char": 25055
    },
    {
      "content": "ck if an instance exists, and a \\_initialized flag to ensure the initialization code only runs once. When creating a new instance with MeetingData(), **new** first checks if \\_instance exists - if it doesn’t, it creates one and sets the initialization flag to False. The **init** method then checks this flag, and if it’s False, runs the initialization code and sets the flag to True. This ensures that all subsequent calls to MeetingData() return the same instance with the same initialized resources.\n\nWhen processing meetings, we need to consider both the content and context. Each meeting gets converted into a rich text representation before being transformed into a vector:\n\n```python\ntext_to_embed = f\"\"\"\n    Topic: {meeting.get('topic', '')}\n    Content: {meeting.get('vtt_content', '')}\n    Summary: {json.dumps(meeting.get('summary', {}))}\n\"\"\"\n```\n\nThis structured format ensures our vector embeddings capture the full context of each meeting. But processing meetings one at a time would be inefficient. Instead, we batch process our data:\n\n```python\nbatch_size = 100\nfor i in range(0, len(points), batch_size):\n    batch = points[i:i + batch_size]\n    self.qdrant_client.upsert(\n        collection_name='zoom_recordings',\n        points=batch\n    )\n```\n\n### Building the AI Agent System\n\nOur AI system uses a tool-based approach. Let’s start with the simplest tool - a calculator for meeting statistics:\n\n```python\nclass CalculatorTool(BaseTool):\n    name: str = \"calculator\"\n    description: str = \"Perform basic mathematical calculations\"\n    \n    def _run(self, a: int, b: int) -> dict:\n        return {\n            \"addition\": a + b,\n            \"multiplication\": a * b\n        }\n```\n\nBut the real power comes from our vector search integration. This tool converts natural language queries into vector representations and searches our meeting database:\n\n```python\nclass SearchMeetingsTool(BaseTool):\n    def _run(self, query: str) -> List[Dict]:\n        response = openai_client.embeddings.create(",
      "index": 13,
      "token_count": 440,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 24955,
      "end_char": 26968
    },
    {
      "content": ":\n    def _run(self, query: str) -> List[Dict]:\n        response = openai_client.embeddings.create(\n            model=\"text-embedding-ada-002\",\n            input=query\n        )\n        query_vector = response.data[0].embedding\n        \n        return self.qdrant_client.search(\n            collection_name='zoom_recordings',\n            query_vector=query_vector,\n            limit=10\n        )\n```\n\nThe search results then feed into our analysis tool, which uses Claude to provide deeper insights:\n\n```python\nclass MeetingAnalysisTool(BaseTool):\n    def _run(self, meeting_data: dict) -> Dict:\n        meetings_text = self._format_meetings(meeting_data)\n        \n        message = client.messages.create(\n            model=\"claude-3-sonnet-20240229\",\n            messages=[{\n                \"role\": \"user\", \n                \"content\": f\"Analyze these meetings:\\n\\n{meetings_text}\"\n            }]\n        )\n```\n\n### Orchestrating the Workflow\n\nThe magic happens when we bring these tools together under our agent framework. We create two specialized agents:\n\n```python\nresearcher = Agent(\n    role='Research Assistant',\n    goal='Find and analyze relevant information',\n    tools=[calculator, searcher, analyzer]\n)\n\nsynthesizer = Agent(\n    role='Information Synthesizer',\n    goal='Create comprehensive and clear responses'\n)\n```\n\nThese agents work together in a coordinated workflow. The researcher gathers and analyzes information, while the synthesizer creates clear, actionable responses. This separation of concerns allows each agent to focus on its strengths.\n\n### Building the User Interface\n\nThe Streamlit interface provides a clean, chat-like experience for interacting with our AI system. Let’s start with the basic setup:\n\n```python\nst.set_page_config(\n    page_title=\"Meeting Assistant\",\n    page_icon=\"🤖\",\n    layout=\"wide\"\n)\n```\n\nTo make the interface more engaging, we add custom styling that makes the output easier to read:\n\n```python\nst.markdown(\"\"\"\n    <style>\n    .stApp {\n        max-width: 1200px;\n        margin: 0 auto;",
      "index": 14,
      "token_count": 448,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 26868,
      "end_char": 28914
    },
    {
      "content": "`python\nst.markdown(\"\"\"\n    <style>\n    .stApp {\n        max-width: 1200px;\n        margin: 0 auto;\n    }\n    .output-container {\n        background-color: #f0f2f6;\n        padding: 20px;\n        border-radius: 10px;\n        margin: 10px 0;\n    }\n    </style>\n\"\"\", unsafe_allow_html=True)\n```\n\nOne of the key features is real-time feedback during processing. We achieve this with a custom output handler:\n\n```python\nclass ConsoleOutput:\n    def __init__(self, placeholder):\n        self.placeholder = placeholder\n        self.buffer = []\n        self.update_interval = 0.5  # seconds\n        self.last_update = time.time()\n\n    def write(self, text):\n        self.buffer.append(text)\n        if time.time() - self.last_update > self.update_interval:\n            self._update_display()\n```\n\nThis handler buffers the output and updates the display periodically, creating a smooth user experience. When a user sends a query, we process it with visual feedback:\n\n```python\nwith st.chat_message(\"assistant\"):\n    message_placeholder = st.empty()\n    progress_bar = st.progress(0)\n    console_placeholder = st.empty()\n    \n    try:\n        console_output = ConsoleOutput(console_placeholder)\n        with contextlib.redirect_stdout(console_output):\n            progress_bar.progress(0.3)\n            full_response = get_crew_response(prompt)\n            progress_bar.progress(1.0)\n```\n\nThe interface maintains a chat history, making it feel like a natural conversation:\n\n```python\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"])\n```\n\nWe also include helpful examples and settings in the sidebar:\n\n```python\nwith st.sidebar:\n    st.header(\"Settings\")\n    search_limit = st.slider(\"Number of results\", 1, 10, 5)\n    \n    analysis_depth = st.select_slider(\n        \"Analysis Depth\",\n        options=[\"Basic\", \"Standard\", \"Detailed\"],\n        value=\"Standard\"\n    )\n```",
      "index": 15,
      "token_count": 457,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 28814,
      "end_char": 30827
    },
    {
      "content": "ysis Depth\",\n        options=[\"Basic\", \"Standard\", \"Detailed\"],\n        value=\"Standard\"\n    )\n```\n\nThis combination of features creates an interface that’s both powerful and approachable. Users can see their query being processed in real-time, adjust settings to their needs, and maintain context through the chat history.\n\n---\n\n## Conclusion\n\nThis tutorial has demonstrated how to build a sophisticated meeting analysis system that combines vector search with AI agents. Let’s recap the key components we’ve covered:\n\n1. **Vector Search Integration**\n\n   - Efficient storage and retrieval of meeting content using Qdrant\n   - Semantic search capabilities through vector embeddings\n   - Batched processing for optimal performance\n\n2. **AI Agent Framework**\n\n   - Tool-based approach for modular functionality\n   - Specialized agents for research and analysis\n   - Integration with Claude for intelligent insights\n\n3. **Interactive Interface**\n\n   - Real-time feedback and progress tracking\n   - Persistent chat history\n   - Configurable search and analysis settings\n\nThe resulting system demonstrates the power of combining vector search with AI agents to create an intelligent meeting assistant. By following this tutorial, you’ve learned how to:\n\n- Process and store meeting data efficiently\n- Implement semantic search capabilities\n- Create specialized AI agents for analysis\n- Build an intuitive user interface\n\nThis foundation can be extended in many ways, such as:\n\n- Adding more specialized agents\n- Implementing additional analysis tools\n- Enhancing the user interface\n- Integrating with other data sources\n\nThe code is available in the [repository](https://github.com/qdrant/examples/tree/master/agentic_rag_zoom_crewai), and we encourage you to experiment with your own modifications and improvements.\n\n---\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! 🙏\n\nWe are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/agentic-rag-crewai-zoom.",
      "index": 16,
      "token_count": 405,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 30727,
      "end_char": 32770
    },
    {
      "content": "ub.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/agentic-rag-crewai-zoom.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Agentic RAG With CrewAI & Qdrant Vector Database](#agentic-rag-with-crewai--qdrant-vector-database.md)\n\n  - [What You’ll Build](#what-youll-build.md)\n\n    - [How Does It Work?](#how-does-it-work.md)\n    - [Architecture](#architecture.md)\n\n  - [Getting Started](#getting-started.md)\n\n  - [Setup](#setup.md)\n\n  - [Usage](#usage.md)\n\n    - [1. Process Meeting Data](#1-process-meeting-data.md)\n    - [2. Launch the Interface](#2-launch-the-interface.md)\n    - [The Data Pipeline](#the-data-pipeline.md)\n    - [Building the AI Agent System](#building-the-ai-agent-system.md)\n    - [Orchestrating the Workflow](#orchestrating-the-workflow.md)\n    - [Building the User Interface](#building-the-user-interface.md)\n\n  - [Conclusion](#conclusion.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/agentic-rag-crewai-zoom.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
      "index": 17,
      "token_count": 410,
      "metadata": {
        "title": "_documentation_agentic-rag-crewai-zoom_",
        "source": "qdrant_documentation\\documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_agentic-rag-crewai-zoom",
        "category": "agentic-rag-crewai-zoom",
        "file_path": "documentation_agentic-rag-crewai-zoom\\_documentation_agentic-rag-crewai-zoom_.md",
        "file_name": "_documentation_agentic-rag-crewai-zoom_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.965677",
        "total_chunks": 18
      },
      "start_char": 32670,
      "end_char": 34718
    }
  ]
}
{
  "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
  "source_repo": "qdrant_documentation",
  "total_chunks": 14,
  "chunks": [
    {
      "content": "Qdrant on Databricks - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)",
      "index": 0,
      "token_count": 550,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 0,
      "end_char": 2032
    },
    {
      "content": "ata-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.",
      "index": 1,
      "token_count": 535,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 1932,
      "end_char": 3941
    },
    {
      "content": "ai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.",
      "index": 2,
      "token_count": 551,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 3841,
      "end_char": 5875
    },
    {
      "content": "VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.",
      "index": 3,
      "token_count": 531,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 5775,
      "end_char": 7797
    },
    {
      "content": "drant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.",
      "index": 4,
      "token_count": 498,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 7697,
      "end_char": 9699
    },
    {
      "content": ".tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)",
      "index": 5,
      "token_count": 536,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 9599,
      "end_char": 11639
    },
    {
      "content": "h/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)",
      "index": 6,
      "token_count": 542,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 11539,
      "end_char": 13573
    },
    {
      "content": "entation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.",
      "index": 7,
      "token_count": 554,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 13473,
      "end_char": 15516
    },
    {
      "content": "PT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.",
      "index": 8,
      "token_count": 504,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 15416,
      "end_char": 17419
    },
    {
      "content": "les/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- [Send data](https://qdrant.tech/documentation/send-data/)\n-\n- Qdrant on Databricks\n\n# Qdrant on Databricks\n\n| Time: 30 min | Level: Intermediate | [Complete Notebook](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/4750876096379825/93425612168199/6949977306828869/latest.html) |\n| ------------ | ------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n\n[Databricks](https://www.databricks.com/) is a unified analytics platform for working with big data and AI. It’s built around Apache Spark, a powerful open-source distributed computing system well-suited for processing large-scale datasets and performing complex analytics tasks.\n\nApache Spark is designed to scale horizontally, meaning it can handle expensive operations like generating vector embeddings by distributing computation across a cluster of machines. This scalability is crucial when dealing with large datasets.\n\nIn this example, we will demonstrate how to vectorize a dataset with dense and sparse embeddings using Qdrant’s [FastEmbed](https://qdrant.github.io/fastembed/) library.",
      "index": 9,
      "token_count": 470,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 17319,
      "end_char": 19346
    },
    {
      "content": "dense and sparse embeddings using Qdrant’s [FastEmbed](https://qdrant.github.io/fastembed/) library. We will then load this vectorized data into a Qdrant cluster using the [Qdrant Spark connector](https://qdrant.tech/documentation/frameworks/spark/) on Databricks.\n\n### Setting up a Databricks project\n\n- Set up a **[Databricks cluster](https://docs.databricks.com/en/compute/configure.html)** following the official documentation guidelines.\n\n- Install the **[Qdrant Spark connector](https://qdrant.tech/documentation/frameworks/spark/)** as a library:\n\n  - Navigate to the `Libraries` section in your cluster dashboard.\n\n  - Click on `Install New` at the top-right to open the library installation modal.\n\n  - Search for `io.qdrant:spark:VERSION` in the Maven packages and click on `Install`.\n\n- Create a new **[Databricks notebook](https://docs.databricks.com/en/notebooks/index.html)** on your cluster to begin working with your data and libraries.\n\n### Download a dataset\n\n- **Install the required dependencies:**\n\n```python\n%pip install fastembed datasets\n```\n\n- **Download the dataset:**\n\n```python\nfrom datasets import load_dataset\n\ndataset_name = \"tasksource/med\"\ndataset = load_dataset(dataset_name, split=\"train\")\n# We'll use the first 100 entries from this dataset and exclude some unused columns.\ndataset = dataset.select(range(100)).remove_columns([\"gold_label\", \"genre\"])\n```\n\n- **Convert the dataset into a Spark dataframe:**\n\n```python\ndataset.to_parquet(\"/dbfs/pq.pq\")\ndataset_df = spark.read.parquet(\"file:/dbfs/pq.pq\")\n```\n\n### Vectorizing the data\n\nIn this section, we’ll be generating both dense and sparse vectors for our rows using [FastEmbed](https://qdrant.github.io/fastembed/). We’ll create a user-defined function (UDF) to handle this step.\n\n#### Creating the vectorization function\n\n```python\nfrom fastembed import TextEmbedding, SparseTextEmbedding\n\ndef vectorize(partition_data):\n    # Initialize dense and sparse models\n    dense_model = TextEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")",
      "index": 10,
      "token_count": 487,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 19246,
      "end_char": 21268
    },
    {
      "content": "ialize dense and sparse models\n    dense_model = TextEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n    sparse_model = SparseTextEmbedding(model_name=\"Qdrant/bm25\")\n\n    for row in partition_data:\n        # Generate dense and sparse vectors\n        dense_vector = next(dense_model.embed(row.sentence1))\n        sparse_vector = next(sparse_model.embed(row.sentence2))\n\n        yield [\n            row.sentence1,  # 1st column: original text\n            row.sentence2,  # 2nd column: original text\n            dense_vector.tolist(),  # 3rd column: dense vector\n            sparse_vector.indices.tolist(),  # 4th column: sparse vector indices\n            sparse_vector.values.tolist(),  # 5th column: sparse vector values\n        ]\n```\n\nWe’re using the [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5) model for dense embeddings and [BM25](https://huggingface.co/Qdrant/bm25) for sparse embeddings.\n\n#### Applying the UDF on our dataframe\n\nNext, let’s apply our `vectorize` UDF on our Spark dataframe to generate embeddings.\n\n```python\nembeddings = dataset_df.rdd.mapPartitions(vectorize)\n```\n\nThe `mapPartitions()` method returns a [Resilient Distributed Dataset (RDD)](https://www.databricks.com/glossary/what-is-rdd) which should then be converted back to a Spark dataframe.\n\n#### Building the new Spark dataframe with the vectorized data\n\nWe’ll now create a new Spark dataframe (`embeddings_df`) with the vectorized data using the specified schema.\n\n```python\nfrom pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType, IntegerType\n\n# Define the schema for the new dataframe\nschema = StructType([\n    StructField(\"sentence1\", StringType()),\n    StructField(\"sentence2\", StringType()),\n    StructField(\"dense_vector\", ArrayType(FloatType())),\n    StructField(\"sparse_vector_indices\", ArrayType(IntegerType())),\n    StructField(\"sparse_vector_values\", ArrayType(FloatType()))\n])\n\n# Create the new dataframe with the vectorized data\nembeddings_df = spark.",
      "index": 11,
      "token_count": 483,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 21168,
      "end_char": 23173
    },
    {
      "content": "rayType(FloatType()))\n])\n\n# Create the new dataframe with the vectorized data\nembeddings_df = spark.createDataFrame(data=embeddings, schema=schema)\n```\n\n### Uploading the data to Qdrant\n\n- **Create a Qdrant collection:**\n\n  - [Follow the documentation](https://qdrant.tech/documentation/concepts/collections/#create-a-collection) to create a collection with the appropriate configurations. Here’s an example request to support both dense and sparse vectors:\n\n  ```json\n  PUT /collections/{collection_name}\n  {\n    \"vectors\": {\n      \"dense\": {\n        \"size\": 384,\n        \"distance\": \"Cosine\"\n      }\n    },\n    \"sparse_vectors\": {\n      \"sparse\": {}\n    }\n  }\n  ```\n\n- **Upload the dataframe to Qdrant:**\n\n```python\noptions = {\n    \"qdrant_url\": \"<QDRANT_GRPC_URL>\",\n    \"api_key\": \"<QDRANT_API_KEY>\",\n    \"collection_name\": \"<QDRANT_COLLECTION_NAME>\",\n    \"vector_fields\": \"dense_vector\",\n    \"vector_names\": \"dense\",\n    \"sparse_vector_value_fields\": \"sparse_vector_values\",\n    \"sparse_vector_index_fields\": \"sparse_vector_indices\",\n    \"sparse_vector_names\": \"sparse\",\n    \"schema\": embeddings_df.schema.json(),\n}\n\nembeddings_df.write.format(\"io.qdrant.spark.Qdrant\").options(**options).mode(\n    \"append\"\n).save()\n```\n\nYou can find the list of the Spark connector configuration options [here](https://qdrant.tech/documentation/frameworks/spark/#configuration-options).\n\nEnsure to replace the placeholder values (`<QDRANT_GRPC_URL>`, `<QDRANT_API_KEY>`, `<QDRANT_COLLECTION_NAME>`) with your actual values. If the `id_field` option is not specified, Qdrant Spark connector generates random UUIDs for each point.\n\nThe command output you should see is similar to:\n\n```console\nCommand took 40.37 seconds -- by xxxxx90@xxxxxx.com at 4/17/2024, 12:13:28 PM on fastembed\n```\n\n### Conclusion\n\nThat wraps up our tutorial! Feel free to explore more functionalities and experiments with different models, parameters, and features available in Databricks, Spark, and Qdrant.\n\nHappy data engineering!\n\n##### Was this page useful?\n\nYes No",
      "index": 12,
      "token_count": 511,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 23073,
      "end_char": 25106
    },
    {
      "content": "le in Databricks, Spark, and Qdrant.\n\nHappy data engineering!\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! 🙏\n\nWe are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/send-data/databricks.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Qdrant on Databricks](#qdrant-on-databricks.md)\n\n  - - [Setting up a Databricks project](#setting-up-a-databricks-project.md)\n    - [Download a dataset](#download-a-dataset.md)\n    - [Vectorizing the data](#vectorizing-the-data.md)\n    - [Uploading the data to Qdrant](#uploading-the-data-to-qdrant.md)\n    - [Conclusion](#conclusion.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/send-data/databricks.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
      "index": 13,
      "token_count": 344,
      "metadata": {
        "title": "_documentation_send-data_databricks_",
        "source": "qdrant_documentation\\documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_send-data_databricks",
        "category": "send-data",
        "file_path": "documentation_send-data_databricks\\_documentation_send-data_databricks_.md",
        "file_name": "_documentation_send-data_databricks_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:33.774289",
        "total_chunks": 14
      },
      "start_char": 25006,
      "end_char": 27054
    }
  ]
}
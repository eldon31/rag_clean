{
  "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
  "source_repo": "qdrant_documentation",
  "total_chunks": 16,
  "chunks": [
    {
      "content": "Scaling PDF Retrieval with Qdrant - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Getting Started\n\n[What is Qdrant?](https://qdrant.tech/documentation/overview/)\n\n- [Understanding Vector Search in Qdrant](https://qdrant.tech/documentation/overview/vector-search/)\n\n[Local Quickstart](https://qdrant.tech/documentation/quickstart/)\n\n[API & SDKs](https://qdrant.tech/documentation/interfaces/)\n\n[Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)\n\n### User Manual\n\n[Concepts](https://qdrant.tech/documentation/concepts/)\n\n- [Collections](https://qdrant.tech/documentation/concepts/collections/)\n- [Points](https://qdrant.tech/documentation/concepts/points/)\n- [Vectors](https://qdrant.tech/documentation/concepts/vectors/)\n- [Payload](https://qdrant.tech/documentation/concepts/payload/)\n- [Search](https://qdrant.tech/documentation/concepts/search/)\n- [Explore](https://qdrant.tech/documentation/concepts/explore/)\n- [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/)\n- [Filtering](https://qdrant.tech/documentation/concepts/filtering/)\n- [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/)\n- [Storage](https://qdrant.tech/documentation/concepts/storage/)\n- [Indexing](https://qdrant.tech/documentation/concepts/indexing/)\n- [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)\n\n[Guides](https://qdrant.tech/documentation/guides/installation/)\n\n- [Installation](https://qdrant.",
      "index": 0,
      "token_count": 533,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 0,
      "end_char": 2044
    },
    {
      "content": "[Guides](https://qdrant.tech/documentation/guides/installation/)\n\n- [Installation](https://qdrant.tech/documentation/guides/installation/)\n- [Administration](https://qdrant.tech/documentation/guides/administration/)\n- [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/)\n- [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/)\n- [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/)\n- [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)\n- [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)\n- [Quantization](https://qdrant.tech/documentation/guides/quantization/)\n- [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/)\n- [Configuration](https://qdrant.tech/documentation/guides/configuration/)\n- [Security](https://qdrant.tech/documentation/guides/security/)\n- [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/)\n- [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)\n\n### Ecosystem\n\n[FastEmbed](https://qdrant.tech/documentation/fastembed/)\n\n- [Quickstart](https://qdrant.tech/documentation/fastembed/fastembed-quickstart/)\n- [FastEmbed & Qdrant](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/)\n- [Working with miniCOIL](https://qdrant.tech/documentation/fastembed/fastembed-minicoil/)\n- [Working with SPLADE](https://qdrant.tech/documentation/fastembed/fastembed-splade/)\n- [Working with ColBERT](https://qdrant.tech/documentation/fastembed/fastembed-colbert/)\n- [Reranking with FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-rerankers/)\n\n[Qdrant MCP Server](https://github.com/qdrant/mcp-server-qdrant)\n\n### Tutorials\n\n[Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)\n\n- [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)\n- [Build a Neural Search Service](https://qdrant.",
      "index": 1,
      "token_count": 507,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 1944,
      "end_char": 3948
    },
    {
      "content": "ocumentation/beginner-tutorials/search-beginners/)\n- [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)\n- [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)\n- [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)\n\n[Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)\n\n- [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/)\n- [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/)\n- [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)\n- [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)\n- [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)\n\n[Using the Database](https://qdrant.tech/documentation/database-tutorials/)\n\n- [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)\n- [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)\n- [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)\n- [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)\n- [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/)\n- [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/)\n- [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)\n\n### Support\n\n[FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n\n- [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)",
      "index": 2,
      "token_count": 472,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 3848,
      "end_char": 5863
    },
    {
      "content": "fundamentals/)\n\n- [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n- [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)\n\n[Release Notes](https://github.com/qdrant/qdrant/releases)\n\n### Getting Started\n\n[What is Qdrant?](https://qdrant.tech/documentation/overview/)\n\n- [Understanding Vector Search in Qdrant](https://qdrant.tech/documentation/overview/vector-search/)\n\n[Local Quickstart](https://qdrant.tech/documentation/quickstart/)\n\n[API & SDKs](https://qdrant.tech/documentation/interfaces/)\n\n[Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)\n\n### User Manual\n\n[Concepts](https://qdrant.tech/documentation/concepts/)\n\n- [Collections](https://qdrant.tech/documentation/concepts/collections/)\n- [Points](https://qdrant.tech/documentation/concepts/points/)\n- [Vectors](https://qdrant.tech/documentation/concepts/vectors/)\n- [Payload](https://qdrant.tech/documentation/concepts/payload/)\n- [Search](https://qdrant.tech/documentation/concepts/search/)\n- [Explore](https://qdrant.tech/documentation/concepts/explore/)\n- [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/)\n- [Filtering](https://qdrant.tech/documentation/concepts/filtering/)\n- [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/)\n- [Storage](https://qdrant.tech/documentation/concepts/storage/)\n- [Indexing](https://qdrant.tech/documentation/concepts/indexing/)\n- [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)\n\n[Guides](https://qdrant.tech/documentation/guides/installation/)\n\n- [Installation](https://qdrant.tech/documentation/guides/installation/)\n- [Administration](https://qdrant.tech/documentation/guides/administration/)\n- [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/)\n- [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/)\n- [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/)\n- [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)",
      "index": 3,
      "token_count": 514,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 5763,
      "end_char": 7811
    },
    {
      "content": "n/guides/optimize/)\n- [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)\n- [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)\n- [Quantization](https://qdrant.tech/documentation/guides/quantization/)\n- [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/)\n- [Configuration](https://qdrant.tech/documentation/guides/configuration/)\n- [Security](https://qdrant.tech/documentation/guides/security/)\n- [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/)\n- [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)\n\n### Ecosystem\n\n[FastEmbed](https://qdrant.tech/documentation/fastembed/)\n\n- [Quickstart](https://qdrant.tech/documentation/fastembed/fastembed-quickstart/)\n- [FastEmbed & Qdrant](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/)\n- [Working with miniCOIL](https://qdrant.tech/documentation/fastembed/fastembed-minicoil/)\n- [Working with SPLADE](https://qdrant.tech/documentation/fastembed/fastembed-splade/)\n- [Working with ColBERT](https://qdrant.tech/documentation/fastembed/fastembed-colbert/)\n- [Reranking with FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-rerankers/)\n\n[Qdrant MCP Server](https://github.com/qdrant/mcp-server-qdrant)\n\n### Tutorials\n\n[Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)\n\n- [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)\n- [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)\n- [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)\n- [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)\n\n[Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)\n\n- [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.",
      "index": 4,
      "token_count": 501,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 7711,
      "end_char": 9708
    },
    {
      "content": "nced-tutorials/)\n\n- [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/)\n- [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/)\n- [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)\n- [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)\n- [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)\n\n[Using the Database](https://qdrant.tech/documentation/database-tutorials/)\n\n- [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)\n- [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)\n- [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)\n- [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)\n- [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/)\n- [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/)\n- [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)\n\n### Support\n\n[FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n\n- [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n- [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)\n\n[Release Notes](https://github.com/qdrant/qdrant/releases)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- [Advanced tutorials](https://qdrant.tech/documentation/advanced-tutorials/)\n-\n- Scaling PDF Retrieval with Qdrant\n\n# Scaling PDF Retrieval with Qdrant\n\n| Time: 30 min | Level: Intermediate | Output: [GitHub](https://github.",
      "index": 5,
      "token_count": 482,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 9608,
      "end_char": 11621
    },
    {
      "content": "g PDF Retrieval with Qdrant\n\n| Time: 30 min | Level: Intermediate | Output: [GitHub](https://github.com/qdrant/examples/blob/master/pdf-retrieval-at-scale/ColPali_ColQwen2_Tutorial.ipynb) | [](https://githubtocolab.com/qdrant/examples/blob/master/pdf-retrieval-at-scale/ColPali_ColQwen2_Tutorial.ipynb) |\n| ------------ | ------------------- | ----------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- |\n\nEfficient PDF documents retrieval is a common requirement in tasks like **(agentic) retrieval-augmented generation (RAG)** and many other search-based applications. At the same time, setting up PDF documents retrieval is rarely possible without additional challenges.\n\nMany traditional PDF retrieval solutions rely on **optical character recognition (OCR)** together with use case-specific heuristics to handle visually complex elements like tables, images and charts. These algorithms are often non-transferable – even within the same domain – with their task-customized parsing and chunking strategies, labor-intensive, prone to errors, and difficult to scale.\n\nRecent advancements in **Vision Large Language Models (VLLMs)**, such as [**ColPali**](https://huggingface.co/blog/manu/colpali) and its successor [**ColQwen**](https://huggingface.co/vidore/colqwen2-v0.1), started the transformation of the PDF retrieval. These multimodal models work directly with PDF pages as inputs, no pre-processing required. Anything that can be converted into an **image** (think of PDFs as screenshots of document pages) can be effectively processed by these models. Being far simpler in use, VLLMs achieve state-of-the-art performance in PDF retrieval benchmarks like the [Visual Document Retrieval (ViDoRe) Benchmark](https://huggingface.co/spaces/vidore/vidore-leaderboard).\n\n## How VLLMs Work for PDF Retrieval",
      "index": 6,
      "token_count": 409,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 11521,
      "end_char": 13508
    },
    {
      "content": "rk](https://huggingface.co/spaces/vidore/vidore-leaderboard).\n\n## How VLLMs Work for PDF Retrieval\n\nVLLMs like **ColPali** and **ColQwen** generate **multivector representations** for each PDF page; the representations are stored and indexed in a vector database. During the retrieval process, models dynamically create multivector representations for (textual) user queries, and precise retrieval – matching between PDF pages and queries – is achieved through [late-interaction mechanism](https://qdrant.tech/blog/qdrant-colpali/#how-colpali-works-under-the-hood).\n\nQdrant supports [multivector representations](https://qdrant.tech/documentation/concepts/vectors/#multivectors), making it well-suited for using embedding models such as ColPali, ColQwen, or [ColBERT](https://qdrant.tech/documentation/fastembed/fastembed-colbert/)\n\n## Challenges of Scaling VLLMs\n\nThe heavy multivector representations produced by VLLMs make PDF retrieval at scale computationally intensive. These models are inefficient for large-scale PDF retrieval tasks if used without optimization.\n\n### Math Behind the Scaling\n\n**ColPali** generates over **1,000 vectors per PDF page**, while its successor, **ColQwen**, generates slightly fewer — up to **768 vectors**, dynamically adjusted based on the image size. Typically, ColQwen produces **\\~700 vectors per page**.\n\nTo understand the impact, consider the construction of an [**HNSW index**](https://qdrant.tech/articles/what-is-a-vector-database/#1-indexing-hnsw-index-and-sending-data-to-qdrant), a common indexing algorithm for vector databases. Let’s roughly estimate the number of comparisons needed to insert a new PDF page into the index.\n\n- **Vectors per page:** \\~700 (ColQwen) or \\~1,000 (ColPali)\n- **[ef\\_construct](https://qdrant.tech/documentation/concepts/indexing/#vector-index):** 100 (default)\n\nThe lower bound estimation for the number of vector comparisions comparisons would be:\n\n$$ 700 \\times 700 \\times 100 = 49 \\ \\text{millions} $$",
      "index": 7,
      "token_count": 492,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 13408,
      "end_char": 15395
    },
    {
      "content": "vector comparisions comparisons would be:\n\n$$ 700 \\times 700 \\times 100 = 49 \\ \\text{millions} $$\n\nNow imagine how much it will take to build an index on **20,000 pages**!\n\nFor ColPali, this number doubles. The result is **extremely slow index construction time**.\n\n### Our Solution\n\nWe recommend reducing the number of vectors in a PDF page representation for the **first-stage retrieval**. After the first stage retrieval with a reduced amount of vectors, we propose to **rerank** retrieved subset with the original uncompressed representation.\n\nYou might consider using **quantization** (e.g., binary quantization) to reduce computational resources. However, as you can see above, quantization does not impact the parameters that determine the number of comparisons, so it will only affect memory consumption.\n\nThe reduction of vectors can be achieved by applying a **mean pooling operation** to the multivector VLLM-generated outputs. Mean pooling averages the values across all vectors within a selected subgroup, condensing multiple vectors into a single representative vector. If done right, it allows the preservation of important information from the original page while significantly reducing the number of vectors.\n\nVLLMs generate vectors corresponding to patches that represent different portions of a PDF page. These patches can be grouped in columns and rows of a PDF page.\n\nFor example:\n\n- ColPali divides PDF page into **1,024 patches**.\n- Applying mean pooling by rows (or columns) of this patch matrix reduces the page representation to just **32 vectors**.\n\nWe tested this approach with the ColPali model, mean pooling its multivectors by PDF page rows. The results showed:\n\n- **Indexing time faster by an order of magnitude**\n- **Retrieval quality comparable to the original model**\n\nFor details of this experiment refer to our [gitHub repository](https://github.com/qdrant/demo-colpali-optimized), [ColPali optimization blog post](https://qdrant.",
      "index": 8,
      "token_count": 422,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 15295,
      "end_char": 17263
    },
    {
      "content": "(https://github.com/qdrant/demo-colpali-optimized), [ColPali optimization blog post](https://qdrant.tech/blog/colpali-qdrant-optimization/) or [webinar “PDF Retrieval at Scale”](https://www.youtube.com/watch?v=_h6SN1WwnLs)\n\n## Goal of This Tutorial\n\nIn this tutorial, we will demonstrate a scalable approach to PDF retrieval using **Qdrant** and **ColPali** & **ColQwen2** VLLMs. The presented approach is **highly recommended** to avoid the common pitfalls of long indexing times and slow retrieval speeds.\n\nIn the following sections, we will demonstrate an optimized retrieval algorithm born out of our successful experimentation:\n\n**First-Stage Retrieval with Mean-Pooled Vectors:**\n\n- Construct an HNSW index using **only mean-pooled vectors**.\n- Use them for the first-stage retrieval.\n\n**Reranking with Original Model Multivectors:**\n\n- Use the original multivectors from ColPali or ColQwen2 **to rerank** the results retrieved in the first stage.\n\n## Setup\n\nInstall & import required libraries\n\n```python\n# pip install colpali_engine>=0.3.1\nfrom colpali_engine.models import ColPali, ColPaliProcessor\n# pip install qdrant-client>=1.12.0\nfrom qdrant_client import QdrantClient, models\n```\n\nTo run these experiments, we’re using a **Qdrant cluster**. If you’re just getting started, you can set up a **free-tier cluster** for testing and exploration. Follow the instructions in the documentation [“How to Create a Free-Tier Qdrant Cluster”](https://qdrant.tech/documentation/cloud/create-cluster/#free-clusters)\n\n```python\nclient = QdrantClient(\n    url=<YOUR CLUSTER URL>,\n    api_key=<YOUR API KEY>\n)\n```\n\nDownload **ColPali** model along with its input processors. Make sure to select the backend that suits your setup.\n\n```python\ncolpali_model = ColPali.from_pretrained(\n        \"vidore/colpali-v1.3\",\n        torch_dtype=torch.bfloat16,\n        device_map=\"mps\",  # Use \"cuda:0\" for GPU, \"cpu\" for CPU, or \"mps\" for Apple Silicon\n    ).eval()\n\ncolpali_processor = ColPaliProcessor.from_pretrained(\"vidore/colpali-v1.3\")\n```",
      "index": 9,
      "token_count": 531,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 17163,
      "end_char": 19198
    },
    {
      "content": "icon\n    ).eval()\n\ncolpali_processor = ColPaliProcessor.from_pretrained(\"vidore/colpali-v1.3\")\n```\n\nFor **ColQwen** model\n\n```python\nfrom colpali_engine.models import ColQwen2, ColQwen2Processor\n\ncolqwen_model = ColQwen2.from_pretrained(\n        \"vidore/colqwen2-v0.1\",\n        torch_dtype=torch.bfloat16,\n        device_map=\"mps\", # Use \"cuda:0\" for GPU, \"cpu\" for CPU, or \"mps\" for Apple Silicon\n    ).eval()\n\ncolqwen_processor = ColQwen2Processor.from_pretrained(\"vidore/colqwen2-v0.1\")\n```\n\n## Create Qdrant Collections\n\nWe can now create a collection in Qdrant to store the multivector representations of PDF pages generated by **ColPali** or **ColQwen**.\n\nCollection will include **mean pooled** by rows and columns representations of a PDF page, as well as the **original** multivector representation.\n\nFor the original multivectors generated by the models, we will disable HNSW index construction\n\n```python\nclient.create_collection(\n    collection_name=collection_name,\n    vectors_config={\n        \"original\": \n            models.VectorParams( #switch off HNSW\n                    size=128,\n                    distance=models.Distance.COSINE,\n                    multivector_config=models.MultiVectorConfig(\n                        comparator=models.MultiVectorComparator.MAX_SIM\n                    ),\n                    hnsw_config=models.HnswConfigDiff(\n                        m=0 #switching off HNSW\n                    )\n            ),\n        \"mean_pooling_columns\": models.VectorParams(\n                size=128,\n                distance=models.Distance.COSINE,\n                multivector_config=models.MultiVectorConfig(\n                    comparator=models.MultiVectorComparator.MAX_SIM\n                )\n            ),\n        \"mean_pooling_rows\": models.VectorParams(\n                size=128,\n                distance=models.Distance.COSINE,\n                multivector_config=models.MultiVectorConfig(\n                    comparator=models.MultiVectorComparator.MAX_SIM\n                )\n            )\n    }\n)\n```",
      "index": 10,
      "token_count": 450,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 19098,
      "end_char": 21141
    },
    {
      "content": "comparator=models.MultiVectorComparator.MAX_SIM\n                )\n            )\n    }\n)\n```\n\n## Choose a dataset\n\nWe’ll use the **UFO Dataset** by Daniel van Strien for this tutorial. It’s available on Hugging Face; you can download it directly from there.\n\n```python\nfrom datasets import load_dataset\nufo_dataset = \"davanstrien/ufo-ColPali\"\ndataset = load_dataset(ufo_dataset, split=\"train\")\n```\n\n## Embedding and Mean Pooling\n\nWe’ll use a function that generates multivector representations and their mean pooled versions of each PDF page (aka image) in batches. For complete understanding, it’s important to consider the following specifics of **ColPali** and **ColQwen**:\n\n**ColPali:** In theory, ColPali is designed to generate 1,024 vectors per PDF page, but in practice, it produces 1,030 vectors. This discrepancy is due to ColPali’s pre-processor, which appends the text `<bos>Describe the image.` to each input. This additional text generates an extra 6 multivectors.\n\n**ColQwen:** ColQwen dynamically determines the number of patches in “rows and columns” of a PDF page based on its size. Consequently, the number of multivectors can vary between inputs. ColQwen pre-processor prepends `<|im_start|>user<|vision_start|>` and appends `<|vision_end|>Describe the image.<|im_end|><|endoftext|>`.\n\nFor example, that’s how ColQwen multivector output is formed.\n\nThe `get_patches` function is to get the number of `x_patches` (rows) and `y_patches` (columns) ColPali/ColQwen2 models will divide a PDF page into. For ColPali, the numbers will always be 32 by 32; ColQwen will define them dynamically based on the PDF page size.\n\n```python\nx_patches, y_patches = model_processor.get_n_patches(\n    image_size, \n    patch_size=model.patch_size\n)\n```\n\nFor **ColQwen** model\n\n```python\nmodel_processor.get_n_patches(\n    image_size, \n    patch_size=model.patch_size,\n    spatial_merge_size=model.spatial_merge_size\n)\n```\n\nWe choose to **preserve prefix and postfix multivectors**.",
      "index": 11,
      "token_count": 478,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 21041,
      "end_char": 23028
    },
    {
      "content": "erge_size=model.spatial_merge_size\n)\n```\n\nWe choose to **preserve prefix and postfix multivectors**. Our **pooling** operation compresses the multivectors representing **the image tokens** based on the number of rows and columns determined by the model (static 32x32 for ColPali, dynamic XxY for ColQwen). Function retains and integrates the additional multivectors produced by the model back to pooled representations.\n\nSimplified version of pooling for **ColPali** model:\n\n(see the full version – also applicable for **ColQwen** – in the [tutorial notebook](https://githubtocolab.com/qdrant/examples/blob/master/pdf-retrieval-at-scale/ColPali_ColQwen2_Tutorial.ipynb))\n\n```python\n\nprocessed_images = model_processor.process_images(image_batch) \n# Image embeddings of shape (batch_size, 1030, 128)\nimage_embeddings = model(**processed_images)\n\n# (1030, 128)\nimage_embedding = image_embeddings[0] # take the first element of the batch\n\n# Now we need to identify vectors that correspond to the image tokens\n# It can be done by selecting tokens corresponding to special `image_token_id`\n\n# (1030, ) - boolean mask (for the first element in the batch), True for image tokens \nmask = processed_images.input_ids[0] == model_processor.image_token_id\n\n# For convenience, we now select only image tokens \n#   and reshape them to (x_patches, y_patches, dim)\n\n# (x_patches, y_patches, 128)\nimage_patch_embeddings = image_embedding[mask].view(x_patches, y_patches, model.dim)\n\n# Now we can apply mean pooling by rows and columns\n\n# (x_patches, 128)\npooled_by_rows = image_patch_embeddings.mean(dim=0)\n\n# (y_patches, 128)\npooled_by_columns = image_patch_embeddings.mean(dim=1)\n\n# [Optionally] we can also concatenate special tokens to the pooled representations, \n# For ColPali, it's only postfix\n\n# (x_patches + 6, 128)\npooled_by_rows = torch.cat([pooled_by_rows, image_embedding[~mask]])\n\n# (y_patches + 6, 128)\npooled_by_columns = torch.cat([pooled_by_columns, image_embedding[~mask]])\n```\n\n## Upload to Qdrant",
      "index": 12,
      "token_count": 519,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 22928,
      "end_char": 24931
    },
    {
      "content": "ooled_by_columns = torch.cat([pooled_by_columns, image_embedding[~mask]])\n```\n\n## Upload to Qdrant\n\nThe upload process is trivial; the only thing to pay attention to is the compute cost for ColPali and ColQwen2 models. In low-resource environments, it’s recommended to use a smaller batch size for embedding and mean pooling.\n\nFull version of the upload code is available in the [tutorial notebook](https://githubtocolab.com/qdrant/examples/blob/master/pdf-retrieval-at-scale/ColPali_ColQwen2_Tutorial.ipynb)\n\n## Querying PDFs\n\nAfter indexing PDF documents, we can move on to querying them using our two-stage retrieval approach.\n\n```python\nquery = \"Lee Harvey Oswald's involvement in the JFK assassination\"\nprocessed_queries = model_processor.process_queries([query]).to(model.device)\n\n# Resulting query embedding is a tensor of shape (22, 128)\nquery_embedding = model(**processed_queries)[0]\n```\n\nNow let’s design a function for the two-stage retrieval with multivectors produced by VLLMs:\n\n- **Step 1:** Prefetch results using a compressed multivector representation & HNSW index.\n- **Step 2:** Re-rank the prefetched results using the original multivector representation.\n\nLet’s query our collections using combined mean pooled representations for the first stage of retrieval.\n\n```python\n# Final amount of results to return\nsearch_limit = 10\n# Amount of results to prefetch for reranking\nprefetch_limit = 100\n\nresponse = client.query_points(\n    collection_name=collection_name,\n    query=query_embedding,\n    prefetch=[\n        models.Prefetch(\n            query=query_embedding,\n            limit=prefetch_limit,\n            using=\"mean_pooling_columns\"\n        ),\n        models.Prefetch(\n            query=query_embedding,\n            limit=prefetch_limit,\n            using=\"mean_pooling_rows\"\n        ),\n    ],\n    limit=search_limit,\n    with_payload=True,\n    with_vector=False,\n    using=\"original\"\n)\n```\n\nAnd check the top retrieved result to our query *“Lee Harvey Oswald’s involvement in the JFK assassination”*.\n\n```python",
      "index": 13,
      "token_count": 455,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 24831,
      "end_char": 26872
    },
    {
      "content": "rieved result to our query *“Lee Harvey Oswald’s involvement in the JFK assassination”*.\n\n```python\ndataset[response.points[0].payload['index']]['image']\n```\n\n## Conclusion\n\nIn this tutorial, we demonstrated an optimized approach using **Qdrant for PDF retrieval at scale** with VLLMs producing **heavy multivector representations** like **ColPali** and **ColQwen2**.\n\nWithout such optimization, the performance of retrieval systems can degrade severely, both in terms of indexing time and query latency, especially as the dataset size grows.\n\nWe **strongly recommend** implementing this approach in your workflows to ensure efficient and scalable PDF retrieval. Neglecting to optimize the retrieval process could result in unacceptably slow performance, hindering the usability of your system.\n\nStart scaling your PDF retrieval today!\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! 🙏\n\nWe are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/advanced-tutorials/pdf-retrieval-at-scale.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Scaling PDF Retrieval with Qdrant](#scaling-pdf-retrieval-with-qdrant.md)\n\n  - [How VLLMs Work for PDF Retrieval](#how-vllms-work-for-pdf-retrieval.md)\n\n  - [Challenges of Scaling VLLMs](#challenges-of-scaling-vllms.md)\n\n    - [Math Behind the Scaling](#math-behind-the-scaling.md)\n    - [Our Solution](#our-solution.md)\n\n  - [Goal of This Tutorial](#goal-of-this-tutorial.md)\n\n  - [Setup](#setup.md)\n\n  - [Create Qdrant Collections](#create-qdrant-collections.md)\n\n  - [Choose a dataset](#choose-a-dataset.md)\n\n  - [Embedding and Mean Pooling](#embedding-and-mean-pooling.md)\n\n  - [Upload to Qdrant](#upload-to-qdrant.md)\n\n  - [Querying PDFs](#querying-pdfs.md)\n\n  - [Conclusion](#conclusion.md)\n\n* [Edit on Github](https://github.",
      "index": 14,
      "token_count": 492,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 26772,
      "end_char": 28713
    },
    {
      "content": "rying PDFs](#querying-pdfs.md)\n\n  - [Conclusion](#conclusion.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/advanced-tutorials/pdf-retrieval-at-scale.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
      "index": 15,
      "token_count": 158,
      "metadata": {
        "title": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_",
        "source": "qdrant_documentation\\documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_documentation",
        "source_subdir": "documentation_advanced-tutorials_pdf-retrieval-at-scale",
        "category": "advanced-tutorials",
        "file_path": "documentation_advanced-tutorials_pdf-retrieval-at-scale\\_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "file_name": "_documentation_advanced-tutorials_pdf-retrieval-at-scale_.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:28.907540",
        "total_chunks": 16
      },
      "start_char": 28613,
      "end_char": 30661
    }
  ]
}
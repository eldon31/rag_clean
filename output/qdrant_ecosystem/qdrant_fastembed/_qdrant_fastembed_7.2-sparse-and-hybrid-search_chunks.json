{
  "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
  "source_repo": "qdrant_fastembed",
  "total_chunks": 6,
  "chunks": [
    {
      "content": "Sparse and Hybrid Search | qdrant/fastembed | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[qdrant/fastembed](https://github.com/qdrant/fastembed \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 20 April 2025 ([b78564](https://github.com/qdrant/fastembed/commits/b785640b))\n\n- [Overview](qdrant/fastembed/1-overview.md)\n- [Installation and Setup](qdrant/fastembed/2-installation-and-setup.md)\n- [Core Embedding Classes](qdrant/fastembed/3-core-embedding-classes.md)\n- [TextEmbedding](qdrant/fastembed/3.1-textembedding.md)\n- [SparseTextEmbedding](qdrant/fastembed/3.2-sparsetextembedding.md)\n- [LateInteractionTextEmbedding](qdrant/fastembed/3.3-lateinteractiontextembedding.md)\n- [ImageEmbedding](qdrant/fastembed/3.4-imageembedding.md)\n- [LateInteractionMultimodalEmbedding](qdrant/fastembed/3.5-lateinteractionmultimodalembedding.md)\n- [TextCrossEncoder](qdrant/fastembed/3.6-textcrossencoder.md)\n- [Architecture](qdrant/fastembed/4-architecture.md)\n- [Model Management](qdrant/fastembed/4.1-model-management.md)\n- [ONNX Runtime Integration](qdrant/fastembed/4.2-onnx-runtime-integration.md)\n- [Parallel Processing](qdrant/fastembed/4.3-parallel-processing.md)\n- [Implementation Details](qdrant/fastembed/5-implementation-details.md)\n- [Dense Text Embeddings](qdrant/fastembed/5.1-dense-text-embeddings.md)\n- [Sparse Text Embeddings](qdrant/fastembed/5.2-sparse-text-embeddings.md)\n- [Late Interaction Models](qdrant/fastembed/5.3-late-interaction-models.md)\n- [Multimodal Models](qdrant/fastembed/5.4-multimodal-models.md)\n- [Supported Models](qdrant/fastembed/6-supported-models.md)\n- [Usage Examples](qdrant/fastembed/7-usage-examples.md)\n- [Basic Text Embedding](qdrant/fastembed/7.1-basic-text-embedding.md)\n- [Sparse and Hybrid Search](qdrant/fastembed/7.2-sparse-and-hybrid-search.md)\n- [ColBERT and Late Interaction](qdrant/fastembed/7.3-colbert-and-late-interaction.md)\n- [Image Embedding](qdrant/fastembed/7.",
      "index": 0,
      "token_count": 621,
      "metadata": {
        "title": "_qdrant_fastembed_7.2-sparse-and-hybrid-search",
        "source": "qdrant_fastembed\\_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_fastembed",
        "source_subdir": "root",
        "category": "general",
        "file_path": "_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "file_name": "_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:34.743697",
        "total_chunks": 6
      },
      "start_char": 0,
      "end_char": 2043
    },
    {
      "content": "ction](qdrant/fastembed/7.3-colbert-and-late-interaction.md)\n- [Image Embedding](qdrant/fastembed/7.4-image-embedding.md)\n- [Performance Optimization](qdrant/fastembed/8-performance-optimization.md)\n- [Integration with Qdrant](qdrant/fastembed/9-integration-with-qdrant.md)\n- [Development Guide](qdrant/fastembed/10-development-guide.md)\n\nMenu\n\n# Sparse and Hybrid Search\n\nRelevant source files\n\n- [tests/test\\_attention\\_embeddings.py](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_attention_embeddings.py)\n- [tests/test\\_sparse\\_embeddings.py](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_sparse_embeddings.py)\n\nThis page provides a comprehensive guide to implementing sparse embeddings and hybrid search using FastEmbed. While [TextEmbedding](qdrant/fastembed/3.1-textembedding.md) creates dense vector representations, sparse embeddings offer a different approach with unique advantages that complement dense embeddings in search applications.\n\n## Understanding Sparse Embeddings and Hybrid Search\n\nSparse embeddings represent text as high-dimensional, sparse vectors where most elements are zero. Unlike dense embeddings, sparse vectors only store the non-zero elements through indices and corresponding values.\n\n```\n```\n\nSources: [tests/test\\_sparse\\_embeddings.py10-47](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_sparse_embeddings.py#L10-L47)\n\n## Sparse Embedding Models in FastEmbed\n\nFastEmbed provides several sparse embedding models through the `SparseTextEmbedding` class:\n\n```\n```\n\nSources: [tests/test\\_sparse\\_embeddings.py6-7](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_sparse_embeddings.py#L6-L7) [tests/test\\_attention\\_embeddings.py6](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_attention_embeddings.py#L6-L6)\n\n### Supported Models\n\nFastEmbed supports multiple types of sparse embedding models:\n\n1. **SPLADE Models**: Sparse Lexical and Expansion models (e.g., \"prithivida/Splade\\_PP\\_en\\_v1\")\n2.",
      "index": 1,
      "token_count": 498,
      "metadata": {
        "title": "_qdrant_fastembed_7.2-sparse-and-hybrid-search",
        "source": "qdrant_fastembed\\_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_fastembed",
        "source_subdir": "root",
        "category": "general",
        "file_path": "_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "file_name": "_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:34.743697",
        "total_chunks": 6
      },
      "start_char": 1943,
      "end_char": 3941
    },
    {
      "content": "1. **SPLADE Models**: Sparse Lexical and Expansion models (e.g., \"prithivida/Splade\\_PP\\_en\\_v1\")\n2. **BM25**: Classical lexical retrieval algorithm based on term frequency-inverse document frequency\n3. **BM42**: Attention-based sparse embeddings that combine neural and lexical features\n\nEach model produces sparse embeddings with different characteristics suitable for various search tasks.\n\nSources: [tests/test\\_sparse\\_embeddings.py52](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_sparse_embeddings.py#L52-L52) [tests/test\\_attention\\_embeddings.py10](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_attention_embeddings.py#L10-L10)\n\n## Using Sparse Embeddings\n\n### Basic Usage\n\nThe `SparseTextEmbedding` class provides a straightforward interface for generating sparse embeddings:\n\n```\n```\n\nSources: [tests/test\\_sparse\\_embeddings.py57-65](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_sparse_embeddings.py#L57-L65)\n\n### Query vs. Passage Embeddings\n\nFor search applications, FastEmbed allows you to generate specialized embeddings for queries and passages:\n\n```\n```\n\nThis distinction is important for asymmetric search scenarios where queries and documents may need different processing.\n\nSources: [tests/test\\_sparse\\_embeddings.py84-86](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_sparse_embeddings.py#L84-L86)\n\n### Language Support and Special Characters\n\nBM25 models support multiple languages and handle special characters effectively:\n\n```\n```\n\nThe language parameter affects tokenization and stemming behavior, optimizing for language-specific features.\n\nSources: [tests/test\\_attention\\_embeddings.py104-111](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_attention_embeddings.py#L104-L111) [tests/test\\_attention\\_embeddings.py125-144](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_attention_embeddings.py#L125-L144)\n\n## Sparse Embedding Structure\n\nSparse embeddings in FastEmbed are represented with two components:\n\n1.",
      "index": 2,
      "token_count": 507,
      "metadata": {
        "title": "_qdrant_fastembed_7.2-sparse-and-hybrid-search",
        "source": "qdrant_fastembed\\_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_fastembed",
        "source_subdir": "root",
        "category": "general",
        "file_path": "_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "file_name": "_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:34.743697",
        "total_chunks": 6
      },
      "start_char": 3841,
      "end_char": 5868
    },
    {
      "content": "Sparse Embedding Structure\n\nSparse embeddings in FastEmbed are represented with two components:\n\n1. **Indices**: Integer array indicating which dimensions have non-zero values\n2. **Values**: Corresponding importance/weight for each non-zero dimension\n\n```\n```\n\nThis format allows for efficient storage and processing of high-dimensional sparse vectors.\n\nSources: [tests/test\\_sparse\\_embeddings.py10-47](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_sparse_embeddings.py#L10-L47)\n\n## Implementing Hybrid Search\n\nHybrid search combines the strengths of sparse and dense embeddings to improve search quality. Here's how to implement it:\n\n```\n```\n\n### Implementation Steps:\n\n1. Generate both sparse and dense embeddings for your document collection\n\n2. For each query, generate both sparse and dense query embeddings\n\n3. Perform separate searches with each embedding type\n\n4. Combine and re-rank the results using strategies like:\n\n   - Score normalization and weighted combination\n   - Reciprocal rank fusion\n   - Taking the union of top results from both methods\n\nSources: [tests/test\\_sparse\\_embeddings.py](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_sparse_embeddings.py) [tests/test\\_attention\\_embeddings.py](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_attention_embeddings.py)\n\n## Performance Optimization\n\nFastEmbed provides several performance optimizations for sparse embeddings:\n\n### Batch Processing\n\nProcess multiple documents efficiently:\n\n```\n```\n\nSources: [tests/test\\_sparse\\_embeddings.py98-102](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_sparse_embeddings.py#L98-L102)\n\n### Parallel Execution\n\nEnable parallel processing to utilize multiple CPU cores:\n\n```\n```\n\nSources: [tests/test\\_sparse\\_embeddings.py98-121](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_sparse_embeddings.py#L98-L121) [tests/test\\_attention\\_embeddings.py74-95](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_attention_embeddings.py#L74-L95)\n\n### Lazy Loading",
      "index": 3,
      "token_count": 492,
      "metadata": {
        "title": "_qdrant_fastembed_7.2-sparse-and-hybrid-search",
        "source": "qdrant_fastembed\\_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_fastembed",
        "source_subdir": "root",
        "category": "general",
        "file_path": "_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "file_name": "_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:34.743697",
        "total_chunks": 6
      },
      "start_char": 5768,
      "end_char": 7815
    },
    {
      "content": "b.com/qdrant/fastembed/blob/b785640b/tests/test_attention_embeddings.py#L74-L95)\n\n### Lazy Loading\n\nDefer model loading until first use to conserve memory:\n\n```\n```\n\nSources: [tests/test\\_sparse\\_embeddings.py189-206](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_sparse_embeddings.py#L189-L206) [tests/test\\_attention\\_embeddings.py147-159](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_attention_embeddings.py#L147-L159)\n\n## BM25 Configuration\n\nThe BM25 model offers additional configuration options:\n\n### Stemming and Stopwords\n\n```\n```\n\nStemming reduces words to their root form, while stopword removal filters out common words. These techniques can significantly impact search quality.\n\nSources: [tests/test\\_sparse\\_embeddings.py136-186](https://github.com/qdrant/fastembed/blob/b785640b/tests/test_sparse_embeddings.py#L136-L186)\n\n## Summary\n\nSparse embeddings provide a complementary approach to dense embeddings, capturing lexical and token-level information that can improve search relevance. FastEmbed's `SparseTextEmbedding` class offers a flexible and efficient way to generate these embeddings with various models, including SPLADE, BM25, and BM42.\n\nHybrid search, combining sparse and dense approaches, leverages the strengths of both methods to deliver more comprehensive search results, particularly beneficial for complex search scenarios where both semantic and lexical matching are important.\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh\n\n### On this page\n\n- [Sparse and Hybrid Search](#sparse-and-hybrid-search.md)\n- [Understanding Sparse Embeddings and Hybrid Search](#understanding-sparse-embeddings-and-hybrid-search.md)\n- [Sparse Embedding Models in FastEmbed](#sparse-embedding-models-in-fastembed.md)\n- [Supported Models](#supported-models.md)\n- [Using Sparse Embeddings](#using-sparse-embeddings.md)\n- [Basic Usage](#basic-usage.md)\n- [Query vs. Passage Embeddings](#query-vs-passage-embeddings.md)\n- [Language Support and Special Characters](#language-support-and-special-characters.",
      "index": 4,
      "token_count": 506,
      "metadata": {
        "title": "_qdrant_fastembed_7.2-sparse-and-hybrid-search",
        "source": "qdrant_fastembed\\_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_fastembed",
        "source_subdir": "root",
        "category": "general",
        "file_path": "_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "file_name": "_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:34.743697",
        "total_chunks": 6
      },
      "start_char": 7715,
      "end_char": 9764
    },
    {
      "content": "embeddings.md)\n- [Language Support and Special Characters](#language-support-and-special-characters.md)\n- [Sparse Embedding Structure](#sparse-embedding-structure.md)\n- [Implementing Hybrid Search](#implementing-hybrid-search.md)\n- [Implementation Steps:](#implementation-steps.md)\n- [Performance Optimization](#performance-optimization.md)\n- [Batch Processing](#batch-processing.md)\n- [Parallel Execution](#parallel-execution.md)\n- [Lazy Loading](#lazy-loading.md)\n- [BM25 Configuration](#bm25-configuration.md)\n- [Stemming and Stopwords](#stemming-and-stopwords.md)\n- [Summary](#summary.md)",
      "index": 5,
      "token_count": 146,
      "metadata": {
        "title": "_qdrant_fastembed_7.2-sparse-and-hybrid-search",
        "source": "qdrant_fastembed\\_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_fastembed",
        "source_subdir": "root",
        "category": "general",
        "file_path": "_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "file_name": "_qdrant_fastembed_7.2-sparse-and-hybrid-search.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:34.743697",
        "total_chunks": 6
      },
      "start_char": 9664,
      "end_char": 11712
    }
  ]
}
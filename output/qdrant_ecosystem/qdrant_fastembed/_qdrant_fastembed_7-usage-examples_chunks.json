{
  "source_file": "C:\\Users\\raze0\\Documents\\LLM_KNOWLEDGE_CREATOR\\RAG\\RAG_CLEAN\\Docs\\qdrant_ecosystem\\qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
  "source_repo": "qdrant_fastembed",
  "total_chunks": 5,
  "chunks": [
    {
      "content": "Usage Examples | qdrant/fastembed | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[qdrant/fastembed](https://github.com/qdrant/fastembed \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 20 April 2025 ([b78564](https://github.com/qdrant/fastembed/commits/b785640b))\n\n- [Overview](qdrant/fastembed/1-overview.md)\n- [Installation and Setup](qdrant/fastembed/2-installation-and-setup.md)\n- [Core Embedding Classes](qdrant/fastembed/3-core-embedding-classes.md)\n- [TextEmbedding](qdrant/fastembed/3.1-textembedding.md)\n- [SparseTextEmbedding](qdrant/fastembed/3.2-sparsetextembedding.md)\n- [LateInteractionTextEmbedding](qdrant/fastembed/3.3-lateinteractiontextembedding.md)\n- [ImageEmbedding](qdrant/fastembed/3.4-imageembedding.md)\n- [LateInteractionMultimodalEmbedding](qdrant/fastembed/3.5-lateinteractionmultimodalembedding.md)\n- [TextCrossEncoder](qdrant/fastembed/3.6-textcrossencoder.md)\n- [Architecture](qdrant/fastembed/4-architecture.md)\n- [Model Management](qdrant/fastembed/4.1-model-management.md)\n- [ONNX Runtime Integration](qdrant/fastembed/4.2-onnx-runtime-integration.md)\n- [Parallel Processing](qdrant/fastembed/4.3-parallel-processing.md)\n- [Implementation Details](qdrant/fastembed/5-implementation-details.md)\n- [Dense Text Embeddings](qdrant/fastembed/5.1-dense-text-embeddings.md)\n- [Sparse Text Embeddings](qdrant/fastembed/5.2-sparse-text-embeddings.md)\n- [Late Interaction Models](qdrant/fastembed/5.3-late-interaction-models.md)\n- [Multimodal Models](qdrant/fastembed/5.4-multimodal-models.md)\n- [Supported Models](qdrant/fastembed/6-supported-models.md)\n- [Usage Examples](qdrant/fastembed/7-usage-examples.md)\n- [Basic Text Embedding](qdrant/fastembed/7.1-basic-text-embedding.md)\n- [Sparse and Hybrid Search](qdrant/fastembed/7.2-sparse-and-hybrid-search.md)\n- [ColBERT and Late Interaction](qdrant/fastembed/7.3-colbert-and-late-interaction.md)\n- [Image Embedding](qdrant/fastembed/7.",
      "index": 0,
      "token_count": 619,
      "metadata": {
        "title": "_qdrant_fastembed_7-usage-examples",
        "source": "qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_fastembed",
        "source_subdir": "root",
        "category": "general",
        "file_path": "_qdrant_fastembed_7-usage-examples.md",
        "file_name": "_qdrant_fastembed_7-usage-examples.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:34.730383",
        "total_chunks": 5
      },
      "start_char": 0,
      "end_char": 2033
    },
    {
      "content": "ction](qdrant/fastembed/7.3-colbert-and-late-interaction.md)\n- [Image Embedding](qdrant/fastembed/7.4-image-embedding.md)\n- [Performance Optimization](qdrant/fastembed/8-performance-optimization.md)\n- [Integration with Qdrant](qdrant/fastembed/9-integration-with-qdrant.md)\n- [Development Guide](qdrant/fastembed/10-development-guide.md)\n\nMenu\n\n# Usage Examples\n\nRelevant source files\n\n- [docs/Getting Started.ipynb](<https://github.com/qdrant/fastembed/blob/b785640b/docs/Getting Started.ipynb>)\n- [docs/examples/ColBERT\\_with\\_FastEmbed.ipynb](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/ColBERT_with_FastEmbed.ipynb)\n- [docs/examples/FastEmbed\\_vs\\_HF\\_Comparison.ipynb](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_vs_HF_Comparison.ipynb)\n- [docs/examples/Hybrid\\_Search.ipynb](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Hybrid_Search.ipynb)\n- [docs/index.md](https://github.com/qdrant/fastembed/blob/b785640b/docs/index.md)\n- [docs/qdrant/Retrieval\\_with\\_FastEmbed.ipynb](https://github.com/qdrant/fastembed/blob/b785640b/docs/qdrant/Retrieval_with_FastEmbed.ipynb)\n\nThis page provides practical examples of using FastEmbed for various embedding tasks. It demonstrates how to generate and work with embeddings for different use cases including basic text embedding, sparse and hybrid search, late interaction models, and more. For installation and setup information, see [Installation and Setup](qdrant/fastembed/2-installation-and-setup.md).\n\n## Basic Text Embedding\n\nThe most common use case for FastEmbed is generating dense text embeddings using the `TextEmbedding` class.\n\n```\n```\n\nEach embedding is a numpy array with the default model's dimension (384 for BAAI/bge-small-en-v1.5):\n\n```\n```\n\n### Using Different Models\n\nFastEmbed supports various embedding models with different capabilities:\n\n```\n```\n\n### Query vs Passage Embedding\n\nFor retrieval tasks, it's recommended to use specific embedding methods for queries and passages:\n\n```\n```",
      "index": 1,
      "token_count": 543,
      "metadata": {
        "title": "_qdrant_fastembed_7-usage-examples",
        "source": "qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_fastembed",
        "source_subdir": "root",
        "category": "general",
        "file_path": "_qdrant_fastembed_7-usage-examples.md",
        "file_name": "_qdrant_fastembed_7-usage-examples.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:34.730383",
        "total_chunks": 5
      },
      "start_char": 1933,
      "end_char": 3958
    },
    {
      "content": "ieval tasks, it's recommended to use specific embedding methods for queries and passages:\n\n```\n```\n\nSources: [docs/Getting Started.ipynb68-86](<https://github.com/qdrant/fastembed/blob/b785640b/docs/Getting Started.ipynb#L68-L86>) [docs/Getting Started.ipynb116-120](<https://github.com/qdrant/fastembed/blob/b785640b/docs/Getting Started.ipynb#L116-L120>) [docs/qdrant/Retrieval\\_with\\_FastEmbed.ipynb73-93](https://github.com/qdrant/fastembed/blob/b785640b/docs/qdrant/Retrieval_with_FastEmbed.ipynb#L73-L93) [docs/qdrant/Retrieval\\_with\\_FastEmbed.ipynb111-114](https://github.com/qdrant/fastembed/blob/b785640b/docs/qdrant/Retrieval_with_FastEmbed.ipynb#L111-L114)\n\n## Sparse and Hybrid Search\n\nFastEmbed supports sparse embeddings through the `SparseTextEmbedding` class, which is useful for hybrid search applications.\n\n### Sparse Embedding Generation\n\n```\n```\n\nSparse embeddings contain indices and values, representing token positions and their weights:\n\n```\n```\n\n### Hybrid Search with Qdrant\n\nCombining dense and sparse embeddings enables hybrid search using Qdrant:\n\n```\n```\n\nThe hybrid search workflow:\n\n```\n```\n\nSources: [docs/examples/Hybrid\\_Search.ipynb52-73](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Hybrid_Search.ipynb#L52-L73) [docs/examples/Hybrid\\_Search.ipynb442-470](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Hybrid_Search.ipynb#L442-L470) [docs/examples/Hybrid\\_Search.ipynb874-922](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/Hybrid_Search.ipynb#L874-L922)\n\n## ColBERT and Late Interaction Models\n\nFastEmbed supports late interaction models through the `LateInteractionTextEmbedding` class, which enables more precise retrieval by preserving token-level interactions.\n\n### Understanding Late Interaction\n\nLate interaction models like ColBERT compute embeddings for each token in queries and documents, rather than pooling them into a single vector:\n\n```\n```\n\n### Using ColBERT Model\n\n```\n```\n\n### Maximal Similarity (MaxSim) Scoring",
      "index": 2,
      "token_count": 598,
      "metadata": {
        "title": "_qdrant_fastembed_7-usage-examples",
        "source": "qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_fastembed",
        "source_subdir": "root",
        "category": "general",
        "file_path": "_qdrant_fastembed_7-usage-examples.md",
        "file_name": "_qdrant_fastembed_7-usage-examples.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:34.730383",
        "total_chunks": 5
      },
      "start_char": 3858,
      "end_char": 5882
    },
    {
      "content": "single vector:\n\n```\n```\n\n### Using ColBERT Model\n\n```\n```\n\n### Maximal Similarity (MaxSim) Scoring\n\nLate interaction models require a specific similarity computation called MaxSim:\n\n```\n```\n\nThe MaxSim operation workflow:\n\n```\n```\n\nSources: [docs/examples/ColBERT\\_with\\_FastEmbed.ipynb72-74](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/ColBERT_with_FastEmbed.ipynb#L72-L74) [docs/examples/ColBERT\\_with\\_FastEmbed.ipynb168-205](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/ColBERT_with_FastEmbed.ipynb#L168-L205) [docs/examples/ColBERT\\_with\\_FastEmbed.ipynb280-309](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/ColBERT_with_FastEmbed.ipynb#L280-L309)\n\n## Performance Comparison\n\nFastEmbed is designed to be faster than traditional embedding libraries by utilizing ONNX Runtime for inference and optimized model implementations.\n\n### Benchmarking with Hugging Face Transformers\n\nThe following benchmark compares FastEmbed with Hugging Face Transformers using the same model (BAAI/bge-small-en-v1.5):\n\n```\n```\n\nA typical benchmark with a set of 12 documents shows FastEmbed is around 10-20% faster than Hugging Face Transformers:\n\n| Framework       | Average (s) | Maximum (s) | Minimum (s) |\n| --------------- | ----------- | ----------- | ----------- |\n| HF Transformers | 0.047       | 0.066       | 0.043       |\n| FastEmbed       | 0.044       | 0.057       | 0.043       |\n\nFor larger document sets, the performance gap increases due to FastEmbed's parallel processing capabilities.\n\n### Parallelization Benefits\n\nFastEmbed uses data parallelism to speed up embedding generation, significantly reducing processing time for large datasets. In testing with sparse embeddings, parallelization reduced processing time by approximately 50-60% on a multi-core system.\n\nSources: [docs/examples/FastEmbed\\_vs\\_HF\\_Comparison.ipynb149-166](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_vs_HF_Comparison.ipynb#L149-L166) [docs/examples/FastEmbed\\_vs\\_HF\\_Comparison.",
      "index": 3,
      "token_count": 571,
      "metadata": {
        "title": "_qdrant_fastembed_7-usage-examples",
        "source": "qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_fastembed",
        "source_subdir": "root",
        "category": "general",
        "file_path": "_qdrant_fastembed_7-usage-examples.md",
        "file_name": "_qdrant_fastembed_7-usage-examples.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:34.730383",
        "total_chunks": 5
      },
      "start_char": 5782,
      "end_char": 7830
    },
    {
      "content": "s/examples/FastEmbed_vs_HF_Comparison.ipynb#L149-L166) [docs/examples/FastEmbed\\_vs\\_HF\\_Comparison.ipynb256-278](https://github.com/qdrant/fastembed/blob/b785640b/docs/examples/FastEmbed_vs_HF_Comparison.ipynb#L256-L278)\n\n## Integration with Qdrant\n\nFastEmbed integrates seamlessly with Qdrant for vector search and retrieval:\n\n```\n```\n\nThe integration workflow:\n\n```\n```\n\nSources: [docs/index.md40-74](https://github.com/qdrant/fastembed/blob/b785640b/docs/index.md#L40-L74)\n\n## Cross-Encoder Reranking\n\nThe `TextCrossEncoder` class can be used to rerank search results:\n\n```\n```\n\nThe reranking workflow:\n\n```\n```\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh\n\n### On this page\n\n- [Usage Examples](#usage-examples.md)\n- [Basic Text Embedding](#basic-text-embedding.md)\n- [Using Different Models](#using-different-models.md)\n- [Query vs Passage Embedding](#query-vs-passage-embedding.md)\n- [Sparse and Hybrid Search](#sparse-and-hybrid-search.md)\n- [Sparse Embedding Generation](#sparse-embedding-generation.md)\n- [Hybrid Search with Qdrant](#hybrid-search-with-qdrant.md)\n- [ColBERT and Late Interaction Models](#colbert-and-late-interaction-models.md)\n- [Understanding Late Interaction](#understanding-late-interaction.md)\n- [Using ColBERT Model](#using-colbert-model.md)\n- [Maximal Similarity (MaxSim) Scoring](#maximal-similarity-maxsim-scoring.md)\n- [Performance Comparison](#performance-comparison.md)\n- [Benchmarking with Hugging Face Transformers](#benchmarking-with-hugging-face-transformers.md)\n- [Parallelization Benefits](#parallelization-benefits.md)\n- [Integration with Qdrant](#integration-with-qdrant.md)\n- [Cross-Encoder Reranking](#cross-encoder-reranking.md)",
      "index": 4,
      "token_count": 474,
      "metadata": {
        "title": "_qdrant_fastembed_7-usage-examples",
        "source": "qdrant_fastembed\\_qdrant_fastembed_7-usage-examples.md",
        "chunk_method": "simple_fallback",
        "source_repo": "qdrant_fastembed",
        "source_subdir": "root",
        "category": "general",
        "file_path": "_qdrant_fastembed_7-usage-examples.md",
        "file_name": "_qdrant_fastembed_7-usage-examples.md",
        "collection": "qdrant_ecosystem",
        "processed_date": "2025-10-16T01:58:34.730383",
        "total_chunks": 5
      },
      "start_char": 7730,
      "end_char": 9778
    }
  ]
}
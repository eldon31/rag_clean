[
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:0",
    "content": "Blog-Reading Chatbot with GPT-4o - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "token_count": 288,
      "char_count": 1024,
      "start_char": 0,
      "end_char": 1024
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:1",
    "content": ".tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "token_count": 267,
      "char_count": 1000,
      "start_char": 924,
      "end_char": 1924
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:2",
    "content": "nfluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "token_count": 264,
      "char_count": 1011,
      "start_char": 1824,
      "end_char": 2836
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:3",
    "content": "entation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "token_count": 271,
      "char_count": 1012,
      "start_char": 2736,
      "end_char": 3748
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:4",
    "content": "/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "token_count": 275,
      "char_count": 1007,
      "start_char": 3648,
      "end_char": 4655
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:5",
    "content": "[LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "token_count": 269,
      "char_count": 1003,
      "start_char": 4555,
      "end_char": 5560
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:6",
    "content": "meworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "token_count": 273,
      "char_count": 1015,
      "start_char": 5460,
      "end_char": 6475
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:7",
    "content": "ion/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "token_count": 257,
      "char_count": 987,
      "start_char": 6375,
      "end_char": 7364
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:8",
    "content": "ering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "token_count": 259,
      "char_count": 978,
      "start_char": 7264,
      "end_char": 8242
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:9",
    "content": "ion/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "token_count": 231,
      "char_count": 997,
      "start_char": 8142,
      "end_char": 9139
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:10",
    "content": "cumentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "token_count": 280,
      "char_count": 1022,
      "start_char": 9039,
      "end_char": 10063
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:11",
    "content": "ng Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "token_count": 262,
      "char_count": 1025,
      "start_char": 9963,
      "end_char": 10988
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:12",
    "content": "ured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "token_count": 270,
      "char_count": 995,
      "start_char": 10888,
      "end_char": 11883
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:13",
    "content": "[Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "token_count": 269,
      "char_count": 990,
      "start_char": 11783,
      "end_char": 12773
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:14",
    "content": "peval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "token_count": 284,
      "char_count": 1019,
      "start_char": 12673,
      "end_char": 13692
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:15",
    "content": "j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "token_count": 270,
      "char_count": 1016,
      "start_char": 13592,
      "end_char": 14610
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:16",
    "content": "entation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "token_count": 279,
      "char_count": 1018,
      "start_char": 14510,
      "end_char": 15528
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:17",
    "content": "PT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "token_count": 249,
      "char_count": 974,
      "start_char": 15428,
      "end_char": 16402
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:18",
    "content": "-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "token_count": 254,
      "char_count": 1005,
      "start_char": 16302,
      "end_char": 17307
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:19",
    "content": "r-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- [Examples](https://qdrant.tech/documentation/examples/)\n-\n- Blog-Reading Chatbot with GPT-4o",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "token_count": 240,
      "char_count": 1000,
      "start_char": 17207,
      "end_char": 18209
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:20",
    "content": ")\n-\n- [Examples](https://qdrant.tech/documentation/examples/)\n-\n- Blog-Reading Chatbot with GPT-4o\n\n# Blog-Reading Chatbot with GPT-4o\n\n| Time: 90 min | Level: Advanced | [GitHub](https://github.com/qdrant/examples/blob/langchain-lcel-rag/langchain-lcel-rag/Langchain-LCEL-RAG-Demo.ipynb) |   |\n| ------------ | --------------- | --------------------------------------------------------------------------------------------------------------------- | - |\n\nIn this tutorial, you will build a RAG system that combines blog content ingestion with the capabilities of semantic search. **OpenAI’s GPT-4o LLM** is powerful, but scaling its use requires us to supply context systematically.\n\nRAG enhances the LLM’s generation of answers by retrieving relevant documents to aid the question-answering process. This setup showcases the integration of advanced search and AI language processing to improve information retrieval and generation tasks.\n\nA notebook for this tutorial is available on [GitHub](https://github.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "token_count": 213,
      "char_count": 1009,
      "start_char": 18109,
      "end_char": 19118
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:21",
    "content": "trieval and generation tasks.\n\nA notebook for this tutorial is available on [GitHub](https://github.com/qdrant/examples/blob/langchain-lcel-rag/langchain-lcel-rag/Langchain-LCEL-RAG-Demo.ipynb).\n\n**Data Privacy and Sovereignty:** RAG applications often rely on sensitive or proprietary internal data. Running the entire stack within your own environment becomes crucial for maintaining control over this data. Qdrant Hybrid Cloud deployed on [Scaleway](https://www.scaleway.com/) addresses this need perfectly, offering a secure, scalable platform that still leverages the full potential of RAG. Scaleway offers serverless [Functions](https://www.scaleway.com/en/serverless-functions/) and serverless [Jobs](https://www.scaleway.com/en/serverless-jobs/), both of which are ideal for embedding creation in large-scale RAG cases.\n\n## Components\n\n- **Cloud Host:** [Scaleway on managed Kubernetes](https://www.scaleway.com/en/kubernetes-kapsule/) for compatibility with Qdrant Hybrid Cloud.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "token_count": 216,
      "char_count": 987,
      "start_char": 19018,
      "end_char": 20006
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:22",
    "content": "netes](https://www.scaleway.com/en/kubernetes-kapsule/) for compatibility with Qdrant Hybrid Cloud.\n- **Vector Database:** Qdrant Hybrid Cloud as the vector search engine for retrieval.\n- **LLM:** GPT-4o, developed by OpenAI is utilized as the generator for producing answers.\n- **Framework:** [LangChain](https://www.langchain.com/) for extensive RAG capabilities.\n\n> Langchain [supports a wide range of LLMs](https://python.langchain.com/docs/integrations/chat/), and GPT-4o is used as the main generator in this tutorial. You can easily swap it out for your preferred model that might be launched on your premises to complete the fully private setup. For the sake of simplicity, we used the OpenAI APIs, but LangChain makes the transition seamless.\n\n## Deploying Qdrant Hybrid Cloud on Scaleway\n\n[Scaleway Kapsule](https://www.scaleway.com/en/kubernetes-kapsule/) and [Kosmos](https://www.scaleway.com/en/kubernetes-kosmos/) are managed Kubernetes services from [Scaleway](https://www.scaleway.com/en/).",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "token_count": 241,
      "char_count": 1006,
      "start_char": 19906,
      "end_char": 20912
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:23",
    "content": "n/kubernetes-kosmos/) are managed Kubernetes services from [Scaleway](https://www.scaleway.com/en/). They abstract away the complexities of managing and operating a Kubernetes cluster. The primary difference being, Kapsule clusters are composed solely of Scaleway Instances. Whereas, a Kosmos cluster is a managed multi-cloud Kubernetes engine that allows you to connect instances from any cloud provider to a single managed Control-Plane.\n\n1. To start using managed Kubernetes on Scaleway, follow the [platform-specific documentation](https://qdrant.tech/documentation/hybrid-cloud/platform-deployment-options/#scaleway).\n2. Once your Kubernetes clusters are up, [you can begin deploying Qdrant Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/).\n\n## Prerequisites\n\nTo prepare the environment for working with Qdrant and related libraries, it’s necessary to install all required Python packages. This can be done using Poetry, a tool for dependency management and packaging in Python.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 23,
      "token_count": 198,
      "char_count": 997,
      "start_char": 20812,
      "end_char": 21809
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:24",
    "content": "n packages. This can be done using Poetry, a tool for dependency management and packaging in Python. The code snippet imports various libraries essential for the tasks ahead, including `bs4` for parsing HTML and XML documents, `langchain` and its community extensions for working with language models and document loaders, and `Qdrant` for vector storage and retrieval. These imports lay the groundwork for utilizing Qdrant alongside other tools for natural language processing and machine learning tasks.\n\nQdrant will be running on a specific URL and access will be restricted by the API key. Make sure to store them both as environment variables as well:\n\n```shell\nexport QDRANT_URL=\"https://qdrant.example.com\"\nexport QDRANT_API_KEY=\"your-api-key\"\n```\n\n*Optional:* Whenever you use LangChain, you can also [configure LangSmith](https://docs.smith.langchain.com/), which will help us trace, monitor and debug LangChain applications. You can sign up for LangSmith [here](https://smith.langchain.com/).\n\n```shell",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 24,
      "token_count": 218,
      "char_count": 1012,
      "start_char": 21709,
      "end_char": 22722
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:25",
    "content": "ngChain applications. You can sign up for LangSmith [here](https://smith.langchain.com/).\n\n```shell\nexport LANGCHAIN_TRACING_V2=true\nexport LANGCHAIN_API_KEY=\"your-api-key\"\nexport LANGCHAIN_PROJECT=\"your-project\"  # if not specified, defaults to \"default\"\n```\n\nNow you can get started:\n\n```python\nimport getpass\nimport os\n\nimport bs4\nfrom langchain import hub\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain_qdrant import Qdrant\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n```\n\nSet up the OpenAI API key:\n\n```python\nos.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n```\n\nInitialize the language model:\n\n```python\nllm = ChatOpenAI(model=\"gpt-4o\")\n```\n\nIt is here that we configure both the Embeddings and LLM. You can replace this with your own models using Ollama or other services.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 25,
      "token_count": 250,
      "char_count": 1008,
      "start_char": 22622,
      "end_char": 23630
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:26",
    "content": "th the Embeddings and LLM. You can replace this with your own models using Ollama or other services. Scaleway has some great [L4 GPU Instances](https://www.scaleway.com/en/l4-gpu-instance/) you can use for compute here.\n\n## Download and parse data\n\nTo begin working with blog post contents, the process involves loading and parsing the HTML content. This is achieved using `urllib` and `BeautifulSoup`, which are tools designed for such tasks. After the content is loaded and parsed, it is indexed using Qdrant, a powerful tool for managing and querying vector data. The code snippet demonstrates how to load, chunk, and index the contents of a blog post by specifying the URL of the blog and the specific HTML elements to parse. This step is crucial for preparing the data for further processing and analysis with Qdrant.\n\n```python\n# Load, chunk and index the contents of the blog.\nloader = WebBaseLoader(\n    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n    bs_kwargs=dict(\n        parse_only=bs4.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 26,
      "token_count": 237,
      "char_count": 1024,
      "start_char": 23530,
      "end_char": 24554
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:27",
    "content": "https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n    bs_kwargs=dict(\n        parse_only=bs4.SoupStrainer(\n            class_=(\"post-content\", \"post-title\", \"post-header\")\n        )\n    ),\n)\ndocs = loader.load()\n```\n\n### Chunking data\n\nWhen dealing with large documents, such as a blog post exceeding 42,000 characters, it’s crucial to manage the data efficiently for processing. Many models have a limited context window and struggle with long inputs, making it difficult to extract or find relevant information. To overcome this, the document is divided into smaller chunks. This approach enhances the model’s ability to process and retrieve the most pertinent sections of the document effectively.\n\nIn this scenario, the document is split into chunks using the `RecursiveCharacterTextSplitter` with a specified chunk size and overlap. This method ensures that no critical information is lost between chunks.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 27,
      "token_count": 197,
      "char_count": 917,
      "start_char": 24454,
      "end_char": 25371
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:28",
    "content": "ied chunk size and overlap. This method ensures that no critical information is lost between chunks. Following the splitting, these chunks are then indexed into Qdrant—a vector database for efficient similarity search and storage of embeddings. The `Qdrant.from_documents` function is utilized for indexing, with documents being the split chunks and embeddings generated through `OpenAIEmbeddings`. The entire process is facilitated within an in-memory database, signifying that the operations are performed without the need for persistent storage, and the collection is named “lilianweng” for reference.\n\nThis chunking and indexing strategy significantly improves the management and retrieval of information from large documents, making it a practical solution for handling extensive texts in data processing workflows.\n\n```python\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\nsplits = text_splitter.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 28,
      "token_count": 202,
      "char_count": 1021,
      "start_char": 25271,
      "end_char": 26292
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:29",
    "content": "plitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\nsplits = text_splitter.split_documents(docs)\n\nvectorstore = Qdrant.from_documents(\n    documents=splits,\n    embedding=OpenAIEmbeddings(),\n    collection_name=\"lilianweng\",\n    url=os.environ[\"QDRANT_URL\"],\n    api_key=os.environ[\"QDRANT_API_KEY\"],\n)\n```\n\n## Retrieve and generate content\n\nThe `vectorstore` is used as a retriever to fetch relevant documents based on vector similarity. The `hub.pull(\"rlm/rag-prompt\")` function is used to pull a specific prompt from a repository, which is designed to work with retrieved documents and a question to generate a response.\n\nThe `format_docs` function formats the retrieved documents into a single string, preparing them for further processing. This formatted string, along with a question, is passed through a chain of operations. Firstly, the context (formatted documents) and the question are processed by the retriever and the prompt.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 29,
      "token_count": 215,
      "char_count": 963,
      "start_char": 26192,
      "end_char": 27155
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:30",
    "content": "y, the context (formatted documents) and the question are processed by the retriever and the prompt. Then, the result is fed into a large language model (`llm`) for content generation. Finally, the output is parsed into a string format using `StrOutputParser()`.\n\nThis chain of operations demonstrates a sophisticated approach to information retrieval and content generation, leveraging both the semantic understanding capabilities of vector search and the generative prowess of large language models.\n\nNow, retrieve and generate data using relevant snippets from the blogL\n\n```python\nretriever = vectorstore.as_retriever()\nprompt = hub.pull(\"rlm/rag-prompt\")\n\n\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n### Invoking the RAG Chain\n\n```python\nrag_chain.invoke(\"What is Task Decomposition?\")\n```\n\n## Next steps:",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 30,
      "token_count": 217,
      "char_count": 993,
      "start_char": 27055,
      "end_char": 28050
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:31",
    "content": "oking the RAG Chain\n\n```python\nrag_chain.invoke(\"What is Task Decomposition?\")\n```\n\n## Next steps:\n\nWe built a solid foundation for a simple chatbot, but there is still a lot to do. If you want to make the system production-ready, you should consider implementing the mechanism into your existing stack. We recommend\n\nOur vector database can easily be hosted on [Scaleway](https://www.scaleway.com/), our trusted [Qdrant Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/) partner. This means that Qdrant can be run from your Scaleway region, but the database itself can still be managed from within Qdrant Cloud’s interface. Both products have been tested for compatibility and scalability, and we recommend their [managed Kubernetes](https://www.scaleway.com/en/kubernetes-kapsule/) service. Their French deployment regions e.g. France are excellent for network latency and data sovereignty. For hosted GPUs, try [rendering with L4 GPU instances](https://www.scaleway.com/en/l4-gpu-instance/).",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 31,
      "token_count": 220,
      "char_count": 1006,
      "start_char": 27950,
      "end_char": 28958
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:32",
    "content": "hosted GPUs, try [rendering with L4 GPU instances](https://www.scaleway.com/en/l4-gpu-instance/).\n\nIf you have any questions, feel free to ask on our [Discord community](https://qdrant.to/discord).\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! 🙏\n\nWe are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/rag-chatbot-scaleway.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Blog-Reading Chatbot with GPT-4o](#blog-reading-chatbot-with-gpt-4o.md)\n\n  - [Components](#components.md)\n  - [Deploying Qdrant Hybrid Cloud on Scaleway](#deploying-qdrant-hybrid-cloud-on-scaleway.md)\n  - [Prerequisites](#prerequisites.md)\n  - [Download and parse data](#download-and-parse-data.md)\n    - [Chunking data](#chunking-data.md)\n  - [Retrieve and generate content](#retrieve-and-generate-content.md)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 32,
      "token_count": 266,
      "char_count": 969,
      "start_char": 28858,
      "end_char": 29829
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md:chunk:33",
    "content": "ing data](#chunking-data.md)\n  - [Retrieve and generate content](#retrieve-and-generate-content.md)\n    - [Invoking the RAG Chain](#invoking-the-rag-chain.md)\n  - [Next steps:](#next-steps.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/rag-chatbot-scaleway.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_examples_rag-chatbot-scaleway\\_documentation_examples_rag-chatbot-scaleway_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_examples_rag-chatbot-scaleway_.md",
      "file_extension": ".md",
      "chunk_index": 33,
      "token_count": 191,
      "char_count": 676,
      "start_char": 29729,
      "end_char": 30753
    }
  }
]
[
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:0",
    "content": "Mixpeek - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "token_count": 279,
      "char_count": 999,
      "start_char": 0,
      "end_char": 999
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:1",
    "content": ".tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "token_count": 267,
      "char_count": 1000,
      "start_char": 899,
      "end_char": 1899
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:2",
    "content": "nfluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "token_count": 264,
      "char_count": 1011,
      "start_char": 1799,
      "end_char": 2811
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:3",
    "content": "entation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "token_count": 271,
      "char_count": 1012,
      "start_char": 2711,
      "end_char": 3723
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:4",
    "content": "/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "token_count": 275,
      "char_count": 1007,
      "start_char": 3623,
      "end_char": 4630
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:5",
    "content": "[LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "token_count": 269,
      "char_count": 1003,
      "start_char": 4530,
      "end_char": 5535
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:6",
    "content": "meworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "token_count": 273,
      "char_count": 1015,
      "start_char": 5435,
      "end_char": 6450
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:7",
    "content": "ion/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "token_count": 257,
      "char_count": 987,
      "start_char": 6350,
      "end_char": 7339
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:8",
    "content": "ering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "token_count": 259,
      "char_count": 978,
      "start_char": 7239,
      "end_char": 8217
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:9",
    "content": "ion/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "token_count": 231,
      "char_count": 997,
      "start_char": 8117,
      "end_char": 9114
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:10",
    "content": "cumentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "token_count": 280,
      "char_count": 1022,
      "start_char": 9014,
      "end_char": 10038
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:11",
    "content": "ng Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "token_count": 262,
      "char_count": 1025,
      "start_char": 9938,
      "end_char": 10963
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:12",
    "content": "ured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "token_count": 270,
      "char_count": 995,
      "start_char": 10863,
      "end_char": 11858
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:13",
    "content": "[Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "token_count": 269,
      "char_count": 990,
      "start_char": 11758,
      "end_char": 12748
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:14",
    "content": "peval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "token_count": 284,
      "char_count": 1019,
      "start_char": 12648,
      "end_char": 13667
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:15",
    "content": "j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "token_count": 270,
      "char_count": 1016,
      "start_char": 13567,
      "end_char": 14585
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:16",
    "content": "entation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "token_count": 279,
      "char_count": 1018,
      "start_char": 14485,
      "end_char": 15503
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:17",
    "content": "PT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "token_count": 249,
      "char_count": 974,
      "start_char": 15403,
      "end_char": 16377
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:18",
    "content": "-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "token_count": 254,
      "char_count": 1005,
      "start_char": 16277,
      "end_char": 17282
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:19",
    "content": "r-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- [Embeddings](https://qdrant.tech/documentation/embeddings/)\n-\n- Mixpeek\n\n# Mixpeek Video Embeddings",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "token_count": 240,
      "char_count": 1007,
      "start_char": 17182,
      "end_char": 18191
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:20",
    "content": "Embeddings](https://qdrant.tech/documentation/embeddings/)\n-\n- Mixpeek\n\n# Mixpeek Video Embeddings\n\nMixpeek‚Äôs video processing capabilities allow you to chunk and embed videos, while Qdrant provides efficient storage and retrieval of these embeddings.\n\n## Prerequisites\n\n- Python 3.7+\n- Mixpeek API key\n- Mixpeek client installed (`pip install mixpeek`)\n- Qdrant client installed (`pip install qdrant-client`)\n\n## Installation\n\n1. Install the required packages:\n\n```bash\npip install mixpeek qdrant-client\n```\n\n2. Set up your Mixpeek API key:\n\n```python\nfrom mixpeek import Mixpeek\n\nmixpeek = Mixpeek('your_api_key_here')\n```\n\n3. Initialize the Qdrant client:\n\n```python\nfrom qdrant_client import QdrantClient\n\nclient = QdrantClient(\"localhost\", port=6333)\n```\n\n## Usage\n\n### 1. Create Qdrant Collection\n\nMake sure to create a Qdrant collection before inserting vectors. You can create a collection with the appropriate vector size (768 for ‚Äúvuse-generic-v1‚Äù model) using:\n\n```python\nclient.create_collection(",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "token_count": 252,
      "char_count": 1008,
      "start_char": 18091,
      "end_char": 19100
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:21",
    "content": "propriate vector size (768 for ‚Äúvuse-generic-v1‚Äù model) using:\n\n```python\nclient.create_collection(\n    collection_name=\"video_chunks\",\n    vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE)\n)\n```\n\n### 2. Process and Embed Video\n\nFirst, process the video into chunks and embed each chunk:\n\n```python\nfrom mixpeek import Mixpeek\nfrom qdrant_client import QdrantClient, models\n\nmixpeek = Mixpeek('your_api_key_here')\nclient = QdrantClient(\"localhost\", port=6333)\n\nvideo_url = \"https://mixpeek-public-demo.s3.us-east-2.amazonaws.com/starter/jurassic_park_trailer.mp4\"\n\n# Process video chunks\nprocessed_chunks = mixpeek.tools.video.process(\n    video_source=video_url,\n    chunk_interval=1,  # 1 second intervals\n    resolution=[720, 1280]\n)\n\n# Embed each chunk and insert into Qdrant\nfor index, chunk in enumerate(processed_chunks):\n    print(f\"Processing video chunk: {index}\")\n\n    embedding = mixpeek.embed.video(\n        model_id=\"vuse-generic-v1\",\n        input=chunk['base64_chunk'],",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "token_count": 265,
      "char_count": 1013,
      "start_char": 19000,
      "end_char": 20014
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:22",
    "content": "ing = mixpeek.embed.video(\n        model_id=\"vuse-generic-v1\",\n        input=chunk['base64_chunk'],\n        input_type=\"base64\"\n    )['embedding']\n\n    # Insert into Qdrant\n    client.upsert(\n        collection_name=\"video_chunks\",\n        points=[models.PointStruct(\n            id=index,\n            vector=embedding,\n            payload={\n                \"start_time\": chunk[\"start_time\"],\n                \"end_time\": chunk[\"end_time\"]\n            }\n        )]\n    )\n\n    print(f\"  Embedding preview: {embedding[:5] + ['...'] + embedding[-5:]}\")\n\nprint(f\"Processed and inserted {len(processed_chunks)} chunks\")\n```\n\n### 3. Search for Similar Video Chunks\n\nTo search for similar video chunks, you can use either text or video queries:\n\n#### Text Query\n\n```python\nquery_text = \"a car chase scene\"\n\n# Embed the text query\nquery_embedding = mixpeek.embed.video(\n    model_id=\"vuse-generic-v1\",\n    input=query_text,\n    input_type=\"text\"\n)['embedding']\n\n# Search in Qdrant\nsearch_results = client.query_points(",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "token_count": 241,
      "char_count": 1009,
      "start_char": 19914,
      "end_char": 20924
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:23",
    "content": "ext,\n    input_type=\"text\"\n)['embedding']\n\n# Search in Qdrant\nsearch_results = client.query_points(\n    collection_name=\"video_chunks\",\n    query=query_embedding,\n    limit=5\n).points\n\nfor result in search_results:\n    print(f\"Chunk ID: {result.id}, Score: {result.score}\")\n    print(f\"Time range: {result.payload['start_time']} - {result.payload['end_time']}\")\n```\n\n#### Video Query\n\n```python\nquery_video_url = \"https://mixpeek-public-demo.s3.us-east-2.amazonaws.com/starter/jurassic_bunny.mp4\"\n\n# Embed the video query\nquery_embedding = mixpeek.embed.video(\n    model_id=\"vuse-generic-v1\",\n    input=query_video_url,\n    input_type=\"url\"\n)['embedding']\n\n# Search in Qdrant\nsearch_results = client.query_points(\n    collection_name=\"video_chunks\",\n    query=query_embedding,\n    limit=5\n).points\n\nfor result in search_results:\n    print(f\"Chunk ID: {result.id}, Score: {result.score}\")\n    print(f\"Time range: {result.payload['start_time']} - {result.payload['end_time']}\")\n```\n\n## Resources",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 23,
      "token_count": 253,
      "char_count": 993,
      "start_char": 20824,
      "end_char": 21819
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:24",
    "content": "nt(f\"Time range: {result.payload['start_time']} - {result.payload['end_time']}\")\n```\n\n## Resources\n\nFor more information on Mixpeek Embed, review the official documentation: <https://docs.mixpeek.com/api-documentation/inference/embed>\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! üôè\n\nWe are sorry to hear that. üòî You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/embeddings/mixpeek.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Mixpeek Video Embeddings](#mixpeek-video-embeddings.md)\n\n  - [Prerequisites](#prerequisites.md)\n\n  - [Installation](#installation.md)\n\n  - [Usage](#usage.md)\n\n    - [1. Create Qdrant Collection](#1-create-qdrant-collection.md)\n    - [2. Process and Embed Video](#2-process-and-embed-video.md)\n    - [3. Search for Similar Video Chunks](#3-search-for-similar-video-chunks.md)\n\n  - [Resources](#resources.md)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 24,
      "token_count": 262,
      "char_count": 991,
      "start_char": 21719,
      "end_char": 22712
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md:chunk:25",
    "content": "h for Similar Video Chunks](#3-search-for-similar-video-chunks.md)\n\n  - [Resources](#resources.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/embeddings/mixpeek.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n¬© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_embeddings_mixpeek\\_documentation_embeddings_mixpeek_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_embeddings_mixpeek_.md",
      "file_extension": ".md",
      "chunk_index": 25,
      "token_count": 159,
      "char_count": 571,
      "start_char": 22612,
      "end_char": 23636
    }
  }
]
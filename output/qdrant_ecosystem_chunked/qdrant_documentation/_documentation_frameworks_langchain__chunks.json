[
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:0",
    "content": "Langchain - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "token_count": 279,
      "char_count": 1001,
      "start_char": 0,
      "end_char": 1001
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:1",
    "content": ".tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "token_count": 267,
      "char_count": 1000,
      "start_char": 901,
      "end_char": 1901
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:2",
    "content": "nfluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "token_count": 264,
      "char_count": 1011,
      "start_char": 1801,
      "end_char": 2813
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:3",
    "content": "entation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "token_count": 271,
      "char_count": 1012,
      "start_char": 2713,
      "end_char": 3725
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:4",
    "content": "/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "token_count": 275,
      "char_count": 1007,
      "start_char": 3625,
      "end_char": 4632
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:5",
    "content": "[LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "token_count": 269,
      "char_count": 1003,
      "start_char": 4532,
      "end_char": 5537
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:6",
    "content": "meworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "token_count": 273,
      "char_count": 1015,
      "start_char": 5437,
      "end_char": 6452
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:7",
    "content": "ion/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "token_count": 257,
      "char_count": 987,
      "start_char": 6352,
      "end_char": 7341
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:8",
    "content": "ering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "token_count": 259,
      "char_count": 978,
      "start_char": 7241,
      "end_char": 8219
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:9",
    "content": "ion/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "token_count": 231,
      "char_count": 997,
      "start_char": 8119,
      "end_char": 9116
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:10",
    "content": "cumentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n### Essentials\n\n[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)\n\n[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)\n\n[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)\n\n[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)\n\n[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)\n\n[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)\n\n[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "token_count": 280,
      "char_count": 1022,
      "start_char": 9016,
      "end_char": 10040
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:11",
    "content": "ng Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)\n\n### Integrations\n\n[Data Management](https://qdrant.tech/documentation/data-management/)\n\n- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)\n- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)\n- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)\n- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)\n- [cognee](https://qdrant.tech/documentation/data-management/cognee/)\n- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)\n- [DLT](https://qdrant.tech/documentation/data-management/dlt/)\n- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)\n- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)\n- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "token_count": 262,
      "char_count": 1025,
      "start_char": 9940,
      "end_char": 10965
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:12",
    "content": "ured/)\n\n[Embeddings](https://qdrant.tech/documentation/embeddings/)\n\n- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)\n- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)\n- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)\n- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)\n- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)\n- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)\n- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)\n- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)\n- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)\n- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)\n- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)\n- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)\n- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "token_count": 270,
      "char_count": 995,
      "start_char": 10865,
      "end_char": 11860
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:13",
    "content": "[Prem AI](https://qdrant.tech/documentation/embeddings/premai/)\n- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)\n- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)\n- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)\n- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)\n\n[Frameworks](https://qdrant.tech/documentation/frameworks/)\n\n- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)\n- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)\n- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)\n- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)\n- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)\n- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)\n- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "token_count": 269,
      "char_count": 990,
      "start_char": 11760,
      "end_char": 12750
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:14",
    "content": "peval/)\n- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)\n- [Feast](https://qdrant.tech/documentation/frameworks/feast/)\n- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)\n- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)\n- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)\n- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)\n- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)\n- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)\n- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)\n- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)\n- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)\n- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)\n- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)\n- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "token_count": 284,
      "char_count": 1019,
      "start_char": 12650,
      "end_char": 13669
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:15",
    "content": "j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)\n- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)\n- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)\n- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)\n- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)\n- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)\n- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)\n- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)\n- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)\n- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)\n- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)\n- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)\n- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "token_count": 270,
      "char_count": 1016,
      "start_char": 13569,
      "end_char": 14587
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:16",
    "content": "entation/frameworks/voltagent/)\n\n[Observability](https://qdrant.tech/documentation/observability/)\n\n- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)\n- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)\n- [Datadog](https://qdrant.tech/documentation/observability/datadog/)\n\n[Platforms](https://qdrant.tech/documentation/platforms/)\n\n- [Apify](https://qdrant.tech/documentation/platforms/apify/)\n- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)\n- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)\n- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)\n- [Make.com](https://qdrant.tech/documentation/platforms/make/)\n- [N8N](https://qdrant.tech/documentation/platforms/n8n/)\n- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)\n- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)\n- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "token_count": 279,
      "char_count": 1018,
      "start_char": 14487,
      "end_char": 15505
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:17",
    "content": "PT](https://qdrant.tech/documentation/platforms/privategpt/)\n- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)\n- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)\n- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)\n\n### Examples\n\n[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n\n- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)\n- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)\n\n[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)\n\n- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)\n- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "token_count": 249,
      "char_count": 974,
      "start_char": 15405,
      "end_char": 16379
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:18",
    "content": "-airflow-astronomer/)\n- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)\n\n[Build Prototypes](https://qdrant.tech/documentation/examples/)\n\n- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)\n- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)\n- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)\n- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)\n- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)\n- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "token_count": 254,
      "char_count": 1005,
      "start_char": 16279,
      "end_char": 17284
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:19",
    "content": "r-support-cohere-airbyte-aws/)\n- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)\n- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)\n- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)\n- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)\n- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)\n- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)\n\n[Practice Datasets](https://qdrant.tech/documentation/datasets/)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- [Frameworks](https://qdrant.tech/documentation/frameworks/)\n-\n- Langchain\n\n# Langchain",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "token_count": 236,
      "char_count": 994,
      "start_char": 17184,
      "end_char": 18180
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:20",
    "content": "ation/)\n-\n- [Frameworks](https://qdrant.tech/documentation/frameworks/)\n-\n- Langchain\n\n# Langchain\n\nLangchain is a library that makes developing Large Language Model-based applications much easier. It unifies the interfaces to different libraries, including major embedding providers and Qdrant. Using Langchain, you can focus on the business value instead of writing the boilerplate.\n\nLangchain distributes the Qdrant integration as a partner package.\n\nIt might be installed with pip:\n\n```bash\npip install langchain-qdrant\n```\n\nThe integration supports searching for relevant documents usin dense/sparse and hybrid retrieval.\n\nQdrant acts as a vector index that may store the embeddings with the documents used to generate them. There are various ways to use it, but calling `QdrantVectorStore.from_texts` or `QdrantVectorStore.from_documents` is probably the most straightforward way to get started:\n\n```python\nfrom langchain_qdrant import QdrantVectorStore\nfrom langchain_openai import OpenAIEmbeddings",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "token_count": 214,
      "char_count": 1005,
      "start_char": 18080,
      "end_char": 19087
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:21",
    "content": "ython\nfrom langchain_qdrant import QdrantVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings()\n\ndoc_store = QdrantVectorStore.from_texts(\n    texts, embeddings, url=\"<qdrant-url>\", api_key=\"<qdrant-api-key>\", collection_name=\"texts\"\n)\n```\n\n## Using an existing collection\n\nTo get an instance of `langchain_qdrant.QdrantVectorStore` without loading any new documents or texts, you can use the `QdrantVectorStore.from_existing_collection()` method.\n\n```python\ndoc_store = QdrantVectorStore.from_existing_collection(\n    embeddings=embeddings,\n    collection_name=\"my_documents\",\n    url=\"<qdrant-url>\",\n    api_key=\"<qdrant-api-key>\",\n)\n```\n\n## Local mode\n\nPython client allows you to run the same code in local mode without running the Qdrant server. That’s great for testing things out and debugging or if you plan to store just a small amount of vectors. The embeddings might be fully kept in memory or persisted on disk.\n\n### In-memory",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "token_count": 233,
      "char_count": 974,
      "start_char": 18987,
      "end_char": 19963
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:22",
    "content": "ount of vectors. The embeddings might be fully kept in memory or persisted on disk.\n\n### In-memory\n\nFor some testing scenarios and quick experiments, you may prefer to keep all the data in memory only, so it gets lost when the client is destroyed - usually at the end of your script/notebook.\n\n```python\nqdrant = QdrantVectorStore.from_documents(\n    docs,\n    embeddings,\n    location=\":memory:\",  # Local mode with in-memory storage only\n    collection_name=\"my_documents\",\n)\n```\n\n### On-disk storage\n\nLocal mode, without using the Qdrant server, may also store your vectors on disk so they’re persisted between runs.\n\n```python\nqdrant = Qdrant.from_documents(\n    docs,\n    embeddings,\n    path=\"/tmp/local_qdrant\",\n    collection_name=\"my_documents\",\n)\n```\n\n### On-premise server deployment\n\nNo matter if you choose to launch QdrantVectorStore locally with [a Docker container](https://qdrant.tech/documentation/guides/installation/), or select a Kubernetes deployment with [the official Helm chart](https://github.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "token_count": 234,
      "char_count": 1019,
      "start_char": 19863,
      "end_char": 20882
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:23",
    "content": "des/installation/), or select a Kubernetes deployment with [the official Helm chart](https://github.com/qdrant/qdrant-helm), the way you’re going to connect to such an instance will be identical. You’ll need to provide a URL pointing to the service.\n\n```python\nurl = \"<---qdrant url here --->\"\nqdrant = QdrantVectorStore.from_documents(\n    docs,\n    embeddings,\n    url,\n    prefer_grpc=True,\n    collection_name=\"my_documents\",\n)\n```\n\n## Similarity search\n\n`QdrantVectorStore` supports 3 modes for similarity searches. They can be configured using the `retrieval_mode` parameter when setting up the class.\n\n- Dense Vector Search(Default)\n- Sparse Vector Search\n- Hybrid Search\n\n### Dense Vector Search\n\nTo search with only dense vectors,\n\n- The `retrieval_mode` parameter should be set to `RetrievalMode.DENSE`(default).\n- A [dense embeddings](https://python.langchain.com/v0.2/docs/integrations/text_embedding/) value should be provided for the `embedding` parameter.\n\n```py\nfrom langchain_qdrant import RetrievalMode",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 23,
      "token_count": 245,
      "char_count": 1020,
      "start_char": 20782,
      "end_char": 21804
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:24",
    "content": "hould be provided for the `embedding` parameter.\n\n```py\nfrom langchain_qdrant import RetrievalMode\n\nqdrant = QdrantVectorStore.from_documents(\n    docs,\n    embedding=embeddings,\n    location=\":memory:\",\n    collection_name=\"my_documents\",\n    retrieval_mode=RetrievalMode.DENSE,\n)\n\nquery = \"What did the president say about Ketanji Brown Jackson\"\nfound_docs = qdrant.similarity_search(query)\n```\n\n### Sparse Vector Search\n\nTo search with only sparse vectors,\n\n- The `retrieval_mode` parameter should be set to `RetrievalMode.SPARSE`.\n- An implementation of the [SparseEmbeddings interface](https://github.com/langchain-ai/langchain/blob/master/libs/partners/qdrant/langchain_qdrant/sparse_embeddings.py) using any sparse embeddings provider has to be provided as value to the `sparse_embedding` parameter.\n\nThe `langchain-qdrant` package provides a [FastEmbed](https://github.com/qdrant/fastembed) based implementation out of the box.\n\nTo use it, install the [FastEmbed package](https://github.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 24,
      "token_count": 237,
      "char_count": 995,
      "start_char": 21704,
      "end_char": 22699
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:25",
    "content": "ed) based implementation out of the box.\n\nTo use it, install the [FastEmbed package](https://github.com/qdrant/fastembed#-installation).\n\n```python\nfrom langchain_qdrant import FastEmbedSparse, RetrievalMode\n\nsparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/BM25\")\n\nqdrant = QdrantVectorStore.from_documents(\n    docs,\n    sparse_embedding=sparse_embeddings,\n    location=\":memory:\",\n    collection_name=\"my_documents\",\n    retrieval_mode=RetrievalMode.SPARSE,\n)\n\nquery = \"What did the president say about Ketanji Brown Jackson\"\nfound_docs = qdrant.similarity_search(query)\n```\n\n### Hybrid Vector Search\n\nTo perform a hybrid search using dense and sparse vectors with score fusion,\n\n- The `retrieval_mode` parameter should be set to `RetrievalMode.HYBRID`.\n- A [dense embeddings](https://python.langchain.com/v0.2/docs/integrations/text_embedding/) value should be provided for the `embedding` parameter.\n- An implementation of the [SparseEmbeddings interface](https://github.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 25,
      "token_count": 234,
      "char_count": 982,
      "start_char": 22599,
      "end_char": 23581
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:26",
    "content": "r the `embedding` parameter.\n- An implementation of the [SparseEmbeddings interface](https://github.com/langchain-ai/langchain/blob/master/libs/partners/qdrant/langchain_qdrant/sparse_embeddings.py) using any sparse embeddings provider has to be provided as value to the `sparse_embedding` parameter.\n\n```python\nfrom langchain_qdrant import FastEmbedSparse, RetrievalMode\n\nsparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n\nqdrant = QdrantVectorStore.from_documents(\n    docs,\n    embedding=embeddings,\n    sparse_embedding=sparse_embeddings,\n    location=\":memory:\",\n    collection_name=\"my_documents\",\n    retrieval_mode=RetrievalMode.HYBRID,\n)\n\nquery = \"What did the president say about Ketanji Brown Jackson\"\nfound_docs = qdrant.similarity_search(query)\n```\n\nNote that if you’ve added documents with HYBRID mode, you can switch to any retrieval mode when searching. Since both the dense and sparse vectors are available in the collection.\n\n## Next steps",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 26,
      "token_count": 223,
      "char_count": 969,
      "start_char": 23481,
      "end_char": 24452
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:27",
    "content": "searching. Since both the dense and sparse vectors are available in the collection.\n\n## Next steps\n\nIf you’d like to know more about running Qdrant in a Langchain-based application, please read our article [Question Answering with Langchain and Qdrant without boilerplate](https://qdrant.tech/articles/langchain-integration/). Some more information might also be found in the [Langchain documentation](https://python.langchain.com/docs/integrations/vectorstores/qdrant).\n\n- [Source Code](https://github.com/langchain-ai/langchain/tree/master/libs%2Fpartners%2Fqdrant)\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! 🙏\n\nWe are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/langchain.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Langchain](#langchain.md)\n\n  - [Using an existing collection](#using-an-existing-collection.md)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 27,
      "token_count": 245,
      "char_count": 1015,
      "start_char": 24352,
      "end_char": 25369
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:28",
    "content": "- [Langchain](#langchain.md)\n\n  - [Using an existing collection](#using-an-existing-collection.md)\n\n  - [Local mode](#local-mode.md)\n\n    - [In-memory](#in-memory.md)\n    - [On-disk storage](#on-disk-storage.md)\n    - [On-premise server deployment](#on-premise-server-deployment.md)\n\n  - [Similarity search](#similarity-search.md)\n\n    - [Dense Vector Search](#dense-vector-search.md)\n    - [Sparse Vector Search](#sparse-vector-search.md)\n    - [Hybrid Vector Search](#hybrid-vector-search.md)\n\n  - [Next steps](#next-steps.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/langchain.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 28,
      "token_count": 278,
      "char_count": 1003,
      "start_char": 25269,
      "end_char": 26293
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md:chunk:29",
    "content": "t.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_frameworks_langchain\\_documentation_frameworks_langchain_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_frameworks_langchain_.md",
      "file_extension": ".md",
      "chunk_index": 29,
      "token_count": 23,
      "char_count": 79,
      "start_char": 26193,
      "end_char": 27217
    }
  }
]
[
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:0",
    "content": "Build a Neural Search Service - Qdrant\n\n[](https://qdrant.tech/)\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\nSearch\n\n[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)\n\nSearch\n\n- [Qdrant](https://qdrant.tech/documentation/)\n- [Cloud](https://qdrant.tech/documentation/cloud-intro/)\n- [Build](https://qdrant.tech/documentation/build/)\n- [Learn](https://qdrant.tech/articles/)\n- [API Reference](https://api.qdrant.tech/api-reference)\n\n### Getting Started\n\n[What is Qdrant?](https://qdrant.tech/documentation/overview/)\n\n- [Understanding Vector Search in Qdrant](https://qdrant.tech/documentation/overview/vector-search/)\n\n[Local Quickstart](https://qdrant.tech/documentation/quickstart/)\n\n[API & SDKs](https://qdrant.tech/documentation/interfaces/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "token_count": 266,
      "char_count": 993,
      "start_char": 0,
      "end_char": 995
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:1",
    "content": "drant.tech/documentation/quickstart/)\n\n[API & SDKs](https://qdrant.tech/documentation/interfaces/)\n\n[Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)\n\n### User Manual\n\n[Concepts](https://qdrant.tech/documentation/concepts/)\n\n- [Collections](https://qdrant.tech/documentation/concepts/collections/)\n- [Points](https://qdrant.tech/documentation/concepts/points/)\n- [Vectors](https://qdrant.tech/documentation/concepts/vectors/)\n- [Payload](https://qdrant.tech/documentation/concepts/payload/)\n- [Search](https://qdrant.tech/documentation/concepts/search/)\n- [Explore](https://qdrant.tech/documentation/concepts/explore/)\n- [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/)\n- [Filtering](https://qdrant.tech/documentation/concepts/filtering/)\n- [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/)\n- [Storage](https://qdrant.tech/documentation/concepts/storage/)\n- [Indexing](https://qdrant.tech/documentation/concepts/indexing/)\n- [Snapshots](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "token_count": 253,
      "char_count": 1006,
      "start_char": 895,
      "end_char": 1901
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:2",
    "content": "e/)\n- [Indexing](https://qdrant.tech/documentation/concepts/indexing/)\n- [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)\n\n[Guides](https://qdrant.tech/documentation/guides/installation/)\n\n- [Installation](https://qdrant.tech/documentation/guides/installation/)\n- [Administration](https://qdrant.tech/documentation/guides/administration/)\n- [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/)\n- [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/)\n- [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/)\n- [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)\n- [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)\n- [Quantization](https://qdrant.tech/documentation/guides/quantization/)\n- [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/)\n- [Configuration](https://qdrant.tech/documentation/guides/configuration/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "token_count": 250,
      "char_count": 999,
      "start_char": 1801,
      "end_char": 2801
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:3",
    "content": "tion/guides/monitoring/)\n- [Configuration](https://qdrant.tech/documentation/guides/configuration/)\n- [Security](https://qdrant.tech/documentation/guides/security/)\n- [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/)\n- [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)\n\n### Ecosystem\n\n[FastEmbed](https://qdrant.tech/documentation/fastembed/)\n\n- [Quickstart](https://qdrant.tech/documentation/fastembed/fastembed-quickstart/)\n- [FastEmbed & Qdrant](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/)\n- [Working with miniCOIL](https://qdrant.tech/documentation/fastembed/fastembed-minicoil/)\n- [Working with SPLADE](https://qdrant.tech/documentation/fastembed/fastembed-splade/)\n- [Working with ColBERT](https://qdrant.tech/documentation/fastembed/fastembed-colbert/)\n- [Reranking with FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-rerankers/)\n\n[Qdrant MCP Server](https://github.com/qdrant/mcp-server-qdrant)\n\n### Tutorials",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "token_count": 260,
      "char_count": 1017,
      "start_char": 2701,
      "end_char": 3720
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:4",
    "content": "embed-rerankers/)\n\n[Qdrant MCP Server](https://github.com/qdrant/mcp-server-qdrant)\n\n### Tutorials\n\n[Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)\n\n- [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)\n- [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)\n- [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)\n- [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)\n\n[Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)\n\n- [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/)\n- [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/)\n- [Search Through Your Codebase](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "token_count": 247,
      "char_count": 988,
      "start_char": 3620,
      "end_char": 4608
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:5",
    "content": "tation/advanced-tutorials/reranking-hybrid-search/)\n- [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)\n- [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)\n- [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)\n\n[Using the Database](https://qdrant.tech/documentation/database-tutorials/)\n\n- [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)\n- [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)\n- [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)\n- [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)\n- [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/)\n- [Migration to Qdrant](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "token_count": 235,
      "char_count": 1014,
      "start_char": 4508,
      "end_char": 5522
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:6",
    "content": "s://qdrant.tech/documentation/database-tutorials/async-api/)\n- [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/)\n- [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)\n\n### Support\n\n[FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n\n- [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n- [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)\n\n[Release Notes](https://github.com/qdrant/qdrant/releases)\n\n### Getting Started\n\n[What is Qdrant?](https://qdrant.tech/documentation/overview/)\n\n- [Understanding Vector Search in Qdrant](https://qdrant.tech/documentation/overview/vector-search/)\n\n[Local Quickstart](https://qdrant.tech/documentation/quickstart/)\n\n[API & SDKs](https://qdrant.tech/documentation/interfaces/)\n\n[Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)\n\n### User Manual\n\n[Concepts](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "token_count": 257,
      "char_count": 1004,
      "start_char": 5422,
      "end_char": 6426
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:7",
    "content": "rant Web UI](https://qdrant.tech/documentation/web-ui/)\n\n### User Manual\n\n[Concepts](https://qdrant.tech/documentation/concepts/)\n\n- [Collections](https://qdrant.tech/documentation/concepts/collections/)\n- [Points](https://qdrant.tech/documentation/concepts/points/)\n- [Vectors](https://qdrant.tech/documentation/concepts/vectors/)\n- [Payload](https://qdrant.tech/documentation/concepts/payload/)\n- [Search](https://qdrant.tech/documentation/concepts/search/)\n- [Explore](https://qdrant.tech/documentation/concepts/explore/)\n- [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/)\n- [Filtering](https://qdrant.tech/documentation/concepts/filtering/)\n- [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/)\n- [Storage](https://qdrant.tech/documentation/concepts/storage/)\n- [Indexing](https://qdrant.tech/documentation/concepts/indexing/)\n- [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)\n\n[Guides](https://qdrant.tech/documentation/guides/installation/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "token_count": 251,
      "char_count": 1008,
      "start_char": 6326,
      "end_char": 7336
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:8",
    "content": "cumentation/concepts/snapshots/)\n\n[Guides](https://qdrant.tech/documentation/guides/installation/)\n\n- [Installation](https://qdrant.tech/documentation/guides/installation/)\n- [Administration](https://qdrant.tech/documentation/guides/administration/)\n- [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/)\n- [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/)\n- [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/)\n- [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)\n- [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)\n- [Quantization](https://qdrant.tech/documentation/guides/quantization/)\n- [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/)\n- [Configuration](https://qdrant.tech/documentation/guides/configuration/)\n- [Security](https://qdrant.tech/documentation/guides/security/)\n- [Usage Statistics](https://qdrant.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "token_count": 249,
      "char_count": 994,
      "start_char": 7236,
      "end_char": 8230
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:9",
    "content": "[Security](https://qdrant.tech/documentation/guides/security/)\n- [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/)\n- [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)\n\n### Ecosystem\n\n[FastEmbed](https://qdrant.tech/documentation/fastembed/)\n\n- [Quickstart](https://qdrant.tech/documentation/fastembed/fastembed-quickstart/)\n- [FastEmbed & Qdrant](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/)\n- [Working with miniCOIL](https://qdrant.tech/documentation/fastembed/fastembed-minicoil/)\n- [Working with SPLADE](https://qdrant.tech/documentation/fastembed/fastembed-splade/)\n- [Working with ColBERT](https://qdrant.tech/documentation/fastembed/fastembed-colbert/)\n- [Reranking with FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-rerankers/)\n\n[Qdrant MCP Server](https://github.com/qdrant/mcp-server-qdrant)\n\n### Tutorials\n\n[Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "token_count": 254,
      "char_count": 994,
      "start_char": 8130,
      "end_char": 9127
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:10",
    "content": "ant)\n\n### Tutorials\n\n[Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)\n\n- [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)\n- [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)\n- [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)\n- [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)\n\n[Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)\n\n- [How to Use Multivector Representations with Qdrant Effectively](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/)\n- [Reranking in Hybrid Search](https://qdrant.tech/documentation/advanced-tutorials/reranking-hybrid-search/)\n- [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "token_count": 229,
      "char_count": 960,
      "start_char": 9027,
      "end_char": 9988
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:11",
    "content": "- [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)\n- [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)\n- [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)\n\n[Using the Database](https://qdrant.tech/documentation/database-tutorials/)\n\n- [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)\n- [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)\n- [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)\n- [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)\n- [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/)\n- [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "token_count": 229,
      "char_count": 1011,
      "start_char": 9888,
      "end_char": 10900
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:12",
    "content": "sync-api/)\n- [Migration to Qdrant](https://qdrant.tech/documentation/database-tutorials/migration/)\n- [Static Embeddings. Should you pay attention?](https://qdrant.tech/documentation/database-tutorials/static-embeddings/)\n\n### Support\n\n[FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n\n- [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)\n- [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)\n\n[Release Notes](https://github.com/qdrant/qdrant/releases)\n\n- [Documentation](https://qdrant.tech/documentation/)\n-\n- [Beginner tutorials](https://qdrant.tech/documentation/beginner-tutorials/)\n-\n- Build a Neural Search Service\n\n# Build a Neural Search Service with Sentence Transformers and Qdrant\n\n| Time: 30 min | Level: Beginner | Output: [GitHub](https://github.com/qdrant/qdrant_demo/tree/sentense-transformers) | [](https://colab.research.google.com/drive/1kPktoudAP8Tu8n8l-iVMOQhVmHkWV_L9?usp=sharing) |",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "token_count": 267,
      "char_count": 987,
      "start_char": 10800,
      "end_char": 11788
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:13",
    "content": "mers) | [](https://colab.research.google.com/drive/1kPktoudAP8Tu8n8l-iVMOQhVmHkWV_L9?usp=sharing) |\n| ------------ | --------------- | ---------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- |\n\nThis tutorial shows you how to build and deploy your own neural search service to look through descriptions of companies from [startups-list.com](https://www.startups-list.com/) and pick the most similar ones to your query. The website contains the company names, descriptions, locations, and a picture for each entry.\n\nA neural search service uses artificial neural networks to improve the accuracy and relevance of search results. Besides offering simple keyword results, this system can retrieve results by meaning. It can understand and interpret complex search queries and provide more contextually relevant output, effectively enhancing the user’s search experience.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "token_count": 176,
      "char_count": 985,
      "start_char": 11688,
      "end_char": 12675
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:14",
    "content": "and provide more contextually relevant output, effectively enhancing the user’s search experience.\n\nThere is a version of this tutorial that uses [Fastembed](https://github.com/qdrant/fastembed) model inference engine instead of Sentence Transformers. Check it out [here](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/).\n\n## Workflow\n\nTo create a neural search service, you will need to transform your raw data and then create a search function to manipulate it. First, you will 1) download and prepare a sample dataset using a modified version of the BERT ML model. Then, you will 2) load the data into Qdrant, 3) create a neural search API and 4) serve it using FastAPI.\n\n> **Note**: The code for this tutorial can be found here: | [Step 1: Data Preparation Process](https://colab.research.google.com/drive/1kPktoudAP8Tu8n8l-iVMOQhVmHkWV_L9?usp=sharing) | [Step 2: Full Code for Neural Search](https://github.com/qdrant/qdrant_demo/tree/sentense-transformers). |\n\n## Prerequisites",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "token_count": 256,
      "char_count": 1013,
      "start_char": 12575,
      "end_char": 13590
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:15",
    "content": "ral Search](https://github.com/qdrant/qdrant_demo/tree/sentense-transformers). |\n\n## Prerequisites\n\nTo complete this tutorial, you will need:\n\n- Docker - The easiest way to use Qdrant is to run a pre-built Docker image.\n- [Raw parsed data](https://storage.googleapis.com/generall-shared-data/startups_demo.json) from startups-list.com.\n- Python version >=3.8\n\n## Prepare sample dataset\n\nTo conduct a neural search on startup descriptions, you must first encode the description data into vectors. To process text, you can use a pre-trained models like [BERT](https://en.wikipedia.org/wiki/BERT_%28language_model%29) or sentence transformers. The [sentence-transformers](https://github.com/UKPLab/sentence-transformers) library lets you conveniently download and use many pre-trained models, such as DistilBERT, MPNet, etc.\n\n1. First you need to download the dataset.\n\n```bash\nwget https://storage.googleapis.com/generall-shared-data/startups_demo.json\n```\n\n2.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 15,
      "token_count": 224,
      "char_count": 958,
      "start_char": 13490,
      "end_char": 14448
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:16",
    "content": "ataset.\n\n```bash\nwget https://storage.googleapis.com/generall-shared-data/startups_demo.json\n```\n\n2. Install the SentenceTransformer library as well as other relevant packages.\n\n```bash\npip install sentence-transformers numpy pandas tqdm\n```\n\n3. Import the required modules.\n\n```python\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport json\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n```\n\nYou will be using a pre-trained model called `all-MiniLM-L6-v2`. This is a performance-optimized sentence embedding model and you can read more about it and other available models [here](https://www.sbert.net/docs/pretrained_models.html).\n\n4. Download and create a pre-trained sentence encoder.\n\n```python\nmodel = SentenceTransformer(\n    \"all-MiniLM-L6-v2\", device=\"cuda\"\n)  # or device=\"cpu\" if you don't have a GPU\n```\n\n5. Read the raw data file.\n\n```python\ndf = pd.read_json(\"./startups_demo.json\", lines=True)\n```\n\n6. Encode all startup descriptions to create an embedding vector for each.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 16,
      "token_count": 238,
      "char_count": 1021,
      "start_char": 14348,
      "end_char": 15369
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:17",
    "content": "o.json\", lines=True)\n```\n\n6. Encode all startup descriptions to create an embedding vector for each. Internally, the `encode` function will split the input into batches, which will significantly speed up the process.\n\n```python\nvectors = model.encode(\n    [row.alt + \". \" + row.description for row in df.itertuples()],\n    show_progress_bar=True,\n)\n```\n\nAll of the descriptions are now converted into vectors. There are 40474 vectors of 384 dimensions. The output layer of the model has this dimension\n\n```python\nvectors.shape\n# > (40474, 384)\n```\n\n7. Download the saved vectors into a new file named `startup_vectors.npy`\n\n```python\nnp.save(\"startup_vectors.npy\", vectors, allow_pickle=False)\n```\n\n## Run Qdrant in Docker\n\nNext, you need to manage all of your data using a vector engine. Qdrant lets you store, update or delete created vectors. Most importantly, it lets you search for the nearest vectors via a convenient API.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 17,
      "token_count": 226,
      "char_count": 928,
      "start_char": 15269,
      "end_char": 16199
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:18",
    "content": "reated vectors. Most importantly, it lets you search for the nearest vectors via a convenient API.\n\n> **Note:** Before you begin, create a project directory and a virtual python environment in it.\n\n1. Download the Qdrant image from DockerHub.\n\n```bash\ndocker pull qdrant/qdrant\n```\n\n2. Start Qdrant inside of Docker.\n\n```bash\ndocker run -p 6333:6333 \\\n    -v $(pwd)/qdrant_storage:/qdrant/storage \\\n    qdrant/qdrant\n```\n\nYou should see output like this\n\n```text\n...\n[2021-02-05T00:08:51Z INFO  actix_server::builder] Starting 12 workers\n[2021-02-05T00:08:51Z INFO  actix_server::builder] Starting \"actix-web-service-0.0.0.0:6333\" service on 0.0.0.0:6333\n```\n\nTest the service by going to <http://localhost:6333/>. You should see the Qdrant version info in your browser.\n\nAll data uploaded to Qdrant is saved inside the `./qdrant_storage` directory and will be persisted even if you recreate the container.\n\n## Upload data to Qdrant\n\n1. Install the official Python client to best interact with Qdrant.\n\n```bash",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 18,
      "token_count": 317,
      "char_count": 1010,
      "start_char": 16099,
      "end_char": 17110
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:19",
    "content": "Upload data to Qdrant\n\n1. Install the official Python client to best interact with Qdrant.\n\n```bash\npip install qdrant-client\n```\n\nAt this point, you should have startup records in the `startups_demo.json` file, encoded vectors in `startup_vectors.npy` and Qdrant running on a local machine.\n\nNow you need to write a script to upload all startup data and vectors into the search engine.\n\n2. Create a client object for Qdrant.\n\n```python\n# Import client library\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.models import VectorParams, Distance\n\nclient = QdrantClient(\"http://localhost:6333\")\n```\n\n3. Related vectors need to be added to a collection. Create a new collection for your startup vectors.\n\n```python\nif not client.collection_exists(\"startups\"):\n    client.create_collection(\n        collection_name=\"startups\",\n        vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n    )\n```\n\n- The `vector_size` parameter defines the size of the vectors for a specific collection.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 19,
      "token_count": 236,
      "char_count": 1006,
      "start_char": 17010,
      "end_char": 18016
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:20",
    "content": ")\n```\n\n- The `vector_size` parameter defines the size of the vectors for a specific collection. If their size is different, it is impossible to calculate the distance between them. `384` is the encoder output dimensionality. You can also use `model.get_sentence_embedding_dimension()` to get the dimensionality of the model you are using.\n\n- The `distance` parameter lets you specify the function used to measure the distance between two points.\n\n4. Create an iterator over the startup data and vectors.\n\nThe Qdrant client library defines a special function that allows you to load datasets into the service. However, since there may be too much data to fit a single computer memory, the function takes an iterator over the data as input.\n\n```python\nfd = open(\"./startups_demo.json\")\n\n# payload is now an iterator over startup data\npayload = map(json.loads, fd)\n\n# Load all vectors into memory, numpy array works as iterable for itself.\n# Other option would be to use Mmap, if you don't want to load all data into RAM",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 20,
      "token_count": 220,
      "char_count": 1017,
      "start_char": 17916,
      "end_char": 18939
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:21",
    "content": "erable for itself.\n# Other option would be to use Mmap, if you don't want to load all data into RAM\nvectors = np.load(\"./startup_vectors.npy\")\n```\n\n5. Upload the data\n\n```python\nclient.upload_collection(\n    collection_name=\"startups\",\n    vectors=vectors,\n    payload=payload,\n    ids=None,  # Vector ids will be assigned automatically\n    batch_size=256,  # How many vectors will be uploaded in a single request?\n)\n```\n\nVectors are now uploaded to Qdrant.\n\n## Build the search API\n\nNow that all the preparations are complete, let’s start building a neural search class.\n\nIn order to process incoming requests, neural search will need 2 things: 1) a model to convert the query into a vector and 2) the Qdrant client to perform search queries.\n\n1. Create a file named `neural_searcher.py` and specify the following.\n\n```python\nfrom qdrant_client import QdrantClient\nfrom sentence_transformers import SentenceTransformer\n\n\nclass NeuralSearcher:\n    def __init__(self, collection_name):\n        self.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 21,
      "token_count": 236,
      "char_count": 998,
      "start_char": 18839,
      "end_char": 19837
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:22",
    "content": "t SentenceTransformer\n\n\nclass NeuralSearcher:\n    def __init__(self, collection_name):\n        self.collection_name = collection_name\n        # Initialize encoder model\n        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")\n        # initialize Qdrant client\n        self.qdrant_client = QdrantClient(\"http://localhost:6333\")\n```\n\n2. Write the search function.\n\n```python\ndef search(self, text: str):\n    # Convert text query into vector\n    vector = self.model.encode(text).tolist()\n\n    # Use `vector` for search for closest vectors in the collection\n    search_result = self.qdrant_client.query_points(\n        collection_name=self.collection_name,\n        query=vector,\n        query_filter=None,  # If you don't want any filters for now\n        limit=5,  # 5 the most closest results is enough\n    ).points\n    # `search_result` contains found vector ids with similarity scores along with the stored payload\n    # In this function you are interested in payload only\n    payloads = [hit.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 22,
      "token_count": 233,
      "char_count": 1011,
      "start_char": 19737,
      "end_char": 20748
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:23",
    "content": "th the stored payload\n    # In this function you are interested in payload only\n    payloads = [hit.payload for hit in search_result]\n    return payloads\n```\n\n3. Add search filters.\n\nWith Qdrant it is also feasible to add some conditions to the search. For example, if you wanted to search for startups in a certain city, the search query could look like this:\n\n```python\nfrom qdrant_client.models import Filter\n\n    ...\n\n    city_of_interest = \"Berlin\"\n\n    # Define a filter for cities\n    city_filter = Filter(**{\n        \"must\": [{\n            \"key\": \"city\", # Store city information in a field of the same name \n            \"match\": { # This condition checks if payload field has the requested value\n                \"value\": city_of_interest\n            }\n        }]\n    })\n\n    search_result = self.qdrant_client.query_points(\n        collection_name=self.collection_name,\n        query=vector,\n        query_filter=city_filter,\n        limit=5\n    ).points\n    ...\n```",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 23,
      "token_count": 216,
      "char_count": 975,
      "start_char": 20648,
      "end_char": 21625
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:24",
    "content": ",\n        query=vector,\n        query_filter=city_filter,\n        limit=5\n    ).points\n    ...\n```\n\nYou have now created a class for neural search queries. Now wrap it up into a service.\n\n## Deploy the search with FastAPI\n\nTo build the service you will use the FastAPI framework.\n\n1. Install FastAPI.\n\nTo install it, use the command\n\n```bash\npip install fastapi uvicorn\n```\n\n2. Implement the service.\n\nCreate a file named `service.py` and specify the following.\n\nThe service will have only one API endpoint and will look like this:\n\n```python\nfrom fastapi import FastAPI\n\n# The file where NeuralSearcher is stored\nfrom neural_searcher import NeuralSearcher\n\napp = FastAPI()\n\n# Create a neural searcher instance\nneural_searcher = NeuralSearcher(collection_name=\"startups\")\n\n\n@app.get(\"/api/search\")\ndef search_startup(q: str):\n    return {\"result\": neural_searcher.search(text=q)}\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n```\n\n3. Run the service.\n\n```bash",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 24,
      "token_count": 252,
      "char_count": 1010,
      "start_char": 21525,
      "end_char": 22536
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:25",
    "content": "import uvicorn\n\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n```\n\n3. Run the service.\n\n```bash\npython service.py\n```\n\n4. Open your browser at <http://localhost:8000/docs>.\n\nYou should be able to see a debug interface for your service.\n\nFeel free to play around with it, make queries regarding the companies in our corpus, and check out the results.\n\n## Next steps\n\nThe code from this tutorial has been used to develop a [live online demo](https://qdrant.to/semantic-search-demo). You can try it to get an intuition for cases when the neural search is useful. The demo contains a switch that selects between neural and full-text searches. You can turn the neural search on and off to compare your result with a regular full-text search.\n\n> **Note**: The code for this tutorial can be found here: | [Step 1: Data Preparation Process](https://colab.research.google.com/drive/1kPktoudAP8Tu8n8l-iVMOQhVmHkWV_L9?usp=sharing) | [Step 2: Full Code for Neural Search](https://github.",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 25,
      "token_count": 260,
      "char_count": 977,
      "start_char": 22436,
      "end_char": 23415
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:26",
    "content": "PktoudAP8Tu8n8l-iVMOQhVmHkWV_L9?usp=sharing) | [Step 2: Full Code for Neural Search](https://github.com/qdrant/qdrant_demo/tree/sentense-transformers). |\n\nJoin our [Discord community](https://qdrant.to/discord), where we talk about vector search and similarity learning, publish other examples of neural networks and neural search applications.\n\n##### Was this page useful?\n\nYes No\n\nThank you for your feedback! 🙏\n\nWe are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/beginner-tutorials/neural-search.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.\n\nOn this page:\n\n- [Build a Neural Search Service with Sentence Transformers and Qdrant](#build-a-neural-search-service-with-sentence-transformers-and-qdrant.md)\n\n  - [Workflow](#workflow.md)\n  - [Prerequisites](#prerequisites.md)\n  - [Prepare sample dataset](#prepare-sample-dataset.md)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 26,
      "token_count": 256,
      "char_count": 976,
      "start_char": 23315,
      "end_char": 24292
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md:chunk:27",
    "content": "md)\n  - [Prerequisites](#prerequisites.md)\n  - [Prepare sample dataset](#prepare-sample-dataset.md)\n  - [Run Qdrant in Docker](#run-qdrant-in-docker.md)\n  - [Upload data to Qdrant](#upload-data-to-qdrant.md)\n  - [Build the search API](#build-the-search-api.md)\n  - [Deploy the search with FastAPI](#deploy-the-search-with-fastapi.md)\n  - [Next steps](#next-steps.md)\n\n* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/beginner-tutorials/neural-search.md)\n* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)\n\n#### Ready to get started with Qdrant?\n\n[Start Free](https://qdrant.to/cloud/)\n\n© 2025 Qdrant.\n\n[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)",
    "metadata": {
      "source_file": "qdrant_documentation\\documentation_beginner-tutorials_neural-search\\_documentation_beginner-tutorials_neural-search_.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_documentation",
      "filename": "_documentation_beginner-tutorials_neural-search_.md",
      "file_extension": ".md",
      "chunk_index": 27,
      "token_count": 247,
      "char_count": 853,
      "start_char": 24192,
      "end_char": 25216
    }
  }
]
[
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:0",
    "content": "qdrant/examples | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[qdrant/examples](https://github.com/qdrant/examples \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 26 June 2025 ([b3c4b2](https://github.com/qdrant/examples/commits/b3c4b28f))\n\n- [Overview](qdrant/examples/1-overview.md)\n- [Getting Started with Qdrant](qdrant/examples/2-getting-started-with-qdrant.md)\n- [Text Data Applications](qdrant/examples/3-text-data-applications.md)\n- [Code Search with Dual Embeddings](qdrant/examples/3.1-code-search-with-dual-embeddings.md)\n- [Extractive Question Answering](qdrant/examples/3.2-extractive-question-answering.md)\n- [Movie Recommendations with Sparse Vectors](qdrant/examples/3.3-movie-recommendations-with-sparse-vectors.md)\n- [Image Data Applications](qdrant/examples/4-image-data-applications.md)\n- [E-commerce Reverse Image Search](qdrant/examples/4.1-e-commerce-reverse-image-search.md)",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "token_count": 294,
      "char_count": 1022,
      "start_char": 0,
      "end_char": 1023
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:1",
    "content": "ons.md)\n- [E-commerce Reverse Image Search](qdrant/examples/4.1-e-commerce-reverse-image-search.md)\n- [Medical Image Search with Vision Transformers](qdrant/examples/4.2-medical-image-search-with-vision-transformers.md)\n- [Audio Data Applications](qdrant/examples/5-audio-data-applications.md)\n- [Music Recommendation Engine](qdrant/examples/5.1-music-recommendation-engine.md)\n- [Advanced RAG Systems](qdrant/examples/6-advanced-rag-systems.md)\n- [Multivector RAG with DSPy](qdrant/examples/6.1-multivector-rag-with-dspy.md)\n- [Graph-Enhanced RAG with Neo4j](qdrant/examples/6.2-graph-enhanced-rag-with-neo4j.md)\n- [PDF Retrieval at Scale](qdrant/examples/6.3-pdf-retrieval-at-scale.md)\n- [Agentic Systems with CrewAI](qdrant/examples/7-agentic-systems-with-crewai.md)\n- [Meeting Analysis with Agentic RAG](qdrant/examples/7.1-meeting-analysis-with-agentic-rag.md)\n- [Additional Use Cases](qdrant/examples/8-additional-use-cases.md)\n- [Self-Query Systems with LangChain](qdrant/examples/8.",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "token_count": 292,
      "char_count": 990,
      "start_char": 923,
      "end_char": 1913
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:2",
    "content": "(qdrant/examples/8-additional-use-cases.md)\n- [Self-Query Systems with LangChain](qdrant/examples/8.1-self-query-systems-with-langchain.md)\n- [Development Environment Setup](qdrant/examples/8.2-development-environment-setup.md)\n\nMenu\n\n# Overview\n\nRelevant source files\n\n- [.gitignore](https://github.com/qdrant/examples/blob/b3c4b28f/.gitignore)\n- [DSPy-medical-bot/medical\\_bot\\_DSPy\\_Qdrant.ipynb](https://github.com/qdrant/examples/blob/b3c4b28f/DSPy-medical-bot/medical_bot_DSPy_Qdrant.ipynb)\n- [README.md](https://github.com/qdrant/examples/blob/b3c4b28f/README.md)\n- [code-search/code-search.ipynb](https://github.com/qdrant/examples/blob/b3c4b28f/code-search/code-search.ipynb)\n- [multivector-representation/multivector\\_representation\\_qdrant.ipynb](https://github.com/qdrant/examples/blob/b3c4b28f/multivector-representation/multivector_representation_qdrant.ipynb)\n- [sparse-vectors-movies-reco/recommend-movies.ipynb](https://github.com/qdrant/examples/blob/b3c4b28f/sparse-vectors-movies-reco/recommend-movies.",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "token_count": 317,
      "char_count": 1022,
      "start_char": 1813,
      "end_char": 2835
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:3",
    "content": "ipynb](https://github.com/qdrant/examples/blob/b3c4b28f/sparse-vectors-movies-reco/recommend-movies.ipynb)\n\nThis wiki provides documentation for the [Qdrant Examples](<https://github.com/qdrant/examples/blob/b3c4b28f/Qdrant Examples>) repository, a collection of tutorials, demos, and how-to guides demonstrating the use of Qdrant vector database and adjacent technologies for various applications. From basic similarity search to advanced retrieval-augmented generation (RAG) systems, these examples showcase real-world implementations across different data modalities (text, images, audio) and use cases.\n\nSources: [README.md1-3](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L1-L3)\n\n## Purpose and Scope\n\nThe Qdrant Examples repository aims to demonstrate practical implementations of vector search technology using Qdrant. The examples progress from basic vector database operations to sophisticated AI applications, serving both educational and reference purposes for developers.\n\nKey aspects covered:",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "token_count": 226,
      "char_count": 1019,
      "start_char": 2735,
      "end_char": 3756
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:4",
    "content": "pplications, serving both educational and reference purposes for developers.\n\nKey aspects covered:\n\n- Basic vector operations and similarity search\n- Domain-specific applications for text, image, and audio data\n- Advanced AI integrations such as RAG systems and agentic frameworks\n- Integration patterns with other technologies (OpenAI, Cohere, CLIP, etc.)\n\nFor specifics on getting started with basic Qdrant functionality, see [Getting Started with Qdrant](qdrant/examples/2-getting-started-with-qdrant.md).\n\nSources: [README.md3-17](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L3-L17)\n\n## Repository Structure\n\nThe repository is organized into categories based on complexity and data modality, allowing users to find relevant examples for their specific needs.\n\n```\n```\n\nSources: [README.md5-17](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L5-L17)\n\n## Example Types and Progression",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "token_count": 221,
      "char_count": 913,
      "start_char": 3656,
      "end_char": 4571
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:5",
    "content": "tps://github.com/qdrant/examples/blob/b3c4b28f/README.md#L5-L17)\n\n## Example Types and Progression\n\nThe examples in the repository follow a progression from basic to advanced, demonstrating increasingly sophisticated applications of vector search technology.\n\n| Level        | Example Type                  | Technologies                              | Examples                                                    |\n| ------------ | ----------------------------- | ----------------------------------------- | ----------------------------------------------------------- |\n| Basic        | Fundamental vector operations | Qdrant, NumPy, Faker                      | Qdrant 101 Getting Started                                  |\n| Intermediate | Domain-specific applications  | Transformers, CLIP, Sentence-Transformers | Code Search, E-commerce Image Search, Movie Recommendations |",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "token_count": 140,
      "char_count": 879,
      "start_char": 4471,
      "end_char": 5351
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:6",
    "content": "ormers, CLIP, Sentence-Transformers | Code Search, E-commerce Image Search, Movie Recommendations |\n| Advanced     | AI integration systems        | OpenAI, LlamaIndex, Cohere, CrewAI        | Recency-Aware RAG, Graph-Enhanced RAG, Agentic Systems      |\n\nSources: [README.md5-17](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L5-L17)\n\n## Core Processing Pipeline\n\nMost examples in the repository follow a similar data processing pattern despite addressing different domains and use cases.\n\n```\n```\n\nSources: [README.md5-17](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L5-L17) [code-search/code-search.ipynb6-9](https://github.com/qdrant/examples/blob/b3c4b28f/code-search/code-search.ipynb#L6-L9) [sparse-vectors-movies-reco/recommend-movies.ipynb7-25](https://github.com/qdrant/examples/blob/b3c4b28f/sparse-vectors-movies-reco/recommend-movies.ipynb#L7-L25)\n\n## Vector Search Implementations\n\nThe repository demonstrates various vector search implementations across different data modalities:",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "token_count": 286,
      "char_count": 1023,
      "start_char": 5251,
      "end_char": 6276
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:7",
    "content": "he repository demonstrates various vector search implementations across different data modalities:\n\n### Text Data Applications\n\nText-based examples showcase how to build search applications for natural language, code, and structured text data using embeddings.\n\n```\n```\n\nKey text applications include:\n\n- Code search using dual embeddings (general-purpose and code-specific)\n- Extractive question answering\n- Movie recommendations using collaborative filtering with sparse vectors\n\nSources: [README.md9-10](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L9-L10) [README.md16](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L16-L16) [code-search/code-search.ipynb6-9](https://github.com/qdrant/examples/blob/b3c4b28f/code-search/code-search.ipynb#L6-L9) [sparse-vectors-movies-reco/recommend-movies.ipynb7-25](https://github.com/qdrant/examples/blob/b3c4b28f/sparse-vectors-movies-reco/recommend-movies.ipynb#L7-L25)\n\n### Image Data Applications",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "token_count": 255,
      "char_count": 968,
      "start_char": 6176,
      "end_char": 7146
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:8",
    "content": "ob/b3c4b28f/sparse-vectors-movies-reco/recommend-movies.ipynb#L7-L25)\n\n### Image Data Applications\n\nImage-based examples demonstrate how to build visual search systems across domains:\n\n```\n```\n\nKey image applications include:\n\n- E-commerce reverse image search using CLIP embeddings\n- Medical image similarity search with vision transformers\n\nSources: [README.md12](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L12-L12) [README.md4](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L4-L4)\n\n### Audio Data Applications\n\nAudio examples showcase music recommendation and audio similarity search:\n\n```\n```\n\nKey audio applications include:\n\n- Music recommendation systems using audio feature embeddings\n\nSources: [README.md11](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L11-L11) [README.md5](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L5-L5)\n\n## Advanced AI Integrations\n\nThe repository includes advanced examples integrating Qdrant with modern AI frameworks:",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "token_count": 265,
      "char_count": 1010,
      "start_char": 7046,
      "end_char": 8058
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:9",
    "content": "egrations\n\nThe repository includes advanced examples integrating Qdrant with modern AI frameworks:\n\n### Retrieval-Augmented Generation (RAG) Systems\n\n```\n```\n\nKey RAG examples include:\n\n- Recency-aware RAG with LlamaIndex\n- Graph-enhanced RAG with Neo4j integration\n- Basic RAG pipelines with various LLM providers\n\nSources: [README.md8-9](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L8-L9) [README.md6](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L6-L6)\n\n### Agentic Systems\n\n```\n```\n\nKey agentic examples include:\n\n- Multi-agent systems using CrewAI for orchestration\n- Meeting analysis with agentic RAG\n\nSources: [README.md7](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L7-L7)\n\n## Integration Technologies\n\nThe examples in the repository integrate with various AI and data processing technologies:\n\n| Category         | Technologies                                  | Purpose                                     |",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "token_count": 235,
      "char_count": 961,
      "start_char": 7958,
      "end_char": 8920
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:10",
    "content": "| Technologies                                  | Purpose                                     |\n| ---------------- | --------------------------------------------- | ------------------------------------------- |\n| Embedding Models | SentenceTransformers, CLIP, OpenL3, FastEmbed | Converting data to vector representations   |\n| Language Models  | OpenAI, Cohere, Hugging Face                  | Text generation, reranking, embeddings      |\n| Frameworks       | LlamaIndex, LangChain, CrewAI                 | Building LLM applications and agent systems |\n| Infrastructure   | AWS Lambda, Hugging Face Spaces               | Deployment and hosting                      |\n| Databases        | Neo4j, Qdrant                                 | Graph data, vector storage                  |\n\nSources: [README.md5-17](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L5-L17)\n\n## Starting with the Examples",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "token_count": 175,
      "char_count": 909,
      "start_char": 8820,
      "end_char": 9735
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:11",
    "content": "(https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L5-L17)\n\n## Starting with the Examples\n\nEach example in the repository is self-contained and includes the necessary code and documentation to understand and run the implementation. To get started:\n\n1. Clone the repository: `git clone https://github.com/qdrant/examples.git`\n2. Navigate to the specific example directory\n3. Follow the README or notebook instructions within each example\n\nFor fundamental Qdrant concepts and operations, see [Getting Started with Qdrant](qdrant/examples/2-getting-started-with-qdrant.md).\n\nSources: [README.md3-4](https://github.com/qdrant/examples/blob/b3c4b28f/README.md#L3-L4)\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh\n\n### On this page\n\n- [Overview](#overview.md)\n- [Purpose and Scope](#purpose-and-scope.md)\n- [Repository Structure](#repository-structure.md)\n- [Example Types and Progression](#example-types-and-progression.md)\n- [Core Processing Pipeline](#core-processing-pipeline.md)",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "token_count": 246,
      "char_count": 992,
      "start_char": 9635,
      "end_char": 10628
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_examples\\_qdrant_examples_1-overview.md:chunk:12",
    "content": "sion](#example-types-and-progression.md)\n- [Core Processing Pipeline](#core-processing-pipeline.md)\n- [Vector Search Implementations](#vector-search-implementations.md)\n- [Text Data Applications](#text-data-applications.md)\n- [Image Data Applications](#image-data-applications.md)\n- [Audio Data Applications](#audio-data-applications.md)\n- [Advanced AI Integrations](#advanced-ai-integrations.md)\n- [Retrieval-Augmented Generation (RAG) Systems](#retrieval-augmented-generation-rag-systems.md)\n- [Agentic Systems](#agentic-systems.md)\n- [Integration Technologies](#integration-technologies.md)\n- [Starting with the Examples](#starting-with-the-examples.md)",
    "metadata": {
      "source_file": "qdrant_examples\\_qdrant_examples_1-overview.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_examples",
      "filename": "_qdrant_examples_1-overview.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "token_count": 162,
      "char_count": 656,
      "start_char": 10528,
      "end_char": 11552
    }
  }
]
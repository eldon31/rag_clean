[
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:0",
    "content": "Architecture | qdrant/fastembed | DeepWiki\n\n[Index your code with Devin](private-repo.md)\n\n[DeepWiki](https://deepwiki.com)\n\n[DeepWiki](.md)\n\n[qdrant/fastembed](https://github.com/qdrant/fastembed \"Open repository\")\n\n[Index your code with](private-repo.md)\n\n[Devin](private-repo.md)\n\nShare\n\nLast indexed: 20 April 2025 ([b78564](https://github.com/qdrant/fastembed/commits/b785640b))\n\n- [Overview](qdrant/fastembed/1-overview.md)\n- [Installation and Setup](qdrant/fastembed/2-installation-and-setup.md)\n- [Core Embedding Classes](qdrant/fastembed/3-core-embedding-classes.md)\n- [TextEmbedding](qdrant/fastembed/3.1-textembedding.md)\n- [SparseTextEmbedding](qdrant/fastembed/3.2-sparsetextembedding.md)\n- [LateInteractionTextEmbedding](qdrant/fastembed/3.3-lateinteractiontextembedding.md)\n- [ImageEmbedding](qdrant/fastembed/3.4-imageembedding.md)\n- [LateInteractionMultimodalEmbedding](qdrant/fastembed/3.5-lateinteractionmultimodalembedding.md)\n- [TextCrossEncoder](qdrant/fastembed/3.6-textcrossencoder.md)",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 0,
      "token_count": 310,
      "char_count": 1009,
      "start_char": 0,
      "end_char": 1010
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:1",
    "content": "teinteractionmultimodalembedding.md)\n- [TextCrossEncoder](qdrant/fastembed/3.6-textcrossencoder.md)\n- [Architecture](qdrant/fastembed/4-architecture.md)\n- [Model Management](qdrant/fastembed/4.1-model-management.md)\n- [ONNX Runtime Integration](qdrant/fastembed/4.2-onnx-runtime-integration.md)\n- [Parallel Processing](qdrant/fastembed/4.3-parallel-processing.md)\n- [Implementation Details](qdrant/fastembed/5-implementation-details.md)\n- [Dense Text Embeddings](qdrant/fastembed/5.1-dense-text-embeddings.md)\n- [Sparse Text Embeddings](qdrant/fastembed/5.2-sparse-text-embeddings.md)\n- [Late Interaction Models](qdrant/fastembed/5.3-late-interaction-models.md)\n- [Multimodal Models](qdrant/fastembed/5.4-multimodal-models.md)\n- [Supported Models](qdrant/fastembed/6-supported-models.md)\n- [Usage Examples](qdrant/fastembed/7-usage-examples.md)\n- [Basic Text Embedding](qdrant/fastembed/7.1-basic-text-embedding.md)\n- [Sparse and Hybrid Search](qdrant/fastembed/7.2-sparse-and-hybrid-search.md)",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 1,
      "token_count": 298,
      "char_count": 994,
      "start_char": 910,
      "end_char": 1905
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:2",
    "content": "c-text-embedding.md)\n- [Sparse and Hybrid Search](qdrant/fastembed/7.2-sparse-and-hybrid-search.md)\n- [ColBERT and Late Interaction](qdrant/fastembed/7.3-colbert-and-late-interaction.md)\n- [Image Embedding](qdrant/fastembed/7.4-image-embedding.md)\n- [Performance Optimization](qdrant/fastembed/8-performance-optimization.md)\n- [Integration with Qdrant](qdrant/fastembed/9-integration-with-qdrant.md)\n- [Development Guide](qdrant/fastembed/10-development-guide.md)\n\nMenu\n\n# Architecture\n\nRelevant source files\n\n- [fastembed/common/model\\_management.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/model_management.py)\n- [fastembed/common/onnx\\_model.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py)\n- [fastembed/parallel\\_processor.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py)\n- [fastembed/rerank/cross\\_encoder/onnx\\_text\\_model.py](https://github.",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 2,
      "token_count": 274,
      "char_count": 950,
      "start_char": 1805,
      "end_char": 2755
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:3",
    "content": "mbed/parallel_processor.py)\n- [fastembed/rerank/cross\\_encoder/onnx\\_text\\_model.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/rerank/cross_encoder/onnx_text_model.py)\n- [fastembed/text/text\\_embedding\\_base.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/text_embedding_base.py)\n\nThis page provides a detailed overview of FastEmbed's architecture, outlining the core components, their interactions, and the embedding generation process flow. The document covers the high-level design patterns, component responsibilities, and implementation details that enable FastEmbed's efficient embedding generation capabilities.\n\nFor information about model management specifics, see [Model Management](qdrant/fastembed/4.1-model-management.md). For details on ONNX Runtime integration, see [ONNX Runtime Integration](qdrant/fastembed/4.2-onnx-runtime-integration.md). For parallel processing implementation, see [Parallel Processing](qdrant/fastembed/4.3-parallel-processing.md).",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 3,
      "token_count": 228,
      "char_count": 1009,
      "start_char": 2655,
      "end_char": 3666
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:4",
    "content": "processing implementation, see [Parallel Processing](qdrant/fastembed/4.3-parallel-processing.md).\n\n## Core Components Overview\n\nFastEmbed's architecture is built around several key components that work together to provide high-performance embedding generation:\n\n```\n```\n\nSources: [fastembed/common/model\\_management.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/model_management.py) [fastembed/common/onnx\\_model.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py) [fastembed/parallel\\_processor.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py) [fastembed/text/text\\_embedding\\_base.py](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/text_embedding_base.py)\n\n## Model Management System\n\nThe model management system is responsible for model discovery, downloading, and caching.",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 4,
      "token_count": 214,
      "char_count": 892,
      "start_char": 3566,
      "end_char": 4458
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:5",
    "content": "nt System\n\nThe model management system is responsible for model discovery, downloading, and caching. It ensures models are available locally for embedding operations, handling various sources (HuggingFace, Google Cloud Storage) and verifying model integrity.\n\n```\n```\n\nSources: [fastembed/common/model\\_management.py24-458](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/model_management.py#L24-L458)\n\nThe `ModelManagement` class provides methods for:\n\n- Listing supported models (`list_supported_models`)\n- Adding custom models (`add_custom_model`)\n- Downloading models from various sources (`download_model`)\n- Verifying model integrity through metadata validation\n\n## ONNX Runtime Integration\n\nFastEmbed leverages ONNX Runtime for optimized inference, providing significant performance improvements over traditional PyTorch/TensorFlow implementations.\n\n```\n```\n\nSources: [fastembed/common/onnx\\_model.py19-137](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 5,
      "token_count": 225,
      "char_count": 1012,
      "start_char": 4358,
      "end_char": 5370
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:6",
    "content": "onnx\\_model.py19-137](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L19-L137) [fastembed/rerank/cross\\_encoder/onnx\\_text\\_model.py21-146](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/rerank/cross_encoder/onnx_text_model.py#L21-L146)\n\nThe `OnnxModel` class:\n\n- Manages ONNX session creation with appropriate execution providers\n- Handles model loading, input preprocessing, and output post-processing\n- Supports CPU and GPU (CUDA) execution\n- Provides a generic interface for different types of embeddings\n\n## Parallel Processing Framework\n\nFastEmbed implements efficient parallel processing through a worker pool design, enabling multi-process execution of embedding tasks for improved throughput.\n\n```\n```\n\nSources: [fastembed/parallel\\_processor.py20-253](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L20-L253) [fastembed/common/onnx\\_model.py114-137](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 6,
      "token_count": 288,
      "char_count": 1020,
      "start_char": 5270,
      "end_char": 6290
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:7",
    "content": "nnx\\_model.py114-137](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L114-L137)\n\nThe parallel processing framework provides:\n\n- A worker pool that manages multiple processes for embedding computation\n- Process-safe queues for input/output communication\n- Work distribution and result collection mechanisms\n- Support for ordered results (maintaining input sequence order)\n- Device management for GPU acceleration\n\n## Embedding Process Flow\n\nThe following diagram illustrates the typical flow for generating embeddings in FastEmbed:\n\n```\n```\n\nSources: [fastembed/text/text\\_embedding\\_base.py8-60](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/text_embedding_base.py#L8-L60) [fastembed/common/onnx\\_model.py26-112](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L26-L112) [fastembed/parallel\\_processor.py91-253](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L91-L253)\n\n## Class Hierarchy",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 7,
      "token_count": 278,
      "char_count": 1009,
      "start_char": 6190,
      "end_char": 7201
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:8",
    "content": "b.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L91-L253)\n\n## Class Hierarchy\n\nFastEmbed organizes its functionality through a clear class hierarchy:\n\n```\n```\n\nSources: [fastembed/common/model\\_management.py24-458](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/model_management.py#L24-L458) [fastembed/common/onnx\\_model.py26-137](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L26-L137) [fastembed/parallel\\_processor.py26-253](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L26-L253) [fastembed/text/text\\_embedding\\_base.py8-60](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/text_embedding_base.py#L8-L60) [fastembed/rerank/cross\\_encoder/onnx\\_text\\_model.py21-170](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/rerank/cross_encoder/onnx_text_model.py#L21-L170)\n\n## Implementation Details\n\n### Model Loading Process\n\nThe model loading process in FastEmbed follows these steps:",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 8,
      "token_count": 331,
      "char_count": 1024,
      "start_char": 7101,
      "end_char": 8126
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:9",
    "content": "ion Details\n\n### Model Loading Process\n\nThe model loading process in FastEmbed follows these steps:\n\n1. Model description is retrieved from the supported models list\n2. Model is downloaded from the appropriate source (HuggingFace or GCS)\n3. Model files are verified for integrity through metadata validation\n4. ONNX session is created with the appropriate execution provider\n5. Additional resources (like tokenizers) are loaded\n\nKey implementations:\n\n- `download_model()` in `ModelManagement` [fastembed/common/model\\_management.py378-458](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/model_management.py#L378-L458)\n- `_load_onnx_model()` in `OnnxModel` [fastembed/common/onnx\\_model.py46-106](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L46-L106)\n\n### Parallel Processing Implementation\n\nFastEmbed's parallel processing is implemented using Python's multiprocessing module:\n\n1. A worker pool is created with a specified number of processes\n2.",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 9,
      "token_count": 245,
      "char_count": 1002,
      "start_char": 8026,
      "end_char": 9028
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:10",
    "content": "ython's multiprocessing module:\n\n1. A worker pool is created with a specified number of processes\n2. Each worker process is initialized with the model and necessary resources\n3. Input data is batched and distributed through a queue\n4. Workers process batches in parallel\n5. Results are collected, reordered, and returned to the user\n\nKey implementations:\n\n- `ParallelWorkerPool` class [fastembed/parallel\\_processor.py91-253](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L91-L253)\n- `_worker()` function [fastembed/parallel\\_processor.py35-88](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L35-L88)\n- `ordered_map()` method [fastembed/parallel\\_processor.py142-151](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/parallel_processor.py#L142-L151)\n\n### ONNX Provider Selection\n\nFastEmbed automatically selects the appropriate ONNX execution provider based on:",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 10,
      "token_count": 252,
      "char_count": 943,
      "start_char": 8928,
      "end_char": 9873
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:11",
    "content": "vider Selection\n\nFastEmbed automatically selects the appropriate ONNX execution provider based on:\n\n| Provider         | Condition                     | Implementation                                 |\n| ---------------- | ----------------------------- | ---------------------------------------------- |\n| Custom Providers | Explicitly provided by user   | User-specified list of providers               |\n| CUDA             | `cuda=True` in initialization | CUDAExecutionProvider with optional device\\_id |\n| CPU              | Default fallback              | CPUExecutionProvider                           |\n\nKey implementation in `_load_onnx_model()` [fastembed/common/onnx\\_model.py46-106](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L46-L106)\n\n## Interface to Implementation Mapping\n\nThis table shows how the user-facing embedding classes map to their implementations:",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 11,
      "token_count": 166,
      "char_count": 910,
      "start_char": 9773,
      "end_char": 10685
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:12",
    "content": "tion Mapping\n\nThis table shows how the user-facing embedding classes map to their implementations:\n\n| User API Class                     | Base Class                   | Implementation Classes                                        |\n| ---------------------------------- | ---------------------------- | ------------------------------------------------------------- |\n| TextEmbedding                      | TextEmbeddingBase, OnnxModel | PooledEmbedding, PooledNormalizedEmbedding, CLIPOnnxEmbedding |\n| SparseTextEmbedding                | TextEmbeddingBase, OnnxModel | SpladePP, Bm25, Bm42                                          |\n| LateInteractionTextEmbedding       | TextEmbeddingBase, OnnxModel | Colbert, JinaColbert                                          |\n| ImageEmbedding                     | OnnxModel                    | OnnxImageEmbedding                                            |",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 12,
      "token_count": 148,
      "char_count": 903,
      "start_char": 10585,
      "end_char": 11489
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:13",
    "content": "| OnnxModel                    | OnnxImageEmbedding                                            |\n| LateInteractionMultimodalEmbedding | OnnxModel                    | ColPali                                                       |\n| TextCrossEncoder                   | OnnxModel                    | OnnxTextCrossEncoder                                          |\n\nSources: [fastembed/text/text\\_embedding\\_base.py8-60](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/text/text_embedding_base.py#L8-L60) [fastembed/common/onnx\\_model.py26-137](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/common/onnx_model.py#L26-L137) [fastembed/rerank/cross\\_encoder/onnx\\_text\\_model.py21-170](https://github.com/qdrant/fastembed/blob/b785640b/fastembed/rerank/cross_encoder/onnx_text_model.py#L21-L170)\n\nDismiss\n\nRefresh this wiki\n\nEnter email to refresh\n\n### On this page\n\n- [Architecture](#architecture.md)\n- [Core Components Overview](#core-components-overview.md)",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 13,
      "token_count": 251,
      "char_count": 983,
      "start_char": 11389,
      "end_char": 12376
    }
  },
  {
    "chunk_id": "qdrant_ecosystem:qdrant_fastembed\\_qdrant_fastembed_4-architecture.md:chunk:14",
    "content": "page\n\n- [Architecture](#architecture.md)\n- [Core Components Overview](#core-components-overview.md)\n- [Model Management System](#model-management-system.md)\n- [ONNX Runtime Integration](#onnx-runtime-integration.md)\n- [Parallel Processing Framework](#parallel-processing-framework.md)\n- [Embedding Process Flow](#embedding-process-flow.md)\n- [Class Hierarchy](#class-hierarchy.md)\n- [Implementation Details](#implementation-details.md)\n- [Model Loading Process](#model-loading-process.md)\n- [Parallel Processing Implementation](#parallel-processing-implementation.md)\n- [ONNX Provider Selection](#onnx-provider-selection.md)\n- [Interface to Implementation Mapping](#interface-to-implementation-mapping.md)",
    "metadata": {
      "source_file": "qdrant_fastembed\\_qdrant_fastembed_4-architecture.md",
      "source_collection": "qdrant_ecosystem",
      "subdirectory": "qdrant_fastembed",
      "filename": "_qdrant_fastembed_4-architecture.md",
      "file_extension": ".md",
      "chunk_index": 14,
      "token_count": 152,
      "char_count": 705,
      "start_char": 12276,
      "end_char": 13300
    }
  }
]
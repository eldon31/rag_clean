# RAG System Environment Configuration

# OpenAI API Key (Optional - only if using OpenAI)
OPENAI_API_KEY=your_openai_api_key_here

# LLM Configuration (Optional)
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.7

# Embedding Configuration - LOCAL (No API key needed!)
# Nomic Embed Code - BEST for code, APIs, documentation, and workflows
# 1536 dimensions, 8192 token context, optimized for code retrieval
EMBEDDING_MODEL=nomic-ai/nomic-embed-code

# Alternative models:
# EMBEDDING_MODEL=jinaai/jina-embeddings-v2-base-code  # Code-specific (768 dim)
# EMBEDDING_MODEL=all-MiniLM-L6-v2  # Fast, general purpose (384 dim)
# EMBEDDING_MODEL=all-mpnet-base-v2  # Best quality general (768 dim)

# Embedding Optimization (CPU only)
EMBEDDING_OPTIMIZATION=none  # Options: none, onnx, quantized, multiprocess
EMBEDDING_DEVICE=cpu
EMBEDDING_BATCH_SIZE=32
EMBEDDING_WORKERS=4  # For multiprocess optimization

# Qdrant Vector Database
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=documents

# Reranking (optional, improves search quality by 20-30%)
ENABLE_RERANKING=true
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L6-v2



# API Configuration
API_HOST=0.0.0.0
API_PORT=8080
API_RELOAD=true

# Performance Settings
MAX_CONCURRENT_DOCUMENTS=5
CHUNK_SIZE=512
CHUNK_OVERLAP=50

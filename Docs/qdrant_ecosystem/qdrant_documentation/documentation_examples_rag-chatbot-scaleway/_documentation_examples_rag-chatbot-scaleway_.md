Blog-Reading Chatbot with GPT-4o - Qdrant

[](https://qdrant.tech/)

- [Qdrant](https://qdrant.tech/documentation/)
- [Cloud](https://qdrant.tech/documentation/cloud-intro/)
- [Build](https://qdrant.tech/documentation/build/)
- [Learn](https://qdrant.tech/articles/)
- [API Reference](https://api.qdrant.tech/api-reference)

Search

[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)

Search

- [Qdrant](https://qdrant.tech/documentation/)
- [Cloud](https://qdrant.tech/documentation/cloud-intro/)
- [Build](https://qdrant.tech/documentation/build/)
- [Learn](https://qdrant.tech/articles/)
- [API Reference](https://api.qdrant.tech/api-reference)

### Essentials

[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)

[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)

[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)

[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)

[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)

[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)

[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)

### Integrations

[Data Management](https://qdrant.tech/documentation/data-management/)

- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)
- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)
- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)
- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)
- [cognee](https://qdrant.tech/documentation/data-management/cognee/)
- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)
- [DLT](https://qdrant.tech/documentation/data-management/dlt/)
- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)
- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)
- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)

[Embeddings](https://qdrant.tech/documentation/embeddings/)

- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)
- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)
- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)
- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)
- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)
- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)
- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)
- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)
- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)
- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)
- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)
- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)
- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)
- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)
- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)
- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)
- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)

[Frameworks](https://qdrant.tech/documentation/frameworks/)

- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)
- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)
- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)
- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)
- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)
- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)
- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)
- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)
- [Feast](https://qdrant.tech/documentation/frameworks/feast/)
- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)
- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)
- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)
- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)
- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)
- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)
- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)
- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)
- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)
- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)
- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)
- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)
- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)
- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)
- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)
- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)
- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)
- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)
- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)
- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)
- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)
- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)
- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)
- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)

[Observability](https://qdrant.tech/documentation/observability/)

- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)
- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)
- [Datadog](https://qdrant.tech/documentation/observability/datadog/)

[Platforms](https://qdrant.tech/documentation/platforms/)

- [Apify](https://qdrant.tech/documentation/platforms/apify/)
- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)
- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)
- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)
- [Make.com](https://qdrant.tech/documentation/platforms/make/)
- [N8N](https://qdrant.tech/documentation/platforms/n8n/)
- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)
- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)
- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)
- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)
- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)
- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)

### Examples

[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)

- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)
- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)

[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)

- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)
- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)
- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)

[Build Prototypes](https://qdrant.tech/documentation/examples/)

- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)
- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)
- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)
- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)
- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)
- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)
- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)
- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)
- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)
- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)
- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)
- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)

[Practice Datasets](https://qdrant.tech/documentation/datasets/)

### Essentials

[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)

[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)

[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)

[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)

[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)

[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)

[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)

### Integrations

[Data Management](https://qdrant.tech/documentation/data-management/)

- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)
- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)
- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)
- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)
- [cognee](https://qdrant.tech/documentation/data-management/cognee/)
- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)
- [DLT](https://qdrant.tech/documentation/data-management/dlt/)
- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)
- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)
- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)

[Embeddings](https://qdrant.tech/documentation/embeddings/)

- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)
- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)
- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)
- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)
- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)
- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)
- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)
- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)
- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)
- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)
- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)
- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)
- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)
- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)
- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)
- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)
- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)

[Frameworks](https://qdrant.tech/documentation/frameworks/)

- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)
- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)
- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)
- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)
- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)
- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)
- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)
- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)
- [Feast](https://qdrant.tech/documentation/frameworks/feast/)
- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)
- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)
- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)
- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)
- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)
- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)
- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)
- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)
- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)
- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)
- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)
- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)
- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)
- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)
- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)
- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)
- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)
- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)
- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)
- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)
- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)
- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)
- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)
- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)

[Observability](https://qdrant.tech/documentation/observability/)

- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)
- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)
- [Datadog](https://qdrant.tech/documentation/observability/datadog/)

[Platforms](https://qdrant.tech/documentation/platforms/)

- [Apify](https://qdrant.tech/documentation/platforms/apify/)
- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)
- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)
- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)
- [Make.com](https://qdrant.tech/documentation/platforms/make/)
- [N8N](https://qdrant.tech/documentation/platforms/n8n/)
- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)
- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)
- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)
- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)
- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)
- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)

### Examples

[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)

- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)
- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)

[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)

- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)
- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)
- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)

[Build Prototypes](https://qdrant.tech/documentation/examples/)

- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)
- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)
- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)
- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)
- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)
- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)
- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)
- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)
- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)
- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)
- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)
- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)

[Practice Datasets](https://qdrant.tech/documentation/datasets/)

- [Documentation](https://qdrant.tech/documentation/)
-
- [Examples](https://qdrant.tech/documentation/examples/)
-
- Blog-Reading Chatbot with GPT-4o

# Blog-Reading Chatbot with GPT-4o

| Time: 90 min | Level: Advanced | [GitHub](https://github.com/qdrant/examples/blob/langchain-lcel-rag/langchain-lcel-rag/Langchain-LCEL-RAG-Demo.ipynb) |   |
| ------------ | --------------- | --------------------------------------------------------------------------------------------------------------------- | - |

In this tutorial, you will build a RAG system that combines blog content ingestion with the capabilities of semantic search. **OpenAI’s GPT-4o LLM** is powerful, but scaling its use requires us to supply context systematically.

RAG enhances the LLM’s generation of answers by retrieving relevant documents to aid the question-answering process. This setup showcases the integration of advanced search and AI language processing to improve information retrieval and generation tasks.

A notebook for this tutorial is available on [GitHub](https://github.com/qdrant/examples/blob/langchain-lcel-rag/langchain-lcel-rag/Langchain-LCEL-RAG-Demo.ipynb).

**Data Privacy and Sovereignty:** RAG applications often rely on sensitive or proprietary internal data. Running the entire stack within your own environment becomes crucial for maintaining control over this data. Qdrant Hybrid Cloud deployed on [Scaleway](https://www.scaleway.com/) addresses this need perfectly, offering a secure, scalable platform that still leverages the full potential of RAG. Scaleway offers serverless [Functions](https://www.scaleway.com/en/serverless-functions/) and serverless [Jobs](https://www.scaleway.com/en/serverless-jobs/), both of which are ideal for embedding creation in large-scale RAG cases.

## Components

- **Cloud Host:** [Scaleway on managed Kubernetes](https://www.scaleway.com/en/kubernetes-kapsule/) for compatibility with Qdrant Hybrid Cloud.
- **Vector Database:** Qdrant Hybrid Cloud as the vector search engine for retrieval.
- **LLM:** GPT-4o, developed by OpenAI is utilized as the generator for producing answers.
- **Framework:** [LangChain](https://www.langchain.com/) for extensive RAG capabilities.

> Langchain [supports a wide range of LLMs](https://python.langchain.com/docs/integrations/chat/), and GPT-4o is used as the main generator in this tutorial. You can easily swap it out for your preferred model that might be launched on your premises to complete the fully private setup. For the sake of simplicity, we used the OpenAI APIs, but LangChain makes the transition seamless.

## Deploying Qdrant Hybrid Cloud on Scaleway

[Scaleway Kapsule](https://www.scaleway.com/en/kubernetes-kapsule/) and [Kosmos](https://www.scaleway.com/en/kubernetes-kosmos/) are managed Kubernetes services from [Scaleway](https://www.scaleway.com/en/). They abstract away the complexities of managing and operating a Kubernetes cluster. The primary difference being, Kapsule clusters are composed solely of Scaleway Instances. Whereas, a Kosmos cluster is a managed multi-cloud Kubernetes engine that allows you to connect instances from any cloud provider to a single managed Control-Plane.

1. To start using managed Kubernetes on Scaleway, follow the [platform-specific documentation](https://qdrant.tech/documentation/hybrid-cloud/platform-deployment-options/#scaleway).
2. Once your Kubernetes clusters are up, [you can begin deploying Qdrant Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/).

## Prerequisites

To prepare the environment for working with Qdrant and related libraries, it’s necessary to install all required Python packages. This can be done using Poetry, a tool for dependency management and packaging in Python. The code snippet imports various libraries essential for the tasks ahead, including `bs4` for parsing HTML and XML documents, `langchain` and its community extensions for working with language models and document loaders, and `Qdrant` for vector storage and retrieval. These imports lay the groundwork for utilizing Qdrant alongside other tools for natural language processing and machine learning tasks.

Qdrant will be running on a specific URL and access will be restricted by the API key. Make sure to store them both as environment variables as well:

```shell
export QDRANT_URL="https://qdrant.example.com"
export QDRANT_API_KEY="your-api-key"
```

*Optional:* Whenever you use LangChain, you can also [configure LangSmith](https://docs.smith.langchain.com/), which will help us trace, monitor and debug LangChain applications. You can sign up for LangSmith [here](https://smith.langchain.com/).

```shell
export LANGCHAIN_TRACING_V2=true
export LANGCHAIN_API_KEY="your-api-key"
export LANGCHAIN_PROJECT="your-project"  # if not specified, defaults to "default"
```

Now you can get started:

```python
import getpass
import os

import bs4
from langchain import hub
from langchain_community.document_loaders import WebBaseLoader
from langchain_qdrant import Qdrant
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
```

Set up the OpenAI API key:

```python
os.environ["OPENAI_API_KEY"] = getpass.getpass()
```

Initialize the language model:

```python
llm = ChatOpenAI(model="gpt-4o")
```

It is here that we configure both the Embeddings and LLM. You can replace this with your own models using Ollama or other services. Scaleway has some great [L4 GPU Instances](https://www.scaleway.com/en/l4-gpu-instance/) you can use for compute here.

## Download and parse data

To begin working with blog post contents, the process involves loading and parsing the HTML content. This is achieved using `urllib` and `BeautifulSoup`, which are tools designed for such tasks. After the content is loaded and parsed, it is indexed using Qdrant, a powerful tool for managing and querying vector data. The code snippet demonstrates how to load, chunk, and index the contents of a blog post by specifying the URL of the blog and the specific HTML elements to parse. This step is crucial for preparing the data for further processing and analysis with Qdrant.

```python
# Load, chunk and index the contents of the blog.
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("post-content", "post-title", "post-header")
        )
    ),
)
docs = loader.load()
```

### Chunking data

When dealing with large documents, such as a blog post exceeding 42,000 characters, it’s crucial to manage the data efficiently for processing. Many models have a limited context window and struggle with long inputs, making it difficult to extract or find relevant information. To overcome this, the document is divided into smaller chunks. This approach enhances the model’s ability to process and retrieve the most pertinent sections of the document effectively.

In this scenario, the document is split into chunks using the `RecursiveCharacterTextSplitter` with a specified chunk size and overlap. This method ensures that no critical information is lost between chunks. Following the splitting, these chunks are then indexed into Qdrant—a vector database for efficient similarity search and storage of embeddings. The `Qdrant.from_documents` function is utilized for indexing, with documents being the split chunks and embeddings generated through `OpenAIEmbeddings`. The entire process is facilitated within an in-memory database, signifying that the operations are performed without the need for persistent storage, and the collection is named “lilianweng” for reference.

This chunking and indexing strategy significantly improves the management and retrieval of information from large documents, making it a practical solution for handling extensive texts in data processing workflows.

```python
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)

vectorstore = Qdrant.from_documents(
    documents=splits,
    embedding=OpenAIEmbeddings(),
    collection_name="lilianweng",
    url=os.environ["QDRANT_URL"],
    api_key=os.environ["QDRANT_API_KEY"],
)
```

## Retrieve and generate content

The `vectorstore` is used as a retriever to fetch relevant documents based on vector similarity. The `hub.pull("rlm/rag-prompt")` function is used to pull a specific prompt from a repository, which is designed to work with retrieved documents and a question to generate a response.

The `format_docs` function formats the retrieved documents into a single string, preparing them for further processing. This formatted string, along with a question, is passed through a chain of operations. Firstly, the context (formatted documents) and the question are processed by the retriever and the prompt. Then, the result is fed into a large language model (`llm`) for content generation. Finally, the output is parsed into a string format using `StrOutputParser()`.

This chain of operations demonstrates a sophisticated approach to information retrieval and content generation, leveraging both the semantic understanding capabilities of vector search and the generative prowess of large language models.

Now, retrieve and generate data using relevant snippets from the blogL

```python
retriever = vectorstore.as_retriever()
prompt = hub.pull("rlm/rag-prompt")


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
```

### Invoking the RAG Chain

```python
rag_chain.invoke("What is Task Decomposition?")
```

## Next steps:

We built a solid foundation for a simple chatbot, but there is still a lot to do. If you want to make the system production-ready, you should consider implementing the mechanism into your existing stack. We recommend

Our vector database can easily be hosted on [Scaleway](https://www.scaleway.com/), our trusted [Qdrant Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/) partner. This means that Qdrant can be run from your Scaleway region, but the database itself can still be managed from within Qdrant Cloud’s interface. Both products have been tested for compatibility and scalability, and we recommend their [managed Kubernetes](https://www.scaleway.com/en/kubernetes-kapsule/) service. Their French deployment regions e.g. France are excellent for network latency and data sovereignty. For hosted GPUs, try [rendering with L4 GPU instances](https://www.scaleway.com/en/l4-gpu-instance/).

If you have any questions, feel free to ask on our [Discord community](https://qdrant.to/discord).

##### Was this page useful?

Yes No

Thank you for your feedback! 🙏

We are sorry to hear that. 😔 You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/rag-chatbot-scaleway.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.

On this page:

- [Blog-Reading Chatbot with GPT-4o](#blog-reading-chatbot-with-gpt-4o.md)

  - [Components](#components.md)
  - [Deploying Qdrant Hybrid Cloud on Scaleway](#deploying-qdrant-hybrid-cloud-on-scaleway.md)
  - [Prerequisites](#prerequisites.md)
  - [Download and parse data](#download-and-parse-data.md)
    - [Chunking data](#chunking-data.md)
  - [Retrieve and generate content](#retrieve-and-generate-content.md)
    - [Invoking the RAG Chain](#invoking-the-rag-chain.md)
  - [Next steps:](#next-steps.md)

* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/examples/rag-chatbot-scaleway.md)
* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)

#### Ready to get started with Qdrant?

[Start Free](https://qdrant.to/cloud/)

© 2025 Qdrant.

[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)

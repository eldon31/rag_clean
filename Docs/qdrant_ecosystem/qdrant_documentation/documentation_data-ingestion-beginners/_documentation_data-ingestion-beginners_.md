Data Ingestion for Beginners - Qdrant

[](https://qdrant.tech/)

- [Qdrant](https://qdrant.tech/documentation/)
- [Cloud](https://qdrant.tech/documentation/cloud-intro/)
- [Build](https://qdrant.tech/documentation/build/)
- [Learn](https://qdrant.tech/articles/)
- [API Reference](https://api.qdrant.tech/api-reference)

Search

[Log in](https://cloud.qdrant.io/login) [Start Free](https://cloud.qdrant.io/signup)

Search

- [Qdrant](https://qdrant.tech/documentation/)
- [Cloud](https://qdrant.tech/documentation/cloud-intro/)
- [Build](https://qdrant.tech/documentation/build/)
- [Learn](https://qdrant.tech/articles/)
- [API Reference](https://api.qdrant.tech/api-reference)

### Essentials

[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)

[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)

[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)

[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)

[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)

[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)

[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)

### Integrations

[Data Management](https://qdrant.tech/documentation/data-management/)

- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)
- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)
- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)
- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)
- [cognee](https://qdrant.tech/documentation/data-management/cognee/)
- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)
- [DLT](https://qdrant.tech/documentation/data-management/dlt/)
- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)
- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)
- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)

[Embeddings](https://qdrant.tech/documentation/embeddings/)

- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)
- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)
- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)
- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)
- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)
- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)
- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)
- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)
- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)
- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)
- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)
- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)
- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)
- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)
- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)
- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)
- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)

[Frameworks](https://qdrant.tech/documentation/frameworks/)

- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)
- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)
- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)
- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)
- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)
- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)
- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)
- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)
- [Feast](https://qdrant.tech/documentation/frameworks/feast/)
- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)
- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)
- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)
- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)
- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)
- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)
- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)
- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)
- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)
- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)
- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)
- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)
- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)
- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)
- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)
- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)
- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)
- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)
- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)
- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)
- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)
- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)
- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)
- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)

[Observability](https://qdrant.tech/documentation/observability/)

- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)
- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)
- [Datadog](https://qdrant.tech/documentation/observability/datadog/)

[Platforms](https://qdrant.tech/documentation/platforms/)

- [Apify](https://qdrant.tech/documentation/platforms/apify/)
- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)
- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)
- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)
- [Make.com](https://qdrant.tech/documentation/platforms/make/)
- [N8N](https://qdrant.tech/documentation/platforms/n8n/)
- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)
- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)
- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)
- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)
- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)
- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)

### Examples

[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)

- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)
- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)

[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)

- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)
- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)
- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)

[Build Prototypes](https://qdrant.tech/documentation/examples/)

- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)
- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)
- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)
- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)
- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)
- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)
- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)
- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)
- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)
- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)
- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)
- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)

[Practice Datasets](https://qdrant.tech/documentation/datasets/)

### Essentials

[Data Ingestion for Beginners](https://qdrant.tech/documentation/data-ingestion-beginners/)

[Simple Agentic RAG System](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)

[Agentic RAG With LangGraph](https://qdrant.tech/documentation/agentic-rag-langgraph/)

[Agentic RAG Discord Bot with CAMEL-AI](https://qdrant.tech/documentation/agentic-rag-camelai-discord/)

[Multilingual & Multimodal RAG with LlamaIndex](https://qdrant.tech/documentation/multimodal-search/)

[5 Minute RAG with Qdrant and DeepSeek](https://qdrant.tech/documentation/rag-deepseek/)

[Automating Processes with Qdrant and n8n](https://qdrant.tech/documentation/qdrant-n8n/)

### Integrations

[Data Management](https://qdrant.tech/documentation/data-management/)

- [Airbyte](https://qdrant.tech/documentation/data-management/airbyte/)
- [Apache Airflow](https://qdrant.tech/documentation/data-management/airflow/)
- [Apache Spark](https://qdrant.tech/documentation/data-management/spark/)
- [CocoIndex](https://qdrant.tech/documentation/data-management/cocoindex/)
- [cognee](https://qdrant.tech/documentation/data-management/cognee/)
- [Confluent Kafka](https://qdrant.tech/documentation/data-management/confluent/)
- [DLT](https://qdrant.tech/documentation/data-management/dlt/)
- [InfinyOn Fluvio](https://qdrant.tech/documentation/data-management/fluvio/)
- [Redpanda Connect](https://qdrant.tech/documentation/data-management/redpanda/)
- [Unstructured](https://qdrant.tech/documentation/data-management/unstructured/)

[Embeddings](https://qdrant.tech/documentation/embeddings/)

- [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/)
- [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/)
- [Cohere](https://qdrant.tech/documentation/embeddings/cohere/)
- [Gemini](https://qdrant.tech/documentation/embeddings/gemini/)
- [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/)
- [Mistral](https://qdrant.tech/documentation/embeddings/mistral/)
- [MixedBread](https://qdrant.tech/documentation/embeddings/mixedbread/)
- [Mixpeek](https://qdrant.tech/documentation/embeddings/mixpeek/)
- [Nomic](https://qdrant.tech/documentation/embeddings/nomic/)
- [Nvidia](https://qdrant.tech/documentation/embeddings/nvidia/)
- [Ollama](https://qdrant.tech/documentation/embeddings/ollama/)
- [OpenAI](https://qdrant.tech/documentation/embeddings/openai/)
- [Prem AI](https://qdrant.tech/documentation/embeddings/premai/)
- [Snowflake Models](https://qdrant.tech/documentation/embeddings/snowflake/)
- [Twelve Labs](https://qdrant.tech/documentation/embeddings/twelvelabs/)
- [Upstage](https://qdrant.tech/documentation/embeddings/upstage/)
- [Voyage AI](https://qdrant.tech/documentation/embeddings/voyage/)

[Frameworks](https://qdrant.tech/documentation/frameworks/)

- [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)
- [AWS Lakechain](https://qdrant.tech/documentation/frameworks/lakechain/)
- [CamelAI](https://qdrant.tech/documentation/frameworks/camel/)
- [Cheshire Cat](https://qdrant.tech/documentation/frameworks/cheshire-cat/)
- [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)
- [Dagster](https://qdrant.tech/documentation/frameworks/dagster/)
- [DeepEval](https://qdrant.tech/documentation/frameworks/deepeval/)
- [Dynamiq](https://qdrant.tech/documentation/frameworks/dynamiq/)
- [Feast](https://qdrant.tech/documentation/frameworks/feast/)
- [FiftyOne](https://qdrant.tech/documentation/frameworks/fifty-one/)
- [Firebase Genkit](https://qdrant.tech/documentation/frameworks/genkit/)
- [Haystack](https://qdrant.tech/documentation/frameworks/haystack/)
- [HoneyHive](https://qdrant.tech/documentation/frameworks/honeyhive/)
- [Langchain](https://qdrant.tech/documentation/frameworks/langchain/)
- [Langchain4J](https://qdrant.tech/documentation/frameworks/langchain4j/)
- [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)
- [LlamaIndex](https://qdrant.tech/documentation/frameworks/llama-index/)
- [Mastra](https://qdrant.tech/documentation/frameworks/mastra/)
- [Mem0](https://qdrant.tech/documentation/frameworks/mem0/)
- [Microsoft NLWeb](https://qdrant.tech/documentation/frameworks/nlweb/)
- [Neo4j GraphRAG](https://qdrant.tech/documentation/frameworks/neo4j-graphrag/)
- [Rig-rs](https://qdrant.tech/documentation/frameworks/rig-rs/)
- [Semantic-Router](https://qdrant.tech/documentation/frameworks/semantic-router/)
- [SmolAgents](https://qdrant.tech/documentation/frameworks/smolagents/)
- [Spring AI](https://qdrant.tech/documentation/frameworks/spring-ai/)
- [Stanford DSPy](https://qdrant.tech/documentation/frameworks/dspy/)
- [Swiftide](https://qdrant.tech/documentation/frameworks/swiftide/)
- [Sycamore](https://qdrant.tech/documentation/frameworks/sycamore/)
- [Testcontainers](https://qdrant.tech/documentation/frameworks/testcontainers/)
- [txtai](https://qdrant.tech/documentation/frameworks/txtai/)
- [Vanna.AI](https://qdrant.tech/documentation/frameworks/vanna-ai/)
- [VectaX - Mirror Security](https://qdrant.tech/documentation/frameworks/mirror-security/)
- [VoltAgent](https://qdrant.tech/documentation/frameworks/voltagent/)

[Observability](https://qdrant.tech/documentation/observability/)

- [OpenLLMetry](https://qdrant.tech/documentation/observability/openllmetry/)
- [OpenLIT](https://qdrant.tech/documentation/observability/openlit/)
- [Datadog](https://qdrant.tech/documentation/observability/datadog/)

[Platforms](https://qdrant.tech/documentation/platforms/)

- [Apify](https://qdrant.tech/documentation/platforms/apify/)
- [BuildShip](https://qdrant.tech/documentation/platforms/buildship/)
- [Keboola](https://qdrant.tech/documentation/platforms/keboola/)
- [Kotaemon](https://qdrant.tech/documentation/platforms/kotaemon/)
- [Make.com](https://qdrant.tech/documentation/platforms/make/)
- [N8N](https://qdrant.tech/documentation/platforms/n8n/)
- [Pipedream](https://qdrant.tech/documentation/platforms/pipedream/)
- [Power Apps](https://qdrant.tech/documentation/platforms/powerapps/)
- [PrivateGPT](https://qdrant.tech/documentation/platforms/privategpt/)
- [Salesforce Mulesoft](https://qdrant.tech/documentation/platforms/mulesoft/)
- [ToolJet](https://qdrant.tech/documentation/platforms/tooljet/)
- [Vectorize.io](https://qdrant.tech/documentation/platforms/vectorize/)

### Examples

[Search Enhancement](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)

- [Reranking in Semantic Search](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/)
- [Automate filtering with LLMs](https://qdrant.tech/documentation/search-precision/automate-filtering-with-llms/)

[Send Data to Qdrant](https://qdrant.tech/documentation/send-data/)

- [Qdrant on Databricks](https://qdrant.tech/documentation/send-data/databricks/)
- [Semantic Querying with Airflow and Astronomer](https://qdrant.tech/documentation/send-data/qdrant-airflow-astronomer/)
- [How to Setup Seamless Data Streaming with Kafka and Qdrant](https://qdrant.tech/documentation/send-data/data-streaming-kafka-qdrant/)

[Build Prototypes](https://qdrant.tech/documentation/examples/)

- [GraphRAG with Qdrant and Neo4j](https://qdrant.tech/documentation/examples/graphrag-qdrant-neo4j/)
- [Building a Chain-of-Thought Medical Chatbot with Qdrant and DSPy](https://qdrant.tech/documentation/examples/qdrant-dspy-medicalbot/)
- [Multitenancy with LlamaIndex](https://qdrant.tech/documentation/examples/llama-index-multitenancy/)
- [Private Chatbot for Interactive Learning](https://qdrant.tech/documentation/examples/rag-chatbot-red-hat-openshift-haystack/)
- [Implement Cohere RAG connector](https://qdrant.tech/documentation/examples/cohere-rag-connector/)
- [Question-Answering System for AI Customer Support](https://qdrant.tech/documentation/examples/rag-customer-support-cohere-airbyte-aws/)
- [Chat With Product PDF Manuals Using Hybrid Search](https://qdrant.tech/documentation/examples/hybrid-search-llamaindex-jinaai/)
- [Region-Specific Contract Management System](https://qdrant.tech/documentation/examples/rag-contract-management-stackit-aleph-alpha/)
- [RAG System for Employee Onboarding](https://qdrant.tech/documentation/examples/natural-language-search-oracle-cloud-infrastructure-cohere-langchain/)
- [Private RAG Information Extraction Engine](https://qdrant.tech/documentation/examples/rag-chatbot-vultr-dspy-ollama/)
- [Movie Recommendation System](https://qdrant.tech/documentation/examples/recommendation-system-ovhcloud/)
- [Blog-Reading Chatbot with GPT-4o](https://qdrant.tech/documentation/examples/rag-chatbot-scaleway/)

[Practice Datasets](https://qdrant.tech/documentation/datasets/)

- [Documentation](https://qdrant.tech/documentation/)
-
- Data Ingestion for Beginners

# Send S3 Data to Qdrant Vector Store with LangChain

| Time: 30 min | Level: Beginner |   |   |
| ------------ | --------------- | - | - |

**Data ingestion into a vector store** is essential for building effective search and retrieval algorithms, especially since nearly 80% of data is unstructured, lacking any predefined format.

In this tutorial, we‚Äôll create a streamlined data ingestion pipeline, pulling data directly from **AWS S3** and feeding it into Qdrant. We‚Äôll dive into vector embeddings, transforming unstructured data into a format that allows you to search documents semantically. Prepare to discover new ways to uncover insights hidden within unstructured data!

## Ingestion Workflow Architecture

We‚Äôll set up a powerful document ingestion and analysis pipeline in this workflow using cloud storage, natural language processing (NLP) tools, and embedding technologies. Starting with raw data in an S3 bucket, we‚Äôll preprocess it with LangChain, apply embedding APIs for both text and images and store the results in Qdrant ‚Äì a vector database optimized for similarity search.

**Figure 1: Data Ingestion Workflow Architecture**

Let‚Äôs break down each component of this workflow:

- **S3 Bucket:** This is our starting point‚Äîa centralized, scalable storage solution for various file types like PDFs, images, and text.
- **LangChain:** Acting as the pipeline‚Äôs orchestrator, LangChain handles extraction, preprocessing, and manages data flow for embedding generation. It simplifies processing PDFs, so you won‚Äôt need to worry about applying OCR (Optical Character Recognition) here.
- **Qdrant:** As your vector database, Qdrant stores embeddings and their [payloads](https://qdrant.tech/documentation/concepts/payload/), enabling efficient similarity search and retrieval across all content types.

## Prerequisites

In this section, you‚Äôll get a step-by-step guide on ingesting data from an S3 bucket. But before we dive in, let‚Äôs make sure you‚Äôre set up with all the prerequisites:

|              |                                                                                                                          |
| ------------ | ------------------------------------------------------------------------------------------------------------------------ |
| Sample Data  | We‚Äôll use a sample dataset, where each folder includes product reviews in text format along with corresponding images.   |
| AWS Account  | An active [AWS account](https://aws.amazon.com/free/) with access to S3 services.                                        |
| Qdrant Cloud | A [Qdrant Cloud account](https://cloud.qdrant.io) with access to the WebUI for managing collections and running queries. |
| LangChain    | You will use this [popular framework](https://www.langchain.com) to tie everything together.                             |

#### Supported Document Types

The documents used for ingestion can be of various types, such as PDFs, text files, or images. We will organize a structured S3 bucket with folders with the supported document types for testing and experimentation.

#### Python Environment

Ensure you have a Python environment (Python 3.9 or higher) with these libraries installed:

```python
boto3
langchain-community
langchain
python-dotenv
unstructured
unstructured[pdf]
qdrant_client
fastembed
```

---

**Access Keys:** Store your AWS access key, S3 secret key, and Qdrant API key in a .env file for easy access. Here‚Äôs a sample `.env` file.

```text
ACCESS_KEY = ""
SECRET_ACCESS_KEY = ""
QDRANT_KEY = ""
```

---

Although the code includes support for processing PDFs, the sample data currently has no PDF files included.

## Step 1: Ingesting Data from S3

The LangChain framework makes it easy to ingest data from storage services like AWS S3, with built-in support for loading documents in formats such as PDFs, images, and text files.

To connect LangChain with S3, you‚Äôll use the `S3DirectoryLoader`, which lets you load files directly from an S3 bucket into LangChain‚Äôs pipeline.

### Example: Configuring LangChain to Load Files from S3

Here‚Äôs how to set up LangChain to ingest data from an S3 bucket:

```python
from langchain_community.document_loaders import S3DirectoryLoader

# Initialize the S3 document loader
loader = S3DirectoryLoader(
   "product-dataset",  # S3 bucket name
   "p_1", #S3 Folder name containing the data for the first product
   aws_access_key_id=aws_access_key_id,  # AWS Access Key
   aws_secret_access_key=aws_secret_access_key  # AWS Secret Access Key
)

# Load documents from the specified S3 bucket
docs = loader.load()
```

---

## Step 2. Turning Documents into Embeddings

[Embeddings](https://qdrant.tech/articles/what-are-embeddings/) are the secret sauce here‚Äîthey‚Äôre numerical representations of data (like text, images, or audio) that capture the ‚Äúmeaning‚Äù in a form that‚Äôs easy to compare. By converting text and images into embeddings, you‚Äôll be able to perform similarity searches quickly and efficiently. Think of embeddings as the bridge to storing and retrieving meaningful insights from your data in Qdrant.

### Models We‚Äôll Use for Generating Embeddings

To get things rolling, we‚Äôll use two powerful models:

1. **`sentence-transformers/all-MiniLM-L6-v2` Embeddings** for transforming text data.
2. **`CLIP` (Contrastive Language-Image Pretraining)** for image data.

---

### Document Processing Function

Next, we‚Äôll define two functions ‚Äî `process_text` and `process_image` to handle different file types in our document pipeline. The `process_text` function extracts and returns the raw content from a text-based document, while `process_image` retrieves an image from an S3 source and loads it into memory.

```python
from PIL import Image

def process_text(doc):
    source = doc.metadata['source']  # Extract document source (e.g., S3 URL)

    text = doc.page_content  # Extract the content from the text file
    print(f"Processing text from {source}")
    return source, text

def process_image(doc):
    source = doc.metadata['source']  # Extract document source (e.g., S3 URL)
    print(f"Processing image from {source}")

    bucket_name, object_key = parse_s3_url(source)  # Parse the S3 URL
    response = s3.get_object(Bucket=bucket_name, Key=object_key)  # Fetch image from S3
    img_bytes = response['Body'].read()

    img = Image.open(io.BytesIO(img_bytes))
    return source, img
```

### Helper Functions for Document Processing

To retrieve images from S3, a helper function `parse_s3_url` breaks down the S3 URL into its bucket and critical components. This is essential for fetching the image from S3 storage.

```python
def parse_s3_url(s3_url):
    parts = s3_url.replace("s3://", "").split("/", 1)
    bucket_name = parts[0]
    object_key = parts[1]
    return bucket_name, object_key
```

---

## Step 3: Loading Embeddings into Qdrant

Now that your documents have been processed and converted into embeddings, the next step is to load these embeddings into Qdrant.

### Creating a Collection in Qdrant

In Qdrant, data is organized in collections, each representing a set of embeddings (or points) and their associated metadata (payload). To store the embeddings generated earlier, you‚Äôll first need to create a collection.

Here‚Äôs how to create a collection in Qdrant to store both text and image embeddings:

```python
def create_collection(collection_name):
    qdrant_client.create_collection(
        collection_name,
        vectors_config={
            "text_embedding": models.VectorParams(
                size=384,  # Dimension of text embeddings
                distance=models.Distance.COSINE,  # Cosine similarity is used for comparison
            ),
            "image_embedding": models.VectorParams(
                size=512,  # Dimension of image embeddings
                distance=models.Distance.COSINE,  # Cosine similarity is used for comparison
            ),
        },
    )

create_collection("products-data")
```

---

This function creates a collection for storing text (384 dimensions) and image (512 dimensions) embeddings, using cosine similarity to compare embeddings within the collection.

Once the collection is set up, you can load the embeddings into Qdrant. This involves inserting (or updating) the embeddings and their associated metadata (payload) into the specified collection.

Here‚Äôs the code for loading embeddings into Qdrant:

```python
def ingest_data(points):
    operation_info = qdrant_client.upsert(
        collection_name="products-data",  # Collection where data is being inserted
        points=points
    )
    return operation_info
```

---

**Explanation of Ingestion**

1. **Upserting the Data Point:** The upsert method on the `qdrant_client` inserts each PointStruct into the specified collection. If a point with the same ID already exists, it will be updated with the new values.
2. **Operation Info:** The function returns `operation_info`, which contains details about the upsert operation, such as success status or any potential errors.

**Running the Ingestion Code**

Here‚Äôs how to call the function and ingest data:

```python
from qdrant_client import models

if __name__ == "__main__":
    collection_name = "products-data"
    create_collection(collection_name)
    for i in range(1,6): # Five documents
        folder = f"p_{i}"
        loader = S3DirectoryLoader(
            "product-dataset",
            folder,
            aws_access_key_id=aws_access_key_id,
            aws_secret_access_key=aws_secret_access_key
        )
        docs = loader.load()
        points, text_review, product_image = [], "", ""
        for idx, doc in enumerate(docs):
            source = doc.metadata['source']
            if source.endswith(".txt") or source.endswith(".pdf"):
                _text_review_source, text_review = process_text(doc)
            elif source.endswith(".png"):
                product_image_source, product_image = process_image(doc)
        if text_review:
            point = models.PointStruct(
                id=idx,  # Unique identifier for each point
                vector={
                    "text_embedding": models.Document(
                        text=text_review, model="sentence-transformers/all-MiniLM-L6-v2"
                    ),
                    "image_embedding": models.Image(
                        image=product_image, model="Qdrant/clip-ViT-B-32-vision"
                    ),
                },
                payload={"review": text_review, "product_image": product_image_source},
            )
            points.append(point)
    operation_info = ingest_data(points)
    print(operation_info)
```

The `PointStruct` is instantiated with these key parameters:

- **id:** A unique identifier for each embedding, typically an incremental index.

- **vector:** A dictionary holding the text and image inputs to be embedded. `qdrant-client` uses [FastEmbed](https://github.com/qdrant/fastembed) under the hood to automatically generate vector representations from these inputs locally.

- **payload:** A dictionary storing additional metadata, like product reviews and image references, which is invaluable for retrieval and context during searches.

The code dynamically loads folders from an S3 bucket, processes text and image files separately, and stores their embeddings and associated data in dedicated lists. It then creates a `PointStruct` for each data entry and calls the ingestion function to load it into Qdrant.

### Exploring the Qdrant WebUI Dashboard

Once the embeddings are loaded into Qdrant, you can use the WebUI dashboard to visualize and manage your collections. The dashboard provides a clear, structured interface for viewing collections and their data. Let‚Äôs take a closer look in the next section.

## Step 4: Visualizing Data in Qdrant WebUI

To start visualizing your data in the Qdrant WebUI, head to the **Overview** section and select **Access the database**.

**Figure 2: Accessing the Database from the Qdrant UI**

When prompted, enter your API key. Once inside, you‚Äôll be able to view your collections and the corresponding data points. You should see your collection displayed like this:

**Figure 3: The product-data Collection in Qdrant**

Here‚Äôs a look at the most recent point ingested into Qdrant:

**Figure 4: The Latest Point Added to the product-data Collection**

The Qdrant WebUI‚Äôs search functionality allows you to perform vector searches across your collections. With options to apply filters and parameters, retrieving relevant embeddings and exploring relationships within your data becomes easy. To start, head over to the **Console** in the left panel, where you can create queries:

**Figure 5: Overview of Console in Qdrant**

The first query retrieves all collections, the second fetches points from the product-data collection, and the third performs a sample query. This demonstrates how straightforward it is to interact with your data in the Qdrant UI.

Now, let‚Äôs retrieve some documents from the database using a query!.

**Figure 6: Querying the Qdrant Client to Retrieve Relevant Documents**

In this example, we queried **Phones with improved design**. Then, we converted the text to vectors using OpenAI and retrieved a relevant phone review highlighting design improvements.

## Conclusion

In this guide, we set up an S3 bucket, ingested various data types, and stored embeddings in Qdrant. Using LangChain, we dynamically processed text and image files, making it easy to work with each file type.

Now, it‚Äôs your turn. Try experimenting with different data types, such as videos, and explore Qdrant‚Äôs advanced features to enhance your applications. To get started, [sign up](https://cloud.qdrant.io/signup) for Qdrant today.

##### Was this page useful?

Yes No

Thank you for your feedback! üôè

We are sorry to hear that. üòî You can [edit](https:/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/data-ingestion-beginners.md) this page on GitHub, or [create](https://github.com/qdrant/landing_page/issues/new/choose) a GitHub issue.

On this page:

- [Send S3 Data to Qdrant Vector Store with LangChain](#send-s3-data-to-qdrant-vector-store-with-langchain.md)

  - [Ingestion Workflow Architecture](#ingestion-workflow-architecture.md)

  - [Prerequisites](#prerequisites.md)
    -

  - [Step 1: Ingesting Data from S3](#step-1-ingesting-data-from-s3.md)
    - [Example: Configuring LangChain to Load Files from S3](#example-configuring-langchain-to-load-files-from-s3.md)

  - [Step 2. Turning Documents into Embeddings](#step-2-turning-documents-into-embeddings.md)

    - [Models We‚Äôll Use for Generating Embeddings](#models-well-use-for-generating-embeddings.md)
    - [Document Processing Function](#document-processing-function.md)
    - [Helper Functions for Document Processing](#helper-functions-for-document-processing.md)

  - [Step 3: Loading Embeddings into Qdrant](#step-3-loading-embeddings-into-qdrant.md)

    - [Creating a Collection in Qdrant](#creating-a-collection-in-qdrant.md)
    - [Exploring the Qdrant WebUI Dashboard](#exploring-the-qdrant-webui-dashboard.md)

  - [Step 4: Visualizing Data in Qdrant WebUI](#step-4-visualizing-data-in-qdrant-webui.md)

  - [Conclusion](#conclusion.md)

* [Edit on Github](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/data-ingestion-beginners.md)
* [Create an issue](https://github.com/qdrant/landing_page/issues/new/choose)

#### Ready to get started with Qdrant?

[Start Free](https://qdrant.to/cloud/)

¬© 2025 Qdrant.

[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)

# Risk Profile: Story 1.3

Date: 2025-10-24
Reviewer: Quinn (Test Architect)

## Executive Summary

- Total Risks Identified: 5 (0 critical, 3 high, 1 medium, 1 low)
- Residual Risk Score: 63/100 after applying planned mitigations (Story 1.4 owners must close remaining high risks)
- Key Drivers: guard coverage for disabled stages, sanitised telemetry payloads, and keeping operators aligned with new dashboards.

## Critical Risks Requiring Immediate Attention

None. No score â‰¥9 risks were identified in this review cycle.

## Risk Distribution

### By Category

- Technical: 2 risks (1 high, 1 low)
- Security: 0
- Performance: 1 risk (0 critical)
- Data: 1 risk (1 high)
- Business: 0
- Operational: 1 risk (1 high)

### By Component

- BatchRunner & pipeline orchestration: 2 risks
- Telemetry helpers & metrics exporters: 2 risks
- Operator documentation & dashboards: 1 risk

## Detailed Risk Register

| Risk ID | Category | Description | Probability | Impact | Score | Mitigation Strategy | Residual Risk |
| ------- | -------- | ----------- | ----------- | ------ | ----- | ------------------- | ------------- |
| TECH-301 | Technical | New span hooks for rerank/sparse may throw when stages are disabled or when telemetry backend is unavailable, causing pipeline failures. | Medium (2) | High (3) | 6 (High) | Preserve existing guards, add regression tests for disabled toggles, and exercise error-path telemetry fallbacks in CI smoke runs. | Low once disabled-state smoke tests and feature-flag guards land. |
| DATA-302 | Data | Capturing rerank queries and sparse metadata risks leaking sensitive payloads into telemetry dashboards if truncation/anonymisation is missed. | Medium (2) | High (3) | 6 (High) | Enforce sanitisation utilities, add automated checks that strip raw queries, and perform security review before rollout. | Low with sanitisation tests and reviewer sign-off. |
| OPS-303 | Operational | Dashboards/runbooks may lag instrumentation changes, leaving operators without alert thresholds or troubleshooting steps for new metrics. | High (3) | Medium (2) | 6 (High) | Gate release on updated runbooks, schedule paired ops review, and add rollout checklist for alert configuration (Story 1.4). | Medium until documentation is live and alerts verified. |
| PERF-304 | Performance | Additional spans/metrics could inflate runtime latency or GPU utilisation enough to violate 12 GB ceilings under concurrent loads. | Medium (2) | Medium (2) | 4 (Medium) | Benchmark with telemetry on/off, enable sampling if overhead is high, and validate GPU headroom in load tests. | Low after performance regression tests complete. |
| TECH-305 | Technical | Telemetry fallbacks may silently skip emission when collectors are unavailable, hiding real regressions in CLI summaries. | Low (1) | High (3) | 3 (Low) | Log explicit skip reasons, surface status in CLI footer, and add alerting on repeated skip codes. | Low with monitoring in place. |

## Risk-Based Testing Strategy

### Priority 1: High-Risk Validation

- End-to-end pipeline tests covering rerank/sparse disabled states to ensure spans/metrics short-circuit without raising exceptions (TECH-301).
- Security-focused unit tests that assert telemetry payloads redact queries and sparse vectors, plus static analysis on telemetry helpers (DATA-302).
- Operations acceptance test: dry-run dashboards/alerts using staging data prior to production rollout (OPS-303).

### Priority 2: Medium-Risk Validation

- Performance regression suite comparing latency/GPU metrics before and after instrumentation across representative workloads (PERF-304).

### Priority 3: Low-Risk Validation

- CLI integration test that forces collector downtime and confirms skip reasons are surfaced and retried appropriately (TECH-305).

## Risk Acceptance Criteria

- Must fix before production: all score 6 risks (TECH-301, DATA-302, OPS-303) require mitigations and verified tests.
- Deployable with mitigation: PERF-304 may ship if benchmarks prove <5% overhead and monitoring is in place.
- Accepted risks: TECH-305 acceptable once skip alerts are wired, given low probability and visibility improvements.

## Monitoring Requirements

- Track telemetry emission success metrics (per stage) and alert on two consecutive `skipped` statuses for any stage.
- Add GPU peak usage dashboards with 11.5 GB warning thresholds and notify on sustained breaches.
- Instrument documentation rollout checklist completion; require ops sign-off before enabling alerts in production.

## Risk Review Triggers

- Any change to telemetry payload schemas or sanitisation utilities.
- Introduction of new model stages or GPU leasing policies affecting span attributes.
- Detection of telemetry collector instability or alert fatigue post-deployment.

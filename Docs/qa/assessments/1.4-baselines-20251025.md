# Story 1.4 – Performance & Observability Baselines

## Performance Baseline Status

Current status: **Complete** – staging GPU executions captured on 2025-11-18. CPU fallback data is retained as historical reference.

### Staging GPU Run (2025-11-18)

| Metric                     | Value                 | Source                                                             |
| -------------------------- | --------------------- | ------------------------------------------------------------------ |
| Execution device           | cuda:0                | `staging_gpu_20251118/processing_summary_default-on_20251118.json` |
| GPU peak memory            | 8.4 GB (35% of 24 GB) | `staging_gpu_20251118/processing_summary_default-on_20251118.json` |
| Hydration average duration | 0.74 s (dense p50)    | `staging_gpu_20251118/processing_summary_default-on_20251118.json` |
| Hydration peak duration    | 1.96 s (dense p99)    | `staging_gpu_20251118/processing_summary_default-on_20251118.json` |
| Rerank latency p95         | 0.307 s               | `staging_gpu_20251118/processing_summary_default-on_20251118.json` |
| Sparse latency p95         | 0.694 s               | `staging_gpu_20251118/processing_summary_default-on_20251118.json` |
| Export latency             | 1.21 s                | `staging_gpu_20251118/cli_default-on_20251118.txt`                 |
| Average GPU utilisation    | 35% (combined)        | `docs/qa/assets/gpu-peak-memory-by-stage.txt`                      |
| WARN threshold (11.5 GB)   | Not triggered         | `docs/qa/assets/gpu-peak-memory-by-stage.txt`                      |
| CRIT threshold (12.0 GB)   | Not triggered         | `docs/qa/assets/gpu-peak-memory-by-stage.txt`                      |
| Metrics endpoint           | HTTPS (TLS verified)  | `prometheus-validation-staging-defaults-20251118.json`             |

> NOTE: Refer to **Historical CPU Run (2025-10-26)** below for legacy values used prior to staging availability.

### Historical CPU Run (2025-10-26)

| Metric                     | Value                  | Source                                      |
| -------------------------- | ---------------------- | ------------------------------------------- |
| Execution device           | cpu (fallback applied) | `processing_summary_defaults_20251026.json` |
| GPU peak memory            | 0.0 GB                 | `processing_summary_defaults_20251026.json` |
| Hydration average duration | 0.83 s                 | `processing_summary_defaults_20251026.json` |
| Hydration peak duration    | 1.20 s                 | `processing_summary_defaults_20251026.json` |
| Average CPU utilization    | 45.2%                  | `processing_summary_defaults_20251026.json` |
| Peak CPU utilization       | 78.3%                  | `processing_summary_defaults_20251026.json` |
| Average system memory      | 12.34 GB               | `processing_summary_defaults_20251026.json` |
| Peak system memory         | 14.56 GB               | `processing_summary_defaults_20251026.json` |

### GPU Latency and VRAM Measurements (Staging 2025-11-18)

| Metric                | Measured | Threshold                                    | Status  |
| --------------------- | -------- | -------------------------------------------- | ------- |
| Rerank P50 latency    | 148 ms   | < 2000 ms                                    | ✅ PASS |
| Rerank P95 latency    | 307 ms   | < 5000 ms                                    | ✅ PASS |
| Rerank P99 latency    | 486 ms   | < 8000 ms                                    | ✅ PASS |
| Rerank max latency    | 612 ms   | < 10000 ms                                   | ✅ PASS |
| Sparse P50 latency    | 418 ms   | < 1000 ms                                    | ✅ PASS |
| Sparse P95 latency    | 694 ms   | < 3000 ms                                    | ✅ PASS |
| Sparse P99 latency    | 902 ms   | < 5000 ms                                    | ✅ PASS |
| Sparse max latency    | 1,024 ms | < 8000 ms                                    | ✅ PASS |
| Dense stage max VRAM  | 6.3 GB   | Informational                                | ✅ PASS |
| Rerank stage max VRAM | 2.1 GB   | 6 GB                                         | ✅ PASS |
| Sparse stage max VRAM | 1.8 GB   | Informational                                | ✅ PASS |
| Combined peak VRAM    | 8.4 GB   | 10 GB (soft) / 11.5 GB (warn) / 12 GB (crit) | ✅ PASS |

### Export Stage Throughput (Pending Measurement)

### Export Stage Throughput (Staging 2025-11-18)

| Metric              | Measured | Threshold     | Status  |
| ------------------- | -------- | ------------- | ------- |
| Export P50 latency  | 1,210 ms | < 5000 ms     | ✅ PASS |
| Export P95 latency  | 1,865 ms | < 15000 ms    | ✅ PASS |
| Export max latency  | 2,102 ms | < 20000 ms    | ✅ PASS |
| Total artifact size | 121.6 MB | Informational | ✅ PASS |

> Action: Retain these values as the baseline for future regressions; regenerate if hardware or workload changes materially.

---

## Telemetry Validation Status

Staging GPU evidence (2025-11-18) now underpins the baseline. CPU fallback runs
remain in the archive for historical comparison but are no longer the primary
source of truth.

- GPU-backed run emits dense, rerank, sparse, and export spans with CUDA device
  attribution.
- Prometheus metrics confirm WARN (11.5 GB) and CRIT (12 GB) thresholds remain
  unused; combined peak VRAM stays at 8.4 GB (65% headroom).
- Export throughput recorded at 1.21 s (P50) / 2.10 s (max) with JSONL payload
  size 121.6 MB.

Historical CPU artefacts may be used for regression sanity checks but should
not replace the staging measurements documented above.

---

## Telemetry Validation

### Prometheus Metrics Emission (Staging Validation)

Staging validator output demonstrates the presence of the expected metric families with TLS verification enabled.

| Metric                               | Status   | Source                                                 |
| ------------------------------------ | -------- | ------------------------------------------------------ |
| `rag_dense_latency_seconds`          | Reported | `prometheus-validation-staging-defaults-20251118.json` |
| `rag_rerank_latency_seconds`         | Reported | `prometheus-validation-staging-defaults-20251118.json` |
| `rag_sparse_latency_seconds`         | Reported | `prometheus-validation-staging-defaults-20251118.json` |
| `rag_gpu_peak_bytes{stage="dense"}`  | Reported | `prometheus-validation-staging-defaults-20251118.json` |
| `rag_gpu_peak_bytes{stage="rerank"}` | Reported | `prometheus-validation-staging-defaults-20251118.json` |
| `rag_gpu_peak_bytes{stage="sparse"}` | Reported | `prometheus-validation-staging-defaults-20251118.json` |
| `rag_export_latency_seconds`         | Reported | `prometheus-validation-staging-defaults-20251118.json` |

**Validation Method**:

- Ran `scripts/validate_prometheus_endpoint.py` pointing at staging endpoint with `verify_tls=True`
- Confirmed authentication and TLS checks pass with CA-signed certificate (`prometheus-validation-staging-defaults-20251118.json`)
- Curl transcript (`prometheus-staging-curl-20251118.txt`) records 401 without credentials and 200 with valid credentials under TLS verification

### OpenTelemetry Span Coverage

Sample span events from `docs/qa/assessments/1.4-telemetry-smoke-evidence/processing_summary_defaults_20251026.json` (CPU fallback run):

```json
{
  "telemetry": {
    "spans": {
      "rag.dense": {
        "span_id": "span-dense-20251025-001",
        "status": "active",
        "timestamp": 1729800123.456
      },
      "rag.rerank": {
        "span_id": "span-rerank-20251025-001",
        "status": "active",
        "reason": "Query-time reranking executed",
        "timestamp": 1729800125.789
      },
      "rag.sparse": {
        "span_id": "span-sparse-20251025-001",
        "status": "active",
        "timestamp": 1729800126.234
      },
      "rag.export": {
        "span_id": "span-export-20251025-001",
        "status": "active",
        "timestamp": 1729800128.567
      }
    },
    "metrics": {
      "dense": {
        "status": "emitted",
        "metrics": ["rag_dense_latency_seconds", "rag_gpu_peak_bytes"]
      },
      "rerank": {
        "status": "emitted",
        "metrics": ["rag_rerank_latency_seconds", "rag_gpu_peak_bytes"]
      },
      "sparse": {
        "status": "emitted",
        "metrics": ["rag_sparse_latency_seconds"]
      },
      "export": {
        "status": "emitted",
        "metrics": ["rag_export_latency_seconds"]
      }
    }
  }
}
```

**Span Validation**:

- All 4 stages emit spans with `status: "active"` when enabled (CPU fallback run)
- Disabled stages emit `status: "skipped"` with `reason: "feature_disabled"`
- Span timestamps align with pipeline execution order for the recorded run
- Pending: capture GPU-backed spans to confirm device metadata once staging run completes

---

## GPU Alert Thresholds

### Alert Configuration

Prometheus alert rules configured for GPU peak memory monitoring:

```yaml
groups:
  - name: rag_gpu_alerts
    interval: 30s
    rules:
      - alert: RagGpuMemoryWarning
        expr: rag_gpu_peak_bytes >= 11.5 * 1024^3
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "RAG pipeline GPU memory approaching limit"
          description: "GPU peak usage {{ $value | humanize }} exceeds 11.5 GB warning threshold"

      - alert: RagGpuMemoryCritical
        expr: rag_gpu_peak_bytes >= 12 * 1024^3
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "RAG pipeline GPU memory critical"
          description: "GPU peak usage {{ $value | humanize }} exceeds 12 GB critical threshold (OOM risk)"
```

### Alert Validation Results

| Test Scenario                | Status  | Notes                                                       |
| ---------------------------- | ------- | ----------------------------------------------------------- |
| Normal baseline (3k chunks)  | Pending | CPU fallback run did not exercise GPU alerts                |
| Elevated batch size (128)    | Pending | Requires staging GPU workload                               |
| Simulated warning (11.6 GB)  | Pending | Capture alert manager output when GPU baseline is available |
| Simulated critical (12.1 GB) | Pending | Capture alert manager output when GPU baseline is available |

**Alert Routing**:

- Routing plan documented in `docs/telemetry/rerank_sparse_signals.md`
- Pending: validate Slack and PagerDuty delivery using staging alert manager once GPU run executes

### Regression Test Coverage

Alert threshold scenarios added to `tests/test_telemetry_smoke.py`:

- `test_gpu_alert_warning_threshold_detection`
- `test_gpu_alert_critical_threshold_detection`
- `test_alert_threshold_helper_methods`

All tests passing in CI pipeline (see test execution logs).

---

## Sparse Fallback Coverage

### Degraded Input Scenarios

Expanded regression matrix covers edge cases:

| Scenario                     | Sparse Coverage | Fallback Reason       | Status      |
| ---------------------------- | --------------- | --------------------- | ----------- |
| **Nominal input**            | 1.0 (100%)      | None                  | ✅ PASS     |
| **Empty chunks**             | 0.0 (0%)        | Empty text            | ✅ EXPECTED |
| **Ultra-short (<10 tokens)** | 0.92 (92%)      | Token threshold       | ✅ PASS     |
| **Missing metadata**         | 1.0 (100%)      | Metadata not required | ✅ PASS     |
| **Special characters only**  | 0.0 (0%)        | Non-textual content   | ✅ EXPECTED |
| **Mixed degraded/clean**     | 0.85 (85%)      | Partial degradation   | ✅ PASS     |

**Validation Method**:

- Extended `test_telemetry_smoke.py` with `test_sparse_fallback_degraded_inputs`
- Captured outputs in this assessment file (evidence below)
- Confirmed fallback_reason correctly populated in `processing_summary.json`

### Sample Processing Summary (Degraded Input)

```json
{
  "sparse_run": {
    "enabled": true,
    "executed": true,
    "models": ["naver/splade-cocondenser-ensembledistil"],
    "vectors": {
      "total": 1000,
      "available": 850,
      "coverage_ratio": 0.85
    },
    "devices": {
      "sparse_0": "cuda:0"
    },
    "fallback_used": true,
    "fallback_reason": "150 chunks below minimum token threshold (10 tokens)"
  }
}
```

---

## QA Sign-Off Status

Status: **Complete** – Staging GPU telemetry, Prometheus TLS validation (certificate verified), and export artefacts committed on 2025-11-18. Historical CPU data retained for regression comparison.

### Current Evidence (CPU fallback)

- `docs/qa/assessments/1.4-telemetry-smoke-evidence/processing_summary_defaults_20251026.json` – CPU execution with sparse/rerank enabled, telemetry spans emitted.
- `docs/qa/assessments/1.4-telemetry-smoke-evidence/regression_harness_20251030/` – Deterministic regression bundle (CLI logs, processing summaries, qdrant payloads) validated via `python -m scripts.validate_evidence_integrity --bundle ...`.
- `docs/qa/assessments/1.4-telemetry-smoke-evidence/staging_gpu_20251118/cli_default-on_20251118.txt` – Staging GPU CLI run (RTX 3090, CUDA 12.1) capturing latency, throughput, and GPU utilisation.
- `docs/qa/assessments/1.4-telemetry-smoke-evidence/staging_gpu_20251118/processing_summary_default-on_20251118.json` – Processing summary with GPU metrics (peak VRAM 8.4 GB, rerank p95 0.307 s, sparse p95 0.694 s).
- `docs/qa/assets/gpu-peak-memory-by-stage.txt` – ASCII Grafana export regenerated from staging GPU run.
- `docs/qa/assessments/1.4-telemetry-smoke-evidence/prometheus-validation-staging-defaults-20251118.json` – Staging TLS validation (certificate chain verified, auth enforced).
- `docs/qa/assessments/1.4-telemetry-smoke-evidence/prometheus-staging-curl-20251118.txt` – Curl/OpenSSL transcript confirming TLSv1.3 with RAG Internal Issuing CA.
- `docs/qa/assessments/1.4-telemetry-smoke-evidence/prometheus-validation-*-20251025.json` – Historical mock HTTPS validation reports retained for regression automation.
- Test executions: `python -m pytest -m regression_harness -v` and `python -m pytest tests/test_prometheus_validation.py -q` (results referenced in story debug log).

### Outstanding Evidence

- Alert routing logs or PagerDuty/Slack transcripts demonstrating WARN (≥11.5 GB) and CRIT (≥12 GB) firing paths remain optional (thresholds not triggered in baseline run).

### Validation Activities Completed

- Regression harness refreshed on 2025-10-30 with SPLADE defaults and integrity validator enforcement (no contradictions detected).
- Staging HTTPS validation executed with certificate verification enabled; validator JSON and curl transcripts archived in evidence folder.
- Staging GPU default-on run captured with telemetry spans, processing summary JSON, and Grafana ASCII export; regression harness still available for CPU fallback coverage.
- Telemetry smoke matrix executed locally (CPU fallback) to confirm toggle provenance and sparse fallback behaviour.

## Recommendations

1. Record alert routing evidence (Slack thread + PagerDuty notification) for WARN and CRIT thresholds (optional until alerts triggered).
2. Automate telemetry smoke matrix regeneration in CI with secure access to staging credentials to keep evidence fresh.
3. Schedule quarterly staging re-runs (GPU + TLS validation) to detect drift and re-export dashboards.

---

## Related Documentation

- **Story Reference**: `docs/stories/1.4.story.md`
- **Architecture**: `docs/architecture/observability.md` (updated with baselines)
- **Telemetry Runbook**: `docs/telemetry/rerank_sparse_signals.md` (updated with alerts)
- **QA Gates**: `docs/qa/gates/1.1-default-on-configuration-wiring.yml` (updated to PASS)
- **QA Gates**: `docs/qa/gates/1.2-cli-and-runtime-toggle-integration.yml` (updated to PASS)
- **QA Gates**: `docs/qa/gates/1.3-telemetry-monitoring-baseline-updates.yml` (updated to PASS)
- **Sprint Change Proposal**: `docs/qa/reports/2025-10-25-sprint-change-proposal.md`

---

## Approval Status

**QA Reviewer:** Quinn (Test Architect)  
**Approval Date:** 2025-11-18  
**Sign-Off Status:** ✅ APPROVED – Staging GPU baselines and TLS validation captured; monitor alert routing evidence in production rollouts.

**Observability Lead Acknowledgement:** CPU fallback telemetry validated for development confidence. Update acknowledgement once staging GPU metrics and alert routing artefacts are committed.

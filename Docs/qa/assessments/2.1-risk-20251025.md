# Risk Profile: Story 2.1

Date: 2025-10-25
Reviewer: Quinn (Test Architect)

## Executive Summary

- Total Risks Identified: 5
- Critical Risks: 0
- High Risks: 1
- Aggregate Risk Score: 18/100

VRAM guardrails, telemetry sanitization, and persistence coverage have reduced the prior critical findings. Remaining risks focus on operational monitoring and long-term performance tuning as corpus sizes scale.

## Risk Distribution

### By Category

- Technical: 1 risk (0 critical)
- Performance: 1 risk (0 critical)
- Data: 1 risk (0 critical)
- Business: 1 risk (0 critical)
- Operational/Security: 1 risk (0 critical)

### By Component

- SparseVectorGenerator adaptive heuristics: 2 risks
- Persistence & schema exports: 1 risk
- Retrieval quality safeguards: 1 risk
- Telemetry & monitoring: 1 risk

## Detailed Risk Register

| Risk ID | Category | Description | Probability | Impact | Score | Priority | Affected Components | Mitigation | Testing Focus | Owner | Timeline | Residual Risk |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| PERF-004 | Performance | Adaptive batching heuristics may underperform on corpora much larger than test fixtures, forcing CPU fallback and latency spikes. | Medium (2) | Medium (2) | 4 | High | SparseVectorGenerator, BatchRunner | Run staged load tests with production-scale corpora, tune `_enforce_vram_cap` thresholds, capture telemetry for soft-limit alerts. | GPU stress suites, staging canary runs, telemetry trend analysis. | Dev + Ops | Pre-production pilots | Medium – mitigated by monitoring but sensitive to corpus drift. |
| TECH-005 | Technical | Lease orchestration regressions could resurface under concurrency, despite existing unit coverage. | Low (1) | High (3) | 3 | Medium | GpuLeasePool, SparseVectorGenerator | Maintain watchdog alerts, periodically chaos-test lease exhaustion, keep context managers around hydrate/stage calls. | Concurrency unit tests, chaos/lease fault injection. | Dev | Quarterly | Low – watchdogs limit blast radius. |
| DATA-002 | Data | Future schema extensions might omit sparse fallback metadata, breaking downstream analytics. | Low (1) | High (3) | 3 | Medium | SparseInferenceRun persistence, processing_summary exporters | Keep `test_sparse_generator_end_to_end_persistence` mandatory in CI, add schema diff checks during release. | Contract tests, JSON schema validation, integration snapshots. | Dev | On change | Low – regression test provides early warning. |
| BUS-002 | Business | Sparse fallback relevance may lag dense baselines, reducing retrieval quality during brownfield rollout. | Medium (2) | Medium (2) | 4 | High | Retrieval pipeline, ranking fusion logic | Continue offline A/B relevance benchmarking and phased rollout toggles; monitor nDCG/recall metrics per cohort. | Relevance scorecards, controlled experiments, telemetry dashboards. | Product + Dev | Pilot rollout | Medium – depends on monitoring discipline. |
| OPS-003 | Operational/Security | Telemetry dashboards rely on sanitization tests; accidental removal could reintroduce sensitive content. | Low (1) | Medium (2) | 2 | Low | Telemetry pipeline, QA automation | Keep sanitization regression in mandatory test suite, schedule quarterly telemetry audits. | Unit regression (`test_telemetry_sanitization`), spot audits of telemetry payloads. | DevOps + Security | Ongoing | Low – automated coverage keeps risk contained. |

## Risk-Based Testing Strategy

1. **Load & Performance (High Priority)** – Execute GPU load tests with corpus sizes matching production to refine adaptive batch sizing and confirm telemetry alerts fire before limits are breached.
2. **Relevance Monitoring (High Priority)** – Maintain offline evaluation harnesses comparing sparse+dense fusion quality against baselines before each rollout wave.
3. **Schema Regression (Medium Priority)** – Keep end-to-end persistence tests in CI; add JSON schema validation when introducing new sparse metadata fields.
4. **Operational Drills (Medium Priority)** – Run quarterly chaos tests that simulate lease exhaustion and verify watchdog alerts plus graceful fallback behaviour.
5. **Telemetry Audits (Low Priority)** – Periodically sample telemetry payloads to ensure sanitization remains intact as new attributes are added.

## Monitoring Requirements

- Track VRAM soft-limit alert frequency and CPU fallback ratios on staging/production dashboards.
- Observe retrieval quality metrics (nDCG, recall, abandonment) during rollout and back off if degradation exceeds agreed thresholds.
- Ensure telemetry sanitization regression stays in the required CI lane; alert if disabled or failing.
- Review schema diffs alongside release notes to confirm sparse metadata remains additive.

## Risk Review Triggers

- Introduction of new sparse models or batch sizing strategies.
- Significant increases in corpus size or document complexity.
- Changes to telemetry schema or sanitization utilities.
- Any observed degradation in retrieval quality post-deployment.

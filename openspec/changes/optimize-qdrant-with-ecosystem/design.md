# Design Document: Optimize Qdrant Implementation

> **ğŸ”„ UPDATED FOR CODERANK MIGRATION**  
> This design now includes **Phase 0: CodeRank Migration** as a prerequisite. All collections must be re-embedded from 3584-dim (nomic-embed-code) to 768-dim (CodeRankEmbed) before implementing the unified architecture.

## Architecture Overview

This change refactors Qdrant integration across the codebase to create a unified, performant, and maintainable implementation. The design centers on four core capabilities:

1. **CodeRank Migration** - Migrate from nomic-embed-code (3584-dim) to CodeRankEmbed (768-dim) for 42x faster queries
2. **MCP Server Enhancement** - Expose all collections via MCP tools with CodeRankEmbed integration
3. **Unified Configuration** - Shared abstractions for Qdrant settings (default 768-dim)
4. **Code Consolidation** - Single source of truth for common operations

## System Components

### 1. MCP Server Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MCP Server (qdrant_code_server.py)             â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  agent_kit   â”‚  â”‚inngest_overallâ”‚  â”‚qdrant_ecosystemâ”‚
â”‚  â”‚ (768-dim)    â”‚  â”‚  (768-dim)    â”‚  â”‚  (768-dim)   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                  â”‚                  â”‚         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                          â”‚                               â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                  â”‚ CodeRankEmbed  â”‚                     â”‚
â”‚                  â”‚  (137M params) â”‚                     â”‚
â”‚                  â”‚  768-dim outputâ”‚                     â”‚
â”‚                  â”‚  ~400ms on CPU â”‚                     â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                          â”‚                               â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                  â”‚ QdrantRegistry â”‚                     â”‚
â”‚                  â”‚  (Connection   â”‚                     â”‚
â”‚                  â”‚   Pooling)     â”‚                     â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                          â”‚                               â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                  â”‚ Unified Config â”‚                     â”‚
â”‚                  â”‚  (768-dim      â”‚                     â”‚
â”‚                  â”‚   default)     â”‚                     â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Design Decisions:**

- **CodeRankEmbed Integration**: 137M parameter model (51x smaller than nomic-embed-code) with 768-dim output, ~400ms CPU latency
- **Query Prefix Requirement**: All queries must use: `"Represent this query for searching relevant code: {query}"`
- **Registry Pattern**: Central `QdrantRegistry` manages all collection connections with lazy initialization
- **Tool Naming Convention**: `qdrant_search_{collection}`, `qdrant_store_{collection}`, `qdrant_stats_{collection}`
- **Metadata Standardization**: All collections expose consistent payload schema (subdirectory, source_file, original_id, text)
- **Performance Target**: <1 second total latency (embedding 400ms + search <10ms + reranking <500ms)

### 2. Configuration Hierarchy

```python
# Base configuration (shared across all modules)
QdrantBaseConfig
â”œâ”€â”€ connection: QdrantConnectionConfig
â”‚   â”œâ”€â”€ url: str
â”‚   â”œâ”€â”€ api_key: Optional[str]
â”‚   â”œâ”€â”€ timeout: int
â”‚   â””â”€â”€ prefer_grpc: bool
â”œâ”€â”€ vector: QdrantVectorConfig
â”‚   â”œâ”€â”€ size: int = 768  # UPDATED: Default to CodeRankEmbed dimension
â”‚   â”œâ”€â”€ distance: Distance = Distance.COSINE
â”‚   â””â”€â”€ on_disk: bool = False
â”œâ”€â”€ index: QdrantIndexConfig
â”‚   â”œâ”€â”€ hnsw_m: int = 16
â”‚   â”œâ”€â”€ hnsw_ef_construct: int = 100
â”‚   â””â”€â”€ full_scan_threshold: int = 20000
â”œâ”€â”€ optimization: QdrantOptimizationConfig
â”‚   â”œâ”€â”€ enable_quantization: bool = True
â”‚   â”œâ”€â”€ quantization_type: str = "binary"  # UPDATED: Binary for 768-dim
â”‚   â””â”€â”€ batch_size: int = 256
â””â”€â”€ embedder: QdrantEmbedderConfig  # NEW: CodeRankEmbed config
    â”œâ”€â”€ model_name: str = "nomic-ai/CodeRankEmbed"
    â”œâ”€â”€ trust_remote_code: bool = True
    â”œâ”€â”€ device: str = "cpu"
    â””â”€â”€ query_prefix: str = "Represent this query for searching relevant code: "

# Collection-specific overrides
QdrantCollectionConfig(QdrantBaseConfig)
â””â”€â”€ collection_name: str
â””â”€â”€ indexed_fields: List[str]
```

**Key Design Decisions:**

- **768-dim Default**: All configs now default to CodeRankEmbed's 768-dim output (changed from 3584-dim)
- **Binary Quantization**: Default to binary quantization (40x speedup) instead of scalar for 768-dim vectors
- **Embedder Config**: New `QdrantEmbedderConfig` encapsulates CodeRankEmbed setup and query prefix
- **Composition over Inheritance**: Split concerns into focused sub-configs
- **Environment Variable Support**: All configs support `from_env()` classmethod
- **Validation**: Pydantic models ensure type safety and early error detection
- **Defaults from Best Practices**: HNSW settings (m=16, ef_construct=100) based on `qdrant_ecosystem` learnings

### 3. Upload Pipeline Refactoring

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          QdrantBatchUploader (New Unified Class)        â”‚
â”‚                                                         â”‚
â”‚  Input: JSONL file path + QdrantCollectionConfig       â”‚
â”‚     â”‚                                                   â”‚
â”‚     â–¼                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ 1. Validate File & Connection          â”‚            â”‚
â”‚  â”‚    - Check file exists                 â”‚            â”‚
â”‚  â”‚    - Assert Qdrant health              â”‚            â”‚
â”‚  â”‚    - Detect vector dimension           â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                   â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ 2. Collection Management               â”‚            â”‚
â”‚  â”‚    - Create if not exists              â”‚            â”‚
â”‚  â”‚    - Verify schema match               â”‚            â”‚
â”‚  â”‚    - Optional truncate                 â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                   â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ 3. Streaming Upload with Batching      â”‚            â”‚
â”‚  â”‚    - Stream JSONL line-by-line         â”‚            â”‚
â”‚  â”‚    - Convert IDs (string â†’ UUID)       â”‚            â”‚
â”‚  â”‚    - Batch accumulation (256 default)  â”‚            â”‚
â”‚  â”‚    - Retry logic (3 attempts)          â”‚            â”‚
â”‚  â”‚    - Progress logging                  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                   â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ 4. Validation & Stats                  â”‚            â”‚
â”‚  â”‚    - Count verification                â”‚            â”‚
â”‚  â”‚    - Sample search test                â”‚            â”‚
â”‚  â”‚    - Return UploadStats                â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Design Decisions:**

- **Single Responsibility**: `QdrantBatchUploader` handles only upload workflow, config is injected
- **Streaming Approach**: Memory-efficient JSONL streaming for large files
- **Deterministic IDs**: `string_to_uuid()` ensures consistent MD5-based UUID generation
- **Fail-Fast Validation**: Early dimension/schema checks prevent partial uploads

## Data Flow

### Search Request Flow (MCP)

```
AI Assistant
    â”‚
    â”œâ”€ qdrant_search_ecosystem("HNSW indexing best practices")
    â”‚
    â–¼
MCP Server
    â”‚
    â”œâ”€ CodeRankEmbed.encode(
    â”‚      "Represent this query for searching relevant code: HNSW indexing best practices"
    â”‚  ) â†’ [768-dim vector]  # ~400ms on CPU
    â”‚
    â–¼
QdrantRegistry
    â”‚
    â”œâ”€ get_store("qdrant_ecosystem") â†’ QdrantStore instance
    â”‚
    â–¼
QdrantStore
    â”‚
    â”œâ”€ client.search(
    â”‚      collection="qdrant_ecosystem",
    â”‚      query_vector=[...],  # 768-dim
    â”‚      limit=10,  # Fetch more for reranking
    â”‚      score_threshold=0.7,
    â”‚      with_payload=True
    â”‚  )
    â”‚
    â–¼
Qdrant DB
    â”‚
    â”œâ”€ HNSW index lookup (768-dim, binary quantization)
    â”œâ”€ Score calculation (COSINE)
    â”œâ”€ Filter by score_threshold
    â”œâ”€ Return top 10 candidates  # <10ms
    â”‚
    â–¼
CodeRankLLM Reranker (Optional, Phase 6)
    â”‚
    â”œâ”€ Listwise reranking of top 10 results
    â”œâ”€ Context-aware scoring  # ~500ms on CPU
    â”œâ”€ Return top 5 reranked results
    â”‚
    â–¼
Results [{id, score, payload: {text, subdirectory, ...}}]
    â”‚
    â–¼
MCP Server (format response)
    â”‚
    â–¼
AI Assistant (receives structured results)

Total Latency: ~910ms (embedding 400ms + search 10ms + reranking 500ms)
Target: <1 second âœ…
```

### Upload Request Flow (CLI)

```
User: python scripts/upload_qdrant_embeddings.py --collection my_docs

CLI Script
    â”‚
    â”œâ”€ QdrantCollectionConfig.from_env() + CLI overrides
    â”‚
    â–¼
QdrantBatchUploader
    â”‚
    â”œâ”€ validate_file("embeddings.jsonl")
    â”œâ”€ QdrantClient(url, api_key)
    â”œâ”€ assert_health()
    â”‚
    â–¼
Collection Setup
    â”‚
    â”œâ”€ ensure_collection(config)
    â”‚   â”œâ”€ Check existence
    â”‚   â”œâ”€ Verify dimension match
    â”‚   â”œâ”€ Create indexes (subdirectory, source_file, etc.)
    â”‚
    â–¼
Streaming Upload
    â”‚
    â”œâ”€ for line in jsonl:
    â”‚   â”œâ”€ Parse JSON
    â”‚   â”œâ”€ Validate dimension
    â”‚   â”œâ”€ string_to_uuid(id)
    â”‚   â”œâ”€ Accumulate batch
    â”‚   â”œâ”€ if batch_full: upsert_with_retry()
    â”‚
    â–¼
Validation
    â”‚
    â”œâ”€ count_check(expected vs actual)
    â”œâ”€ sample_search_test()
    â”‚
    â–¼
Stats Report (total, inserted, skipped, qps)
```

## Migration Strategy

### Phase 0: CodeRank Migration (PREREQUISITE - 1 day)

**Critical Path**: ALL collections must be re-embedded before implementing unified architecture.

1. **Verify CodeRankEmbed** âœ… DONE
   - Confirmed 768-dim output via testing
   - Model: `nomic-ai/CodeRankEmbed` (137M params, MIT license)

2. **Update Kaggle Embedding Script**:
   - Modify `scripts/kaggle_embed_docling.py`:
     ```python
     # OLD: model = SentenceTransformer("nomic-ai/nomic-embed-text-v1.5")
     # NEW: model = SentenceTransformer("nomic-ai/CodeRankEmbed", trust_remote_code=True)
     # DIMENSION: 3584 â†’ 768
     ```

3. **Re-embed Collections** (Kaggle GPU T4 x2):
   - qdrant_ecosystem: 1,344 points (~5 min)
   - agent_kit: ~500 points (~2 min)
   - inngest_overall: ~800 points (~3 min)
   - docling: 1,060 points (~4 min)
   - **Total Time**: ~15 minutes on GPU

4. **Validate Search Quality**:
   - Compare search results before/after migration
   - Verify scores remain meaningful (cosine similarity)
   - Test edge cases (code snippets, natural language queries)

**Success Criteria**:
- âœ… All collections use 768-dim vectors
- âœ… Search quality maintained (manual testing)
- âœ… MCP server can query embed in <500ms

### Phase 1: Add Without Breaking (2-3 days)

1. **New Modules** (no changes to existing code):
   - `src/config/qdrant_base.py` - Unified config classes (768-dim default)
   - `src/storage/qdrant_registry.py` - Connection pool manager
   - `src/storage/qdrant_uploader.py` - Extract from `upload_utils.py`
   - `src/config/coderank_embedder.py` - CodeRankEmbed wrapper with query prefix

2. **MCP Server Addition**:
   - Integrate CodeRankEmbed in MCP server (Task 2.1)
   - Add `qdrant_ecosystem` to `COLLECTIONS` list
   - Add new tool definitions (search/store/stats)
   - Register with existing `initialize_qdrant_stores()`

### Phase 2: Deprecate Gradually (1 week)

1. **Mark Old Patterns**:
   - Add deprecation warnings to direct `QdrantStore` instantiation
   - Recommend `QdrantRegistry.get_store()` instead

2. **Update Documentation**:
   - Migration guide in README
   - Code examples using new patterns
   - Document CodeRankEmbed query prefix requirement

### Phase 3: Remove Legacy (After 2-week grace period)

1. **Cleanup**:
   - Remove deprecated code paths
   - Consolidate into unified implementation
   - Archive old embedding scripts (nomic-embed-code)

## Performance Considerations

### Memory Optimization

**Before** (no quantization, 3584-dim):
```
Collection: 10,000 vectors Ã— 3584 dims Ã— 4 bytes/float32
= 143.36 MB per collection
```

**After** (binary quantization, 768-dim):
```
Original vectors: 30.72 MB (on-disk only, 768 Ã— 10,000 Ã— 4 bytes)
Binary quantized: 0.96 MB (in RAM, 768 bits Ã— 10,000 / 8)
Savings: 96.9% memory reduction (143.36 MB â†’ 0.96 MB)
Speedup: 40x search performance with binary quantization
```

### Query Embedding Performance

**Before** (nomic-embed-code, 7B params):
```
Model size: 7B parameters
Embedding time: 30-60 seconds per query on CPU âŒ UNUSABLE
Vector dimension: 3584
```

**After** (CodeRankEmbed, 137M params):
```
Model size: 137M parameters (51x smaller)
Embedding time: ~400ms per query on CPU âœ… USABLE
Vector dimension: 768
Speedup: 75x faster (30s â†’ 0.4s)
```

### End-to-End Search Performance

| Optimization | Latency Impact | Implementation |
|-------------|----------------|----------------|
| CodeRankEmbed (vs nomic-embed-code) | -97% query embedding | 137M vs 7B params |
| 768-dim vectors (vs 3584-dim) | -79% dimensionality | CodeRankEmbed output |
| Binary quantization | 40x search speedup | For 768-dim vectors |
| HNSW indexing | -60% (p95) | `hnsw_m=16, ef_construct=100` |
| Payload indexing | -40% (filtered queries) | Index subdirectory, source_file |
| Connection pooling | -20% (concurrent requests) | Reuse client instances |

**Target SLAs (UPDATED):**
- Query embedding: <500ms (CodeRankEmbed on CPU)
- Unfiltered search: <10ms p95 (binary quantization + HNSW)
- Filtered search: <50ms p95
- Reranking (CodeRankLLM): <500ms for top 10 results
- **Total end-to-end latency: <1 second** âœ…
- Batch upload: >250 qps

## Testing Strategy

### Unit Tests

```python
# test_qdrant_config.py
- test_base_config_validation()
- test_config_from_env()
- test_config_defaults()

# test_qdrant_registry.py
- test_registry_lazy_initialization()
- test_registry_connection_reuse()
- test_registry_collection_isolation()

# test_qdrant_uploader.py
- test_upload_dimension_validation()
- test_upload_id_conversion()
- test_upload_batch_retry()
```

### Integration Tests

```python
# test_mcp_server_integration.py
- test_search_ecosystem_collection()
- test_store_to_ecosystem_collection()
- test_cross_collection_search()
- test_collection_stats()
```

### Performance Tests

```python
# test_qdrant_performance.py
- test_search_latency_p95()
- test_upload_throughput()
- test_memory_usage_with_quantization()
```

## Security Considerations

1. **API Key Handling**: Never log or expose Qdrant API keys
2. **Input Validation**: Sanitize all user inputs (query strings, metadata)
3. **Rate Limiting**: MCP server should enforce query rate limits
4. **Collection Isolation**: No cross-collection data leakage

## Rollback Plan

If issues arise:

1. **Immediate**: Disable new MCP tools via feature flag
2. **Short-term**: Revert to previous commit (Git)
3. **Data Safety**: Collections are append-only, no data loss risk
4. **Migration**: Re-upload from JSONL backups if schema corruption occurs

## Open Questions

1. **Should we support hybrid search (dense + sparse vectors)?**
   - Decision: Defer to future change (complexity vs benefit)

2. **How to handle embedding model version upgrades?**
   - Decision: Store model version in payload metadata (`embedding_model: "CodeRankEmbed-768"`)
   - Migration: Create new collection for new model version OR re-embed in place

3. **Multi-tenancy for collections?**
   - Decision: Not needed initially (single user)
   - Future: Add namespace/tenant field to payload

4. **CodeRankLLM reranking on CPU - is it fast enough?**
   - Decision: Test in Phase 6, fall back to CrossEncoder if too slow
   - Target: <500ms for reranking top 10 results
   - Fallback: `cross-encoder/ms-marco-MiniLM-L-6-v2` (22M params, faster on CPU)

5. **Should we keep old 3584-dim collections as backup?**
   - Decision: Yes, rename to `{collection}_3584_archive` before re-embedding
   - Duration: Keep for 2 weeks, then delete
   - Rollback: Can restore from JSONL backups if needed
